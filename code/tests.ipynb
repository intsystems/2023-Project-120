{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "# Открываем файл с YAML данными\n",
        "with open(\"data.yaml\", \"r\") as file:\n",
        "    # Используем функцию load для загрузки YAML данных\n",
        "    yaml_data = yaml.load(file, Loader=yaml.FullLoader)\n",
        "\n",
        "# Выводим считанный словарь\n",
        "print(yaml_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from importlib import reload\n",
        "import json\n",
        "import logging\n",
        "import time\n",
        "from argparse import ArgumentParser\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import engine.datasets\n",
        "from engine.model import CNN, MyDartsTrainer\n",
        "\n",
        "import engine.utils\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "layers = 1\n",
        "batch_size = 64\n",
        "log_frequency = 40\n",
        "channels = 16\n",
        "unrolled = False\n",
        "visualization = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Getting dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "dataset = \"cifar100\"\n",
        "\n",
        "dataset_train, dataset_valid = datasets.get_dataset(dataset)        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Architecture search for a range of $\\lambda$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "logs = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def warmup_weight(epoch, epochs):\n",
        "    minim, maxim = 0.1, 1\n",
        "    return minim + (epoch / epochs) * (maxim - minim)\n",
        "\n",
        "def warmup_t(epoch, epochs):\n",
        "    minim, maxim = 0.05, 0.5\n",
        "    return maxim - (epoch / epochs) * (maxim - minim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "weight = yes, temoreture = yes lambd = 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pkbab\\Documents\\code\\2023-Project-120\\code\\model.py:306: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  k_left = torch.tensor((lam - left_pivot) / (right_pivot - left_pivot), device=self.device)\n",
            "c:\\Users\\pkbab\\Documents\\code\\2023-Project-120\\code\\model.py:307: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  k_right = torch.tensor(1 - (lam - left_pivot) / (right_pivot - left_pivot), device=self.device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/90] Step [1/391]  acc1 0.015625 (0.015625)  loss 4.603726 (4.603726)\n",
            "Epoch [1/90] Step [41/391]  acc1 0.062500 (0.022104)  loss 4.564459 (4.582175)\n",
            "Epoch [1/90] Step [81/391]  acc1 0.046875 (0.028549)  loss 4.311607 (4.524248)\n",
            "Epoch [1/90] Step [121/391]  acc1 0.062500 (0.032929)  loss 4.281152 (4.467895)\n",
            "Epoch [1/90] Step [161/391]  acc1 0.015625 (0.038432)  loss 4.189116 (4.411940)\n",
            "Epoch [1/90] Step [201/391]  acc1 0.062500 (0.044232)  loss 4.166207 (4.363717)\n",
            "Epoch [1/90] Step [241/391]  acc1 0.015625 (0.047783)  loss 4.209860 (4.327623)\n",
            "Epoch [1/90] Step [281/391]  acc1 0.000000 (0.051991)  loss 4.271982 (4.294724)\n",
            "Epoch [1/90] Step [321/391]  acc1 0.156250 (0.055783)  loss 3.844630 (4.265576)\n",
            "Epoch [1/90] Step [361/391]  acc1 0.062500 (0.059384)  loss 4.099174 (4.238872)\n",
            "Epoch [2/90] Step [1/391]  acc1 0.093750 (0.093750)  loss 3.742763 (3.742763)\n",
            "Epoch [2/90] Step [41/391]  acc1 0.046875 (0.096799)  loss 3.906804 (3.968419)\n",
            "Epoch [2/90] Step [81/391]  acc1 0.078125 (0.096258)  loss 4.027081 (3.974406)\n",
            "Epoch [2/90] Step [121/391]  acc1 0.125000 (0.098657)  loss 3.897372 (3.962824)\n",
            "Epoch [2/90] Step [161/391]  acc1 0.078125 (0.102582)  loss 4.049885 (3.946517)\n",
            "Epoch [2/90] Step [201/391]  acc1 0.078125 (0.103156)  loss 3.858695 (3.934999)\n",
            "Epoch [2/90] Step [241/391]  acc1 0.046875 (0.104448)  loss 3.940498 (3.919956)\n",
            "Epoch [2/90] Step [281/391]  acc1 0.171875 (0.105149)  loss 3.672769 (3.911535)\n",
            "Epoch [2/90] Step [321/391]  acc1 0.093750 (0.105384)  loss 3.915212 (3.904093)\n",
            "Epoch [2/90] Step [361/391]  acc1 0.093750 (0.107038)  loss 3.511010 (3.894654)\n",
            "Epoch [3/90] Step [1/391]  acc1 0.125000 (0.125000)  loss 3.874693 (3.874693)\n",
            "Epoch [3/90] Step [41/391]  acc1 0.109375 (0.116235)  loss 3.765479 (3.785828)\n",
            "Epoch [3/90] Step [81/391]  acc1 0.093750 (0.117863)  loss 3.838086 (3.776562)\n",
            "Epoch [3/90] Step [121/391]  acc1 0.187500 (0.120997)  loss 3.665787 (3.759153)\n",
            "Epoch [3/90] Step [161/391]  acc1 0.093750 (0.123932)  loss 3.910250 (3.758625)\n",
            "Epoch [3/90] Step [201/391]  acc1 0.093750 (0.123601)  loss 3.709578 (3.749769)\n",
            "Epoch [3/90] Step [241/391]  acc1 0.093750 (0.125454)  loss 3.863789 (3.743243)\n",
            "Epoch [3/90] Step [281/391]  acc1 0.203125 (0.126390)  loss 3.553071 (3.737624)\n",
            "Epoch [3/90] Step [321/391]  acc1 0.171875 (0.127677)  loss 3.427789 (3.733396)\n",
            "Epoch [3/90] Step [361/391]  acc1 0.187500 (0.128549)  loss 3.821453 (3.726891)\n",
            "Epoch [4/90] Step [1/391]  acc1 0.109375 (0.109375)  loss 3.792924 (3.792924)\n",
            "Epoch [4/90] Step [41/391]  acc1 0.140625 (0.146723)  loss 3.578055 (3.622723)\n",
            "Epoch [4/90] Step [81/391]  acc1 0.156250 (0.145640)  loss 3.611080 (3.607370)\n",
            "Epoch [4/90] Step [121/391]  acc1 0.187500 (0.148244)  loss 3.626941 (3.597005)\n",
            "Epoch [4/90] Step [161/391]  acc1 0.078125 (0.146933)  loss 3.670167 (3.607989)\n",
            "Epoch [4/90] Step [201/391]  acc1 0.171875 (0.148010)  loss 3.524697 (3.607866)\n",
            "Epoch [4/90] Step [241/391]  acc1 0.171875 (0.146914)  loss 3.306020 (3.607948)\n",
            "Epoch [4/90] Step [281/391]  acc1 0.171875 (0.148243)  loss 3.581142 (3.602575)\n",
            "Epoch [4/90] Step [321/391]  acc1 0.125000 (0.149192)  loss 3.718765 (3.596520)\n",
            "Epoch [4/90] Step [361/391]  acc1 0.250000 (0.150277)  loss 3.333636 (3.588643)\n",
            "Epoch [5/90] Step [1/391]  acc1 0.140625 (0.140625)  loss 3.663286 (3.663286)\n",
            "Epoch [5/90] Step [41/391]  acc1 0.156250 (0.161966)  loss 3.658085 (3.525764)\n",
            "Epoch [5/90] Step [81/391]  acc1 0.187500 (0.169560)  loss 3.447250 (3.498472)\n",
            "Epoch [5/90] Step [121/391]  acc1 0.031250 (0.169034)  loss 3.696965 (3.489074)\n",
            "Epoch [5/90] Step [161/391]  acc1 0.140625 (0.166440)  loss 3.600180 (3.497701)\n",
            "Epoch [5/90] Step [201/391]  acc1 0.218750 (0.170165)  loss 3.570419 (3.480855)\n",
            "Epoch [5/90] Step [241/391]  acc1 0.171875 (0.170124)  loss 3.385201 (3.479494)\n",
            "Epoch [5/90] Step [281/391]  acc1 0.187500 (0.169540)  loss 3.277198 (3.472416)\n",
            "Epoch [5/90] Step [321/391]  acc1 0.125000 (0.169052)  loss 3.575727 (3.471617)\n",
            "Epoch [5/90] Step [361/391]  acc1 0.125000 (0.170533)  loss 3.537194 (3.463286)\n",
            "Epoch [6/90] Step [1/391]  acc1 0.250000 (0.250000)  loss 3.327066 (3.327066)\n",
            "Epoch [6/90] Step [41/391]  acc1 0.203125 (0.182927)  loss 3.369667 (3.383397)\n",
            "Epoch [6/90] Step [81/391]  acc1 0.250000 (0.186150)  loss 3.087753 (3.368503)\n",
            "Epoch [6/90] Step [121/391]  acc1 0.250000 (0.183368)  loss 3.050996 (3.362403)\n",
            "Epoch [6/90] Step [161/391]  acc1 0.250000 (0.186141)  loss 3.096750 (3.364363)\n",
            "Epoch [6/90] Step [201/391]  acc1 0.203125 (0.187811)  loss 3.174578 (3.358618)\n",
            "Epoch [6/90] Step [241/391]  acc1 0.218750 (0.189964)  loss 3.428998 (3.348220)\n",
            "Epoch [6/90] Step [281/391]  acc1 0.171875 (0.188668)  loss 3.293040 (3.350456)\n",
            "Epoch [6/90] Step [321/391]  acc1 0.218750 (0.191053)  loss 3.227549 (3.345249)\n",
            "Epoch [6/90] Step [361/391]  acc1 0.156250 (0.191525)  loss 3.369626 (3.343333)\n",
            "Epoch [7/90] Step [1/391]  acc1 0.265625 (0.265625)  loss 3.187543 (3.187543)\n",
            "Epoch [7/90] Step [41/391]  acc1 0.312500 (0.206936)  loss 2.993992 (3.259969)\n",
            "Epoch [7/90] Step [81/391]  acc1 0.187500 (0.206597)  loss 3.743180 (3.244476)\n",
            "Epoch [7/90] Step [121/391]  acc1 0.093750 (0.207386)  loss 3.328103 (3.234187)\n",
            "Epoch [7/90] Step [161/391]  acc1 0.265625 (0.207783)  loss 3.348356 (3.235626)\n",
            "Epoch [7/90] Step [201/391]  acc1 0.187500 (0.206157)  loss 3.158113 (3.238991)\n",
            "Epoch [7/90] Step [241/391]  acc1 0.265625 (0.208960)  loss 3.458040 (3.230801)\n",
            "Epoch [7/90] Step [281/391]  acc1 0.140625 (0.207907)  loss 3.492071 (3.235526)\n",
            "Epoch [7/90] Step [321/391]  acc1 0.234375 (0.208431)  loss 3.312300 (3.239369)\n",
            "Epoch [7/90] Step [361/391]  acc1 0.171875 (0.208102)  loss 3.596766 (3.239705)\n",
            "Epoch [8/90] Step [1/391]  acc1 0.171875 (0.171875)  loss 3.386802 (3.386802)\n",
            "Epoch [8/90] Step [41/391]  acc1 0.171875 (0.228277)  loss 2.984480 (3.133654)\n",
            "Epoch [8/90] Step [81/391]  acc1 0.250000 (0.225694)  loss 3.199050 (3.163277)\n",
            "Epoch [8/90] Step [121/391]  acc1 0.140625 (0.220300)  loss 3.436696 (3.170300)\n",
            "Epoch [8/90] Step [161/391]  acc1 0.234375 (0.221953)  loss 2.974432 (3.160571)\n",
            "Epoch [8/90] Step [201/391]  acc1 0.265625 (0.222015)  loss 3.044669 (3.153590)\n",
            "Epoch [8/90] Step [241/391]  acc1 0.265625 (0.224261)  loss 2.885599 (3.148217)\n",
            "Epoch [8/90] Step [281/391]  acc1 0.265625 (0.227424)  loss 3.005841 (3.143604)\n",
            "Epoch [8/90] Step [321/391]  acc1 0.187500 (0.227998)  loss 3.281975 (3.138486)\n",
            "Epoch [8/90] Step [361/391]  acc1 0.250000 (0.228229)  loss 3.418318 (3.140120)\n",
            "Epoch [9/90] Step [1/391]  acc1 0.234375 (0.234375)  loss 3.076200 (3.076200)\n",
            "Epoch [9/90] Step [41/391]  acc1 0.187500 (0.243521)  loss 3.147894 (3.034087)\n",
            "Epoch [9/90] Step [81/391]  acc1 0.265625 (0.239390)  loss 2.788571 (3.051114)\n",
            "Epoch [9/90] Step [121/391]  acc1 0.203125 (0.240186)  loss 3.202185 (3.052914)\n",
            "Epoch [9/90] Step [161/391]  acc1 0.171875 (0.239519)  loss 3.049770 (3.040485)\n",
            "Epoch [9/90] Step [201/391]  acc1 0.218750 (0.238184)  loss 3.305007 (3.055810)\n",
            "Epoch [9/90] Step [241/391]  acc1 0.171875 (0.236320)  loss 3.291809 (3.065397)\n",
            "Epoch [9/90] Step [281/391]  acc1 0.187500 (0.237433)  loss 3.385072 (3.066579)\n",
            "Epoch [9/90] Step [321/391]  acc1 0.312500 (0.240070)  loss 2.791800 (3.059041)\n",
            "Epoch [9/90] Step [361/391]  acc1 0.250000 (0.240824)  loss 3.102772 (3.062085)\n",
            "Epoch [10/90] Step [1/391]  acc1 0.281250 (0.281250)  loss 2.972397 (2.972397)\n",
            "Epoch [10/90] Step [41/391]  acc1 0.281250 (0.268674)  loss 2.817997 (2.933220)\n",
            "Epoch [10/90] Step [81/391]  acc1 0.265625 (0.260224)  loss 3.139153 (2.994325)\n",
            "Epoch [10/90] Step [121/391]  acc1 0.328125 (0.254390)  loss 3.024919 (3.012900)\n",
            "Epoch [10/90] Step [161/391]  acc1 0.328125 (0.256599)  loss 2.642349 (3.004021)\n",
            "Epoch [10/90] Step [201/391]  acc1 0.218750 (0.255131)  loss 2.821539 (3.002700)\n",
            "Epoch [10/90] Step [241/391]  acc1 0.296875 (0.254863)  loss 2.792851 (2.998225)\n",
            "Epoch [10/90] Step [281/391]  acc1 0.296875 (0.255672)  loss 3.097044 (2.994263)\n",
            "Epoch [10/90] Step [321/391]  acc1 0.234375 (0.256328)  loss 3.114650 (2.993806)\n",
            "Epoch [10/90] Step [361/391]  acc1 0.281250 (0.255886)  loss 2.801588 (2.989069)\n",
            "Epoch [11/90] Step [1/391]  acc1 0.250000 (0.250000)  loss 2.865281 (2.865281)\n",
            "Epoch [11/90] Step [41/391]  acc1 0.328125 (0.282393)  loss 2.742961 (2.907945)\n",
            "Epoch [11/90] Step [81/391]  acc1 0.250000 (0.270833)  loss 3.253108 (2.937390)\n",
            "Epoch [11/90] Step [121/391]  acc1 0.234375 (0.266400)  loss 2.993422 (2.938063)\n",
            "Epoch [11/90] Step [161/391]  acc1 0.250000 (0.268148)  loss 2.736197 (2.930454)\n",
            "Epoch [11/90] Step [201/391]  acc1 0.265625 (0.266947)  loss 2.999167 (2.933249)\n",
            "Epoch [11/90] Step [241/391]  acc1 0.296875 (0.264977)  loss 2.834057 (2.936188)\n",
            "Epoch [11/90] Step [281/391]  acc1 0.281250 (0.264791)  loss 3.028509 (2.938261)\n",
            "Epoch [11/90] Step [321/391]  acc1 0.203125 (0.264895)  loss 3.058762 (2.935375)\n",
            "Epoch [11/90] Step [361/391]  acc1 0.343750 (0.266015)  loss 2.885562 (2.931800)\n",
            "Epoch [12/90] Step [1/391]  acc1 0.156250 (0.156250)  loss 3.085576 (3.085576)\n",
            "Epoch [12/90] Step [41/391]  acc1 0.281250 (0.268674)  loss 2.721602 (2.878421)\n",
            "Epoch [12/90] Step [81/391]  acc1 0.343750 (0.276427)  loss 2.599432 (2.856784)\n",
            "Epoch [12/90] Step [121/391]  acc1 0.265625 (0.275439)  loss 2.748842 (2.852537)\n",
            "Epoch [12/90] Step [161/391]  acc1 0.343750 (0.279794)  loss 2.861624 (2.858413)\n",
            "Epoch [12/90] Step [201/391]  acc1 0.281250 (0.279773)  loss 2.949579 (2.853650)\n",
            "Epoch [12/90] Step [241/391]  acc1 0.296875 (0.274961)  loss 3.086455 (2.865516)\n",
            "Epoch [12/90] Step [281/391]  acc1 0.375000 (0.275634)  loss 2.517800 (2.871490)\n",
            "Epoch [12/90] Step [321/391]  acc1 0.234375 (0.275263)  loss 3.260549 (2.876156)\n",
            "Epoch [12/90] Step [361/391]  acc1 0.250000 (0.276402)  loss 2.744426 (2.868346)\n",
            "Epoch [13/90] Step [1/391]  acc1 0.281250 (0.281250)  loss 2.795560 (2.795560)\n",
            "Epoch [13/90] Step [41/391]  acc1 0.265625 (0.293826)  loss 2.821629 (2.812022)\n",
            "Epoch [13/90] Step [81/391]  acc1 0.312500 (0.292824)  loss 2.965348 (2.803747)\n",
            "Epoch [13/90] Step [121/391]  acc1 0.312500 (0.288611)  loss 2.476041 (2.804926)\n",
            "Epoch [13/90] Step [161/391]  acc1 0.328125 (0.289596)  loss 2.866659 (2.791829)\n",
            "Epoch [13/90] Step [201/391]  acc1 0.250000 (0.287780)  loss 2.855972 (2.794323)\n",
            "Epoch [13/90] Step [241/391]  acc1 0.312500 (0.287669)  loss 2.999893 (2.807940)\n",
            "Epoch [13/90] Step [281/391]  acc1 0.312500 (0.291537)  loss 2.643875 (2.799577)\n",
            "Epoch [13/90] Step [321/391]  acc1 0.390625 (0.291180)  loss 2.607960 (2.803516)\n",
            "Epoch [13/90] Step [361/391]  acc1 0.250000 (0.290599)  loss 2.902692 (2.806290)\n",
            "Epoch [14/90] Step [1/391]  acc1 0.375000 (0.375000)  loss 2.718074 (2.718074)\n",
            "Epoch [14/90] Step [41/391]  acc1 0.390625 (0.305259)  loss 2.516466 (2.759271)\n",
            "Epoch [14/90] Step [81/391]  acc1 0.234375 (0.299190)  loss 2.716998 (2.767660)\n",
            "Epoch [14/90] Step [121/391]  acc1 0.296875 (0.305527)  loss 2.809344 (2.754199)\n",
            "Epoch [14/90] Step [161/391]  acc1 0.359375 (0.302698)  loss 2.801450 (2.756314)\n",
            "Epoch [14/90] Step [201/391]  acc1 0.328125 (0.304027)  loss 2.990652 (2.753908)\n",
            "Epoch [14/90] Step [241/391]  acc1 0.203125 (0.305109)  loss 3.300299 (2.754806)\n",
            "Epoch [14/90] Step [281/391]  acc1 0.328125 (0.307885)  loss 2.558142 (2.750834)\n",
            "Epoch [14/90] Step [321/391]  acc1 0.375000 (0.305491)  loss 2.661753 (2.756914)\n",
            "Epoch [14/90] Step [361/391]  acc1 0.187500 (0.304060)  loss 3.090339 (2.756801)\n",
            "Epoch [15/90] Step [1/391]  acc1 0.265625 (0.265625)  loss 3.048220 (3.048220)\n",
            "Epoch [15/90] Step [41/391]  acc1 0.328125 (0.314024)  loss 2.807445 (2.713361)\n",
            "Epoch [15/90] Step [81/391]  acc1 0.343750 (0.308642)  loss 2.595603 (2.701798)\n",
            "Epoch [15/90] Step [121/391]  acc1 0.328125 (0.297908)  loss 2.729480 (2.737817)\n",
            "Epoch [15/90] Step [161/391]  acc1 0.343750 (0.304057)  loss 2.777089 (2.723920)\n",
            "Epoch [15/90] Step [201/391]  acc1 0.375000 (0.303016)  loss 2.427106 (2.727070)\n",
            "Epoch [15/90] Step [241/391]  acc1 0.328125 (0.304136)  loss 2.555293 (2.725363)\n",
            "Epoch [15/90] Step [281/391]  acc1 0.296875 (0.304048)  loss 2.548128 (2.721392)\n",
            "Epoch [15/90] Step [321/391]  acc1 0.375000 (0.304858)  loss 2.583910 (2.725030)\n",
            "Epoch [15/90] Step [361/391]  acc1 0.328125 (0.303930)  loss 2.680223 (2.726904)\n",
            "Epoch [16/90] Step [1/391]  acc1 0.343750 (0.343750)  loss 2.540052 (2.540052)\n",
            "Epoch [16/90] Step [41/391]  acc1 0.234375 (0.328887)  loss 2.582981 (2.664928)\n",
            "Epoch [16/90] Step [81/391]  acc1 0.281250 (0.320409)  loss 2.516686 (2.660460)\n",
            "Epoch [16/90] Step [121/391]  acc1 0.281250 (0.319344)  loss 2.707976 (2.659256)\n",
            "Epoch [16/90] Step [161/391]  acc1 0.328125 (0.317450)  loss 2.687745 (2.666537)\n",
            "Epoch [16/90] Step [201/391]  acc1 0.265625 (0.315843)  loss 2.880045 (2.678020)\n",
            "Epoch [16/90] Step [241/391]  acc1 0.265625 (0.313148)  loss 2.818387 (2.674758)\n",
            "Epoch [16/90] Step [281/391]  acc1 0.234375 (0.312611)  loss 2.785308 (2.675019)\n",
            "Epoch [16/90] Step [321/391]  acc1 0.187500 (0.312549)  loss 2.702812 (2.679131)\n",
            "Epoch [16/90] Step [361/391]  acc1 0.343750 (0.312110)  loss 2.465589 (2.676830)\n",
            "Epoch [17/90] Step [1/391]  acc1 0.265625 (0.265625)  loss 2.776646 (2.776646)\n",
            "Epoch [17/90] Step [41/391]  acc1 0.390625 (0.328125)  loss 2.520335 (2.648244)\n",
            "Epoch [17/90] Step [81/391]  acc1 0.296875 (0.321566)  loss 2.518147 (2.658065)\n",
            "Epoch [17/90] Step [121/391]  acc1 0.281250 (0.322960)  loss 2.695093 (2.640575)\n",
            "Epoch [17/90] Step [161/391]  acc1 0.296875 (0.322690)  loss 2.626505 (2.636853)\n",
            "Epoch [17/90] Step [201/391]  acc1 0.406250 (0.323850)  loss 2.337633 (2.629282)\n",
            "Epoch [17/90] Step [241/391]  acc1 0.265625 (0.321512)  loss 2.836998 (2.636369)\n",
            "Epoch [17/90] Step [281/391]  acc1 0.359375 (0.322898)  loss 2.370605 (2.634798)\n",
            "Epoch [17/90] Step [321/391]  acc1 0.312500 (0.321018)  loss 2.596740 (2.642794)\n",
            "Epoch [17/90] Step [361/391]  acc1 0.343750 (0.321113)  loss 2.574469 (2.639715)\n",
            "Epoch [18/90] Step [1/391]  acc1 0.296875 (0.296875)  loss 2.831172 (2.831172)\n",
            "Epoch [18/90] Step [41/391]  acc1 0.312500 (0.346037)  loss 2.442734 (2.545342)\n",
            "Epoch [18/90] Step [81/391]  acc1 0.312500 (0.346258)  loss 2.342510 (2.558161)\n",
            "Epoch [18/90] Step [121/391]  acc1 0.343750 (0.346720)  loss 2.687770 (2.557682)\n",
            "Epoch [18/90] Step [161/391]  acc1 0.343750 (0.344623)  loss 2.654220 (2.568128)\n",
            "Epoch [18/90] Step [201/391]  acc1 0.218750 (0.340407)  loss 2.771240 (2.577420)\n",
            "Epoch [18/90] Step [241/391]  acc1 0.390625 (0.334414)  loss 2.687250 (2.594460)\n",
            "Epoch [18/90] Step [281/391]  acc1 0.281250 (0.334964)  loss 2.684614 (2.592089)\n",
            "Epoch [18/90] Step [321/391]  acc1 0.343750 (0.334258)  loss 2.772574 (2.591073)\n",
            "Epoch [18/90] Step [361/391]  acc1 0.187500 (0.332323)  loss 3.093972 (2.594417)\n",
            "Epoch [19/90] Step [1/391]  acc1 0.437500 (0.437500)  loss 2.187793 (2.187793)\n",
            "Epoch [19/90] Step [41/391]  acc1 0.343750 (0.343369)  loss 2.777936 (2.520539)\n",
            "Epoch [19/90] Step [81/391]  acc1 0.296875 (0.341435)  loss 2.600841 (2.549756)\n",
            "Epoch [19/90] Step [121/391]  acc1 0.296875 (0.341167)  loss 2.885200 (2.550549)\n",
            "Epoch [19/90] Step [161/391]  acc1 0.453125 (0.340547)  loss 2.473973 (2.561807)\n",
            "Epoch [19/90] Step [201/391]  acc1 0.406250 (0.338697)  loss 2.385849 (2.570905)\n",
            "Epoch [19/90] Step [241/391]  acc1 0.406250 (0.339990)  loss 2.434876 (2.571079)\n",
            "Epoch [19/90] Step [281/391]  acc1 0.296875 (0.339969)  loss 2.777912 (2.566369)\n",
            "Epoch [19/90] Step [321/391]  acc1 0.359375 (0.339077)  loss 2.539439 (2.570021)\n",
            "Epoch [19/90] Step [361/391]  acc1 0.312500 (0.338210)  loss 2.699524 (2.573086)\n",
            "Epoch [20/90] Step [1/391]  acc1 0.375000 (0.375000)  loss 2.630648 (2.630648)\n",
            "Epoch [20/90] Step [41/391]  acc1 0.265625 (0.365854)  loss 2.918638 (2.479579)\n",
            "Epoch [20/90] Step [81/391]  acc1 0.390625 (0.353009)  loss 2.573306 (2.520323)\n",
            "Epoch [20/90] Step [121/391]  acc1 0.359375 (0.351756)  loss 2.369381 (2.525357)\n",
            "Epoch [20/90] Step [161/391]  acc1 0.265625 (0.349767)  loss 2.594605 (2.530450)\n",
            "Epoch [20/90] Step [201/391]  acc1 0.406250 (0.351290)  loss 2.409329 (2.528915)\n",
            "Epoch [20/90] Step [241/391]  acc1 0.390625 (0.349909)  loss 2.355904 (2.532911)\n",
            "Epoch [20/90] Step [281/391]  acc1 0.250000 (0.346975)  loss 2.574818 (2.530261)\n",
            "Epoch [20/90] Step [321/391]  acc1 0.312500 (0.344237)  loss 2.797056 (2.539665)\n",
            "Epoch [20/90] Step [361/391]  acc1 0.265625 (0.344529)  loss 2.789950 (2.537310)\n",
            "Epoch [21/90] Step [1/391]  acc1 0.296875 (0.296875)  loss 2.709104 (2.709104)\n",
            "Epoch [21/90] Step [41/391]  acc1 0.265625 (0.353659)  loss 2.571025 (2.545533)\n",
            "Epoch [21/90] Step [81/391]  acc1 0.328125 (0.355710)  loss 2.462934 (2.536587)\n",
            "Epoch [21/90] Step [121/391]  acc1 0.421875 (0.356663)  loss 2.319720 (2.514968)\n",
            "Epoch [21/90] Step [161/391]  acc1 0.312500 (0.357434)  loss 2.696132 (2.505272)\n",
            "Epoch [21/90] Step [201/391]  acc1 0.437500 (0.357198)  loss 2.538208 (2.506245)\n",
            "Epoch [21/90] Step [241/391]  acc1 0.281250 (0.356393)  loss 2.589135 (2.507355)\n",
            "Epoch [21/90] Step [281/391]  acc1 0.359375 (0.356039)  loss 2.487690 (2.508694)\n",
            "Epoch [21/90] Step [321/391]  acc1 0.328125 (0.354069)  loss 2.419054 (2.509497)\n",
            "Epoch [21/90] Step [361/391]  acc1 0.421875 (0.354614)  loss 2.192059 (2.501737)\n",
            "Epoch [22/90] Step [1/391]  acc1 0.500000 (0.500000)  loss 1.996797 (1.996797)\n",
            "Epoch [22/90] Step [41/391]  acc1 0.312500 (0.378049)  loss 2.970126 (2.402709)\n",
            "Epoch [22/90] Step [81/391]  acc1 0.359375 (0.369020)  loss 2.677991 (2.437522)\n",
            "Epoch [22/90] Step [121/391]  acc1 0.437500 (0.369835)  loss 2.275485 (2.441629)\n",
            "Epoch [22/90] Step [161/391]  acc1 0.406250 (0.365877)  loss 2.269709 (2.462783)\n",
            "Epoch [22/90] Step [201/391]  acc1 0.296875 (0.362873)  loss 2.801227 (2.470759)\n",
            "Epoch [22/90] Step [241/391]  acc1 0.296875 (0.363135)  loss 2.437109 (2.469495)\n",
            "Epoch [22/90] Step [281/391]  acc1 0.375000 (0.362544)  loss 2.542563 (2.473453)\n",
            "Epoch [22/90] Step [321/391]  acc1 0.437500 (0.363172)  loss 2.401101 (2.472334)\n",
            "Epoch [22/90] Step [361/391]  acc1 0.296875 (0.361756)  loss 2.888309 (2.476545)\n",
            "Epoch [23/90] Step [1/391]  acc1 0.437500 (0.437500)  loss 2.155926 (2.155926)\n",
            "Epoch [23/90] Step [41/391]  acc1 0.406250 (0.356707)  loss 2.530380 (2.455946)\n",
            "Epoch [23/90] Step [81/391]  acc1 0.296875 (0.354552)  loss 2.592486 (2.466165)\n",
            "Epoch [23/90] Step [121/391]  acc1 0.328125 (0.359246)  loss 2.565215 (2.468600)\n",
            "Epoch [23/90] Step [161/391]  acc1 0.375000 (0.362675)  loss 2.364355 (2.457825)\n",
            "Epoch [23/90] Step [201/391]  acc1 0.406250 (0.364817)  loss 2.393102 (2.455301)\n",
            "Epoch [23/90] Step [241/391]  acc1 0.312500 (0.365469)  loss 2.935750 (2.458931)\n",
            "Epoch [23/90] Step [281/391]  acc1 0.312500 (0.365492)  loss 2.828821 (2.459151)\n",
            "Epoch [23/90] Step [321/391]  acc1 0.437500 (0.365021)  loss 2.365098 (2.462016)\n",
            "Epoch [23/90] Step [361/391]  acc1 0.421875 (0.365305)  loss 2.347350 (2.461284)\n",
            "Epoch [24/90] Step [1/391]  acc1 0.437500 (0.437500)  loss 2.326261 (2.326261)\n",
            "Epoch [24/90] Step [41/391]  acc1 0.375000 (0.373857)  loss 2.237729 (2.395399)\n",
            "Epoch [24/90] Step [81/391]  acc1 0.281250 (0.375579)  loss 2.734689 (2.389466)\n",
            "Epoch [24/90] Step [121/391]  acc1 0.406250 (0.373967)  loss 2.425811 (2.403249)\n",
            "Epoch [24/90] Step [161/391]  acc1 0.328125 (0.369468)  loss 2.309670 (2.410803)\n",
            "Epoch [24/90] Step [201/391]  acc1 0.281250 (0.371735)  loss 2.508091 (2.410954)\n",
            "Epoch [24/90] Step [241/391]  acc1 0.421875 (0.372536)  loss 2.381949 (2.410393)\n",
            "Epoch [24/90] Step [281/391]  acc1 0.343750 (0.370440)  loss 2.542218 (2.420582)\n",
            "Epoch [24/90] Step [321/391]  acc1 0.328125 (0.370814)  loss 2.379205 (2.419119)\n",
            "Epoch [24/90] Step [361/391]  acc1 0.312500 (0.370672)  loss 2.665437 (2.416996)\n",
            "Epoch [25/90] Step [1/391]  acc1 0.281250 (0.281250)  loss 2.522743 (2.522743)\n",
            "Epoch [25/90] Step [41/391]  acc1 0.390625 (0.378811)  loss 2.450778 (2.395583)\n",
            "Epoch [25/90] Step [81/391]  acc1 0.375000 (0.369792)  loss 2.434252 (2.406914)\n",
            "Epoch [25/90] Step [121/391]  acc1 0.265625 (0.375775)  loss 2.677107 (2.387154)\n",
            "Epoch [25/90] Step [161/391]  acc1 0.437500 (0.376747)  loss 2.383376 (2.378491)\n",
            "Epoch [25/90] Step [201/391]  acc1 0.281250 (0.375078)  loss 2.865944 (2.390309)\n",
            "Epoch [25/90] Step [241/391]  acc1 0.406250 (0.373249)  loss 2.093104 (2.394313)\n",
            "Epoch [25/90] Step [281/391]  acc1 0.406250 (0.372275)  loss 2.664665 (2.402788)\n",
            "Epoch [25/90] Step [321/391]  acc1 0.359375 (0.374270)  loss 2.558690 (2.389773)\n",
            "Epoch [25/90] Step [361/391]  acc1 0.296875 (0.375303)  loss 2.736254 (2.390264)\n",
            "Epoch [26/90] Step [1/391]  acc1 0.312500 (0.312500)  loss 2.377116 (2.377116)\n",
            "Epoch [26/90] Step [41/391]  acc1 0.453125 (0.373095)  loss 2.129804 (2.373542)\n",
            "Epoch [26/90] Step [81/391]  acc1 0.328125 (0.374035)  loss 2.436488 (2.386613)\n",
            "Epoch [26/90] Step [121/391]  acc1 0.421875 (0.372288)  loss 2.429145 (2.383119)\n",
            "Epoch [26/90] Step [161/391]  acc1 0.328125 (0.375000)  loss 2.562598 (2.387190)\n",
            "Epoch [26/90] Step [201/391]  acc1 0.343750 (0.376166)  loss 2.542860 (2.380757)\n",
            "Epoch [26/90] Step [241/391]  acc1 0.375000 (0.376297)  loss 2.224630 (2.385605)\n",
            "Epoch [26/90] Step [281/391]  acc1 0.281250 (0.376168)  loss 2.670534 (2.383304)\n",
            "Epoch [26/90] Step [321/391]  acc1 0.296875 (0.375097)  loss 2.456544 (2.388870)\n",
            "Epoch [26/90] Step [361/391]  acc1 0.343750 (0.375087)  loss 2.464255 (2.389869)\n",
            "Epoch [27/90] Step [1/391]  acc1 0.375000 (0.375000)  loss 2.419544 (2.419544)\n",
            "Epoch [27/90] Step [41/391]  acc1 0.343750 (0.391768)  loss 2.485320 (2.307257)\n",
            "Epoch [27/90] Step [81/391]  acc1 0.343750 (0.383681)  loss 2.187008 (2.334516)\n",
            "Epoch [27/90] Step [121/391]  acc1 0.328125 (0.381715)  loss 2.610144 (2.360383)\n",
            "Epoch [27/90] Step [161/391]  acc1 0.296875 (0.382570)  loss 2.561530 (2.351688)\n",
            "Epoch [27/90] Step [201/391]  acc1 0.343750 (0.380752)  loss 2.719878 (2.355191)\n",
            "Epoch [27/90] Step [241/391]  acc1 0.390625 (0.381678)  loss 2.635928 (2.360526)\n",
            "Epoch [27/90] Step [281/391]  acc1 0.390625 (0.381228)  loss 2.473311 (2.365396)\n",
            "Epoch [27/90] Step [321/391]  acc1 0.375000 (0.380890)  loss 2.184816 (2.368397)\n",
            "Epoch [27/90] Step [361/391]  acc1 0.453125 (0.382964)  loss 2.193893 (2.365855)\n",
            "Epoch [28/90] Step [1/391]  acc1 0.281250 (0.281250)  loss 2.676888 (2.676888)\n",
            "Epoch [28/90] Step [41/391]  acc1 0.453125 (0.395579)  loss 2.007209 (2.325471)\n",
            "Epoch [28/90] Step [81/391]  acc1 0.296875 (0.396605)  loss 2.517087 (2.309759)\n",
            "Epoch [28/90] Step [121/391]  acc1 0.281250 (0.385072)  loss 2.479216 (2.335226)\n",
            "Epoch [28/90] Step [161/391]  acc1 0.484375 (0.383443)  loss 2.015560 (2.340693)\n",
            "Epoch [28/90] Step [201/391]  acc1 0.515625 (0.383940)  loss 2.161815 (2.355797)\n",
            "Epoch [28/90] Step [241/391]  acc1 0.312500 (0.384660)  loss 2.511497 (2.348530)\n",
            "Epoch [28/90] Step [281/391]  acc1 0.453125 (0.383452)  loss 2.231209 (2.355852)\n",
            "Epoch [28/90] Step [321/391]  acc1 0.312500 (0.382837)  loss 2.840952 (2.357889)\n",
            "Epoch [28/90] Step [361/391]  acc1 0.250000 (0.382445)  loss 2.669497 (2.361236)\n",
            "Epoch [29/90] Step [1/391]  acc1 0.421875 (0.421875)  loss 2.254030 (2.254030)\n",
            "Epoch [29/90] Step [41/391]  acc1 0.312500 (0.394817)  loss 2.779197 (2.333582)\n",
            "Epoch [29/90] Step [81/391]  acc1 0.250000 (0.392554)  loss 2.506075 (2.318885)\n",
            "Epoch [29/90] Step [121/391]  acc1 0.468750 (0.393853)  loss 2.093318 (2.315069)\n",
            "Epoch [29/90] Step [161/391]  acc1 0.328125 (0.391401)  loss 2.380623 (2.318032)\n",
            "Epoch [29/90] Step [201/391]  acc1 0.375000 (0.392802)  loss 2.408952 (2.321281)\n",
            "Epoch [29/90] Step [241/391]  acc1 0.421875 (0.391468)  loss 2.173582 (2.319738)\n",
            "Epoch [29/90] Step [281/391]  acc1 0.375000 (0.391403)  loss 2.493230 (2.328333)\n",
            "Epoch [29/90] Step [321/391]  acc1 0.390625 (0.391258)  loss 2.550098 (2.333165)\n",
            "Epoch [29/90] Step [361/391]  acc1 0.375000 (0.392746)  loss 2.569492 (2.331453)\n",
            "Epoch [30/90] Step [1/391]  acc1 0.515625 (0.515625)  loss 2.128601 (2.128601)\n",
            "Epoch [30/90] Step [41/391]  acc1 0.343750 (0.407012)  loss 2.286983 (2.291027)\n",
            "Epoch [30/90] Step [81/391]  acc1 0.328125 (0.391397)  loss 2.312778 (2.305006)\n",
            "Epoch [30/90] Step [121/391]  acc1 0.421875 (0.395661)  loss 2.110443 (2.293949)\n",
            "Epoch [30/90] Step [161/391]  acc1 0.359375 (0.395575)  loss 2.495672 (2.298810)\n",
            "Epoch [30/90] Step [201/391]  acc1 0.453125 (0.395134)  loss 2.127047 (2.299778)\n",
            "Epoch [30/90] Step [241/391]  acc1 0.390625 (0.397108)  loss 2.125210 (2.298277)\n",
            "Epoch [30/90] Step [281/391]  acc1 0.343750 (0.396964)  loss 2.562929 (2.298592)\n",
            "Epoch [30/90] Step [321/391]  acc1 0.437500 (0.397634)  loss 2.354092 (2.298639)\n",
            "Epoch [30/90] Step [361/391]  acc1 0.421875 (0.395083)  loss 2.224460 (2.305626)\n",
            "Epoch [31/90] Step [1/391]  acc1 0.406250 (0.406250)  loss 2.096871 (2.096871)\n",
            "Epoch [31/90] Step [41/391]  acc1 0.421875 (0.409680)  loss 2.028223 (2.215904)\n",
            "Epoch [31/90] Step [81/391]  acc1 0.390625 (0.411651)  loss 2.318966 (2.251037)\n",
            "Epoch [31/90] Step [121/391]  acc1 0.453125 (0.415935)  loss 2.322929 (2.241559)\n",
            "Epoch [31/90] Step [161/391]  acc1 0.359375 (0.407318)  loss 2.342147 (2.264322)\n",
            "Epoch [31/90] Step [201/391]  acc1 0.421875 (0.407416)  loss 2.302599 (2.271518)\n",
            "Epoch [31/90] Step [241/391]  acc1 0.578125 (0.405018)  loss 1.811105 (2.281550)\n",
            "Epoch [31/90] Step [281/391]  acc1 0.296875 (0.406862)  loss 2.385055 (2.279725)\n",
            "Epoch [31/90] Step [321/391]  acc1 0.343750 (0.404887)  loss 2.264752 (2.279476)\n",
            "Epoch [31/90] Step [361/391]  acc1 0.453125 (0.402701)  loss 2.121103 (2.286824)\n",
            "Epoch [32/90] Step [1/391]  acc1 0.359375 (0.359375)  loss 2.369980 (2.369980)\n",
            "Epoch [32/90] Step [41/391]  acc1 0.375000 (0.401296)  loss 2.271452 (2.261138)\n",
            "Epoch [32/90] Step [81/391]  acc1 0.531250 (0.402585)  loss 2.013225 (2.265751)\n",
            "Epoch [32/90] Step [121/391]  acc1 0.343750 (0.405604)  loss 2.437804 (2.266570)\n",
            "Epoch [32/90] Step [161/391]  acc1 0.359375 (0.404503)  loss 2.312167 (2.275543)\n",
            "Epoch [32/90] Step [201/391]  acc1 0.515625 (0.402907)  loss 2.114808 (2.280345)\n",
            "Epoch [32/90] Step [241/391]  acc1 0.468750 (0.405407)  loss 2.199195 (2.280905)\n",
            "Epoch [32/90] Step [281/391]  acc1 0.375000 (0.404582)  loss 2.270202 (2.281829)\n",
            "Epoch [32/90] Step [321/391]  acc1 0.437500 (0.404449)  loss 2.257809 (2.281495)\n",
            "Epoch [32/90] Step [361/391]  acc1 0.390625 (0.403913)  loss 2.301904 (2.279229)\n",
            "Epoch [33/90] Step [1/391]  acc1 0.328125 (0.328125)  loss 2.369266 (2.369266)\n",
            "Epoch [33/90] Step [41/391]  acc1 0.515625 (0.432927)  loss 1.965534 (2.189623)\n",
            "Epoch [33/90] Step [81/391]  acc1 0.312500 (0.418981)  loss 2.375612 (2.217824)\n",
            "Epoch [33/90] Step [121/391]  acc1 0.406250 (0.413481)  loss 2.286041 (2.235365)\n",
            "Epoch [33/90] Step [161/391]  acc1 0.500000 (0.413723)  loss 2.155226 (2.231144)\n",
            "Epoch [33/90] Step [201/391]  acc1 0.453125 (0.409282)  loss 2.187516 (2.244019)\n",
            "Epoch [33/90] Step [241/391]  acc1 0.437500 (0.409686)  loss 1.935356 (2.245148)\n",
            "Epoch [33/90] Step [281/391]  acc1 0.250000 (0.409586)  loss 2.540723 (2.252723)\n",
            "Epoch [33/90] Step [321/391]  acc1 0.312500 (0.408343)  loss 2.345917 (2.258298)\n",
            "Epoch [33/90] Step [361/391]  acc1 0.343750 (0.407375)  loss 2.574762 (2.259338)\n",
            "Epoch [34/90] Step [1/391]  acc1 0.468750 (0.468750)  loss 1.970735 (1.970735)\n",
            "Epoch [34/90] Step [41/391]  acc1 0.359375 (0.411204)  loss 2.511374 (2.241166)\n",
            "Epoch [34/90] Step [81/391]  acc1 0.406250 (0.413002)  loss 2.434619 (2.223818)\n",
            "Epoch [34/90] Step [121/391]  acc1 0.515625 (0.418647)  loss 1.932572 (2.212311)\n",
            "Epoch [34/90] Step [161/391]  acc1 0.421875 (0.412752)  loss 2.234102 (2.227562)\n",
            "Epoch [34/90] Step [201/391]  acc1 0.375000 (0.411225)  loss 2.350595 (2.234159)\n",
            "Epoch [34/90] Step [241/391]  acc1 0.359375 (0.410464)  loss 2.400846 (2.234184)\n",
            "Epoch [34/90] Step [281/391]  acc1 0.484375 (0.409864)  loss 2.123317 (2.242112)\n",
            "Epoch [34/90] Step [321/391]  acc1 0.453125 (0.409755)  loss 2.291387 (2.248178)\n",
            "Epoch [34/90] Step [361/391]  acc1 0.437500 (0.410145)  loss 1.996987 (2.248554)\n",
            "Epoch [35/90] Step [1/391]  acc1 0.390625 (0.390625)  loss 2.263402 (2.263402)\n",
            "Epoch [35/90] Step [41/391]  acc1 0.375000 (0.400915)  loss 2.084316 (2.256208)\n",
            "Epoch [35/90] Step [81/391]  acc1 0.375000 (0.405093)  loss 2.568519 (2.258596)\n",
            "Epoch [35/90] Step [121/391]  acc1 0.390625 (0.406637)  loss 2.064217 (2.255535)\n",
            "Epoch [35/90] Step [161/391]  acc1 0.437500 (0.411976)  loss 2.044347 (2.236388)\n",
            "Epoch [35/90] Step [201/391]  acc1 0.437500 (0.410137)  loss 2.099266 (2.244935)\n",
            "Epoch [35/90] Step [241/391]  acc1 0.437500 (0.409492)  loss 2.027748 (2.251798)\n",
            "Epoch [35/90] Step [281/391]  acc1 0.468750 (0.412033)  loss 2.003695 (2.243124)\n",
            "Epoch [35/90] Step [321/391]  acc1 0.515625 (0.412481)  loss 1.949257 (2.246252)\n",
            "Epoch [35/90] Step [361/391]  acc1 0.437500 (0.412786)  loss 2.059070 (2.244657)\n",
            "Epoch [36/90] Step [1/391]  acc1 0.406250 (0.406250)  loss 2.231299 (2.231299)\n",
            "Epoch [36/90] Step [41/391]  acc1 0.328125 (0.426448)  loss 2.427911 (2.224748)\n",
            "Epoch [36/90] Step [81/391]  acc1 0.375000 (0.425154)  loss 2.217589 (2.215972)\n",
            "Epoch [36/90] Step [121/391]  acc1 0.421875 (0.424716)  loss 2.320721 (2.208376)\n",
            "Epoch [36/90] Step [161/391]  acc1 0.265625 (0.421778)  loss 2.645716 (2.205556)\n",
            "Epoch [36/90] Step [201/391]  acc1 0.312500 (0.420009)  loss 2.526318 (2.222639)\n",
            "Epoch [36/90] Step [241/391]  acc1 0.343750 (0.416559)  loss 2.635565 (2.227675)\n",
            "Epoch [36/90] Step [281/391]  acc1 0.359375 (0.417315)  loss 2.772138 (2.227194)\n",
            "Epoch [36/90] Step [321/391]  acc1 0.453125 (0.419198)  loss 2.247039 (2.222228)\n",
            "Epoch [36/90] Step [361/391]  acc1 0.500000 (0.420230)  loss 1.973612 (2.220864)\n",
            "Epoch [37/90] Step [1/391]  acc1 0.406250 (0.406250)  loss 2.100054 (2.100054)\n",
            "Epoch [37/90] Step [41/391]  acc1 0.421875 (0.421494)  loss 2.420927 (2.222619)\n",
            "Epoch [37/90] Step [81/391]  acc1 0.406250 (0.424961)  loss 1.970851 (2.186664)\n",
            "Epoch [37/90] Step [121/391]  acc1 0.453125 (0.419421)  loss 2.089170 (2.208180)\n",
            "Epoch [37/90] Step [161/391]  acc1 0.484375 (0.415179)  loss 1.913608 (2.206251)\n",
            "Epoch [37/90] Step [201/391]  acc1 0.515625 (0.416200)  loss 2.026422 (2.194251)\n",
            "Epoch [37/90] Step [241/391]  acc1 0.406250 (0.416559)  loss 2.322321 (2.200171)\n",
            "Epoch [37/90] Step [281/391]  acc1 0.343750 (0.416148)  loss 2.368501 (2.207011)\n",
            "Epoch [37/90] Step [321/391]  acc1 0.390625 (0.416326)  loss 2.345939 (2.206929)\n",
            "Epoch [37/90] Step [361/391]  acc1 0.515625 (0.416205)  loss 1.841479 (2.207885)\n",
            "Epoch [38/90] Step [1/391]  acc1 0.390625 (0.390625)  loss 2.232596 (2.232596)\n",
            "Epoch [38/90] Step [41/391]  acc1 0.484375 (0.418445)  loss 2.099216 (2.173332)\n",
            "Epoch [38/90] Step [81/391]  acc1 0.468750 (0.422068)  loss 2.275251 (2.172435)\n",
            "Epoch [38/90] Step [121/391]  acc1 0.515625 (0.418905)  loss 1.966952 (2.189830)\n",
            "Epoch [38/90] Step [161/391]  acc1 0.375000 (0.416537)  loss 2.498547 (2.188602)\n",
            "Epoch [38/90] Step [201/391]  acc1 0.421875 (0.413790)  loss 2.189587 (2.200955)\n",
            "Epoch [38/90] Step [241/391]  acc1 0.390625 (0.415262)  loss 2.422442 (2.205478)\n",
            "Epoch [38/90] Step [281/391]  acc1 0.328125 (0.413701)  loss 2.537887 (2.211164)\n",
            "Epoch [38/90] Step [321/391]  acc1 0.375000 (0.412432)  loss 2.510836 (2.217170)\n",
            "Epoch [38/90] Step [361/391]  acc1 0.453125 (0.412872)  loss 2.022668 (2.214195)\n",
            "Epoch [39/90] Step [1/391]  acc1 0.359375 (0.359375)  loss 2.144669 (2.144669)\n",
            "Epoch [39/90] Step [41/391]  acc1 0.437500 (0.426067)  loss 2.282727 (2.166363)\n",
            "Epoch [39/90] Step [81/391]  acc1 0.375000 (0.426119)  loss 2.399456 (2.154933)\n",
            "Epoch [39/90] Step [121/391]  acc1 0.484375 (0.423554)  loss 1.978557 (2.165568)\n",
            "Epoch [39/90] Step [161/391]  acc1 0.343750 (0.420807)  loss 2.545036 (2.174449)\n",
            "Epoch [39/90] Step [201/391]  acc1 0.468750 (0.420631)  loss 2.117791 (2.184680)\n",
            "Epoch [39/90] Step [241/391]  acc1 0.343750 (0.419217)  loss 2.178242 (2.191888)\n",
            "Epoch [39/90] Step [281/391]  acc1 0.437500 (0.418372)  loss 2.025902 (2.200624)\n",
            "Epoch [39/90] Step [321/391]  acc1 0.421875 (0.419831)  loss 2.168990 (2.200286)\n",
            "Epoch [39/90] Step [361/391]  acc1 0.437500 (0.421399)  loss 2.312828 (2.197315)\n",
            "Epoch [40/90] Step [1/391]  acc1 0.437500 (0.437500)  loss 2.127659 (2.127659)\n",
            "Epoch [40/90] Step [41/391]  acc1 0.468750 (0.425305)  loss 2.074529 (2.163927)\n",
            "Epoch [40/90] Step [81/391]  acc1 0.437500 (0.424576)  loss 2.073739 (2.174502)\n",
            "Epoch [40/90] Step [121/391]  acc1 0.359375 (0.424329)  loss 2.274253 (2.179081)\n",
            "Epoch [40/90] Step [161/391]  acc1 0.390625 (0.423719)  loss 2.232810 (2.168607)\n",
            "Epoch [40/90] Step [201/391]  acc1 0.484375 (0.421098)  loss 1.850842 (2.184462)\n",
            "Epoch [40/90] Step [241/391]  acc1 0.328125 (0.421162)  loss 2.527332 (2.183046)\n",
            "Epoch [40/90] Step [281/391]  acc1 0.437500 (0.422542)  loss 2.256615 (2.183072)\n",
            "Epoch [40/90] Step [321/391]  acc1 0.421875 (0.422946)  loss 2.016799 (2.181261)\n",
            "Epoch [40/90] Step [361/391]  acc1 0.484375 (0.423217)  loss 2.224154 (2.183710)\n",
            "Epoch [41/90] Step [1/391]  acc1 0.390625 (0.390625)  loss 2.586464 (2.586464)\n",
            "Epoch [41/90] Step [41/391]  acc1 0.453125 (0.431784)  loss 2.151949 (2.148292)\n",
            "Epoch [41/90] Step [81/391]  acc1 0.421875 (0.432870)  loss 2.055429 (2.154757)\n",
            "Epoch [41/90] Step [121/391]  acc1 0.437500 (0.437629)  loss 2.180469 (2.137836)\n",
            "Epoch [41/90] Step [161/391]  acc1 0.406250 (0.434394)  loss 2.318513 (2.132917)\n",
            "Epoch [41/90] Step [201/391]  acc1 0.421875 (0.432603)  loss 2.144914 (2.138852)\n",
            "Epoch [41/90] Step [241/391]  acc1 0.437500 (0.429785)  loss 2.053212 (2.150258)\n",
            "Epoch [41/90] Step [281/391]  acc1 0.531250 (0.427435)  loss 1.943897 (2.161188)\n",
            "Epoch [41/90] Step [321/391]  acc1 0.546875 (0.425282)  loss 2.066123 (2.167130)\n",
            "Epoch [41/90] Step [361/391]  acc1 0.437500 (0.423087)  loss 2.073702 (2.176846)\n",
            "Epoch [42/90] Step [1/391]  acc1 0.500000 (0.500000)  loss 2.117258 (2.117258)\n",
            "Epoch [42/90] Step [41/391]  acc1 0.390625 (0.432546)  loss 2.308573 (2.153589)\n",
            "Epoch [42/90] Step [81/391]  acc1 0.343750 (0.432870)  loss 2.410688 (2.142096)\n",
            "Epoch [42/90] Step [121/391]  acc1 0.406250 (0.430269)  loss 2.341405 (2.142885)\n",
            "Epoch [42/90] Step [161/391]  acc1 0.500000 (0.428766)  loss 1.863543 (2.149163)\n",
            "Epoch [42/90] Step [201/391]  acc1 0.531250 (0.431592)  loss 1.876296 (2.144653)\n",
            "Epoch [42/90] Step [241/391]  acc1 0.375000 (0.430433)  loss 2.608389 (2.155620)\n",
            "Epoch [42/90] Step [281/391]  acc1 0.421875 (0.431439)  loss 2.266027 (2.155185)\n",
            "Epoch [42/90] Step [321/391]  acc1 0.343750 (0.431854)  loss 2.714900 (2.156585)\n",
            "Epoch [42/90] Step [361/391]  acc1 0.406250 (0.429796)  loss 2.315061 (2.158849)\n",
            "Epoch [43/90] Step [1/391]  acc1 0.468750 (0.468750)  loss 2.065646 (2.065646)\n",
            "Epoch [43/90] Step [41/391]  acc1 0.328125 (0.431021)  loss 2.151521 (2.132984)\n",
            "Epoch [43/90] Step [81/391]  acc1 0.390625 (0.426505)  loss 2.111533 (2.131347)\n",
            "Epoch [43/90] Step [121/391]  acc1 0.437500 (0.429106)  loss 2.089339 (2.125394)\n",
            "Epoch [43/90] Step [161/391]  acc1 0.406250 (0.429542)  loss 2.200245 (2.122910)\n",
            "Epoch [43/90] Step [201/391]  acc1 0.421875 (0.425606)  loss 2.145557 (2.139005)\n",
            "Epoch [43/90] Step [241/391]  acc1 0.468750 (0.422134)  loss 2.174892 (2.154678)\n",
            "Epoch [43/90] Step [281/391]  acc1 0.375000 (0.424488)  loss 2.392683 (2.148944)\n",
            "Epoch [43/90] Step [321/391]  acc1 0.375000 (0.426158)  loss 2.201627 (2.149887)\n",
            "Epoch [43/90] Step [361/391]  acc1 0.328125 (0.426203)  loss 2.232430 (2.147504)\n",
            "Epoch [44/90] Step [1/391]  acc1 0.484375 (0.484375)  loss 1.929551 (1.929551)\n",
            "Epoch [44/90] Step [41/391]  acc1 0.437500 (0.438643)  loss 2.269601 (2.118216)\n",
            "Epoch [44/90] Step [81/391]  acc1 0.468750 (0.444830)  loss 2.132386 (2.102210)\n",
            "Epoch [44/90] Step [121/391]  acc1 0.437500 (0.439566)  loss 2.097581 (2.113959)\n",
            "Epoch [44/90] Step [161/391]  acc1 0.375000 (0.438373)  loss 2.274482 (2.113637)\n",
            "Epoch [44/90] Step [201/391]  acc1 0.312500 (0.439055)  loss 2.476298 (2.118123)\n",
            "Epoch [44/90] Step [241/391]  acc1 0.421875 (0.434971)  loss 2.027445 (2.126868)\n",
            "Epoch [44/90] Step [281/391]  acc1 0.453125 (0.433830)  loss 2.114576 (2.138915)\n",
            "Epoch [44/90] Step [321/391]  acc1 0.375000 (0.432194)  loss 2.549141 (2.148312)\n",
            "Epoch [44/90] Step [361/391]  acc1 0.437500 (0.432566)  loss 2.030668 (2.150974)\n",
            "Epoch [45/90] Step [1/391]  acc1 0.453125 (0.453125)  loss 2.109503 (2.109503)\n",
            "Epoch [45/90] Step [41/391]  acc1 0.296875 (0.439787)  loss 2.362294 (2.083221)\n",
            "Epoch [45/90] Step [81/391]  acc1 0.484375 (0.435185)  loss 2.103825 (2.118092)\n",
            "Epoch [45/90] Step [121/391]  acc1 0.421875 (0.428332)  loss 2.159395 (2.143962)\n",
            "Epoch [45/90] Step [161/391]  acc1 0.375000 (0.429833)  loss 2.365271 (2.141566)\n",
            "Epoch [45/90] Step [201/391]  acc1 0.468750 (0.427394)  loss 2.039551 (2.150950)\n",
            "Epoch [45/90] Step [241/391]  acc1 0.515625 (0.430044)  loss 1.968780 (2.145573)\n",
            "Epoch [45/90] Step [281/391]  acc1 0.390625 (0.431495)  loss 2.126529 (2.142045)\n",
            "Epoch [45/90] Step [321/391]  acc1 0.359375 (0.433849)  loss 2.265769 (2.137530)\n",
            "Epoch [45/90] Step [361/391]  acc1 0.421875 (0.432436)  loss 2.386529 (2.137185)\n",
            "Epoch [46/90] Step [1/391]  acc1 0.453125 (0.453125)  loss 2.064920 (2.064920)\n",
            "Epoch [46/90] Step [41/391]  acc1 0.437500 (0.427591)  loss 2.314116 (2.150095)\n",
            "Epoch [46/90] Step [81/391]  acc1 0.390625 (0.438079)  loss 1.956064 (2.127125)\n",
            "Epoch [46/90] Step [121/391]  acc1 0.390625 (0.436854)  loss 2.502395 (2.136844)\n",
            "Epoch [46/90] Step [161/391]  acc1 0.468750 (0.439150)  loss 1.986086 (2.129045)\n",
            "Epoch [46/90] Step [201/391]  acc1 0.406250 (0.434779)  loss 2.053339 (2.131004)\n",
            "Epoch [46/90] Step [241/391]  acc1 0.312500 (0.434582)  loss 2.329327 (2.131314)\n",
            "Epoch [46/90] Step [281/391]  acc1 0.453125 (0.434942)  loss 2.103083 (2.133139)\n",
            "Epoch [46/90] Step [321/391]  acc1 0.375000 (0.434823)  loss 2.002744 (2.133310)\n",
            "Epoch [46/90] Step [361/391]  acc1 0.406250 (0.435596)  loss 2.346186 (2.131851)\n",
            "Epoch [47/90] Step [1/391]  acc1 0.437500 (0.437500)  loss 2.202463 (2.202463)\n",
            "Epoch [47/90] Step [41/391]  acc1 0.468750 (0.428354)  loss 2.305934 (2.092138)\n",
            "Epoch [47/90] Step [81/391]  acc1 0.343750 (0.431327)  loss 2.357123 (2.130402)\n",
            "Epoch [47/90] Step [121/391]  acc1 0.375000 (0.439308)  loss 2.019250 (2.108792)\n",
            "Epoch [47/90] Step [161/391]  acc1 0.484375 (0.435365)  loss 2.166662 (2.121453)\n",
            "Epoch [47/90] Step [201/391]  acc1 0.484375 (0.434080)  loss 2.112703 (2.115891)\n",
            "Epoch [47/90] Step [241/391]  acc1 0.421875 (0.434842)  loss 2.005283 (2.119373)\n",
            "Epoch [47/90] Step [281/391]  acc1 0.343750 (0.432551)  loss 2.249068 (2.125359)\n",
            "Epoch [47/90] Step [321/391]  acc1 0.515625 (0.433217)  loss 2.049168 (2.125844)\n",
            "Epoch [47/90] Step [361/391]  acc1 0.500000 (0.432003)  loss 1.896954 (2.132380)\n",
            "Epoch [48/90] Step [1/391]  acc1 0.390625 (0.390625)  loss 2.086642 (2.086642)\n",
            "Epoch [48/90] Step [41/391]  acc1 0.515625 (0.451601)  loss 1.995955 (2.081513)\n",
            "Epoch [48/90] Step [81/391]  acc1 0.343750 (0.440586)  loss 2.145820 (2.095723)\n",
            "Epoch [48/90] Step [121/391]  acc1 0.312500 (0.437500)  loss 2.338501 (2.111061)\n",
            "Epoch [48/90] Step [161/391]  acc1 0.453125 (0.436821)  loss 2.059402 (2.106788)\n",
            "Epoch [48/90] Step [201/391]  acc1 0.406250 (0.440454)  loss 2.325850 (2.102230)\n",
            "Epoch [48/90] Step [241/391]  acc1 0.437500 (0.439251)  loss 2.006750 (2.110915)\n",
            "Epoch [48/90] Step [281/391]  acc1 0.484375 (0.439835)  loss 1.970646 (2.112837)\n",
            "Epoch [48/90] Step [321/391]  acc1 0.468750 (0.438620)  loss 2.010142 (2.115137)\n",
            "Epoch [48/90] Step [361/391]  acc1 0.421875 (0.439534)  loss 2.154447 (2.120482)\n",
            "Epoch [49/90] Step [1/391]  acc1 0.437500 (0.437500)  loss 2.300714 (2.300714)\n",
            "Epoch [49/90] Step [41/391]  acc1 0.500000 (0.443216)  loss 1.888045 (2.118851)\n",
            "Epoch [49/90] Step [81/391]  acc1 0.421875 (0.435764)  loss 1.934623 (2.137490)\n",
            "Epoch [49/90] Step [121/391]  acc1 0.500000 (0.433884)  loss 1.904326 (2.132099)\n",
            "Epoch [49/90] Step [161/391]  acc1 0.390625 (0.434977)  loss 2.166962 (2.126065)\n",
            "Epoch [49/90] Step [201/391]  acc1 0.406250 (0.433458)  loss 1.960494 (2.118673)\n",
            "Epoch [49/90] Step [241/391]  acc1 0.421875 (0.431989)  loss 2.097331 (2.122327)\n",
            "Epoch [49/90] Step [281/391]  acc1 0.437500 (0.433719)  loss 1.955135 (2.121612)\n",
            "Epoch [49/90] Step [321/391]  acc1 0.453125 (0.434385)  loss 1.790846 (2.118213)\n",
            "Epoch [49/90] Step [361/391]  acc1 0.437500 (0.433908)  loss 1.980073 (2.124401)\n",
            "Epoch [50/90] Step [1/391]  acc1 0.437500 (0.437500)  loss 2.186692 (2.186692)\n",
            "Epoch [50/90] Step [41/391]  acc1 0.484375 (0.427210)  loss 1.743113 (2.112398)\n",
            "Epoch [50/90] Step [81/391]  acc1 0.328125 (0.445216)  loss 2.412560 (2.092571)\n",
            "Epoch [50/90] Step [121/391]  acc1 0.421875 (0.442278)  loss 1.951774 (2.086816)\n",
            "Epoch [50/90] Step [161/391]  acc1 0.546875 (0.439829)  loss 1.902303 (2.097055)\n",
            "Epoch [50/90] Step [201/391]  acc1 0.390625 (0.438200)  loss 2.224990 (2.101580)\n",
            "Epoch [50/90] Step [241/391]  acc1 0.421875 (0.437370)  loss 2.023327 (2.108141)\n",
            "Epoch [50/90] Step [281/391]  acc1 0.453125 (0.436944)  loss 2.301457 (2.112333)\n",
            "Epoch [50/90] Step [321/391]  acc1 0.390625 (0.436721)  loss 2.270980 (2.113074)\n",
            "Epoch [50/90] Step [361/391]  acc1 0.406250 (0.438063)  loss 2.140643 (2.109892)\n",
            "Epoch [51/90] Step [1/391]  acc1 0.515625 (0.515625)  loss 1.893974 (1.893974)\n",
            "Epoch [51/90] Step [41/391]  acc1 0.375000 (0.436738)  loss 2.386041 (2.065073)\n",
            "Epoch [51/90] Step [81/391]  acc1 0.500000 (0.444252)  loss 1.788607 (2.064722)\n",
            "Epoch [51/90] Step [121/391]  acc1 0.437500 (0.447056)  loss 2.326294 (2.059637)\n",
            "Epoch [51/90] Step [161/391]  acc1 0.484375 (0.448273)  loss 1.849903 (2.070372)\n",
            "Epoch [51/90] Step [201/391]  acc1 0.390625 (0.444729)  loss 2.099550 (2.079816)\n",
            "Epoch [51/90] Step [241/391]  acc1 0.406250 (0.440936)  loss 2.157012 (2.091740)\n",
            "Epoch [51/90] Step [281/391]  acc1 0.453125 (0.440669)  loss 2.092411 (2.094130)\n",
            "Epoch [51/90] Step [321/391]  acc1 0.437500 (0.438668)  loss 2.177352 (2.100429)\n",
            "Epoch [51/90] Step [361/391]  acc1 0.359375 (0.437716)  loss 2.310908 (2.104097)\n",
            "Epoch [52/90] Step [1/391]  acc1 0.343750 (0.343750)  loss 2.253329 (2.253329)\n",
            "Epoch [52/90] Step [41/391]  acc1 0.421875 (0.445122)  loss 2.462194 (2.089547)\n",
            "Epoch [52/90] Step [81/391]  acc1 0.406250 (0.451003)  loss 2.102723 (2.080925)\n",
            "Epoch [52/90] Step [121/391]  acc1 0.468750 (0.439566)  loss 2.178738 (2.114178)\n",
            "Epoch [52/90] Step [161/391]  acc1 0.468750 (0.439150)  loss 1.917031 (2.115910)\n",
            "Epoch [52/90] Step [201/391]  acc1 0.484375 (0.435634)  loss 1.836369 (2.124594)\n",
            "Epoch [52/90] Step [241/391]  acc1 0.468750 (0.439056)  loss 2.020483 (2.119357)\n",
            "Epoch [52/90] Step [281/391]  acc1 0.406250 (0.436555)  loss 2.101637 (2.123162)\n",
            "Epoch [52/90] Step [321/391]  acc1 0.500000 (0.436624)  loss 1.907067 (2.125952)\n",
            "Epoch [52/90] Step [361/391]  acc1 0.421875 (0.438106)  loss 2.357239 (2.119079)\n",
            "Epoch [53/90] Step [1/391]  acc1 0.453125 (0.453125)  loss 2.107191 (2.107191)\n",
            "Epoch [53/90] Step [41/391]  acc1 0.406250 (0.451220)  loss 2.309925 (2.062373)\n",
            "Epoch [53/90] Step [81/391]  acc1 0.468750 (0.447917)  loss 1.893753 (2.046662)\n",
            "Epoch [53/90] Step [121/391]  acc1 0.437500 (0.442278)  loss 2.135607 (2.056716)\n",
            "Epoch [53/90] Step [161/391]  acc1 0.453125 (0.442450)  loss 2.308954 (2.076933)\n",
            "Epoch [53/90] Step [201/391]  acc1 0.546875 (0.440454)  loss 2.064490 (2.087694)\n",
            "Epoch [53/90] Step [241/391]  acc1 0.484375 (0.438213)  loss 1.983053 (2.096411)\n",
            "Epoch [53/90] Step [281/391]  acc1 0.421875 (0.437055)  loss 2.167939 (2.104720)\n",
            "Epoch [53/90] Step [321/391]  acc1 0.328125 (0.436526)  loss 2.215484 (2.110406)\n",
            "Epoch [53/90] Step [361/391]  acc1 0.484375 (0.436158)  loss 2.127853 (2.111291)\n",
            "Epoch [54/90] Step [1/391]  acc1 0.468750 (0.468750)  loss 1.829953 (1.829953)\n",
            "Epoch [54/90] Step [41/391]  acc1 0.546875 (0.471418)  loss 1.683640 (1.970322)\n",
            "Epoch [54/90] Step [81/391]  acc1 0.437500 (0.455247)  loss 2.117594 (2.019690)\n",
            "Epoch [54/90] Step [121/391]  acc1 0.500000 (0.454029)  loss 1.916152 (2.034231)\n",
            "Epoch [54/90] Step [161/391]  acc1 0.406250 (0.449922)  loss 2.157595 (2.056508)\n",
            "Epoch [54/90] Step [201/391]  acc1 0.406250 (0.449316)  loss 1.955350 (2.058367)\n",
            "Epoch [54/90] Step [241/391]  acc1 0.359375 (0.445993)  loss 2.047587 (2.074780)\n",
            "Epoch [54/90] Step [281/391]  acc1 0.468750 (0.446564)  loss 2.245406 (2.076140)\n",
            "Epoch [54/90] Step [321/391]  acc1 0.359375 (0.445580)  loss 2.146947 (2.079226)\n",
            "Epoch [54/90] Step [361/391]  acc1 0.437500 (0.443992)  loss 2.301558 (2.085065)\n",
            "Epoch [55/90] Step [1/391]  acc1 0.437500 (0.437500)  loss 1.866472 (1.866472)\n",
            "Epoch [55/90] Step [41/391]  acc1 0.562500 (0.467226)  loss 1.765565 (2.014007)\n",
            "Epoch [55/90] Step [81/391]  acc1 0.453125 (0.464120)  loss 1.987425 (2.055929)\n",
            "Epoch [55/90] Step [121/391]  acc1 0.515625 (0.454804)  loss 2.055552 (2.065284)\n",
            "Epoch [55/90] Step [161/391]  acc1 0.390625 (0.453707)  loss 2.108568 (2.067512)\n",
            "Epoch [55/90] Step [201/391]  acc1 0.390625 (0.452270)  loss 2.475442 (2.078020)\n",
            "Epoch [55/90] Step [241/391]  acc1 0.390625 (0.450078)  loss 2.331243 (2.086487)\n",
            "Epoch [55/90] Step [281/391]  acc1 0.578125 (0.449399)  loss 1.828841 (2.085729)\n",
            "Epoch [55/90] Step [321/391]  acc1 0.390625 (0.447819)  loss 2.168770 (2.082479)\n",
            "Epoch [55/90] Step [361/391]  acc1 0.562500 (0.447888)  loss 1.892880 (2.080332)\n",
            "Epoch [56/90] Step [1/391]  acc1 0.578125 (0.578125)  loss 2.013334 (2.013334)\n",
            "Epoch [56/90] Step [41/391]  acc1 0.406250 (0.464939)  loss 2.313409 (2.026438)\n",
            "Epoch [56/90] Step [81/391]  acc1 0.468750 (0.453897)  loss 2.072890 (2.033851)\n",
            "Epoch [56/90] Step [121/391]  acc1 0.406250 (0.461906)  loss 2.051112 (2.015737)\n",
            "Epoch [56/90] Step [161/391]  acc1 0.484375 (0.456813)  loss 1.864653 (2.037818)\n",
            "Epoch [56/90] Step [201/391]  acc1 0.468750 (0.448850)  loss 1.874381 (2.057640)\n",
            "Epoch [56/90] Step [241/391]  acc1 0.500000 (0.446058)  loss 2.221676 (2.065069)\n",
            "Epoch [56/90] Step [281/391]  acc1 0.453125 (0.446675)  loss 2.111315 (2.067709)\n",
            "Epoch [56/90] Step [321/391]  acc1 0.390625 (0.445921)  loss 2.205053 (2.068812)\n",
            "Epoch [56/90] Step [361/391]  acc1 0.406250 (0.445551)  loss 1.966536 (2.071728)\n",
            "Epoch [57/90] Step [1/391]  acc1 0.500000 (0.500000)  loss 1.860666 (1.860666)\n",
            "Epoch [57/90] Step [41/391]  acc1 0.546875 (0.477896)  loss 1.710297 (1.984707)\n",
            "Epoch [57/90] Step [81/391]  acc1 0.578125 (0.473187)  loss 1.693894 (2.008096)\n",
            "Epoch [57/90] Step [121/391]  acc1 0.359375 (0.468104)  loss 2.298153 (2.019922)\n",
            "Epoch [57/90] Step [161/391]  acc1 0.515625 (0.466130)  loss 1.975012 (2.033469)\n",
            "Epoch [57/90] Step [201/391]  acc1 0.609375 (0.463386)  loss 1.767281 (2.040210)\n",
            "Epoch [57/90] Step [241/391]  acc1 0.453125 (0.461942)  loss 2.300198 (2.040415)\n",
            "Epoch [57/90] Step [281/391]  acc1 0.484375 (0.460020)  loss 1.843476 (2.043675)\n",
            "Epoch [57/90] Step [321/391]  acc1 0.390625 (0.456581)  loss 2.122429 (2.052818)\n",
            "Epoch [57/90] Step [361/391]  acc1 0.390625 (0.455332)  loss 1.906019 (2.055623)\n",
            "Epoch [58/90] Step [1/391]  acc1 0.421875 (0.421875)  loss 1.861472 (1.861472)\n",
            "Epoch [58/90] Step [41/391]  acc1 0.500000 (0.455793)  loss 2.041996 (2.011080)\n",
            "Epoch [58/90] Step [81/391]  acc1 0.484375 (0.456983)  loss 1.891136 (2.015657)\n",
            "Epoch [58/90] Step [121/391]  acc1 0.437500 (0.453900)  loss 1.925088 (2.043647)\n",
            "Epoch [58/90] Step [161/391]  acc1 0.375000 (0.455066)  loss 2.176174 (2.038187)\n",
            "Epoch [58/90] Step [201/391]  acc1 0.406250 (0.451648)  loss 2.133307 (2.051487)\n",
            "Epoch [58/90] Step [241/391]  acc1 0.421875 (0.450207)  loss 2.053420 (2.055746)\n",
            "Epoch [58/90] Step [281/391]  acc1 0.453125 (0.450289)  loss 1.720127 (2.055031)\n",
            "Epoch [58/90] Step [321/391]  acc1 0.500000 (0.450496)  loss 1.935287 (2.052944)\n",
            "Epoch [58/90] Step [361/391]  acc1 0.515625 (0.449749)  loss 2.239148 (2.058341)\n",
            "Epoch [59/90] Step [1/391]  acc1 0.421875 (0.421875)  loss 2.191686 (2.191686)\n",
            "Epoch [59/90] Step [41/391]  acc1 0.562500 (0.470655)  loss 1.513210 (1.976686)\n",
            "Epoch [59/90] Step [81/391]  acc1 0.500000 (0.455440)  loss 1.826839 (2.032910)\n",
            "Epoch [59/90] Step [121/391]  acc1 0.328125 (0.454287)  loss 2.179428 (2.028209)\n",
            "Epoch [59/90] Step [161/391]  acc1 0.437500 (0.456716)  loss 1.807280 (2.022839)\n",
            "Epoch [59/90] Step [201/391]  acc1 0.328125 (0.456390)  loss 2.141987 (2.036255)\n",
            "Epoch [59/90] Step [241/391]  acc1 0.390625 (0.455329)  loss 2.095328 (2.037638)\n",
            "Epoch [59/90] Step [281/391]  acc1 0.453125 (0.455349)  loss 1.946033 (2.040500)\n",
            "Epoch [59/90] Step [321/391]  acc1 0.265625 (0.454975)  loss 2.389670 (2.039539)\n",
            "Epoch [59/90] Step [361/391]  acc1 0.484375 (0.451350)  loss 2.070426 (2.051986)\n",
            "Epoch [60/90] Step [1/391]  acc1 0.500000 (0.500000)  loss 1.772502 (1.772502)\n",
            "Epoch [60/90] Step [41/391]  acc1 0.421875 (0.475991)  loss 2.045436 (1.990230)\n",
            "Epoch [60/90] Step [81/391]  acc1 0.390625 (0.456790)  loss 2.065760 (2.043740)\n",
            "Epoch [60/90] Step [121/391]  acc1 0.281250 (0.452479)  loss 2.277279 (2.051858)\n",
            "Epoch [60/90] Step [161/391]  acc1 0.453125 (0.453804)  loss 2.002798 (2.050507)\n",
            "Epoch [60/90] Step [201/391]  acc1 0.421875 (0.453047)  loss 1.936906 (2.050367)\n",
            "Epoch [60/90] Step [241/391]  acc1 0.453125 (0.455459)  loss 2.030894 (2.044870)\n",
            "Epoch [60/90] Step [281/391]  acc1 0.546875 (0.454237)  loss 1.915241 (2.052902)\n",
            "Epoch [60/90] Step [321/391]  acc1 0.359375 (0.451811)  loss 2.305357 (2.056757)\n",
            "Epoch [60/90] Step [361/391]  acc1 0.468750 (0.451437)  loss 1.854903 (2.057847)\n",
            "Epoch [61/90] Step [1/391]  acc1 0.484375 (0.484375)  loss 1.902002 (1.902002)\n",
            "Epoch [61/90] Step [41/391]  acc1 0.484375 (0.451982)  loss 2.006623 (2.046924)\n",
            "Epoch [61/90] Step [81/391]  acc1 0.406250 (0.451775)  loss 2.209812 (2.033802)\n",
            "Epoch [61/90] Step [121/391]  acc1 0.390625 (0.455320)  loss 2.098176 (2.035182)\n",
            "Epoch [61/90] Step [161/391]  acc1 0.359375 (0.453222)  loss 2.194370 (2.042778)\n",
            "Epoch [61/90] Step [201/391]  acc1 0.531250 (0.450482)  loss 1.719932 (2.043203)\n",
            "Epoch [61/90] Step [241/391]  acc1 0.437500 (0.452347)  loss 2.207092 (2.046614)\n",
            "Epoch [61/90] Step [281/391]  acc1 0.546875 (0.453347)  loss 1.783548 (2.041770)\n",
            "Epoch [61/90] Step [321/391]  acc1 0.421875 (0.453758)  loss 2.140864 (2.040821)\n",
            "Epoch [61/90] Step [361/391]  acc1 0.484375 (0.452562)  loss 1.952110 (2.041872)\n",
            "Epoch [62/90] Step [1/391]  acc1 0.468750 (0.468750)  loss 1.970940 (1.970940)\n",
            "Epoch [62/90] Step [41/391]  acc1 0.453125 (0.475229)  loss 2.031336 (1.998151)\n",
            "Epoch [62/90] Step [81/391]  acc1 0.546875 (0.459298)  loss 1.701196 (2.022234)\n",
            "Epoch [62/90] Step [121/391]  acc1 0.453125 (0.453642)  loss 2.109324 (2.035355)\n",
            "Epoch [62/90] Step [161/391]  acc1 0.453125 (0.453513)  loss 2.170502 (2.029895)\n",
            "Epoch [62/90] Step [201/391]  acc1 0.500000 (0.453514)  loss 1.911282 (2.033167)\n",
            "Epoch [62/90] Step [241/391]  acc1 0.546875 (0.453579)  loss 1.891059 (2.032667)\n",
            "Epoch [62/90] Step [281/391]  acc1 0.406250 (0.456016)  loss 1.978946 (2.025006)\n",
            "Epoch [62/90] Step [321/391]  acc1 0.531250 (0.456192)  loss 1.898029 (2.023649)\n",
            "Epoch [62/90] Step [361/391]  acc1 0.515625 (0.454077)  loss 1.928913 (2.033668)\n",
            "Epoch [63/90] Step [1/391]  acc1 0.562500 (0.562500)  loss 1.769612 (1.769612)\n",
            "Epoch [63/90] Step [41/391]  acc1 0.484375 (0.474848)  loss 1.769660 (1.964314)\n",
            "Epoch [63/90] Step [81/391]  acc1 0.265625 (0.463156)  loss 2.231601 (1.978335)\n",
            "Epoch [63/90] Step [121/391]  acc1 0.453125 (0.462939)  loss 2.084644 (1.991624)\n",
            "Epoch [63/90] Step [161/391]  acc1 0.484375 (0.460210)  loss 2.166294 (2.014167)\n",
            "Epoch [63/90] Step [201/391]  acc1 0.421875 (0.455768)  loss 2.364849 (2.024785)\n",
            "Epoch [63/90] Step [241/391]  acc1 0.375000 (0.454033)  loss 2.345679 (2.032291)\n",
            "Epoch [63/90] Step [281/391]  acc1 0.453125 (0.454015)  loss 1.955714 (2.032553)\n",
            "Epoch [63/90] Step [321/391]  acc1 0.437500 (0.454829)  loss 2.052889 (2.030977)\n",
            "Epoch [63/90] Step [361/391]  acc1 0.375000 (0.455376)  loss 2.413179 (2.030644)\n",
            "Epoch [64/90] Step [1/391]  acc1 0.500000 (0.500000)  loss 2.154375 (2.154375)\n",
            "Epoch [64/90] Step [41/391]  acc1 0.546875 (0.483613)  loss 1.843990 (1.963516)\n",
            "Epoch [64/90] Step [81/391]  acc1 0.421875 (0.478781)  loss 2.049678 (1.946059)\n",
            "Epoch [64/90] Step [121/391]  acc1 0.437500 (0.468879)  loss 2.383827 (1.983240)\n",
            "Epoch [64/90] Step [161/391]  acc1 0.515625 (0.463703)  loss 2.008968 (2.000285)\n",
            "Epoch [64/90] Step [201/391]  acc1 0.421875 (0.463542)  loss 1.914830 (1.999883)\n",
            "Epoch [64/90] Step [241/391]  acc1 0.421875 (0.461100)  loss 2.409095 (2.016556)\n",
            "Epoch [64/90] Step [281/391]  acc1 0.375000 (0.459520)  loss 2.185711 (2.025855)\n",
            "Epoch [64/90] Step [321/391]  acc1 0.406250 (0.458528)  loss 2.158677 (2.027642)\n",
            "Epoch [64/90] Step [361/391]  acc1 0.406250 (0.458016)  loss 2.050517 (2.030242)\n",
            "Epoch [65/90] Step [1/391]  acc1 0.484375 (0.484375)  loss 1.975624 (1.975624)\n",
            "Epoch [65/90] Step [41/391]  acc1 0.468750 (0.474848)  loss 2.040609 (1.985252)\n",
            "Epoch [65/90] Step [81/391]  acc1 0.468750 (0.474537)  loss 2.241619 (1.991369)\n",
            "Epoch [65/90] Step [121/391]  acc1 0.437500 (0.468621)  loss 1.777840 (1.995144)\n",
            "Epoch [65/90] Step [161/391]  acc1 0.484375 (0.465159)  loss 1.868077 (2.002586)\n",
            "Epoch [65/90] Step [201/391]  acc1 0.453125 (0.460044)  loss 2.158566 (2.014515)\n",
            "Epoch [65/90] Step [241/391]  acc1 0.406250 (0.457210)  loss 2.108940 (2.017107)\n",
            "Epoch [65/90] Step [281/391]  acc1 0.421875 (0.457629)  loss 2.362732 (2.018941)\n",
            "Epoch [65/90] Step [321/391]  acc1 0.531250 (0.457408)  loss 2.010718 (2.024760)\n",
            "Epoch [65/90] Step [361/391]  acc1 0.390625 (0.458362)  loss 2.014163 (2.026279)\n",
            "Epoch [66/90] Step [1/391]  acc1 0.515625 (0.515625)  loss 1.774992 (1.774992)\n",
            "Epoch [66/90] Step [41/391]  acc1 0.500000 (0.472180)  loss 1.685595 (1.980533)\n",
            "Epoch [66/90] Step [81/391]  acc1 0.390625 (0.471644)  loss 2.013613 (1.971432)\n",
            "Epoch [66/90] Step [121/391]  acc1 0.453125 (0.467071)  loss 2.235405 (1.994835)\n",
            "Epoch [66/90] Step [161/391]  acc1 0.500000 (0.467197)  loss 1.841350 (2.004414)\n",
            "Epoch [66/90] Step [201/391]  acc1 0.484375 (0.466340)  loss 1.910253 (2.004527)\n",
            "Epoch [66/90] Step [241/391]  acc1 0.515625 (0.465314)  loss 1.822985 (2.010353)\n",
            "Epoch [66/90] Step [281/391]  acc1 0.437500 (0.463301)  loss 2.000460 (2.014212)\n",
            "Epoch [66/90] Step [321/391]  acc1 0.546875 (0.461449)  loss 1.563907 (2.021224)\n",
            "Epoch [66/90] Step [361/391]  acc1 0.515625 (0.463210)  loss 2.076616 (2.019585)\n",
            "Epoch [67/90] Step [1/391]  acc1 0.453125 (0.453125)  loss 2.175442 (2.175442)\n",
            "Epoch [67/90] Step [41/391]  acc1 0.546875 (0.469512)  loss 1.886460 (2.021783)\n",
            "Epoch [67/90] Step [81/391]  acc1 0.484375 (0.471258)  loss 1.900767 (2.021722)\n",
            "Epoch [67/90] Step [121/391]  acc1 0.468750 (0.473399)  loss 1.869215 (2.008191)\n",
            "Epoch [67/90] Step [161/391]  acc1 0.531250 (0.473214)  loss 2.139928 (2.002282)\n",
            "Epoch [67/90] Step [201/391]  acc1 0.406250 (0.470305)  loss 2.105979 (2.002176)\n",
            "Epoch [67/90] Step [241/391]  acc1 0.593750 (0.470436)  loss 1.645486 (1.996262)\n",
            "Epoch [67/90] Step [281/391]  acc1 0.375000 (0.467916)  loss 2.314756 (1.999358)\n",
            "Epoch [67/90] Step [321/391]  acc1 0.437500 (0.467630)  loss 2.052470 (2.001586)\n",
            "Epoch [67/90] Step [361/391]  acc1 0.484375 (0.466716)  loss 1.943425 (2.007424)\n",
            "Epoch [68/90] Step [1/391]  acc1 0.453125 (0.453125)  loss 1.954717 (1.954717)\n",
            "Epoch [68/90] Step [41/391]  acc1 0.468750 (0.466082)  loss 1.957643 (1.990554)\n",
            "Epoch [68/90] Step [81/391]  acc1 0.453125 (0.460069)  loss 1.983230 (2.011620)\n",
            "Epoch [68/90] Step [121/391]  acc1 0.390625 (0.457386)  loss 2.212834 (2.011774)\n",
            "Epoch [68/90] Step [161/391]  acc1 0.484375 (0.458754)  loss 2.091606 (2.007998)\n",
            "Epoch [68/90] Step [201/391]  acc1 0.593750 (0.459188)  loss 1.583851 (2.015136)\n",
            "Epoch [68/90] Step [241/391]  acc1 0.515625 (0.459090)  loss 2.123177 (2.016348)\n",
            "Epoch [68/90] Step [281/391]  acc1 0.390625 (0.461744)  loss 2.157088 (2.012105)\n",
            "Epoch [68/90] Step [321/391]  acc1 0.421875 (0.459940)  loss 2.161475 (2.020798)\n",
            "Epoch [68/90] Step [361/391]  acc1 0.500000 (0.458925)  loss 1.805147 (2.017524)\n",
            "Epoch [69/90] Step [1/391]  acc1 0.421875 (0.421875)  loss 2.031834 (2.031834)\n",
            "Epoch [69/90] Step [41/391]  acc1 0.484375 (0.490091)  loss 1.923757 (1.938193)\n",
            "Epoch [69/90] Step [81/391]  acc1 0.437500 (0.487461)  loss 2.087970 (1.938574)\n",
            "Epoch [69/90] Step [121/391]  acc1 0.375000 (0.471074)  loss 2.189522 (1.968008)\n",
            "Epoch [69/90] Step [161/391]  acc1 0.437500 (0.467877)  loss 2.040421 (1.978072)\n",
            "Epoch [69/90] Step [201/391]  acc1 0.437500 (0.465174)  loss 2.036153 (1.994703)\n",
            "Epoch [69/90] Step [241/391]  acc1 0.468750 (0.464730)  loss 1.995958 (1.996396)\n",
            "Epoch [69/90] Step [281/391]  acc1 0.406250 (0.465525)  loss 2.120001 (1.995202)\n",
            "Epoch [69/90] Step [321/391]  acc1 0.406250 (0.462909)  loss 2.095046 (2.004361)\n",
            "Epoch [69/90] Step [361/391]  acc1 0.453125 (0.460959)  loss 2.320367 (2.015408)\n",
            "Epoch [70/90] Step [1/391]  acc1 0.500000 (0.500000)  loss 1.617376 (1.617376)\n",
            "Epoch [70/90] Step [41/391]  acc1 0.390625 (0.458460)  loss 2.294089 (1.999586)\n",
            "Epoch [70/90] Step [81/391]  acc1 0.562500 (0.457562)  loss 1.823785 (2.009069)\n",
            "Epoch [70/90] Step [121/391]  acc1 0.468750 (0.458161)  loss 2.142805 (2.012550)\n",
            "Epoch [70/90] Step [161/391]  acc1 0.515625 (0.456328)  loss 1.831359 (2.017087)\n",
            "Epoch [70/90] Step [201/391]  acc1 0.375000 (0.457556)  loss 2.288752 (2.017618)\n",
            "Epoch [70/90] Step [241/391]  acc1 0.453125 (0.457210)  loss 2.160455 (2.017156)\n",
            "Epoch [70/90] Step [281/391]  acc1 0.453125 (0.457963)  loss 1.974122 (2.016518)\n",
            "Epoch [70/90] Step [321/391]  acc1 0.390625 (0.457847)  loss 2.300633 (2.011970)\n",
            "Epoch [70/90] Step [361/391]  acc1 0.515625 (0.456414)  loss 1.693034 (2.012306)\n",
            "Epoch [71/90] Step [1/391]  acc1 0.437500 (0.437500)  loss 1.973711 (1.973711)\n",
            "Epoch [71/90] Step [41/391]  acc1 0.453125 (0.478277)  loss 2.316571 (1.976195)\n",
            "Epoch [71/90] Step [81/391]  acc1 0.562500 (0.472222)  loss 1.792427 (1.972164)\n",
            "Epoch [71/90] Step [121/391]  acc1 0.312500 (0.468492)  loss 2.495168 (1.994405)\n",
            "Epoch [71/90] Step [161/391]  acc1 0.421875 (0.467488)  loss 2.302671 (1.996356)\n",
            "Epoch [71/90] Step [201/391]  acc1 0.515625 (0.471082)  loss 1.925241 (1.988039)\n",
            "Epoch [71/90] Step [241/391]  acc1 0.390625 (0.469852)  loss 2.150370 (1.988659)\n",
            "Epoch [71/90] Step [281/391]  acc1 0.468750 (0.468972)  loss 1.709287 (1.994597)\n",
            "Epoch [71/90] Step [321/391]  acc1 0.406250 (0.467241)  loss 2.074963 (1.994733)\n",
            "Epoch [71/90] Step [361/391]  acc1 0.453125 (0.465374)  loss 1.871196 (1.998441)\n",
            "Epoch [72/90] Step [1/391]  acc1 0.531250 (0.531250)  loss 1.777518 (1.777518)\n",
            "Epoch [72/90] Step [41/391]  acc1 0.500000 (0.476753)  loss 1.923276 (1.946817)\n",
            "Epoch [72/90] Step [81/391]  acc1 0.468750 (0.477623)  loss 1.841414 (1.947669)\n",
            "Epoch [72/90] Step [121/391]  acc1 0.390625 (0.476756)  loss 2.441513 (1.956566)\n",
            "Epoch [72/90] Step [161/391]  acc1 0.484375 (0.470109)  loss 1.941014 (1.974749)\n",
            "Epoch [72/90] Step [201/391]  acc1 0.359375 (0.468206)  loss 2.463404 (1.982223)\n",
            "Epoch [72/90] Step [241/391]  acc1 0.468750 (0.466221)  loss 2.035119 (1.992832)\n",
            "Epoch [72/90] Step [281/391]  acc1 0.515625 (0.462689)  loss 1.733701 (2.003592)\n",
            "Epoch [72/90] Step [321/391]  acc1 0.484375 (0.460864)  loss 1.952435 (2.009695)\n",
            "Epoch [72/90] Step [361/391]  acc1 0.453125 (0.460440)  loss 2.179411 (2.010581)\n",
            "Epoch [73/90] Step [1/391]  acc1 0.546875 (0.546875)  loss 1.736441 (1.736441)\n",
            "Epoch [73/90] Step [41/391]  acc1 0.453125 (0.480183)  loss 2.117915 (1.946092)\n",
            "Epoch [73/90] Step [81/391]  acc1 0.531250 (0.473187)  loss 1.870221 (1.956753)\n",
            "Epoch [73/90] Step [121/391]  acc1 0.453125 (0.473011)  loss 1.695726 (1.953281)\n",
            "Epoch [73/90] Step [161/391]  acc1 0.468750 (0.473894)  loss 1.945616 (1.952856)\n",
            "Epoch [73/90] Step [201/391]  acc1 0.421875 (0.471937)  loss 1.956242 (1.965025)\n",
            "Epoch [73/90] Step [241/391]  acc1 0.515625 (0.470825)  loss 1.830953 (1.972121)\n",
            "Epoch [73/90] Step [281/391]  acc1 0.484375 (0.468027)  loss 1.803978 (1.980457)\n",
            "Epoch [73/90] Step [321/391]  acc1 0.484375 (0.466024)  loss 1.880614 (1.984740)\n",
            "Epoch [73/90] Step [361/391]  acc1 0.484375 (0.465331)  loss 1.598126 (1.989173)\n",
            "Epoch [74/90] Step [1/391]  acc1 0.468750 (0.468750)  loss 2.124108 (2.124108)\n",
            "Epoch [74/90] Step [41/391]  acc1 0.359375 (0.468369)  loss 2.119041 (1.978815)\n",
            "Epoch [74/90] Step [81/391]  acc1 0.453125 (0.456790)  loss 2.299448 (2.017374)\n",
            "Epoch [74/90] Step [121/391]  acc1 0.484375 (0.456612)  loss 1.742300 (2.015199)\n",
            "Epoch [74/90] Step [161/391]  acc1 0.421875 (0.456134)  loss 2.047455 (2.002155)\n",
            "Epoch [74/90] Step [201/391]  acc1 0.390625 (0.456001)  loss 2.076381 (2.001020)\n",
            "Epoch [74/90] Step [241/391]  acc1 0.484375 (0.456626)  loss 2.005553 (1.999189)\n",
            "Epoch [74/90] Step [281/391]  acc1 0.453125 (0.458018)  loss 1.857069 (2.002340)\n",
            "Epoch [74/90] Step [321/391]  acc1 0.484375 (0.460086)  loss 2.057893 (1.997862)\n",
            "Epoch [74/90] Step [361/391]  acc1 0.406250 (0.459704)  loss 2.321280 (2.006156)\n",
            "Epoch [75/90] Step [1/391]  acc1 0.500000 (0.500000)  loss 2.016471 (2.016471)\n",
            "Epoch [75/90] Step [41/391]  acc1 0.531250 (0.474848)  loss 1.774695 (1.972534)\n",
            "Epoch [75/90] Step [81/391]  acc1 0.437500 (0.483025)  loss 2.248616 (1.951597)\n",
            "Epoch [75/90] Step [121/391]  acc1 0.421875 (0.483988)  loss 2.137605 (1.946896)\n",
            "Epoch [75/90] Step [161/391]  acc1 0.500000 (0.476999)  loss 2.024814 (1.960128)\n",
            "Epoch [75/90] Step [201/391]  acc1 0.500000 (0.474269)  loss 1.910289 (1.970292)\n",
            "Epoch [75/90] Step [241/391]  acc1 0.359375 (0.468945)  loss 2.224751 (1.985076)\n",
            "Epoch [75/90] Step [281/391]  acc1 0.437500 (0.465859)  loss 2.073174 (1.989180)\n",
            "Epoch [75/90] Step [321/391]  acc1 0.484375 (0.465975)  loss 1.759504 (1.987007)\n",
            "Epoch [75/90] Step [361/391]  acc1 0.515625 (0.466326)  loss 1.788635 (1.986335)\n",
            "Epoch [76/90] Step [1/391]  acc1 0.578125 (0.578125)  loss 1.750526 (1.750526)\n",
            "Epoch [76/90] Step [41/391]  acc1 0.546875 (0.477896)  loss 1.725820 (1.940403)\n",
            "Epoch [76/90] Step [81/391]  acc1 0.437500 (0.473958)  loss 1.845798 (1.935362)\n",
            "Epoch [76/90] Step [121/391]  acc1 0.515625 (0.468363)  loss 1.814385 (1.963164)\n",
            "Epoch [76/90] Step [161/391]  acc1 0.406250 (0.470012)  loss 2.117958 (1.959450)\n",
            "Epoch [76/90] Step [201/391]  acc1 0.468750 (0.466651)  loss 1.838366 (1.981430)\n",
            "Epoch [76/90] Step [241/391]  acc1 0.359375 (0.467324)  loss 2.024076 (1.980852)\n",
            "Epoch [76/90] Step [281/391]  acc1 0.375000 (0.468027)  loss 2.028347 (1.980673)\n",
            "Epoch [76/90] Step [321/391]  acc1 0.406250 (0.468409)  loss 1.943808 (1.977928)\n",
            "Epoch [76/90] Step [361/391]  acc1 0.578125 (0.467322)  loss 1.750487 (1.980419)\n",
            "Epoch [77/90] Step [1/391]  acc1 0.546875 (0.546875)  loss 1.747463 (1.747463)\n",
            "Epoch [77/90] Step [41/391]  acc1 0.343750 (0.474466)  loss 2.860483 (1.983806)\n",
            "Epoch [77/90] Step [81/391]  acc1 0.343750 (0.467207)  loss 2.468749 (1.988762)\n",
            "Epoch [77/90] Step [121/391]  acc1 0.421875 (0.471462)  loss 2.571297 (1.974595)\n",
            "Epoch [77/90] Step [161/391]  acc1 0.484375 (0.469720)  loss 1.973394 (1.974838)\n",
            "Epoch [77/90] Step [201/391]  acc1 0.453125 (0.465796)  loss 1.989844 (1.991982)\n",
            "Epoch [77/90] Step [241/391]  acc1 0.453125 (0.469917)  loss 2.045375 (1.982117)\n",
            "Epoch [77/90] Step [281/391]  acc1 0.390625 (0.468027)  loss 2.148279 (1.982991)\n",
            "Epoch [77/90] Step [321/391]  acc1 0.484375 (0.468555)  loss 1.752373 (1.983832)\n",
            "Epoch [77/90] Step [361/391]  acc1 0.406250 (0.468187)  loss 2.065343 (1.986141)\n",
            "Epoch [78/90] Step [1/391]  acc1 0.421875 (0.421875)  loss 2.333384 (2.333384)\n",
            "Epoch [78/90] Step [41/391]  acc1 0.468750 (0.475991)  loss 1.974466 (1.920826)\n",
            "Epoch [78/90] Step [81/391]  acc1 0.546875 (0.473573)  loss 1.725769 (1.927951)\n",
            "Epoch [78/90] Step [121/391]  acc1 0.437500 (0.471849)  loss 1.796811 (1.951774)\n",
            "Epoch [78/90] Step [161/391]  acc1 0.562500 (0.469235)  loss 1.841944 (1.960502)\n",
            "Epoch [78/90] Step [201/391]  acc1 0.453125 (0.466807)  loss 2.084909 (1.972455)\n",
            "Epoch [78/90] Step [241/391]  acc1 0.562500 (0.469139)  loss 1.524755 (1.964774)\n",
            "Epoch [78/90] Step [281/391]  acc1 0.500000 (0.469751)  loss 2.047651 (1.967244)\n",
            "Epoch [78/90] Step [321/391]  acc1 0.453125 (0.469724)  loss 2.161214 (1.969757)\n",
            "Epoch [78/90] Step [361/391]  acc1 0.453125 (0.468101)  loss 2.017431 (1.969661)\n",
            "Epoch [79/90] Step [1/391]  acc1 0.468750 (0.468750)  loss 2.060567 (2.060567)\n",
            "Epoch [79/90] Step [41/391]  acc1 0.515625 (0.477896)  loss 1.695425 (1.923622)\n",
            "Epoch [79/90] Step [81/391]  acc1 0.406250 (0.480710)  loss 2.241286 (1.921025)\n",
            "Epoch [79/90] Step [121/391]  acc1 0.468750 (0.480114)  loss 2.093859 (1.929150)\n",
            "Epoch [79/90] Step [161/391]  acc1 0.484375 (0.476029)  loss 2.038624 (1.942525)\n",
            "Epoch [79/90] Step [201/391]  acc1 0.468750 (0.476057)  loss 2.004586 (1.946890)\n",
            "Epoch [79/90] Step [241/391]  acc1 0.484375 (0.474780)  loss 1.972515 (1.951557)\n",
            "Epoch [79/90] Step [281/391]  acc1 0.546875 (0.471419)  loss 2.021252 (1.960644)\n",
            "Epoch [79/90] Step [321/391]  acc1 0.500000 (0.472157)  loss 2.115955 (1.955714)\n",
            "Epoch [79/90] Step [361/391]  acc1 0.515625 (0.471607)  loss 1.886895 (1.960314)\n",
            "Epoch [80/90] Step [1/391]  acc1 0.500000 (0.500000)  loss 2.016781 (2.016781)\n",
            "Epoch [80/90] Step [41/391]  acc1 0.437500 (0.487805)  loss 2.097714 (1.896596)\n",
            "Epoch [80/90] Step [81/391]  acc1 0.546875 (0.474730)  loss 1.788861 (1.951594)\n",
            "Epoch [80/90] Step [121/391]  acc1 0.468750 (0.475077)  loss 2.047382 (1.951589)\n",
            "Epoch [80/90] Step [161/391]  acc1 0.468750 (0.473408)  loss 1.977205 (1.953013)\n",
            "Epoch [80/90] Step [201/391]  acc1 0.296875 (0.473336)  loss 2.360950 (1.951138)\n",
            "Epoch [80/90] Step [241/391]  acc1 0.484375 (0.476465)  loss 1.831865 (1.950723)\n",
            "Epoch [80/90] Step [281/391]  acc1 0.515625 (0.478203)  loss 1.982054 (1.944621)\n",
            "Epoch [80/90] Step [321/391]  acc1 0.500000 (0.475467)  loss 1.887584 (1.955454)\n",
            "Epoch [80/90] Step [361/391]  acc1 0.406250 (0.475589)  loss 2.088179 (1.955505)\n",
            "Epoch [81/90] Step [1/391]  acc1 0.468750 (0.468750)  loss 2.005682 (2.005682)\n",
            "Epoch [81/90] Step [41/391]  acc1 0.468750 (0.474848)  loss 1.925284 (1.956440)\n",
            "Epoch [81/90] Step [81/391]  acc1 0.515625 (0.471836)  loss 2.085035 (1.966686)\n",
            "Epoch [81/90] Step [121/391]  acc1 0.500000 (0.472366)  loss 1.936389 (1.975018)\n",
            "Epoch [81/90] Step [161/391]  acc1 0.468750 (0.472147)  loss 1.859211 (1.973789)\n",
            "Epoch [81/90] Step [201/391]  acc1 0.453125 (0.472870)  loss 2.029363 (1.969691)\n",
            "Epoch [81/90] Step [241/391]  acc1 0.609375 (0.474326)  loss 1.665421 (1.964743)\n",
            "Epoch [81/90] Step [281/391]  acc1 0.406250 (0.472920)  loss 2.427010 (1.969359)\n",
            "Epoch [81/90] Step [321/391]  acc1 0.484375 (0.472303)  loss 1.842374 (1.975381)\n",
            "Epoch [81/90] Step [361/391]  acc1 0.484375 (0.472732)  loss 1.836135 (1.972396)\n",
            "Epoch [82/90] Step [1/391]  acc1 0.468750 (0.468750)  loss 2.089725 (2.089725)\n",
            "Epoch [82/90] Step [41/391]  acc1 0.562500 (0.485137)  loss 1.773996 (1.924002)\n",
            "Epoch [82/90] Step [81/391]  acc1 0.484375 (0.476273)  loss 2.187203 (1.949484)\n",
            "Epoch [82/90] Step [121/391]  acc1 0.468750 (0.477660)  loss 1.928602 (1.943404)\n",
            "Epoch [82/90] Step [161/391]  acc1 0.406250 (0.473311)  loss 2.146690 (1.953584)\n",
            "Epoch [82/90] Step [201/391]  acc1 0.437500 (0.472715)  loss 1.970972 (1.961695)\n",
            "Epoch [82/90] Step [241/391]  acc1 0.437500 (0.474196)  loss 1.903648 (1.961537)\n",
            "Epoch [82/90] Step [281/391]  acc1 0.234375 (0.470974)  loss 3.365118 (1.978389)\n",
            "Epoch [82/90] Step [321/391]  acc1 0.484375 (0.468799)  loss 1.960644 (1.987544)\n",
            "Epoch [82/90] Step [361/391]  acc1 0.468750 (0.467625)  loss 2.309157 (1.990643)\n",
            "Epoch [83/90] Step [1/391]  acc1 0.578125 (0.578125)  loss 2.025897 (2.025897)\n",
            "Epoch [83/90] Step [41/391]  acc1 0.593750 (0.486662)  loss 1.537975 (1.968172)\n",
            "Epoch [83/90] Step [81/391]  acc1 0.593750 (0.487269)  loss 1.710190 (1.945736)\n",
            "Epoch [83/90] Step [121/391]  acc1 0.578125 (0.481018)  loss 1.642899 (1.962665)\n",
            "Epoch [83/90] Step [161/391]  acc1 0.312500 (0.478067)  loss 2.285849 (1.962780)\n",
            "Epoch [83/90] Step [201/391]  acc1 0.390625 (0.473414)  loss 2.030902 (1.976794)\n",
            "Epoch [83/90] Step [241/391]  acc1 0.531250 (0.472575)  loss 1.844427 (1.983477)\n",
            "Epoch [83/90] Step [281/391]  acc1 0.421875 (0.471919)  loss 2.051836 (1.983394)\n",
            "Epoch [83/90] Step [321/391]  acc1 0.468750 (0.471379)  loss 1.882382 (1.986067)\n",
            "Epoch [83/90] Step [361/391]  acc1 0.515625 (0.470698)  loss 2.148271 (1.987497)\n",
            "Epoch [84/90] Step [1/391]  acc1 0.453125 (0.453125)  loss 1.966778 (1.966778)\n",
            "Epoch [84/90] Step [41/391]  acc1 0.515625 (0.472180)  loss 1.742120 (1.967181)\n",
            "Epoch [84/90] Step [81/391]  acc1 0.500000 (0.471451)  loss 2.028072 (1.968349)\n",
            "Epoch [84/90] Step [121/391]  acc1 0.500000 (0.474432)  loss 1.984233 (1.954469)\n",
            "Epoch [84/90] Step [161/391]  acc1 0.390625 (0.472147)  loss 2.066018 (1.962838)\n",
            "Epoch [84/90] Step [201/391]  acc1 0.359375 (0.465485)  loss 2.607118 (1.988396)\n",
            "Epoch [84/90] Step [241/391]  acc1 0.359375 (0.468231)  loss 2.360459 (1.988225)\n",
            "Epoch [84/90] Step [281/391]  acc1 0.531250 (0.470140)  loss 1.852197 (1.983068)\n",
            "Epoch [84/90] Step [321/391]  acc1 0.390625 (0.469870)  loss 2.344312 (1.988754)\n",
            "Epoch [84/90] Step [361/391]  acc1 0.453125 (0.469529)  loss 1.972863 (1.990694)\n",
            "Epoch [85/90] Step [1/391]  acc1 0.687500 (0.687500)  loss 1.427485 (1.427485)\n",
            "Epoch [85/90] Step [41/391]  acc1 0.500000 (0.493140)  loss 2.016672 (1.923368)\n",
            "Epoch [85/90] Step [81/391]  acc1 0.500000 (0.498457)  loss 1.694385 (1.900345)\n",
            "Epoch [85/90] Step [121/391]  acc1 0.375000 (0.491219)  loss 2.074168 (1.911147)\n",
            "Epoch [85/90] Step [161/391]  acc1 0.421875 (0.490101)  loss 1.937482 (1.907757)\n",
            "Epoch [85/90] Step [201/391]  acc1 0.437500 (0.483520)  loss 1.976830 (1.931700)\n",
            "Epoch [85/90] Step [241/391]  acc1 0.562500 (0.480420)  loss 1.860086 (1.942529)\n",
            "Epoch [85/90] Step [281/391]  acc1 0.453125 (0.476590)  loss 1.884924 (1.952343)\n",
            "Epoch [85/90] Step [321/391]  acc1 0.406250 (0.476733)  loss 2.050816 (1.951952)\n",
            "Epoch [85/90] Step [361/391]  acc1 0.531250 (0.477709)  loss 1.975032 (1.947825)\n",
            "Epoch [86/90] Step [1/391]  acc1 0.437500 (0.437500)  loss 1.977860 (1.977860)\n",
            "Epoch [86/90] Step [41/391]  acc1 0.421875 (0.463796)  loss 1.945715 (1.919403)\n",
            "Epoch [86/90] Step [81/391]  acc1 0.328125 (0.472415)  loss 2.323571 (1.926252)\n",
            "Epoch [86/90] Step [121/391]  acc1 0.453125 (0.469912)  loss 1.867932 (1.940971)\n",
            "Epoch [86/90] Step [161/391]  acc1 0.437500 (0.474282)  loss 2.249335 (1.942146)\n",
            "Epoch [86/90] Step [201/391]  acc1 0.421875 (0.475358)  loss 2.140703 (1.939411)\n",
            "Epoch [86/90] Step [241/391]  acc1 0.375000 (0.474715)  loss 2.349149 (1.945983)\n",
            "Epoch [86/90] Step [281/391]  acc1 0.515625 (0.475145)  loss 2.140856 (1.946658)\n",
            "Epoch [86/90] Step [321/391]  acc1 0.437500 (0.474542)  loss 1.951964 (1.946841)\n",
            "Epoch [86/90] Step [361/391]  acc1 0.562500 (0.473901)  loss 1.787969 (1.952077)\n",
            "Epoch [87/90] Step [1/391]  acc1 0.468750 (0.468750)  loss 1.979185 (1.979185)\n",
            "Epoch [87/90] Step [41/391]  acc1 0.468750 (0.488567)  loss 2.012730 (1.906561)\n",
            "Epoch [87/90] Step [81/391]  acc1 0.453125 (0.481289)  loss 2.082465 (1.935094)\n",
            "Epoch [87/90] Step [121/391]  acc1 0.546875 (0.477789)  loss 1.629879 (1.928237)\n",
            "Epoch [87/90] Step [161/391]  acc1 0.578125 (0.476514)  loss 1.759623 (1.937397)\n",
            "Epoch [87/90] Step [201/391]  acc1 0.421875 (0.473803)  loss 2.304965 (1.949643)\n",
            "Epoch [87/90] Step [241/391]  acc1 0.437500 (0.473483)  loss 2.024462 (1.950114)\n",
            "Epoch [87/90] Step [281/391]  acc1 0.453125 (0.473810)  loss 2.046427 (1.954679)\n",
            "Epoch [87/90] Step [321/391]  acc1 0.515625 (0.476343)  loss 1.865641 (1.947625)\n",
            "Epoch [87/90] Step [361/391]  acc1 0.484375 (0.475286)  loss 1.868920 (1.950673)\n",
            "Epoch [88/90] Step [1/391]  acc1 0.468750 (0.468750)  loss 1.822772 (1.822772)\n",
            "Epoch [88/90] Step [41/391]  acc1 0.453125 (0.487043)  loss 2.114594 (1.900833)\n",
            "Epoch [88/90] Step [81/391]  acc1 0.437500 (0.484375)  loss 1.871344 (1.918711)\n",
            "Epoch [88/90] Step [121/391]  acc1 0.484375 (0.481663)  loss 1.950343 (1.920521)\n",
            "Epoch [88/90] Step [161/391]  acc1 0.359375 (0.480008)  loss 2.342769 (1.930505)\n",
            "Epoch [88/90] Step [201/391]  acc1 0.406250 (0.477223)  loss 1.947334 (1.936967)\n",
            "Epoch [88/90] Step [241/391]  acc1 0.390625 (0.477373)  loss 2.130440 (1.942710)\n",
            "Epoch [88/90] Step [281/391]  acc1 0.390625 (0.474032)  loss 2.350703 (1.953575)\n",
            "Epoch [88/90] Step [321/391]  acc1 0.500000 (0.472595)  loss 2.036968 (1.960239)\n",
            "Epoch [88/90] Step [361/391]  acc1 0.421875 (0.472775)  loss 1.872259 (1.960072)\n",
            "Epoch [89/90] Step [1/391]  acc1 0.468750 (0.468750)  loss 2.007072 (2.007072)\n",
            "Epoch [89/90] Step [41/391]  acc1 0.625000 (0.492759)  loss 1.784499 (1.922437)\n",
            "Epoch [89/90] Step [81/391]  acc1 0.562500 (0.481867)  loss 1.732998 (1.932536)\n",
            "Epoch [89/90] Step [121/391]  acc1 0.406250 (0.482696)  loss 1.946004 (1.926618)\n",
            "Epoch [89/90] Step [161/391]  acc1 0.484375 (0.478746)  loss 1.828169 (1.940267)\n",
            "Epoch [89/90] Step [201/391]  acc1 0.500000 (0.478078)  loss 1.638614 (1.943265)\n",
            "Epoch [89/90] Step [241/391]  acc1 0.500000 (0.478410)  loss 2.031777 (1.936876)\n",
            "Epoch [89/90] Step [281/391]  acc1 0.468750 (0.478592)  loss 1.801629 (1.938098)\n",
            "Epoch [89/90] Step [321/391]  acc1 0.406250 (0.477560)  loss 2.171682 (1.942967)\n",
            "Epoch [89/90] Step [361/391]  acc1 0.578125 (0.477580)  loss 1.938398 (1.945229)\n",
            "Epoch [90/90] Step [1/391]  acc1 0.593750 (0.593750)  loss 1.556941 (1.556941)\n",
            "Epoch [90/90] Step [41/391]  acc1 0.484375 (0.491997)  loss 1.880165 (1.871437)\n",
            "Epoch [90/90] Step [81/391]  acc1 0.375000 (0.487654)  loss 2.305127 (1.905644)\n",
            "Epoch [90/90] Step [121/391]  acc1 0.421875 (0.478177)  loss 2.044841 (1.928394)\n",
            "Epoch [90/90] Step [161/391]  acc1 0.515625 (0.482628)  loss 1.964179 (1.920190)\n",
            "Epoch [90/90] Step [201/391]  acc1 0.359375 (0.485230)  loss 2.424047 (1.917749)\n",
            "Epoch [90/90] Step [241/391]  acc1 0.468750 (0.483208)  loss 1.820676 (1.917710)\n",
            "Epoch [90/90] Step [281/391]  acc1 0.484375 (0.479815)  loss 2.036918 (1.929880)\n",
            "Epoch [90/90] Step [321/391]  acc1 0.484375 (0.477658)  loss 1.857696 (1.938334)\n",
            "Epoch [90/90] Step [361/391]  acc1 0.421875 (0.475199)  loss 2.453996 (1.946662)\n",
            "Final architecture: {'reduce_n2_p0': 'sepconv3x3', 'reduce_n2_p1': 'sepconv5x5', 'reduce_n3_p0': 'sepconv5x5', 'reduce_n3_p1': 'sepconv5x5', 'reduce_n3_p2': 'dilconv5x5', 'reduce_n4_p0': 'dilconv3x3', 'reduce_n4_p1': 'sepconv5x5', 'reduce_n4_p2': 'sepconv5x5', 'reduce_n4_p3': 'maxpool', 'reduce_n5_p0': 'sepconv5x5', 'reduce_n5_p1': 'skipconnect', 'reduce_n5_p2': 'sepconv3x3', 'reduce_n5_p3': 'sepconv3x3', 'reduce_n5_p4': 'maxpool', 'reduce_n2_switch': [1], 'reduce_n3_switch': [1], 'reduce_n4_switch': [2], 'reduce_n5_switch': [4]}\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1800x400 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs = 90\n",
        "lambd = 1\n",
        "n_chosen = 1\n",
        "weight = 2\n",
        "wt = None\n",
        "for ww in [warmup_weight]:\n",
        "    for wt in [warmup_t]:\n",
        "        for lambd in [1]:\n",
        "            wr = utils.Writer()\n",
        "            wr.new_name('loss')\n",
        "            wr.new_name('weight')\n",
        "            wr.new_name('tempreture')\n",
        "            wr.new_name('edges')\n",
        "            wr.new_name('accuracy')\n",
        "\n",
        "            ww_label = \"no\" if ww is None else \"yes\"\n",
        "            wt_label = \"no\" if wt is None else \"yes\"\n",
        "\n",
        "            print(f\"weight = {ww_label}, temoreture = {wt_label} lambd = {lambd}\")\n",
        "            if dataset == \"fashionmnist\":\n",
        "                model = CNN(32, 1, channels, 10, layers, n_chosen=1)\n",
        "            elif dataset == \"cifar10\":\n",
        "                model = CNN(32, 3, channels, 10, layers, n_chosen=1)\n",
        "            elif dataset == \"cifar100\":\n",
        "                model = CNN(32, 3, channels, 100, layers, n_chosen=1)\n",
        "\n",
        "            criterion = nn.CrossEntropyLoss() # mycriterion()\n",
        "            optim = torch.optim.SGD(model.parameters(), 0.025, momentum=0.9, weight_decay=3.0E-4)\n",
        "            lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, epochs, eta_min=0.001)\n",
        "            trainer = MyDartsTrainer(\n",
        "                model=model,\n",
        "                loss=criterion, # =mycriterion,\n",
        "                metrics=lambda output, target: utils.accuracy(output, target, topk=(1,)),\n",
        "                optimizer=optim,\n",
        "                num_epochs=epochs,\n",
        "                dataset=dataset_train,\n",
        "                batch_size=batch_size,\n",
        "                log_frequency=log_frequency,\n",
        "                unrolled=unrolled,\n",
        "                weight=weight, # вес регуляризатора\n",
        "                lambd=lambd, # количество общих ребер\n",
        "                train_as_optimal=False,\n",
        "                optimalPath='checkpoints/cifar100/optimal/arc.json',\n",
        "                tau=1.0,\n",
        "                learning_rate=2.5E-3,\n",
        "                arc_learning_rate=5e-2,\n",
        "                n_chosen=1,\n",
        "                t_alpha=0.2,\n",
        "                t_beta=0.2,\n",
        "                turn_on_hypernetwork=True,\n",
        "            )\n",
        "            trainer.fit(writer=wr, warmup_t=wt, warmup_weight=ww)\n",
        "            final_architecture = trainer.export()\n",
        "            print('Final architecture:', final_architecture)\n",
        "            if trainer.train_as_optimal:\n",
        "                json.dump(trainer.export(), open(f'checkpoints/CIFAR100/optimal/arc1.json', 'w+'))\n",
        "            else:\n",
        "                json.dump(trainer.export(), open(f'checkpoints/CIFAR100/hypernet/arc1.json', 'w+'))\n",
        "            logs.update({ f'lambd={lambd}, weight={ww_label}, tempreture={wt_label}' : wr })\n",
        "            wr.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.         0.21052632 0.42105263 0.63157895 0.84210526 1.05263158\n",
            " 1.26315789 1.47368421 1.68421053 1.89473684 2.10526316 2.31578947\n",
            " 2.52631579 2.73684211 2.94736842 3.15789474 3.36842105 3.57894737\n",
            " 3.78947368 4.        ] [0, 0, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 4]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from utils import common_edges\n",
        "\n",
        "\n",
        "edges = []\n",
        "arc_optimal = trainer.checkpoint_optimum\n",
        "lambdas = np.linspace(0, 4, 20)\n",
        "for lam in lambdas:\n",
        "    arc = trainer.get_arch(lam)\n",
        "    edges.append(common_edges(arc_optimal, arc))\n",
        "\n",
        "plt.xlabel(r'$\\lambda$', fontdict=font)\n",
        "plt.ylabel('Common edges', fontdict=font)\n",
        "plt.plot(lambdas, edges)\n",
        "print(lambdas, edges)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lambd=1, weight=yes, tempreture=yes 0.85625\n",
            "lambd=2, weight=yes, tempreture=yes 0.884375\n",
            "lambd=3, weight=yes, tempreture=yes 0.88125\n",
            "lambd=1, weight=yes, tempreture=no 0.878125\n",
            "lambd=2, weight=yes, tempreture=no 0.88125\n",
            "lambd=3, weight=yes, tempreture=no 0.884375\n",
            "lambd=1, weight=no, tempreture=yes 0.9\n",
            "lambd=2, weight=no, tempreture=yes 0.89375\n",
            "lambd=3, weight=no, tempreture=yes 0.884375\n",
            "lambd=1, weight=no, tempreture=no 0.8625\n",
            "lambd=2, weight=no, tempreture=no 0.9\n",
            "lambd=3, weight=no, tempreture=no 0.8875\n"
          ]
        }
      ],
      "source": [
        "for log in logs:\n",
        "    print(log, np.mean(logs[log].get('accuracy')[1][-5:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Common edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4, 1, 2, 3]\n"
          ]
        }
      ],
      "source": [
        "arcs = []\n",
        "\n",
        "with open(f'checkpoints/cifar100/optimal/arc.json') as f:\n",
        "    arc = json.load(f) # оптимальная архитектура в виде словаря\n",
        "    arcs.append(arc)\n",
        "\n",
        "lambds = [1, 2, 3]\n",
        "for lamb in lambds:\n",
        "    with open(f'checkpoints/cifar100/random_edges/lambd={lamb}/arc4.json') as f:\n",
        "        arc = json.load(f)\n",
        "        arcs.append(arc)\n",
        "\n",
        "all_intersections = []\n",
        "for arc in arcs:\n",
        "    intersections = []\n",
        "    for other_arc in arcs:\n",
        "        intersections.append(utils.common_edges(arc, other_arc))\n",
        "\n",
        "    all_intersections.append(intersections)\n",
        "intersections_with_opt = all_intersections[0]\n",
        "print(intersections_with_opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'lambda')"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y = intersections_with_opt[1:]\n",
        "plt.plot(lambds, y)\n",
        "plt.ylabel('common edges')\n",
        "plt.xlabel('lambda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Write archs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "for lambd in np.linspace(0, 4, 20):\n",
        "    arc = trainer.get_arch(lam)\n",
        "    json.dump(arc, open(f'checkpoints/CIFAR100/hypernet/try1/arc_lam{lambd}.json', 'w'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Retrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "layers = 2\n",
        "batch_size = 96\n",
        "log_frequency = 20\n",
        "channels = 16\n",
        "unrolled = False\n",
        "visualization = False\n",
        "dataset = 'cifar100'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "./checkpoints/cifar100/random_edges/lambd=1/\n",
            "[2024-04-01 18:25:14] \u001b[32mFixed architecture: {'reduce_n2_p0': 'maxpool', 'reduce_n2_p1': 'sepconv5x5', 'reduce_n3_p0': 'sepconv5x5', 'reduce_n3_p1': 'sepconv5x5', 'reduce_n3_p2': 'sepconv3x3', 'reduce_n4_p0': 'dilconv3x3', 'reduce_n4_p1': 'skipconnect', 'reduce_n4_p2': 'sepconv5x5', 'reduce_n4_p3': 'sepconv5x5', 'reduce_n5_p0': 'maxpool', 'reduce_n5_p1': 'maxpool', 'reduce_n5_p2': 'maxpool', 'reduce_n5_p3': 'sepconv5x5', 'reduce_n5_p4': 'maxpool', 'reduce_n2_switch': [0], 'reduce_n3_switch': [2], 'reduce_n4_switch': [0], 'reduce_n5_switch': [4]}\u001b[0m\n",
            "[2024-04-01 18:25:14] \u001b[32mEpoch 0 LR 0.025000\u001b[0m\n",
            "[2024-04-01 18:25:21] \u001b[32mTrain: [  1/50] Step 000/520 Loss 6.504 Prec@(1,5) (1.0%, 7.3%)\u001b[0m\n",
            "[2024-04-01 18:25:22] \u001b[32mTrain: [  1/50] Step 020/520 Loss 6.388 Prec@(1,5) (1.8%, 8.6%)\u001b[0m\n",
            "[2024-04-01 18:25:22] \u001b[32mTrain: [  1/50] Step 040/520 Loss 6.248 Prec@(1,5) (3.0%, 12.1%)\u001b[0m\n",
            "[2024-04-01 18:25:22] \u001b[32mTrain: [  1/50] Step 060/520 Loss 6.146 Prec@(1,5) (3.6%, 14.9%)\u001b[0m\n",
            "[2024-04-01 18:25:22] \u001b[32mTrain: [  1/50] Step 080/520 Loss 6.057 Prec@(1,5) (4.5%, 16.8%)\u001b[0m\n",
            "[2024-04-01 18:25:23] \u001b[32mTrain: [  1/50] Step 100/520 Loss 5.990 Prec@(1,5) (5.0%, 18.3%)\u001b[0m\n",
            "[2024-04-01 18:25:23] \u001b[32mTrain: [  1/50] Step 120/520 Loss 5.927 Prec@(1,5) (5.4%, 19.6%)\u001b[0m\n",
            "[2024-04-01 18:25:23] \u001b[32mTrain: [  1/50] Step 140/520 Loss 5.886 Prec@(1,5) (5.6%, 20.2%)\u001b[0m\n",
            "[2024-04-01 18:25:24] \u001b[32mTrain: [  1/50] Step 160/520 Loss 5.838 Prec@(1,5) (6.1%, 21.2%)\u001b[0m\n",
            "[2024-04-01 18:25:24] \u001b[32mTrain: [  1/50] Step 180/520 Loss 5.792 Prec@(1,5) (6.5%, 22.1%)\u001b[0m\n",
            "[2024-04-01 18:25:24] \u001b[32mTrain: [  1/50] Step 200/520 Loss 5.754 Prec@(1,5) (6.8%, 22.9%)\u001b[0m\n",
            "[2024-04-01 18:25:24] \u001b[32mTrain: [  1/50] Step 220/520 Loss 5.714 Prec@(1,5) (7.2%, 23.8%)\u001b[0m\n",
            "[2024-04-01 18:25:25] \u001b[32mTrain: [  1/50] Step 240/520 Loss 5.680 Prec@(1,5) (7.6%, 24.6%)\u001b[0m\n",
            "[2024-04-01 18:25:25] \u001b[32mTrain: [  1/50] Step 260/520 Loss 5.651 Prec@(1,5) (7.9%, 25.2%)\u001b[0m\n",
            "[2024-04-01 18:25:25] \u001b[32mTrain: [  1/50] Step 280/520 Loss 5.620 Prec@(1,5) (8.2%, 25.8%)\u001b[0m\n",
            "[2024-04-01 18:25:26] \u001b[32mTrain: [  1/50] Step 300/520 Loss 5.590 Prec@(1,5) (8.4%, 26.5%)\u001b[0m\n",
            "[2024-04-01 18:25:26] \u001b[32mTrain: [  1/50] Step 320/520 Loss 5.565 Prec@(1,5) (8.7%, 27.1%)\u001b[0m\n",
            "[2024-04-01 18:25:26] \u001b[32mTrain: [  1/50] Step 340/520 Loss 5.543 Prec@(1,5) (8.8%, 27.5%)\u001b[0m\n",
            "[2024-04-01 18:25:27] \u001b[32mTrain: [  1/50] Step 360/520 Loss 5.516 Prec@(1,5) (9.0%, 28.0%)\u001b[0m\n",
            "[2024-04-01 18:25:27] \u001b[32mTrain: [  1/50] Step 380/520 Loss 5.495 Prec@(1,5) (9.2%, 28.5%)\u001b[0m\n",
            "[2024-04-01 18:25:27] \u001b[32mTrain: [  1/50] Step 400/520 Loss 5.470 Prec@(1,5) (9.4%, 29.0%)\u001b[0m\n",
            "[2024-04-01 18:25:27] \u001b[32mTrain: [  1/50] Step 420/520 Loss 5.447 Prec@(1,5) (9.7%, 29.5%)\u001b[0m\n",
            "[2024-04-01 18:25:28] \u001b[32mTrain: [  1/50] Step 440/520 Loss 5.424 Prec@(1,5) (10.0%, 29.9%)\u001b[0m\n",
            "[2024-04-01 18:25:28] \u001b[32mTrain: [  1/50] Step 460/520 Loss 5.403 Prec@(1,5) (10.2%, 30.4%)\u001b[0m\n",
            "[2024-04-01 18:25:28] \u001b[32mTrain: [  1/50] Step 480/520 Loss 5.382 Prec@(1,5) (10.4%, 30.8%)\u001b[0m\n",
            "[2024-04-01 18:25:29] \u001b[32mTrain: [  1/50] Step 500/520 Loss 5.361 Prec@(1,5) (10.7%, 31.3%)\u001b[0m\n",
            "[2024-04-01 18:25:29] \u001b[32mTrain: [  1/50] Step 520/520 Loss 5.346 Prec@(1,5) (10.9%, 31.6%)\u001b[0m\n",
            "[2024-04-01 18:25:29] \u001b[32mTrain: [  1/50] Final Prec@1 10.8640%\u001b[0m\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 64\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# validation\u001b[39;00m\n\u001b[0;32m     63\u001b[0m cur_step \u001b[38;5;241m=\u001b[39m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[1;32m---> 64\u001b[0m top1 \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m best_top1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(best_top1, top1)\n\u001b[0;32m     67\u001b[0m lr_scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
            "File \u001b[1;32mc:\\Users\\pkbab\\Documents\\code\\2023-Project-120\\code\\retrain.py:79\u001b[0m, in \u001b[0;36mvalidate\u001b[1;34m(config, valid_loader, model, criterion, epoch, cur_step)\u001b[0m\n\u001b[0;32m     76\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 79\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     80\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), y\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     81\u001b[0m         bs \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\pkbab\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:435\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\pkbab\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:381\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\pkbab\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1034\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1027\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1030\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1034\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
            "File \u001b[1;32mc:\\Users\\pkbab\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\pkbab\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\pkbab\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\pkbab\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "File \u001b[1;32mc:\\Users\\pkbab\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from retrain import train, validate, fixed_arch\n",
        "# reload(train)\n",
        "\n",
        "config = {\n",
        "'layers' : layers,\n",
        "'batch_size' : batch_size,\n",
        "'log_frequency' : log_frequency,\n",
        "'epochs' : 50,\n",
        "'aux_weight' : 0.4,\n",
        "'drop_path_prob' : 0.1,\n",
        "'workers' : 4,\n",
        "'grad_clip' : 5.,\n",
        "'save_folder' : f\"./checkpoints/{dataset}/\",\n",
        "}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "dataset_train, dataset_valid = datasets.get_dataset(dataset, cutout_length=16)\n",
        "\n",
        "best_top1s = {}\n",
        "for lambd in [1, 2, 3]:\n",
        "    for num in [1, 2, 3, 4]:\n",
        "        if lambd == 0:\n",
        "            folder = config['save_folder'] + \"optimal/\"\n",
        "        else:\n",
        "            folder = config['save_folder'] + f\"random_edges/lambd={lambd}/\"\n",
        "        print(folder)\n",
        "        with fixed_arch(folder + f'arc{1}.json'):\n",
        "        # with fixed_arch(args.save_folder + \"/arc.json\"):\n",
        "            if dataset == 'fashionMNIST':\n",
        "                model = CNN(32, 1, 36, 10, config['layers'], auxiliary=True)\n",
        "            if dataset == 'cifar100':\n",
        "                model = CNN(32, 3, 36, 100, config['layers'], auxiliary=True)\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        model.to(device)\n",
        "        criterion.to(device)\n",
        "\n",
        "        optimizer = torch.optim.SGD(model.parameters(), 0.025, momentum=0.9, weight_decay=3.0E-4)\n",
        "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, config['epochs'], eta_min=1E-6)\n",
        "\n",
        "        train_loader = torch.utils.data.DataLoader(dataset_train,\n",
        "                                                batch_size=config['batch_size'],\n",
        "                                                shuffle=True,\n",
        "                                                num_workers=config['workers'],\n",
        "                                                pin_memory=True)\n",
        "        valid_loader = torch.utils.data.DataLoader(dataset_valid,\n",
        "                                                batch_size=config['batch_size'],\n",
        "                                                shuffle=False,\n",
        "                                                num_workers=config['workers'],\n",
        "                                                pin_memory=True)\n",
        "\n",
        "        best_top1 = 0.\n",
        "        for epoch in range(config['epochs']):\n",
        "            drop_prob = config['drop_path_prob'] * epoch / config['epochs']\n",
        "            model.drop_path_prob(drop_prob)\n",
        "\n",
        "            # training\n",
        "            train(config, train_loader, model, optimizer, criterion, epoch)\n",
        "\n",
        "            # validation\n",
        "            cur_step = (epoch + 1) * len(train_loader)\n",
        "            top1 = validate(config, valid_loader, model, criterion, epoch, cur_step)\n",
        "            best_top1 = max(best_top1, top1)\n",
        "\n",
        "            lr_scheduler.step()\n",
        "\n",
        "        torch.save(model.state_dict(), folder + f\"mod{num}.json\")\n",
        "        # torch.save(model.state_dict(), args.save_folder + \"/mod.json\")\n",
        "        print(\"Final best Prec@1 = {:.4%}\".format(best_top1))\n",
        "        best_top1s.update({f'lambd={lambd} arc{num}' : best_top1})\n",
        "        print(best_top1s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'best_top1s' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m wt \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]:\n\u001b[1;32m----> 4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(ww, wt, l, \u001b[43mbest_top1s\u001b[49m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlambd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ml\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, ww=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mww\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, wt=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m])\n",
            "\u001b[1;31mNameError\u001b[0m: name 'best_top1s' is not defined"
          ]
        }
      ],
      "source": [
        "for ww in ['yes', 'no']:\n",
        "    for wt in ['no']:\n",
        "        for l in [1, 2, 3]:\n",
        "            print(ww, wt, l, best_top1s[f'lambd={l}, ww={ww}, wt={wt}'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hypernet retrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "random_edges/lambd=1.263157894736842/\n",
            "[2024-04-02 18:58:14] \u001b[32mFixed architecture: {'reduce_n2_p0': 'sepconv5x5', 'reduce_n2_p1': 'sepconv5x5', 'reduce_n3_p0': 'dilconv5x5', 'reduce_n3_p1': 'sepconv5x5', 'reduce_n3_p2': 'sepconv5x5', 'reduce_n4_p0': 'sepconv3x3', 'reduce_n4_p1': 'sepconv5x5', 'reduce_n4_p2': 'sepconv5x5', 'reduce_n4_p3': 'sepconv5x5', 'reduce_n5_p0': 'maxpool', 'reduce_n5_p1': 'sepconv3x3', 'reduce_n5_p2': 'sepconv5x5', 'reduce_n5_p3': 'sepconv5x5', 'reduce_n5_p4': 'maxpool', 'reduce_n2_switch': [1], 'reduce_n3_switch': [1], 'reduce_n4_switch': [0], 'reduce_n5_switch': [4]}\u001b[0m\n",
            "[2024-04-02 18:58:14] \u001b[32mEpoch 0 LR 0.025000\u001b[0m\n",
            "[2024-04-02 18:58:19] \u001b[32mTrain: [  1/50] Step 000/520 Loss 6.512 Prec@(1,5) (0.0%, 5.2%)\u001b[0m\n",
            "[2024-04-02 18:58:20] \u001b[32mTrain: [  1/50] Step 020/520 Loss 6.394 Prec@(1,5) (2.0%, 8.2%)\u001b[0m\n",
            "[2024-04-02 18:58:20] \u001b[32mTrain: [  1/50] Step 040/520 Loss 6.293 Prec@(1,5) (2.8%, 11.4%)\u001b[0m\n",
            "[2024-04-02 18:58:21] \u001b[32mTrain: [  1/50] Step 060/520 Loss 6.217 Prec@(1,5) (3.1%, 13.2%)\u001b[0m\n",
            "[2024-04-02 18:58:21] \u001b[32mTrain: [  1/50] Step 080/520 Loss 6.120 Prec@(1,5) (3.8%, 15.0%)\u001b[0m\n",
            "[2024-04-02 18:58:21] \u001b[32mTrain: [  1/50] Step 100/520 Loss 6.064 Prec@(1,5) (4.4%, 16.2%)\u001b[0m\n",
            "[2024-04-02 18:58:22] \u001b[32mTrain: [  1/50] Step 120/520 Loss 5.994 Prec@(1,5) (5.0%, 17.7%)\u001b[0m\n",
            "[2024-04-02 18:58:22] \u001b[32mTrain: [  1/50] Step 140/520 Loss 5.934 Prec@(1,5) (5.4%, 18.9%)\u001b[0m\n",
            "[2024-04-02 18:58:23] \u001b[32mTrain: [  1/50] Step 160/520 Loss 5.874 Prec@(1,5) (5.9%, 20.3%)\u001b[0m\n",
            "[2024-04-02 18:58:23] \u001b[32mTrain: [  1/50] Step 180/520 Loss 5.821 Prec@(1,5) (6.4%, 21.5%)\u001b[0m\n",
            "[2024-04-02 18:58:24] \u001b[32mTrain: [  1/50] Step 200/520 Loss 5.775 Prec@(1,5) (6.8%, 22.5%)\u001b[0m\n",
            "[2024-04-02 18:58:24] \u001b[32mTrain: [  1/50] Step 220/520 Loss 5.728 Prec@(1,5) (7.3%, 23.5%)\u001b[0m\n",
            "[2024-04-02 18:58:25] \u001b[32mTrain: [  1/50] Step 240/520 Loss 5.690 Prec@(1,5) (7.6%, 24.3%)\u001b[0m\n",
            "[2024-04-02 18:58:25] \u001b[32mTrain: [  1/50] Step 260/520 Loss 5.654 Prec@(1,5) (7.9%, 25.1%)\u001b[0m\n",
            "[2024-04-02 18:58:26] \u001b[32mTrain: [  1/50] Step 280/520 Loss 5.621 Prec@(1,5) (8.3%, 25.8%)\u001b[0m\n",
            "[2024-04-02 18:58:26] \u001b[32mTrain: [  1/50] Step 300/520 Loss 5.590 Prec@(1,5) (8.6%, 26.4%)\u001b[0m\n",
            "[2024-04-02 18:58:27] \u001b[32mTrain: [  1/50] Step 320/520 Loss 5.560 Prec@(1,5) (8.9%, 27.1%)\u001b[0m\n",
            "[2024-04-02 18:58:27] \u001b[32mTrain: [  1/50] Step 340/520 Loss 5.535 Prec@(1,5) (9.1%, 27.6%)\u001b[0m\n",
            "[2024-04-02 18:58:27] \u001b[32mTrain: [  1/50] Step 360/520 Loss 5.504 Prec@(1,5) (9.3%, 28.3%)\u001b[0m\n",
            "[2024-04-02 18:58:28] \u001b[32mTrain: [  1/50] Step 380/520 Loss 5.481 Prec@(1,5) (9.6%, 28.8%)\u001b[0m\n",
            "[2024-04-02 18:58:28] \u001b[32mTrain: [  1/50] Step 400/520 Loss 5.455 Prec@(1,5) (9.8%, 29.3%)\u001b[0m\n",
            "[2024-04-02 18:58:29] \u001b[32mTrain: [  1/50] Step 420/520 Loss 5.431 Prec@(1,5) (10.1%, 29.9%)\u001b[0m\n",
            "[2024-04-02 18:58:29] \u001b[32mTrain: [  1/50] Step 440/520 Loss 5.409 Prec@(1,5) (10.3%, 30.4%)\u001b[0m\n",
            "[2024-04-02 18:58:30] \u001b[32mTrain: [  1/50] Step 460/520 Loss 5.383 Prec@(1,5) (10.6%, 31.0%)\u001b[0m\n",
            "[2024-04-02 18:58:30] \u001b[32mTrain: [  1/50] Step 480/520 Loss 5.358 Prec@(1,5) (10.8%, 31.5%)\u001b[0m\n",
            "[2024-04-02 18:58:31] \u001b[32mTrain: [  1/50] Step 500/520 Loss 5.338 Prec@(1,5) (11.1%, 32.0%)\u001b[0m\n",
            "[2024-04-02 18:58:31] \u001b[32mTrain: [  1/50] Step 520/520 Loss 5.313 Prec@(1,5) (11.3%, 32.5%)\u001b[0m\n",
            "[2024-04-02 18:58:31] \u001b[32mTrain: [  1/50] Final Prec@1 11.3440%\u001b[0m\n",
            "[2024-04-02 18:58:35] \u001b[32mValid: [  1/50] Step 000/104 Loss 4.934 Prec@(1,5) (19.8%, 37.5%)\u001b[0m\n",
            "[2024-04-02 18:58:35] \u001b[32mValid: [  1/50] Step 020/104 Loss 4.906 Prec@(1,5) (15.7%, 40.7%)\u001b[0m\n",
            "[2024-04-02 18:58:35] \u001b[32mValid: [  1/50] Step 040/104 Loss 4.882 Prec@(1,5) (15.1%, 40.5%)\u001b[0m\n",
            "[2024-04-02 18:58:35] \u001b[32mValid: [  1/50] Step 060/104 Loss 4.860 Prec@(1,5) (15.2%, 40.6%)\u001b[0m\n",
            "[2024-04-02 18:58:36] \u001b[32mValid: [  1/50] Step 080/104 Loss 4.899 Prec@(1,5) (15.0%, 40.4%)\u001b[0m\n",
            "[2024-04-02 18:58:36] \u001b[32mValid: [  1/50] Step 100/104 Loss 4.921 Prec@(1,5) (14.8%, 40.3%)\u001b[0m\n",
            "[2024-04-02 18:58:36] \u001b[32mValid: [  1/50] Step 104/104 Loss 4.926 Prec@(1,5) (14.8%, 40.2%)\u001b[0m\n",
            "[2024-04-02 18:58:36] \u001b[32mValid: [  1/50] Final Prec@1 14.7600%\u001b[0m\n",
            "[2024-04-02 18:58:36] \u001b[32mEpoch 1 LR 0.024975\u001b[0m\n",
            "[2024-04-02 18:58:41] \u001b[32mTrain: [  2/50] Step 000/520 Loss 4.556 Prec@(1,5) (18.8%, 50.0%)\u001b[0m\n",
            "[2024-04-02 18:58:41] \u001b[32mTrain: [  2/50] Step 020/520 Loss 4.691 Prec@(1,5) (18.8%, 45.8%)\u001b[0m\n",
            "[2024-04-02 18:58:42] \u001b[32mTrain: [  2/50] Step 040/520 Loss 4.645 Prec@(1,5) (18.7%, 46.6%)\u001b[0m\n",
            "[2024-04-02 18:58:42] \u001b[32mTrain: [  2/50] Step 060/520 Loss 4.631 Prec@(1,5) (18.6%, 46.7%)\u001b[0m\n",
            "[2024-04-02 18:58:43] \u001b[32mTrain: [  2/50] Step 080/520 Loss 4.631 Prec@(1,5) (18.8%, 47.0%)\u001b[0m\n",
            "[2024-04-02 18:58:43] \u001b[32mTrain: [  2/50] Step 100/520 Loss 4.624 Prec@(1,5) (18.8%, 47.0%)\u001b[0m\n",
            "[2024-04-02 18:58:44] \u001b[32mTrain: [  2/50] Step 120/520 Loss 4.613 Prec@(1,5) (19.1%, 47.4%)\u001b[0m\n",
            "[2024-04-02 18:58:44] \u001b[32mTrain: [  2/50] Step 140/520 Loss 4.605 Prec@(1,5) (19.2%, 47.1%)\u001b[0m\n",
            "[2024-04-02 18:58:45] \u001b[32mTrain: [  2/50] Step 160/520 Loss 4.591 Prec@(1,5) (19.3%, 47.5%)\u001b[0m\n",
            "[2024-04-02 18:58:45] \u001b[32mTrain: [  2/50] Step 180/520 Loss 4.571 Prec@(1,5) (19.6%, 47.7%)\u001b[0m\n",
            "[2024-04-02 18:58:46] \u001b[32mTrain: [  2/50] Step 200/520 Loss 4.550 Prec@(1,5) (19.9%, 48.1%)\u001b[0m\n",
            "[2024-04-02 18:58:46] \u001b[32mTrain: [  2/50] Step 220/520 Loss 4.533 Prec@(1,5) (20.1%, 48.4%)\u001b[0m\n",
            "[2024-04-02 18:58:47] \u001b[32mTrain: [  2/50] Step 240/520 Loss 4.529 Prec@(1,5) (20.1%, 48.5%)\u001b[0m\n",
            "[2024-04-02 18:58:47] \u001b[32mTrain: [  2/50] Step 260/520 Loss 4.522 Prec@(1,5) (20.3%, 48.7%)\u001b[0m\n",
            "[2024-04-02 18:58:48] \u001b[32mTrain: [  2/50] Step 280/520 Loss 4.510 Prec@(1,5) (20.5%, 48.9%)\u001b[0m\n",
            "[2024-04-02 18:58:48] \u001b[32mTrain: [  2/50] Step 300/520 Loss 4.504 Prec@(1,5) (20.6%, 49.0%)\u001b[0m\n",
            "[2024-04-02 18:58:49] \u001b[32mTrain: [  2/50] Step 320/520 Loss 4.492 Prec@(1,5) (20.7%, 49.2%)\u001b[0m\n",
            "[2024-04-02 18:58:50] \u001b[32mTrain: [  2/50] Step 340/520 Loss 4.483 Prec@(1,5) (20.9%, 49.5%)\u001b[0m\n",
            "[2024-04-02 18:58:50] \u001b[32mTrain: [  2/50] Step 360/520 Loss 4.472 Prec@(1,5) (21.0%, 49.7%)\u001b[0m\n",
            "[2024-04-02 18:58:51] \u001b[32mTrain: [  2/50] Step 380/520 Loss 4.459 Prec@(1,5) (21.1%, 49.9%)\u001b[0m\n",
            "[2024-04-02 18:58:51] \u001b[32mTrain: [  2/50] Step 400/520 Loss 4.449 Prec@(1,5) (21.3%, 50.1%)\u001b[0m\n",
            "[2024-04-02 18:58:51] \u001b[32mTrain: [  2/50] Step 420/520 Loss 4.439 Prec@(1,5) (21.4%, 50.3%)\u001b[0m\n",
            "[2024-04-02 18:58:52] \u001b[32mTrain: [  2/50] Step 440/520 Loss 4.434 Prec@(1,5) (21.5%, 50.4%)\u001b[0m\n",
            "[2024-04-02 18:58:53] \u001b[32mTrain: [  2/50] Step 460/520 Loss 4.425 Prec@(1,5) (21.6%, 50.6%)\u001b[0m\n",
            "[2024-04-02 18:58:53] \u001b[32mTrain: [  2/50] Step 480/520 Loss 4.417 Prec@(1,5) (21.7%, 50.8%)\u001b[0m\n",
            "[2024-04-02 18:58:54] \u001b[32mTrain: [  2/50] Step 500/520 Loss 4.411 Prec@(1,5) (21.8%, 50.9%)\u001b[0m\n",
            "[2024-04-02 18:58:54] \u001b[32mTrain: [  2/50] Step 520/520 Loss 4.402 Prec@(1,5) (21.9%, 51.1%)\u001b[0m\n",
            "[2024-04-02 18:58:54] \u001b[32mTrain: [  2/50] Final Prec@1 21.8560%\u001b[0m\n",
            "[2024-04-02 18:58:58] \u001b[32mValid: [  2/50] Step 000/104 Loss 4.209 Prec@(1,5) (28.1%, 56.2%)\u001b[0m\n",
            "[2024-04-02 18:58:58] \u001b[32mValid: [  2/50] Step 020/104 Loss 4.271 Prec@(1,5) (22.6%, 51.8%)\u001b[0m\n",
            "[2024-04-02 18:58:58] \u001b[32mValid: [  2/50] Step 040/104 Loss 4.223 Prec@(1,5) (21.7%, 52.0%)\u001b[0m\n",
            "[2024-04-02 18:58:58] \u001b[32mValid: [  2/50] Step 060/104 Loss 4.179 Prec@(1,5) (22.0%, 52.0%)\u001b[0m\n",
            "[2024-04-02 18:58:59] \u001b[32mValid: [  2/50] Step 080/104 Loss 4.208 Prec@(1,5) (21.8%, 51.8%)\u001b[0m\n",
            "[2024-04-02 18:58:59] \u001b[32mValid: [  2/50] Step 100/104 Loss 4.221 Prec@(1,5) (22.0%, 51.5%)\u001b[0m\n",
            "[2024-04-02 18:58:59] \u001b[32mValid: [  2/50] Step 104/104 Loss 4.223 Prec@(1,5) (22.0%, 51.5%)\u001b[0m\n",
            "[2024-04-02 18:58:59] \u001b[32mValid: [  2/50] Final Prec@1 21.9800%\u001b[0m\n",
            "[2024-04-02 18:58:59] \u001b[32mEpoch 2 LR 0.024901\u001b[0m\n",
            "[2024-04-02 18:59:04] \u001b[32mTrain: [  3/50] Step 000/520 Loss 3.840 Prec@(1,5) (27.1%, 56.2%)\u001b[0m\n",
            "[2024-04-02 18:59:04] \u001b[32mTrain: [  3/50] Step 020/520 Loss 4.096 Prec@(1,5) (24.8%, 56.4%)\u001b[0m\n",
            "[2024-04-02 18:59:05] \u001b[32mTrain: [  3/50] Step 040/520 Loss 4.063 Prec@(1,5) (25.6%, 57.3%)\u001b[0m\n",
            "[2024-04-02 18:59:05] \u001b[32mTrain: [  3/50] Step 060/520 Loss 4.081 Prec@(1,5) (25.6%, 56.9%)\u001b[0m\n",
            "[2024-04-02 18:59:06] \u001b[32mTrain: [  3/50] Step 080/520 Loss 4.064 Prec@(1,5) (26.1%, 57.1%)\u001b[0m\n",
            "[2024-04-02 18:59:06] \u001b[32mTrain: [  3/50] Step 100/520 Loss 4.068 Prec@(1,5) (25.9%, 57.1%)\u001b[0m\n",
            "[2024-04-02 18:59:07] \u001b[32mTrain: [  3/50] Step 120/520 Loss 4.073 Prec@(1,5) (25.8%, 57.0%)\u001b[0m\n",
            "[2024-04-02 18:59:07] \u001b[32mTrain: [  3/50] Step 140/520 Loss 4.059 Prec@(1,5) (26.2%, 57.5%)\u001b[0m\n",
            "[2024-04-02 18:59:08] \u001b[32mTrain: [  3/50] Step 160/520 Loss 4.049 Prec@(1,5) (26.6%, 57.5%)\u001b[0m\n",
            "[2024-04-02 18:59:08] \u001b[32mTrain: [  3/50] Step 180/520 Loss 4.039 Prec@(1,5) (26.7%, 57.7%)\u001b[0m\n",
            "[2024-04-02 18:59:09] \u001b[32mTrain: [  3/50] Step 200/520 Loss 4.039 Prec@(1,5) (26.6%, 57.8%)\u001b[0m\n",
            "[2024-04-02 18:59:09] \u001b[32mTrain: [  3/50] Step 220/520 Loss 4.040 Prec@(1,5) (26.7%, 57.9%)\u001b[0m\n",
            "[2024-04-02 18:59:10] \u001b[32mTrain: [  3/50] Step 240/520 Loss 4.033 Prec@(1,5) (26.9%, 58.0%)\u001b[0m\n",
            "[2024-04-02 18:59:10] \u001b[32mTrain: [  3/50] Step 260/520 Loss 4.026 Prec@(1,5) (27.0%, 58.2%)\u001b[0m\n",
            "[2024-04-02 18:59:11] \u001b[32mTrain: [  3/50] Step 280/520 Loss 4.024 Prec@(1,5) (26.9%, 58.2%)\u001b[0m\n",
            "[2024-04-02 18:59:11] \u001b[32mTrain: [  3/50] Step 300/520 Loss 4.022 Prec@(1,5) (26.9%, 58.2%)\u001b[0m\n",
            "[2024-04-02 18:59:12] \u001b[32mTrain: [  3/50] Step 320/520 Loss 4.021 Prec@(1,5) (26.9%, 58.2%)\u001b[0m\n",
            "[2024-04-02 18:59:12] \u001b[32mTrain: [  3/50] Step 340/520 Loss 4.013 Prec@(1,5) (27.0%, 58.3%)\u001b[0m\n",
            "[2024-04-02 18:59:13] \u001b[32mTrain: [  3/50] Step 360/520 Loss 4.005 Prec@(1,5) (27.1%, 58.4%)\u001b[0m\n",
            "[2024-04-02 18:59:13] \u001b[32mTrain: [  3/50] Step 380/520 Loss 4.000 Prec@(1,5) (27.1%, 58.5%)\u001b[0m\n",
            "[2024-04-02 18:59:14] \u001b[32mTrain: [  3/50] Step 400/520 Loss 3.998 Prec@(1,5) (27.1%, 58.6%)\u001b[0m\n",
            "[2024-04-02 18:59:14] \u001b[32mTrain: [  3/50] Step 420/520 Loss 3.992 Prec@(1,5) (27.2%, 58.7%)\u001b[0m\n",
            "[2024-04-02 18:59:15] \u001b[32mTrain: [  3/50] Step 440/520 Loss 3.985 Prec@(1,5) (27.3%, 58.8%)\u001b[0m\n",
            "[2024-04-02 18:59:15] \u001b[32mTrain: [  3/50] Step 460/520 Loss 3.981 Prec@(1,5) (27.3%, 58.8%)\u001b[0m\n",
            "[2024-04-02 18:59:16] \u001b[32mTrain: [  3/50] Step 480/520 Loss 3.974 Prec@(1,5) (27.4%, 58.9%)\u001b[0m\n",
            "[2024-04-02 18:59:16] \u001b[32mTrain: [  3/50] Step 500/520 Loss 3.969 Prec@(1,5) (27.5%, 59.0%)\u001b[0m\n",
            "[2024-04-02 18:59:17] \u001b[32mTrain: [  3/50] Step 520/520 Loss 3.965 Prec@(1,5) (27.6%, 59.0%)\u001b[0m\n",
            "[2024-04-02 18:59:17] \u001b[32mTrain: [  3/50] Final Prec@1 27.5820%\u001b[0m\n",
            "[2024-04-02 18:59:20] \u001b[32mValid: [  3/50] Step 000/104 Loss 4.645 Prec@(1,5) (25.0%, 59.4%)\u001b[0m\n",
            "[2024-04-02 18:59:21] \u001b[32mValid: [  3/50] Step 020/104 Loss 4.577 Prec@(1,5) (24.8%, 54.8%)\u001b[0m\n",
            "[2024-04-02 18:59:21] \u001b[32mValid: [  3/50] Step 040/104 Loss 4.499 Prec@(1,5) (24.5%, 55.6%)\u001b[0m\n",
            "[2024-04-02 18:59:21] \u001b[32mValid: [  3/50] Step 060/104 Loss 4.465 Prec@(1,5) (24.6%, 55.5%)\u001b[0m\n",
            "[2024-04-02 18:59:21] \u001b[32mValid: [  3/50] Step 080/104 Loss 4.486 Prec@(1,5) (23.8%, 55.4%)\u001b[0m\n",
            "[2024-04-02 18:59:21] \u001b[32mValid: [  3/50] Step 100/104 Loss 4.497 Prec@(1,5) (24.0%, 55.3%)\u001b[0m\n",
            "[2024-04-02 18:59:21] \u001b[32mValid: [  3/50] Step 104/104 Loss 4.494 Prec@(1,5) (23.9%, 55.2%)\u001b[0m\n",
            "[2024-04-02 18:59:22] \u001b[32mValid: [  3/50] Final Prec@1 23.9400%\u001b[0m\n",
            "[2024-04-02 18:59:22] \u001b[32mEpoch 3 LR 0.024779\u001b[0m\n",
            "[2024-04-02 18:59:26] \u001b[32mTrain: [  4/50] Step 000/520 Loss 3.593 Prec@(1,5) (27.1%, 67.7%)\u001b[0m\n",
            "[2024-04-02 18:59:27] \u001b[32mTrain: [  4/50] Step 020/520 Loss 3.742 Prec@(1,5) (31.2%, 62.9%)\u001b[0m\n",
            "[2024-04-02 18:59:27] \u001b[32mTrain: [  4/50] Step 040/520 Loss 3.702 Prec@(1,5) (31.2%, 62.7%)\u001b[0m\n",
            "[2024-04-02 18:59:28] \u001b[32mTrain: [  4/50] Step 060/520 Loss 3.730 Prec@(1,5) (30.9%, 61.9%)\u001b[0m\n",
            "[2024-04-02 18:59:28] \u001b[32mTrain: [  4/50] Step 080/520 Loss 3.737 Prec@(1,5) (31.0%, 61.8%)\u001b[0m\n",
            "[2024-04-02 18:59:29] \u001b[32mTrain: [  4/50] Step 100/520 Loss 3.729 Prec@(1,5) (30.9%, 62.0%)\u001b[0m\n",
            "[2024-04-02 18:59:29] \u001b[32mTrain: [  4/50] Step 120/520 Loss 3.732 Prec@(1,5) (30.7%, 62.0%)\u001b[0m\n",
            "[2024-04-02 18:59:30] \u001b[32mTrain: [  4/50] Step 140/520 Loss 3.721 Prec@(1,5) (30.9%, 62.2%)\u001b[0m\n",
            "[2024-04-02 18:59:30] \u001b[32mTrain: [  4/50] Step 160/520 Loss 3.735 Prec@(1,5) (30.8%, 62.2%)\u001b[0m\n",
            "[2024-04-02 18:59:31] \u001b[32mTrain: [  4/50] Step 180/520 Loss 3.738 Prec@(1,5) (30.8%, 62.1%)\u001b[0m\n",
            "[2024-04-02 18:59:31] \u001b[32mTrain: [  4/50] Step 200/520 Loss 3.746 Prec@(1,5) (30.7%, 62.0%)\u001b[0m\n",
            "[2024-04-02 18:59:32] \u001b[32mTrain: [  4/50] Step 220/520 Loss 3.741 Prec@(1,5) (30.8%, 62.2%)\u001b[0m\n",
            "[2024-04-02 18:59:32] \u001b[32mTrain: [  4/50] Step 240/520 Loss 3.739 Prec@(1,5) (30.8%, 62.1%)\u001b[0m\n",
            "[2024-04-02 18:59:33] \u001b[32mTrain: [  4/50] Step 260/520 Loss 3.733 Prec@(1,5) (31.0%, 62.3%)\u001b[0m\n",
            "[2024-04-02 18:59:33] \u001b[32mTrain: [  4/50] Step 280/520 Loss 3.733 Prec@(1,5) (31.0%, 62.3%)\u001b[0m\n",
            "[2024-04-02 18:59:34] \u001b[32mTrain: [  4/50] Step 300/520 Loss 3.732 Prec@(1,5) (31.1%, 62.3%)\u001b[0m\n",
            "[2024-04-02 18:59:34] \u001b[32mTrain: [  4/50] Step 320/520 Loss 3.725 Prec@(1,5) (31.2%, 62.4%)\u001b[0m\n",
            "[2024-04-02 18:59:35] \u001b[32mTrain: [  4/50] Step 340/520 Loss 3.718 Prec@(1,5) (31.2%, 62.6%)\u001b[0m\n",
            "[2024-04-02 18:59:35] \u001b[32mTrain: [  4/50] Step 360/520 Loss 3.715 Prec@(1,5) (31.2%, 62.6%)\u001b[0m\n",
            "[2024-04-02 18:59:36] \u001b[32mTrain: [  4/50] Step 380/520 Loss 3.708 Prec@(1,5) (31.3%, 62.8%)\u001b[0m\n",
            "[2024-04-02 18:59:36] \u001b[32mTrain: [  4/50] Step 400/520 Loss 3.705 Prec@(1,5) (31.4%, 62.9%)\u001b[0m\n",
            "[2024-04-02 18:59:37] \u001b[32mTrain: [  4/50] Step 420/520 Loss 3.702 Prec@(1,5) (31.5%, 62.9%)\u001b[0m\n",
            "[2024-04-02 18:59:37] \u001b[32mTrain: [  4/50] Step 440/520 Loss 3.696 Prec@(1,5) (31.5%, 63.1%)\u001b[0m\n",
            "[2024-04-02 18:59:38] \u001b[32mTrain: [  4/50] Step 460/520 Loss 3.695 Prec@(1,5) (31.6%, 63.1%)\u001b[0m\n",
            "[2024-04-02 18:59:38] \u001b[32mTrain: [  4/50] Step 480/520 Loss 3.690 Prec@(1,5) (31.6%, 63.2%)\u001b[0m\n",
            "[2024-04-02 18:59:39] \u001b[32mTrain: [  4/50] Step 500/520 Loss 3.689 Prec@(1,5) (31.6%, 63.2%)\u001b[0m\n",
            "[2024-04-02 18:59:39] \u001b[32mTrain: [  4/50] Step 520/520 Loss 3.686 Prec@(1,5) (31.7%, 63.3%)\u001b[0m\n",
            "[2024-04-02 18:59:39] \u001b[32mTrain: [  4/50] Final Prec@1 31.7120%\u001b[0m\n",
            "[2024-04-02 18:59:43] \u001b[32mValid: [  4/50] Step 000/104 Loss 3.934 Prec@(1,5) (32.3%, 60.4%)\u001b[0m\n",
            "[2024-04-02 18:59:43] \u001b[32mValid: [  4/50] Step 020/104 Loss 3.856 Prec@(1,5) (29.3%, 61.9%)\u001b[0m\n",
            "[2024-04-02 18:59:43] \u001b[32mValid: [  4/50] Step 040/104 Loss 3.786 Prec@(1,5) (29.2%, 62.1%)\u001b[0m\n",
            "[2024-04-02 18:59:43] \u001b[32mValid: [  4/50] Step 060/104 Loss 3.777 Prec@(1,5) (29.3%, 62.0%)\u001b[0m\n",
            "[2024-04-02 18:59:44] \u001b[32mValid: [  4/50] Step 080/104 Loss 3.791 Prec@(1,5) (29.1%, 61.8%)\u001b[0m\n",
            "[2024-04-02 18:59:44] \u001b[32mValid: [  4/50] Step 100/104 Loss 3.792 Prec@(1,5) (29.1%, 61.9%)\u001b[0m\n",
            "[2024-04-02 18:59:44] \u001b[32mValid: [  4/50] Step 104/104 Loss 3.789 Prec@(1,5) (29.0%, 61.9%)\u001b[0m\n",
            "[2024-04-02 18:59:44] \u001b[32mValid: [  4/50] Final Prec@1 29.0000%\u001b[0m\n",
            "[2024-04-02 18:59:44] \u001b[32mEpoch 4 LR 0.024607\u001b[0m\n",
            "[2024-04-02 18:59:49] \u001b[32mTrain: [  5/50] Step 000/520 Loss 3.381 Prec@(1,5) (39.6%, 68.8%)\u001b[0m\n",
            "[2024-04-02 18:59:49] \u001b[32mTrain: [  5/50] Step 020/520 Loss 3.476 Prec@(1,5) (35.0%, 67.0%)\u001b[0m\n",
            "[2024-04-02 18:59:50] \u001b[32mTrain: [  5/50] Step 040/520 Loss 3.516 Prec@(1,5) (34.2%, 66.2%)\u001b[0m\n",
            "[2024-04-02 18:59:50] \u001b[32mTrain: [  5/50] Step 060/520 Loss 3.482 Prec@(1,5) (35.0%, 66.8%)\u001b[0m\n",
            "[2024-04-02 18:59:51] \u001b[32mTrain: [  5/50] Step 080/520 Loss 3.489 Prec@(1,5) (34.8%, 66.6%)\u001b[0m\n",
            "[2024-04-02 18:59:51] \u001b[32mTrain: [  5/50] Step 100/520 Loss 3.473 Prec@(1,5) (34.8%, 66.8%)\u001b[0m\n",
            "[2024-04-02 18:59:51] \u001b[32mTrain: [  5/50] Step 120/520 Loss 3.501 Prec@(1,5) (34.3%, 66.4%)\u001b[0m\n",
            "[2024-04-02 18:59:52] \u001b[32mTrain: [  5/50] Step 140/520 Loss 3.510 Prec@(1,5) (34.1%, 66.2%)\u001b[0m\n",
            "[2024-04-02 18:59:52] \u001b[32mTrain: [  5/50] Step 160/520 Loss 3.501 Prec@(1,5) (34.2%, 66.3%)\u001b[0m\n",
            "[2024-04-02 18:59:53] \u001b[32mTrain: [  5/50] Step 180/520 Loss 3.498 Prec@(1,5) (34.2%, 66.3%)\u001b[0m\n",
            "[2024-04-02 18:59:53] \u001b[32mTrain: [  5/50] Step 200/520 Loss 3.498 Prec@(1,5) (34.3%, 66.4%)\u001b[0m\n",
            "[2024-04-02 18:59:54] \u001b[32mTrain: [  5/50] Step 220/520 Loss 3.495 Prec@(1,5) (34.3%, 66.6%)\u001b[0m\n",
            "[2024-04-02 18:59:54] \u001b[32mTrain: [  5/50] Step 240/520 Loss 3.498 Prec@(1,5) (34.2%, 66.5%)\u001b[0m\n",
            "[2024-04-02 18:59:55] \u001b[32mTrain: [  5/50] Step 260/520 Loss 3.493 Prec@(1,5) (34.3%, 66.7%)\u001b[0m\n",
            "[2024-04-02 18:59:55] \u001b[32mTrain: [  5/50] Step 280/520 Loss 3.495 Prec@(1,5) (34.3%, 66.7%)\u001b[0m\n",
            "[2024-04-02 18:59:56] \u001b[32mTrain: [  5/50] Step 300/520 Loss 3.493 Prec@(1,5) (34.4%, 66.7%)\u001b[0m\n",
            "[2024-04-02 18:59:56] \u001b[32mTrain: [  5/50] Step 320/520 Loss 3.496 Prec@(1,5) (34.3%, 66.7%)\u001b[0m\n",
            "[2024-04-02 18:59:57] \u001b[32mTrain: [  5/50] Step 340/520 Loss 3.494 Prec@(1,5) (34.4%, 66.7%)\u001b[0m\n",
            "[2024-04-02 18:59:57] \u001b[32mTrain: [  5/50] Step 360/520 Loss 3.493 Prec@(1,5) (34.4%, 66.7%)\u001b[0m\n",
            "[2024-04-02 18:59:58] \u001b[32mTrain: [  5/50] Step 380/520 Loss 3.488 Prec@(1,5) (34.5%, 66.8%)\u001b[0m\n",
            "[2024-04-02 18:59:58] \u001b[32mTrain: [  5/50] Step 400/520 Loss 3.485 Prec@(1,5) (34.6%, 66.9%)\u001b[0m\n",
            "[2024-04-02 18:59:59] \u001b[32mTrain: [  5/50] Step 420/520 Loss 3.483 Prec@(1,5) (34.6%, 66.9%)\u001b[0m\n",
            "[2024-04-02 18:59:59] \u001b[32mTrain: [  5/50] Step 440/520 Loss 3.479 Prec@(1,5) (34.7%, 67.0%)\u001b[0m\n",
            "[2024-04-02 19:00:00] \u001b[32mTrain: [  5/50] Step 460/520 Loss 3.475 Prec@(1,5) (34.8%, 67.0%)\u001b[0m\n",
            "[2024-04-02 19:00:00] \u001b[32mTrain: [  5/50] Step 480/520 Loss 3.471 Prec@(1,5) (34.9%, 67.1%)\u001b[0m\n",
            "[2024-04-02 19:00:01] \u001b[32mTrain: [  5/50] Step 500/520 Loss 3.467 Prec@(1,5) (35.0%, 67.2%)\u001b[0m\n",
            "[2024-04-02 19:00:01] \u001b[32mTrain: [  5/50] Step 520/520 Loss 3.465 Prec@(1,5) (35.0%, 67.2%)\u001b[0m\n",
            "[2024-04-02 19:00:02] \u001b[32mTrain: [  5/50] Final Prec@1 34.9920%\u001b[0m\n",
            "[2024-04-02 19:00:05] \u001b[32mValid: [  5/50] Step 000/104 Loss 3.571 Prec@(1,5) (35.4%, 67.7%)\u001b[0m\n",
            "[2024-04-02 19:00:05] \u001b[32mValid: [  5/50] Step 020/104 Loss 3.698 Prec@(1,5) (31.6%, 63.7%)\u001b[0m\n",
            "[2024-04-02 19:00:05] \u001b[32mValid: [  5/50] Step 040/104 Loss 3.651 Prec@(1,5) (31.7%, 63.9%)\u001b[0m\n",
            "[2024-04-02 19:00:06] \u001b[32mValid: [  5/50] Step 060/104 Loss 3.594 Prec@(1,5) (32.0%, 64.3%)\u001b[0m\n",
            "[2024-04-02 19:00:06] \u001b[32mValid: [  5/50] Step 080/104 Loss 3.610 Prec@(1,5) (31.6%, 64.1%)\u001b[0m\n",
            "[2024-04-02 19:00:06] \u001b[32mValid: [  5/50] Step 100/104 Loss 3.602 Prec@(1,5) (31.6%, 64.2%)\u001b[0m\n",
            "[2024-04-02 19:00:06] \u001b[32mValid: [  5/50] Step 104/104 Loss 3.596 Prec@(1,5) (31.7%, 64.3%)\u001b[0m\n",
            "[2024-04-02 19:00:06] \u001b[32mValid: [  5/50] Final Prec@1 31.6800%\u001b[0m\n",
            "[2024-04-02 19:00:06] \u001b[32mEpoch 5 LR 0.024388\u001b[0m\n",
            "[2024-04-02 19:00:11] \u001b[32mTrain: [  6/50] Step 000/520 Loss 3.580 Prec@(1,5) (30.2%, 64.6%)\u001b[0m\n",
            "[2024-04-02 19:00:11] \u001b[32mTrain: [  6/50] Step 020/520 Loss 3.356 Prec@(1,5) (36.8%, 67.6%)\u001b[0m\n",
            "[2024-04-02 19:00:12] \u001b[32mTrain: [  6/50] Step 040/520 Loss 3.372 Prec@(1,5) (37.2%, 67.3%)\u001b[0m\n",
            "[2024-04-02 19:00:12] \u001b[32mTrain: [  6/50] Step 060/520 Loss 3.369 Prec@(1,5) (37.4%, 67.8%)\u001b[0m\n",
            "[2024-04-02 19:00:13] \u001b[32mTrain: [  6/50] Step 080/520 Loss 3.357 Prec@(1,5) (37.4%, 68.3%)\u001b[0m\n",
            "[2024-04-02 19:00:13] \u001b[32mTrain: [  6/50] Step 100/520 Loss 3.350 Prec@(1,5) (37.4%, 68.6%)\u001b[0m\n",
            "[2024-04-02 19:00:14] \u001b[32mTrain: [  6/50] Step 120/520 Loss 3.336 Prec@(1,5) (37.5%, 68.8%)\u001b[0m\n",
            "[2024-04-02 19:00:14] \u001b[32mTrain: [  6/50] Step 140/520 Loss 3.343 Prec@(1,5) (37.5%, 68.6%)\u001b[0m\n",
            "[2024-04-02 19:00:15] \u001b[32mTrain: [  6/50] Step 160/520 Loss 3.334 Prec@(1,5) (37.6%, 68.8%)\u001b[0m\n",
            "[2024-04-02 19:00:15] \u001b[32mTrain: [  6/50] Step 180/520 Loss 3.329 Prec@(1,5) (37.6%, 68.9%)\u001b[0m\n",
            "[2024-04-02 19:00:16] \u001b[32mTrain: [  6/50] Step 200/520 Loss 3.327 Prec@(1,5) (37.6%, 69.0%)\u001b[0m\n",
            "[2024-04-02 19:00:16] \u001b[32mTrain: [  6/50] Step 220/520 Loss 3.327 Prec@(1,5) (37.5%, 69.0%)\u001b[0m\n",
            "[2024-04-02 19:00:17] \u001b[32mTrain: [  6/50] Step 240/520 Loss 3.326 Prec@(1,5) (37.5%, 69.0%)\u001b[0m\n",
            "[2024-04-02 19:00:17] \u001b[32mTrain: [  6/50] Step 260/520 Loss 3.324 Prec@(1,5) (37.4%, 68.9%)\u001b[0m\n",
            "[2024-04-02 19:00:18] \u001b[32mTrain: [  6/50] Step 280/520 Loss 3.323 Prec@(1,5) (37.5%, 69.0%)\u001b[0m\n",
            "[2024-04-02 19:00:18] \u001b[32mTrain: [  6/50] Step 300/520 Loss 3.318 Prec@(1,5) (37.5%, 69.1%)\u001b[0m\n",
            "[2024-04-02 19:00:19] \u001b[32mTrain: [  6/50] Step 320/520 Loss 3.312 Prec@(1,5) (37.5%, 69.2%)\u001b[0m\n",
            "[2024-04-02 19:00:19] \u001b[32mTrain: [  6/50] Step 340/520 Loss 3.312 Prec@(1,5) (37.5%, 69.2%)\u001b[0m\n",
            "[2024-04-02 19:00:20] \u001b[32mTrain: [  6/50] Step 360/520 Loss 3.312 Prec@(1,5) (37.6%, 69.3%)\u001b[0m\n",
            "[2024-04-02 19:00:20] \u001b[32mTrain: [  6/50] Step 380/520 Loss 3.310 Prec@(1,5) (37.6%, 69.4%)\u001b[0m\n",
            "[2024-04-02 19:00:21] \u001b[32mTrain: [  6/50] Step 400/520 Loss 3.307 Prec@(1,5) (37.6%, 69.4%)\u001b[0m\n",
            "[2024-04-02 19:00:21] \u001b[32mTrain: [  6/50] Step 420/520 Loss 3.305 Prec@(1,5) (37.7%, 69.5%)\u001b[0m\n",
            "[2024-04-02 19:00:22] \u001b[32mTrain: [  6/50] Step 440/520 Loss 3.301 Prec@(1,5) (37.7%, 69.6%)\u001b[0m\n",
            "[2024-04-02 19:00:22] \u001b[32mTrain: [  6/50] Step 460/520 Loss 3.295 Prec@(1,5) (37.8%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:00:23] \u001b[32mTrain: [  6/50] Step 480/520 Loss 3.290 Prec@(1,5) (37.9%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:00:23] \u001b[32mTrain: [  6/50] Step 500/520 Loss 3.288 Prec@(1,5) (37.9%, 69.8%)\u001b[0m\n",
            "[2024-04-02 19:00:24] \u001b[32mTrain: [  6/50] Step 520/520 Loss 3.287 Prec@(1,5) (37.9%, 69.9%)\u001b[0m\n",
            "[2024-04-02 19:00:24] \u001b[32mTrain: [  6/50] Final Prec@1 37.8760%\u001b[0m\n",
            "[2024-04-02 19:00:27] \u001b[32mValid: [  6/50] Step 000/104 Loss 3.270 Prec@(1,5) (37.5%, 69.8%)\u001b[0m\n",
            "[2024-04-02 19:00:27] \u001b[32mValid: [  6/50] Step 020/104 Loss 3.430 Prec@(1,5) (35.8%, 69.0%)\u001b[0m\n",
            "[2024-04-02 19:00:28] \u001b[32mValid: [  6/50] Step 040/104 Loss 3.381 Prec@(1,5) (35.6%, 68.2%)\u001b[0m\n",
            "[2024-04-02 19:00:28] \u001b[32mValid: [  6/50] Step 060/104 Loss 3.354 Prec@(1,5) (35.6%, 68.1%)\u001b[0m\n",
            "[2024-04-02 19:00:28] \u001b[32mValid: [  6/50] Step 080/104 Loss 3.372 Prec@(1,5) (35.2%, 68.2%)\u001b[0m\n",
            "[2024-04-02 19:00:28] \u001b[32mValid: [  6/50] Step 100/104 Loss 3.366 Prec@(1,5) (35.5%, 68.1%)\u001b[0m\n",
            "[2024-04-02 19:00:28] \u001b[32mValid: [  6/50] Step 104/104 Loss 3.365 Prec@(1,5) (35.5%, 68.1%)\u001b[0m\n",
            "[2024-04-02 19:00:28] \u001b[32mValid: [  6/50] Final Prec@1 35.5200%\u001b[0m\n",
            "[2024-04-02 19:00:28] \u001b[32mEpoch 6 LR 0.024122\u001b[0m\n",
            "[2024-04-02 19:00:33] \u001b[32mTrain: [  7/50] Step 000/520 Loss 3.406 Prec@(1,5) (32.3%, 64.6%)\u001b[0m\n",
            "[2024-04-02 19:00:33] \u001b[32mTrain: [  7/50] Step 020/520 Loss 3.119 Prec@(1,5) (40.3%, 71.9%)\u001b[0m\n",
            "[2024-04-02 19:00:34] \u001b[32mTrain: [  7/50] Step 040/520 Loss 3.133 Prec@(1,5) (40.2%, 72.1%)\u001b[0m\n",
            "[2024-04-02 19:00:34] \u001b[32mTrain: [  7/50] Step 060/520 Loss 3.134 Prec@(1,5) (40.5%, 72.3%)\u001b[0m\n",
            "[2024-04-02 19:00:35] \u001b[32mTrain: [  7/50] Step 080/520 Loss 3.131 Prec@(1,5) (40.7%, 71.9%)\u001b[0m\n",
            "[2024-04-02 19:00:35] \u001b[32mTrain: [  7/50] Step 100/520 Loss 3.142 Prec@(1,5) (40.4%, 71.9%)\u001b[0m\n",
            "[2024-04-02 19:00:36] \u001b[32mTrain: [  7/50] Step 120/520 Loss 3.147 Prec@(1,5) (40.2%, 71.7%)\u001b[0m\n",
            "[2024-04-02 19:00:36] \u001b[32mTrain: [  7/50] Step 140/520 Loss 3.143 Prec@(1,5) (40.2%, 71.8%)\u001b[0m\n",
            "[2024-04-02 19:00:37] \u001b[32mTrain: [  7/50] Step 160/520 Loss 3.153 Prec@(1,5) (40.1%, 71.7%)\u001b[0m\n",
            "[2024-04-02 19:00:37] \u001b[32mTrain: [  7/50] Step 180/520 Loss 3.156 Prec@(1,5) (40.1%, 71.7%)\u001b[0m\n",
            "[2024-04-02 19:00:38] \u001b[32mTrain: [  7/50] Step 200/520 Loss 3.148 Prec@(1,5) (40.2%, 71.8%)\u001b[0m\n",
            "[2024-04-02 19:00:38] \u001b[32mTrain: [  7/50] Step 220/520 Loss 3.149 Prec@(1,5) (40.3%, 71.8%)\u001b[0m\n",
            "[2024-04-02 19:00:39] \u001b[32mTrain: [  7/50] Step 240/520 Loss 3.154 Prec@(1,5) (40.2%, 71.6%)\u001b[0m\n",
            "[2024-04-02 19:00:39] \u001b[32mTrain: [  7/50] Step 260/520 Loss 3.154 Prec@(1,5) (40.2%, 71.7%)\u001b[0m\n",
            "[2024-04-02 19:00:40] \u001b[32mTrain: [  7/50] Step 280/520 Loss 3.158 Prec@(1,5) (40.0%, 71.7%)\u001b[0m\n",
            "[2024-04-02 19:00:40] \u001b[32mTrain: [  7/50] Step 300/520 Loss 3.159 Prec@(1,5) (40.0%, 71.7%)\u001b[0m\n",
            "[2024-04-02 19:00:41] \u001b[32mTrain: [  7/50] Step 320/520 Loss 3.155 Prec@(1,5) (39.9%, 71.7%)\u001b[0m\n",
            "[2024-04-02 19:00:41] \u001b[32mTrain: [  7/50] Step 340/520 Loss 3.150 Prec@(1,5) (40.0%, 71.8%)\u001b[0m\n",
            "[2024-04-02 19:00:42] \u001b[32mTrain: [  7/50] Step 360/520 Loss 3.150 Prec@(1,5) (40.0%, 71.8%)\u001b[0m\n",
            "[2024-04-02 19:00:42] \u001b[32mTrain: [  7/50] Step 380/520 Loss 3.150 Prec@(1,5) (40.0%, 71.8%)\u001b[0m\n",
            "[2024-04-02 19:00:43] \u001b[32mTrain: [  7/50] Step 400/520 Loss 3.147 Prec@(1,5) (40.0%, 71.9%)\u001b[0m\n",
            "[2024-04-02 19:00:43] \u001b[32mTrain: [  7/50] Step 420/520 Loss 3.149 Prec@(1,5) (40.0%, 71.8%)\u001b[0m\n",
            "[2024-04-02 19:00:44] \u001b[32mTrain: [  7/50] Step 440/520 Loss 3.146 Prec@(1,5) (40.0%, 71.9%)\u001b[0m\n",
            "[2024-04-02 19:00:44] \u001b[32mTrain: [  7/50] Step 460/520 Loss 3.143 Prec@(1,5) (40.1%, 71.9%)\u001b[0m\n",
            "[2024-04-02 19:00:45] \u001b[32mTrain: [  7/50] Step 480/520 Loss 3.142 Prec@(1,5) (40.1%, 71.9%)\u001b[0m\n",
            "[2024-04-02 19:00:45] \u001b[32mTrain: [  7/50] Step 500/520 Loss 3.141 Prec@(1,5) (40.1%, 71.9%)\u001b[0m\n",
            "[2024-04-02 19:00:46] \u001b[32mTrain: [  7/50] Step 520/520 Loss 3.139 Prec@(1,5) (40.2%, 71.9%)\u001b[0m\n",
            "[2024-04-02 19:00:46] \u001b[32mTrain: [  7/50] Final Prec@1 40.2020%\u001b[0m\n",
            "[2024-04-02 19:00:50] \u001b[32mValid: [  7/50] Step 000/104 Loss 3.106 Prec@(1,5) (40.6%, 69.8%)\u001b[0m\n",
            "[2024-04-02 19:00:50] \u001b[32mValid: [  7/50] Step 020/104 Loss 3.359 Prec@(1,5) (37.8%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:00:50] \u001b[32mValid: [  7/50] Step 040/104 Loss 3.376 Prec@(1,5) (37.0%, 69.2%)\u001b[0m\n",
            "[2024-04-02 19:00:50] \u001b[32mValid: [  7/50] Step 060/104 Loss 3.320 Prec@(1,5) (37.4%, 69.5%)\u001b[0m\n",
            "[2024-04-02 19:00:50] \u001b[32mValid: [  7/50] Step 080/104 Loss 3.346 Prec@(1,5) (36.9%, 69.1%)\u001b[0m\n",
            "[2024-04-02 19:00:50] \u001b[32mValid: [  7/50] Step 100/104 Loss 3.336 Prec@(1,5) (36.8%, 69.1%)\u001b[0m\n",
            "[2024-04-02 19:00:50] \u001b[32mValid: [  7/50] Step 104/104 Loss 3.337 Prec@(1,5) (36.7%, 69.1%)\u001b[0m\n",
            "[2024-04-02 19:00:51] \u001b[32mValid: [  7/50] Final Prec@1 36.7400%\u001b[0m\n",
            "[2024-04-02 19:00:51] \u001b[32mEpoch 7 LR 0.023810\u001b[0m\n",
            "[2024-04-02 19:00:55] \u001b[32mTrain: [  8/50] Step 000/520 Loss 3.239 Prec@(1,5) (39.6%, 74.0%)\u001b[0m\n",
            "[2024-04-02 19:00:56] \u001b[32mTrain: [  8/50] Step 020/520 Loss 3.063 Prec@(1,5) (41.4%, 73.4%)\u001b[0m\n",
            "[2024-04-02 19:00:56] \u001b[32mTrain: [  8/50] Step 040/520 Loss 3.000 Prec@(1,5) (41.7%, 74.5%)\u001b[0m\n",
            "[2024-04-02 19:00:57] \u001b[32mTrain: [  8/50] Step 060/520 Loss 3.008 Prec@(1,5) (41.7%, 74.3%)\u001b[0m\n",
            "[2024-04-02 19:00:57] \u001b[32mTrain: [  8/50] Step 080/520 Loss 3.036 Prec@(1,5) (41.3%, 73.9%)\u001b[0m\n",
            "[2024-04-02 19:00:58] \u001b[32mTrain: [  8/50] Step 100/520 Loss 3.042 Prec@(1,5) (41.3%, 73.6%)\u001b[0m\n",
            "[2024-04-02 19:00:58] \u001b[32mTrain: [  8/50] Step 120/520 Loss 3.043 Prec@(1,5) (41.4%, 73.5%)\u001b[0m\n",
            "[2024-04-02 19:00:59] \u001b[32mTrain: [  8/50] Step 140/520 Loss 3.034 Prec@(1,5) (41.6%, 73.4%)\u001b[0m\n",
            "[2024-04-02 19:00:59] \u001b[32mTrain: [  8/50] Step 160/520 Loss 3.038 Prec@(1,5) (41.7%, 73.4%)\u001b[0m\n",
            "[2024-04-02 19:01:00] \u001b[32mTrain: [  8/50] Step 180/520 Loss 3.047 Prec@(1,5) (41.7%, 73.2%)\u001b[0m\n",
            "[2024-04-02 19:01:00] \u001b[32mTrain: [  8/50] Step 200/520 Loss 3.047 Prec@(1,5) (41.7%, 73.1%)\u001b[0m\n",
            "[2024-04-02 19:01:01] \u001b[32mTrain: [  8/50] Step 220/520 Loss 3.041 Prec@(1,5) (41.7%, 73.2%)\u001b[0m\n",
            "[2024-04-02 19:01:01] \u001b[32mTrain: [  8/50] Step 240/520 Loss 3.043 Prec@(1,5) (41.7%, 73.2%)\u001b[0m\n",
            "[2024-04-02 19:01:02] \u001b[32mTrain: [  8/50] Step 260/520 Loss 3.042 Prec@(1,5) (41.7%, 73.2%)\u001b[0m\n",
            "[2024-04-02 19:01:02] \u001b[32mTrain: [  8/50] Step 280/520 Loss 3.045 Prec@(1,5) (41.7%, 73.2%)\u001b[0m\n",
            "[2024-04-02 19:01:03] \u001b[32mTrain: [  8/50] Step 300/520 Loss 3.043 Prec@(1,5) (41.7%, 73.2%)\u001b[0m\n",
            "[2024-04-02 19:01:03] \u001b[32mTrain: [  8/50] Step 320/520 Loss 3.039 Prec@(1,5) (41.8%, 73.3%)\u001b[0m\n",
            "[2024-04-02 19:01:04] \u001b[32mTrain: [  8/50] Step 340/520 Loss 3.032 Prec@(1,5) (41.8%, 73.4%)\u001b[0m\n",
            "[2024-04-02 19:01:04] \u001b[32mTrain: [  8/50] Step 360/520 Loss 3.034 Prec@(1,5) (41.9%, 73.3%)\u001b[0m\n",
            "[2024-04-02 19:01:05] \u001b[32mTrain: [  8/50] Step 380/520 Loss 3.035 Prec@(1,5) (41.9%, 73.4%)\u001b[0m\n",
            "[2024-04-02 19:01:05] \u001b[32mTrain: [  8/50] Step 400/520 Loss 3.031 Prec@(1,5) (41.9%, 73.4%)\u001b[0m\n",
            "[2024-04-02 19:01:06] \u001b[32mTrain: [  8/50] Step 420/520 Loss 3.031 Prec@(1,5) (41.9%, 73.5%)\u001b[0m\n",
            "[2024-04-02 19:01:06] \u001b[32mTrain: [  8/50] Step 440/520 Loss 3.028 Prec@(1,5) (41.9%, 73.6%)\u001b[0m\n",
            "[2024-04-02 19:01:07] \u001b[32mTrain: [  8/50] Step 460/520 Loss 3.028 Prec@(1,5) (41.9%, 73.6%)\u001b[0m\n",
            "[2024-04-02 19:01:07] \u001b[32mTrain: [  8/50] Step 480/520 Loss 3.027 Prec@(1,5) (41.9%, 73.6%)\u001b[0m\n",
            "[2024-04-02 19:01:08] \u001b[32mTrain: [  8/50] Step 500/520 Loss 3.024 Prec@(1,5) (42.0%, 73.6%)\u001b[0m\n",
            "[2024-04-02 19:01:08] \u001b[32mTrain: [  8/50] Step 520/520 Loss 3.027 Prec@(1,5) (41.9%, 73.6%)\u001b[0m\n",
            "[2024-04-02 19:01:08] \u001b[32mTrain: [  8/50] Final Prec@1 41.9060%\u001b[0m\n",
            "[2024-04-02 19:01:12] \u001b[32mValid: [  8/50] Step 000/104 Loss 3.074 Prec@(1,5) (40.6%, 77.1%)\u001b[0m\n",
            "[2024-04-02 19:01:12] \u001b[32mValid: [  8/50] Step 020/104 Loss 2.941 Prec@(1,5) (41.9%, 74.5%)\u001b[0m\n",
            "[2024-04-02 19:01:12] \u001b[32mValid: [  8/50] Step 040/104 Loss 2.902 Prec@(1,5) (41.7%, 74.5%)\u001b[0m\n",
            "[2024-04-02 19:01:12] \u001b[32mValid: [  8/50] Step 060/104 Loss 2.887 Prec@(1,5) (41.7%, 74.2%)\u001b[0m\n",
            "[2024-04-02 19:01:13] \u001b[32mValid: [  8/50] Step 080/104 Loss 2.901 Prec@(1,5) (41.1%, 73.9%)\u001b[0m\n",
            "[2024-04-02 19:01:13] \u001b[32mValid: [  8/50] Step 100/104 Loss 2.894 Prec@(1,5) (41.4%, 73.8%)\u001b[0m\n",
            "[2024-04-02 19:01:13] \u001b[32mValid: [  8/50] Step 104/104 Loss 2.891 Prec@(1,5) (41.5%, 73.8%)\u001b[0m\n",
            "[2024-04-02 19:01:13] \u001b[32mValid: [  8/50] Final Prec@1 41.4800%\u001b[0m\n",
            "[2024-04-02 19:01:13] \u001b[32mEpoch 8 LR 0.023454\u001b[0m\n",
            "[2024-04-02 19:01:18] \u001b[32mTrain: [  9/50] Step 000/520 Loss 2.958 Prec@(1,5) (45.8%, 74.0%)\u001b[0m\n",
            "[2024-04-02 19:01:18] \u001b[32mTrain: [  9/50] Step 020/520 Loss 2.927 Prec@(1,5) (44.2%, 74.2%)\u001b[0m\n",
            "[2024-04-02 19:01:19] \u001b[32mTrain: [  9/50] Step 040/520 Loss 2.936 Prec@(1,5) (43.7%, 74.0%)\u001b[0m\n",
            "[2024-04-02 19:01:19] \u001b[32mTrain: [  9/50] Step 060/520 Loss 2.934 Prec@(1,5) (43.9%, 74.3%)\u001b[0m\n",
            "[2024-04-02 19:01:20] \u001b[32mTrain: [  9/50] Step 080/520 Loss 2.944 Prec@(1,5) (43.2%, 74.5%)\u001b[0m\n",
            "[2024-04-02 19:01:20] \u001b[32mTrain: [  9/50] Step 100/520 Loss 2.924 Prec@(1,5) (43.7%, 74.8%)\u001b[0m\n",
            "[2024-04-02 19:01:21] \u001b[32mTrain: [  9/50] Step 120/520 Loss 2.926 Prec@(1,5) (43.7%, 74.7%)\u001b[0m\n",
            "[2024-04-02 19:01:21] \u001b[32mTrain: [  9/50] Step 140/520 Loss 2.919 Prec@(1,5) (43.9%, 74.8%)\u001b[0m\n",
            "[2024-04-02 19:01:22] \u001b[32mTrain: [  9/50] Step 160/520 Loss 2.922 Prec@(1,5) (43.9%, 74.8%)\u001b[0m\n",
            "[2024-04-02 19:01:22] \u001b[32mTrain: [  9/50] Step 180/520 Loss 2.922 Prec@(1,5) (43.9%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:01:23] \u001b[32mTrain: [  9/50] Step 200/520 Loss 2.921 Prec@(1,5) (43.8%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:01:23] \u001b[32mTrain: [  9/50] Step 220/520 Loss 2.919 Prec@(1,5) (43.8%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:01:24] \u001b[32mTrain: [  9/50] Step 240/520 Loss 2.919 Prec@(1,5) (43.7%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:01:24] \u001b[32mTrain: [  9/50] Step 260/520 Loss 2.920 Prec@(1,5) (43.7%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:01:25] \u001b[32mTrain: [  9/50] Step 280/520 Loss 2.921 Prec@(1,5) (43.6%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:01:25] \u001b[32mTrain: [  9/50] Step 300/520 Loss 2.924 Prec@(1,5) (43.6%, 74.9%)\u001b[0m\n",
            "[2024-04-02 19:01:26] \u001b[32mTrain: [  9/50] Step 320/520 Loss 2.926 Prec@(1,5) (43.6%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:01:26] \u001b[32mTrain: [  9/50] Step 340/520 Loss 2.922 Prec@(1,5) (43.7%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:01:27] \u001b[32mTrain: [  9/50] Step 360/520 Loss 2.922 Prec@(1,5) (43.6%, 75.1%)\u001b[0m\n",
            "[2024-04-02 19:01:27] \u001b[32mTrain: [  9/50] Step 380/520 Loss 2.921 Prec@(1,5) (43.6%, 75.1%)\u001b[0m\n",
            "[2024-04-02 19:01:27] \u001b[32mTrain: [  9/50] Step 400/520 Loss 2.919 Prec@(1,5) (43.7%, 75.1%)\u001b[0m\n",
            "[2024-04-02 19:01:28] \u001b[32mTrain: [  9/50] Step 420/520 Loss 2.920 Prec@(1,5) (43.6%, 75.2%)\u001b[0m\n",
            "[2024-04-02 19:01:28] \u001b[32mTrain: [  9/50] Step 440/520 Loss 2.918 Prec@(1,5) (43.6%, 75.2%)\u001b[0m\n",
            "[2024-04-02 19:01:29] \u001b[32mTrain: [  9/50] Step 460/520 Loss 2.916 Prec@(1,5) (43.7%, 75.2%)\u001b[0m\n",
            "[2024-04-02 19:01:29] \u001b[32mTrain: [  9/50] Step 480/520 Loss 2.914 Prec@(1,5) (43.8%, 75.2%)\u001b[0m\n",
            "[2024-04-02 19:01:30] \u001b[32mTrain: [  9/50] Step 500/520 Loss 2.917 Prec@(1,5) (43.8%, 75.2%)\u001b[0m\n",
            "[2024-04-02 19:01:30] \u001b[32mTrain: [  9/50] Step 520/520 Loss 2.913 Prec@(1,5) (43.9%, 75.3%)\u001b[0m\n",
            "[2024-04-02 19:01:31] \u001b[32mTrain: [  9/50] Final Prec@1 43.9180%\u001b[0m\n",
            "[2024-04-02 19:01:34] \u001b[32mValid: [  9/50] Step 000/104 Loss 2.981 Prec@(1,5) (45.8%, 71.9%)\u001b[0m\n",
            "[2024-04-02 19:01:34] \u001b[32mValid: [  9/50] Step 020/104 Loss 2.957 Prec@(1,5) (43.1%, 73.8%)\u001b[0m\n",
            "[2024-04-02 19:01:34] \u001b[32mValid: [  9/50] Step 040/104 Loss 2.952 Prec@(1,5) (42.3%, 73.9%)\u001b[0m\n",
            "[2024-04-02 19:01:35] \u001b[32mValid: [  9/50] Step 060/104 Loss 2.901 Prec@(1,5) (42.7%, 74.3%)\u001b[0m\n",
            "[2024-04-02 19:01:35] \u001b[32mValid: [  9/50] Step 080/104 Loss 2.928 Prec@(1,5) (42.2%, 74.2%)\u001b[0m\n",
            "[2024-04-02 19:01:35] \u001b[32mValid: [  9/50] Step 100/104 Loss 2.922 Prec@(1,5) (42.3%, 74.0%)\u001b[0m\n",
            "[2024-04-02 19:01:35] \u001b[32mValid: [  9/50] Step 104/104 Loss 2.922 Prec@(1,5) (42.3%, 74.1%)\u001b[0m\n",
            "[2024-04-02 19:01:35] \u001b[32mValid: [  9/50] Final Prec@1 42.2800%\u001b[0m\n",
            "[2024-04-02 19:01:35] \u001b[32mEpoch 9 LR 0.023054\u001b[0m\n",
            "[2024-04-02 19:01:40] \u001b[32mTrain: [ 10/50] Step 000/520 Loss 2.832 Prec@(1,5) (44.8%, 76.0%)\u001b[0m\n",
            "[2024-04-02 19:01:40] \u001b[32mTrain: [ 10/50] Step 020/520 Loss 2.861 Prec@(1,5) (45.1%, 75.2%)\u001b[0m\n",
            "[2024-04-02 19:01:41] \u001b[32mTrain: [ 10/50] Step 040/520 Loss 2.859 Prec@(1,5) (44.2%, 75.8%)\u001b[0m\n",
            "[2024-04-02 19:01:41] \u001b[32mTrain: [ 10/50] Step 060/520 Loss 2.856 Prec@(1,5) (44.4%, 76.3%)\u001b[0m\n",
            "[2024-04-02 19:01:42] \u001b[32mTrain: [ 10/50] Step 080/520 Loss 2.843 Prec@(1,5) (44.6%, 76.3%)\u001b[0m\n",
            "[2024-04-02 19:01:42] \u001b[32mTrain: [ 10/50] Step 100/520 Loss 2.836 Prec@(1,5) (44.8%, 76.3%)\u001b[0m\n",
            "[2024-04-02 19:01:43] \u001b[32mTrain: [ 10/50] Step 120/520 Loss 2.823 Prec@(1,5) (44.8%, 76.7%)\u001b[0m\n",
            "[2024-04-02 19:01:43] \u001b[32mTrain: [ 10/50] Step 140/520 Loss 2.827 Prec@(1,5) (44.8%, 76.5%)\u001b[0m\n",
            "[2024-04-02 19:01:44] \u001b[32mTrain: [ 10/50] Step 160/520 Loss 2.826 Prec@(1,5) (45.1%, 76.5%)\u001b[0m\n",
            "[2024-04-02 19:01:44] \u001b[32mTrain: [ 10/50] Step 180/520 Loss 2.821 Prec@(1,5) (45.1%, 76.5%)\u001b[0m\n",
            "[2024-04-02 19:01:45] \u001b[32mTrain: [ 10/50] Step 200/520 Loss 2.825 Prec@(1,5) (45.1%, 76.5%)\u001b[0m\n",
            "[2024-04-02 19:01:45] \u001b[32mTrain: [ 10/50] Step 220/520 Loss 2.820 Prec@(1,5) (45.1%, 76.5%)\u001b[0m\n",
            "[2024-04-02 19:01:46] \u001b[32mTrain: [ 10/50] Step 240/520 Loss 2.819 Prec@(1,5) (45.4%, 76.4%)\u001b[0m\n",
            "[2024-04-02 19:01:46] \u001b[32mTrain: [ 10/50] Step 260/520 Loss 2.816 Prec@(1,5) (45.4%, 76.4%)\u001b[0m\n",
            "[2024-04-02 19:01:47] \u001b[32mTrain: [ 10/50] Step 280/520 Loss 2.825 Prec@(1,5) (45.4%, 76.3%)\u001b[0m\n",
            "[2024-04-02 19:01:47] \u001b[32mTrain: [ 10/50] Step 300/520 Loss 2.831 Prec@(1,5) (45.3%, 76.3%)\u001b[0m\n",
            "[2024-04-02 19:01:48] \u001b[32mTrain: [ 10/50] Step 320/520 Loss 2.832 Prec@(1,5) (45.2%, 76.3%)\u001b[0m\n",
            "[2024-04-02 19:01:48] \u001b[32mTrain: [ 10/50] Step 340/520 Loss 2.833 Prec@(1,5) (45.2%, 76.3%)\u001b[0m\n",
            "[2024-04-02 19:01:49] \u001b[32mTrain: [ 10/50] Step 360/520 Loss 2.829 Prec@(1,5) (45.2%, 76.4%)\u001b[0m\n",
            "[2024-04-02 19:01:49] \u001b[32mTrain: [ 10/50] Step 380/520 Loss 2.826 Prec@(1,5) (45.3%, 76.4%)\u001b[0m\n",
            "[2024-04-02 19:01:50] \u001b[32mTrain: [ 10/50] Step 400/520 Loss 2.831 Prec@(1,5) (45.2%, 76.4%)\u001b[0m\n",
            "[2024-04-02 19:01:50] \u001b[32mTrain: [ 10/50] Step 420/520 Loss 2.830 Prec@(1,5) (45.1%, 76.4%)\u001b[0m\n",
            "[2024-04-02 19:01:51] \u001b[32mTrain: [ 10/50] Step 440/520 Loss 2.826 Prec@(1,5) (45.2%, 76.5%)\u001b[0m\n",
            "[2024-04-02 19:01:51] \u001b[32mTrain: [ 10/50] Step 460/520 Loss 2.826 Prec@(1,5) (45.2%, 76.5%)\u001b[0m\n",
            "[2024-04-02 19:01:52] \u001b[32mTrain: [ 10/50] Step 480/520 Loss 2.824 Prec@(1,5) (45.3%, 76.5%)\u001b[0m\n",
            "[2024-04-02 19:01:52] \u001b[32mTrain: [ 10/50] Step 500/520 Loss 2.823 Prec@(1,5) (45.3%, 76.6%)\u001b[0m\n",
            "[2024-04-02 19:01:53] \u001b[32mTrain: [ 10/50] Step 520/520 Loss 2.822 Prec@(1,5) (45.2%, 76.6%)\u001b[0m\n",
            "[2024-04-02 19:01:53] \u001b[32mTrain: [ 10/50] Final Prec@1 45.2300%\u001b[0m\n",
            "[2024-04-02 19:01:56] \u001b[32mValid: [ 10/50] Step 000/104 Loss 2.838 Prec@(1,5) (46.9%, 76.0%)\u001b[0m\n",
            "[2024-04-02 19:01:56] \u001b[32mValid: [ 10/50] Step 020/104 Loss 2.984 Prec@(1,5) (42.6%, 74.0%)\u001b[0m\n",
            "[2024-04-02 19:01:57] \u001b[32mValid: [ 10/50] Step 040/104 Loss 2.964 Prec@(1,5) (41.9%, 73.8%)\u001b[0m\n",
            "[2024-04-02 19:01:57] \u001b[32mValid: [ 10/50] Step 060/104 Loss 2.923 Prec@(1,5) (42.5%, 73.9%)\u001b[0m\n",
            "[2024-04-02 19:01:57] \u001b[32mValid: [ 10/50] Step 080/104 Loss 2.932 Prec@(1,5) (41.9%, 73.7%)\u001b[0m\n",
            "[2024-04-02 19:01:57] \u001b[32mValid: [ 10/50] Step 100/104 Loss 2.942 Prec@(1,5) (42.0%, 73.6%)\u001b[0m\n",
            "[2024-04-02 19:01:57] \u001b[32mValid: [ 10/50] Step 104/104 Loss 2.945 Prec@(1,5) (42.0%, 73.6%)\u001b[0m\n",
            "[2024-04-02 19:01:57] \u001b[32mValid: [ 10/50] Final Prec@1 42.0000%\u001b[0m\n",
            "[2024-04-02 19:01:57] \u001b[32mEpoch 10 LR 0.022613\u001b[0m\n",
            "[2024-04-02 19:02:02] \u001b[32mTrain: [ 11/50] Step 000/520 Loss 2.552 Prec@(1,5) (53.1%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:02:03] \u001b[32mTrain: [ 11/50] Step 020/520 Loss 2.613 Prec@(1,5) (47.3%, 79.5%)\u001b[0m\n",
            "[2024-04-02 19:02:03] \u001b[32mTrain: [ 11/50] Step 040/520 Loss 2.653 Prec@(1,5) (47.0%, 78.9%)\u001b[0m\n",
            "[2024-04-02 19:02:04] \u001b[32mTrain: [ 11/50] Step 060/520 Loss 2.673 Prec@(1,5) (47.0%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:02:04] \u001b[32mTrain: [ 11/50] Step 080/520 Loss 2.699 Prec@(1,5) (47.0%, 78.0%)\u001b[0m\n",
            "[2024-04-02 19:02:04] \u001b[32mTrain: [ 11/50] Step 100/520 Loss 2.701 Prec@(1,5) (47.1%, 77.8%)\u001b[0m\n",
            "[2024-04-02 19:02:05] \u001b[32mTrain: [ 11/50] Step 120/520 Loss 2.713 Prec@(1,5) (47.0%, 77.7%)\u001b[0m\n",
            "[2024-04-02 19:02:05] \u001b[32mTrain: [ 11/50] Step 140/520 Loss 2.731 Prec@(1,5) (46.8%, 77.5%)\u001b[0m\n",
            "[2024-04-02 19:02:06] \u001b[32mTrain: [ 11/50] Step 160/520 Loss 2.745 Prec@(1,5) (46.5%, 77.3%)\u001b[0m\n",
            "[2024-04-02 19:02:06] \u001b[32mTrain: [ 11/50] Step 180/520 Loss 2.748 Prec@(1,5) (46.7%, 77.2%)\u001b[0m\n",
            "[2024-04-02 19:02:07] \u001b[32mTrain: [ 11/50] Step 200/520 Loss 2.747 Prec@(1,5) (46.7%, 77.3%)\u001b[0m\n",
            "[2024-04-02 19:02:07] \u001b[32mTrain: [ 11/50] Step 220/520 Loss 2.759 Prec@(1,5) (46.5%, 77.1%)\u001b[0m\n",
            "[2024-04-02 19:02:08] \u001b[32mTrain: [ 11/50] Step 240/520 Loss 2.754 Prec@(1,5) (46.6%, 77.1%)\u001b[0m\n",
            "[2024-04-02 19:02:08] \u001b[32mTrain: [ 11/50] Step 260/520 Loss 2.755 Prec@(1,5) (46.5%, 77.1%)\u001b[0m\n",
            "[2024-04-02 19:02:09] \u001b[32mTrain: [ 11/50] Step 280/520 Loss 2.756 Prec@(1,5) (46.6%, 77.2%)\u001b[0m\n",
            "[2024-04-02 19:02:09] \u001b[32mTrain: [ 11/50] Step 300/520 Loss 2.759 Prec@(1,5) (46.6%, 77.1%)\u001b[0m\n",
            "[2024-04-02 19:02:10] \u001b[32mTrain: [ 11/50] Step 320/520 Loss 2.757 Prec@(1,5) (46.6%, 77.2%)\u001b[0m\n",
            "[2024-04-02 19:02:10] \u001b[32mTrain: [ 11/50] Step 340/520 Loss 2.759 Prec@(1,5) (46.5%, 77.2%)\u001b[0m\n",
            "[2024-04-02 19:02:11] \u001b[32mTrain: [ 11/50] Step 360/520 Loss 2.761 Prec@(1,5) (46.5%, 77.1%)\u001b[0m\n",
            "[2024-04-02 19:02:11] \u001b[32mTrain: [ 11/50] Step 380/520 Loss 2.759 Prec@(1,5) (46.6%, 77.2%)\u001b[0m\n",
            "[2024-04-02 19:02:12] \u001b[32mTrain: [ 11/50] Step 400/520 Loss 2.755 Prec@(1,5) (46.6%, 77.2%)\u001b[0m\n",
            "[2024-04-02 19:02:12] \u001b[32mTrain: [ 11/50] Step 420/520 Loss 2.755 Prec@(1,5) (46.7%, 77.2%)\u001b[0m\n",
            "[2024-04-02 19:02:13] \u001b[32mTrain: [ 11/50] Step 440/520 Loss 2.757 Prec@(1,5) (46.6%, 77.2%)\u001b[0m\n",
            "[2024-04-02 19:02:13] \u001b[32mTrain: [ 11/50] Step 460/520 Loss 2.756 Prec@(1,5) (46.6%, 77.3%)\u001b[0m\n",
            "[2024-04-02 19:02:14] \u001b[32mTrain: [ 11/50] Step 480/520 Loss 2.755 Prec@(1,5) (46.6%, 77.3%)\u001b[0m\n",
            "[2024-04-02 19:02:14] \u001b[32mTrain: [ 11/50] Step 500/520 Loss 2.757 Prec@(1,5) (46.5%, 77.2%)\u001b[0m\n",
            "[2024-04-02 19:02:15] \u001b[32mTrain: [ 11/50] Step 520/520 Loss 2.756 Prec@(1,5) (46.5%, 77.3%)\u001b[0m\n",
            "[2024-04-02 19:02:15] \u001b[32mTrain: [ 11/50] Final Prec@1 46.4960%\u001b[0m\n",
            "[2024-04-02 19:02:19] \u001b[32mValid: [ 11/50] Step 000/104 Loss 2.533 Prec@(1,5) (56.2%, 77.1%)\u001b[0m\n",
            "[2024-04-02 19:02:19] \u001b[32mValid: [ 11/50] Step 020/104 Loss 2.705 Prec@(1,5) (46.1%, 77.1%)\u001b[0m\n",
            "[2024-04-02 19:02:19] \u001b[32mValid: [ 11/50] Step 040/104 Loss 2.706 Prec@(1,5) (45.2%, 77.4%)\u001b[0m\n",
            "[2024-04-02 19:02:19] \u001b[32mValid: [ 11/50] Step 060/104 Loss 2.680 Prec@(1,5) (45.9%, 77.1%)\u001b[0m\n",
            "[2024-04-02 19:02:19] \u001b[32mValid: [ 11/50] Step 080/104 Loss 2.684 Prec@(1,5) (45.4%, 77.1%)\u001b[0m\n",
            "[2024-04-02 19:02:19] \u001b[32mValid: [ 11/50] Step 100/104 Loss 2.676 Prec@(1,5) (45.1%, 77.2%)\u001b[0m\n",
            "[2024-04-02 19:02:20] \u001b[32mValid: [ 11/50] Step 104/104 Loss 2.675 Prec@(1,5) (45.1%, 77.2%)\u001b[0m\n",
            "[2024-04-02 19:02:20] \u001b[32mValid: [ 11/50] Final Prec@1 45.1200%\u001b[0m\n",
            "[2024-04-02 19:02:20] \u001b[32mEpoch 11 LR 0.022132\u001b[0m\n",
            "[2024-04-02 19:02:24] \u001b[32mTrain: [ 12/50] Step 000/520 Loss 2.648 Prec@(1,5) (47.9%, 77.1%)\u001b[0m\n",
            "[2024-04-02 19:02:25] \u001b[32mTrain: [ 12/50] Step 020/520 Loss 2.655 Prec@(1,5) (47.8%, 78.2%)\u001b[0m\n",
            "[2024-04-02 19:02:25] \u001b[32mTrain: [ 12/50] Step 040/520 Loss 2.654 Prec@(1,5) (48.7%, 78.6%)\u001b[0m\n",
            "[2024-04-02 19:02:26] \u001b[32mTrain: [ 12/50] Step 060/520 Loss 2.642 Prec@(1,5) (48.9%, 78.9%)\u001b[0m\n",
            "[2024-04-02 19:02:26] \u001b[32mTrain: [ 12/50] Step 080/520 Loss 2.621 Prec@(1,5) (49.3%, 79.0%)\u001b[0m\n",
            "[2024-04-02 19:02:27] \u001b[32mTrain: [ 12/50] Step 100/520 Loss 2.644 Prec@(1,5) (48.9%, 78.6%)\u001b[0m\n",
            "[2024-04-02 19:02:27] \u001b[32mTrain: [ 12/50] Step 120/520 Loss 2.641 Prec@(1,5) (48.8%, 78.7%)\u001b[0m\n",
            "[2024-04-02 19:02:28] \u001b[32mTrain: [ 12/50] Step 140/520 Loss 2.644 Prec@(1,5) (48.8%, 78.6%)\u001b[0m\n",
            "[2024-04-02 19:02:28] \u001b[32mTrain: [ 12/50] Step 160/520 Loss 2.649 Prec@(1,5) (48.5%, 78.6%)\u001b[0m\n",
            "[2024-04-02 19:02:29] \u001b[32mTrain: [ 12/50] Step 180/520 Loss 2.664 Prec@(1,5) (48.4%, 78.4%)\u001b[0m\n",
            "[2024-04-02 19:02:29] \u001b[32mTrain: [ 12/50] Step 200/520 Loss 2.664 Prec@(1,5) (48.4%, 78.3%)\u001b[0m\n",
            "[2024-04-02 19:02:30] \u001b[32mTrain: [ 12/50] Step 220/520 Loss 2.663 Prec@(1,5) (48.3%, 78.4%)\u001b[0m\n",
            "[2024-04-02 19:02:30] \u001b[32mTrain: [ 12/50] Step 240/520 Loss 2.669 Prec@(1,5) (48.3%, 78.4%)\u001b[0m\n",
            "[2024-04-02 19:02:31] \u001b[32mTrain: [ 12/50] Step 260/520 Loss 2.673 Prec@(1,5) (48.1%, 78.4%)\u001b[0m\n",
            "[2024-04-02 19:02:31] \u001b[32mTrain: [ 12/50] Step 280/520 Loss 2.682 Prec@(1,5) (47.9%, 78.2%)\u001b[0m\n",
            "[2024-04-02 19:02:32] \u001b[32mTrain: [ 12/50] Step 300/520 Loss 2.683 Prec@(1,5) (47.9%, 78.2%)\u001b[0m\n",
            "[2024-04-02 19:02:32] \u001b[32mTrain: [ 12/50] Step 320/520 Loss 2.686 Prec@(1,5) (47.8%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:02:33] \u001b[32mTrain: [ 12/50] Step 340/520 Loss 2.685 Prec@(1,5) (47.9%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:02:33] \u001b[32mTrain: [ 12/50] Step 360/520 Loss 2.686 Prec@(1,5) (47.7%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:02:34] \u001b[32mTrain: [ 12/50] Step 380/520 Loss 2.686 Prec@(1,5) (47.7%, 78.2%)\u001b[0m\n",
            "[2024-04-02 19:02:34] \u001b[32mTrain: [ 12/50] Step 400/520 Loss 2.686 Prec@(1,5) (47.6%, 78.2%)\u001b[0m\n",
            "[2024-04-02 19:02:35] \u001b[32mTrain: [ 12/50] Step 420/520 Loss 2.687 Prec@(1,5) (47.6%, 78.2%)\u001b[0m\n",
            "[2024-04-02 19:02:35] \u001b[32mTrain: [ 12/50] Step 440/520 Loss 2.681 Prec@(1,5) (47.8%, 78.3%)\u001b[0m\n",
            "[2024-04-02 19:02:36] \u001b[32mTrain: [ 12/50] Step 460/520 Loss 2.681 Prec@(1,5) (47.8%, 78.3%)\u001b[0m\n",
            "[2024-04-02 19:02:36] \u001b[32mTrain: [ 12/50] Step 480/520 Loss 2.684 Prec@(1,5) (47.8%, 78.2%)\u001b[0m\n",
            "[2024-04-02 19:02:37] \u001b[32mTrain: [ 12/50] Step 500/520 Loss 2.683 Prec@(1,5) (47.8%, 78.3%)\u001b[0m\n",
            "[2024-04-02 19:02:37] \u001b[32mTrain: [ 12/50] Step 520/520 Loss 2.680 Prec@(1,5) (47.9%, 78.3%)\u001b[0m\n",
            "[2024-04-02 19:02:37] \u001b[32mTrain: [ 12/50] Final Prec@1 47.8620%\u001b[0m\n",
            "[2024-04-02 19:02:41] \u001b[32mValid: [ 12/50] Step 000/104 Loss 2.781 Prec@(1,5) (51.0%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:02:41] \u001b[32mValid: [ 12/50] Step 020/104 Loss 2.857 Prec@(1,5) (44.3%, 76.0%)\u001b[0m\n",
            "[2024-04-02 19:02:41] \u001b[32mValid: [ 12/50] Step 040/104 Loss 2.852 Prec@(1,5) (44.1%, 75.2%)\u001b[0m\n",
            "[2024-04-02 19:02:42] \u001b[32mValid: [ 12/50] Step 060/104 Loss 2.799 Prec@(1,5) (45.0%, 75.7%)\u001b[0m\n",
            "[2024-04-02 19:02:42] \u001b[32mValid: [ 12/50] Step 080/104 Loss 2.807 Prec@(1,5) (44.7%, 75.8%)\u001b[0m\n",
            "[2024-04-02 19:02:42] \u001b[32mValid: [ 12/50] Step 100/104 Loss 2.808 Prec@(1,5) (44.7%, 75.8%)\u001b[0m\n",
            "[2024-04-02 19:02:42] \u001b[32mValid: [ 12/50] Step 104/104 Loss 2.810 Prec@(1,5) (44.7%, 75.8%)\u001b[0m\n",
            "[2024-04-02 19:02:42] \u001b[32mValid: [ 12/50] Final Prec@1 44.7000%\u001b[0m\n",
            "[2024-04-02 19:02:42] \u001b[32mEpoch 12 LR 0.021612\u001b[0m\n",
            "[2024-04-02 19:02:47] \u001b[32mTrain: [ 13/50] Step 000/520 Loss 2.906 Prec@(1,5) (47.9%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:02:47] \u001b[32mTrain: [ 13/50] Step 020/520 Loss 2.578 Prec@(1,5) (48.2%, 79.7%)\u001b[0m\n",
            "[2024-04-02 19:02:48] \u001b[32mTrain: [ 13/50] Step 040/520 Loss 2.605 Prec@(1,5) (48.6%, 79.6%)\u001b[0m\n",
            "[2024-04-02 19:02:48] \u001b[32mTrain: [ 13/50] Step 060/520 Loss 2.603 Prec@(1,5) (48.6%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:02:49] \u001b[32mTrain: [ 13/50] Step 080/520 Loss 2.626 Prec@(1,5) (48.3%, 79.3%)\u001b[0m\n",
            "[2024-04-02 19:02:49] \u001b[32mTrain: [ 13/50] Step 100/520 Loss 2.624 Prec@(1,5) (48.3%, 79.4%)\u001b[0m\n",
            "[2024-04-02 19:02:50] \u001b[32mTrain: [ 13/50] Step 120/520 Loss 2.619 Prec@(1,5) (48.5%, 79.4%)\u001b[0m\n",
            "[2024-04-02 19:02:50] \u001b[32mTrain: [ 13/50] Step 140/520 Loss 2.620 Prec@(1,5) (48.5%, 79.4%)\u001b[0m\n",
            "[2024-04-02 19:02:51] \u001b[32mTrain: [ 13/50] Step 160/520 Loss 2.632 Prec@(1,5) (48.2%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:02:51] \u001b[32mTrain: [ 13/50] Step 180/520 Loss 2.635 Prec@(1,5) (48.0%, 79.3%)\u001b[0m\n",
            "[2024-04-02 19:02:52] \u001b[32mTrain: [ 13/50] Step 200/520 Loss 2.636 Prec@(1,5) (48.1%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:02:52] \u001b[32mTrain: [ 13/50] Step 220/520 Loss 2.631 Prec@(1,5) (48.2%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:02:53] \u001b[32mTrain: [ 13/50] Step 240/520 Loss 2.625 Prec@(1,5) (48.5%, 79.3%)\u001b[0m\n",
            "[2024-04-02 19:02:53] \u001b[32mTrain: [ 13/50] Step 260/520 Loss 2.627 Prec@(1,5) (48.4%, 79.3%)\u001b[0m\n",
            "[2024-04-02 19:02:54] \u001b[32mTrain: [ 13/50] Step 280/520 Loss 2.624 Prec@(1,5) (48.5%, 79.4%)\u001b[0m\n",
            "[2024-04-02 19:02:54] \u001b[32mTrain: [ 13/50] Step 300/520 Loss 2.620 Prec@(1,5) (48.5%, 79.5%)\u001b[0m\n",
            "[2024-04-02 19:02:55] \u001b[32mTrain: [ 13/50] Step 320/520 Loss 2.617 Prec@(1,5) (48.5%, 79.5%)\u001b[0m\n",
            "[2024-04-02 19:02:56] \u001b[32mTrain: [ 13/50] Step 340/520 Loss 2.619 Prec@(1,5) (48.5%, 79.5%)\u001b[0m\n",
            "[2024-04-02 19:02:56] \u001b[32mTrain: [ 13/50] Step 360/520 Loss 2.619 Prec@(1,5) (48.6%, 79.5%)\u001b[0m\n",
            "[2024-04-02 19:02:57] \u001b[32mTrain: [ 13/50] Step 380/520 Loss 2.618 Prec@(1,5) (48.6%, 79.4%)\u001b[0m\n",
            "[2024-04-02 19:02:57] \u001b[32mTrain: [ 13/50] Step 400/520 Loss 2.617 Prec@(1,5) (48.6%, 79.5%)\u001b[0m\n",
            "[2024-04-02 19:02:58] \u001b[32mTrain: [ 13/50] Step 420/520 Loss 2.620 Prec@(1,5) (48.5%, 79.4%)\u001b[0m\n",
            "[2024-04-02 19:02:58] \u001b[32mTrain: [ 13/50] Step 440/520 Loss 2.619 Prec@(1,5) (48.6%, 79.4%)\u001b[0m\n",
            "[2024-04-02 19:02:59] \u001b[32mTrain: [ 13/50] Step 460/520 Loss 2.618 Prec@(1,5) (48.6%, 79.4%)\u001b[0m\n",
            "[2024-04-02 19:02:59] \u001b[32mTrain: [ 13/50] Step 480/520 Loss 2.618 Prec@(1,5) (48.6%, 79.4%)\u001b[0m\n",
            "[2024-04-02 19:03:00] \u001b[32mTrain: [ 13/50] Step 500/520 Loss 2.618 Prec@(1,5) (48.6%, 79.4%)\u001b[0m\n",
            "[2024-04-02 19:03:00] \u001b[32mTrain: [ 13/50] Step 520/520 Loss 2.620 Prec@(1,5) (48.5%, 79.3%)\u001b[0m\n",
            "[2024-04-02 19:03:00] \u001b[32mTrain: [ 13/50] Final Prec@1 48.5140%\u001b[0m\n",
            "[2024-04-02 19:03:04] \u001b[32mValid: [ 13/50] Step 000/104 Loss 2.993 Prec@(1,5) (53.1%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:03:04] \u001b[32mValid: [ 13/50] Step 020/104 Loss 3.115 Prec@(1,5) (43.7%, 74.2%)\u001b[0m\n",
            "[2024-04-02 19:03:04] \u001b[32mValid: [ 13/50] Step 040/104 Loss 3.085 Prec@(1,5) (43.0%, 73.8%)\u001b[0m\n",
            "[2024-04-02 19:03:04] \u001b[32mValid: [ 13/50] Step 060/104 Loss 3.028 Prec@(1,5) (43.6%, 74.1%)\u001b[0m\n",
            "[2024-04-02 19:03:05] \u001b[32mValid: [ 13/50] Step 080/104 Loss 3.048 Prec@(1,5) (43.2%, 73.9%)\u001b[0m\n",
            "[2024-04-02 19:03:05] \u001b[32mValid: [ 13/50] Step 100/104 Loss 3.043 Prec@(1,5) (43.3%, 74.0%)\u001b[0m\n",
            "[2024-04-02 19:03:05] \u001b[32mValid: [ 13/50] Step 104/104 Loss 3.047 Prec@(1,5) (43.4%, 73.9%)\u001b[0m\n",
            "[2024-04-02 19:03:05] \u001b[32mValid: [ 13/50] Final Prec@1 43.3800%\u001b[0m\n",
            "[2024-04-02 19:03:05] \u001b[32mEpoch 13 LR 0.021057\u001b[0m\n",
            "[2024-04-02 19:03:10] \u001b[32mTrain: [ 14/50] Step 000/520 Loss 2.583 Prec@(1,5) (47.9%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:03:10] \u001b[32mTrain: [ 14/50] Step 020/520 Loss 2.482 Prec@(1,5) (51.1%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:03:11] \u001b[32mTrain: [ 14/50] Step 040/520 Loss 2.494 Prec@(1,5) (50.9%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:03:11] \u001b[32mTrain: [ 14/50] Step 060/520 Loss 2.525 Prec@(1,5) (50.3%, 80.1%)\u001b[0m\n",
            "[2024-04-02 19:03:12] \u001b[32mTrain: [ 14/50] Step 080/520 Loss 2.557 Prec@(1,5) (50.0%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:03:12] \u001b[32mTrain: [ 14/50] Step 100/520 Loss 2.555 Prec@(1,5) (50.2%, 79.7%)\u001b[0m\n",
            "[2024-04-02 19:03:13] \u001b[32mTrain: [ 14/50] Step 120/520 Loss 2.561 Prec@(1,5) (50.2%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:03:13] \u001b[32mTrain: [ 14/50] Step 140/520 Loss 2.562 Prec@(1,5) (50.0%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:03:14] \u001b[32mTrain: [ 14/50] Step 160/520 Loss 2.552 Prec@(1,5) (50.2%, 79.9%)\u001b[0m\n",
            "[2024-04-02 19:03:14] \u001b[32mTrain: [ 14/50] Step 180/520 Loss 2.554 Prec@(1,5) (50.1%, 79.9%)\u001b[0m\n",
            "[2024-04-02 19:03:15] \u001b[32mTrain: [ 14/50] Step 200/520 Loss 2.560 Prec@(1,5) (50.1%, 79.9%)\u001b[0m\n",
            "[2024-04-02 19:03:15] \u001b[32mTrain: [ 14/50] Step 220/520 Loss 2.561 Prec@(1,5) (50.0%, 79.9%)\u001b[0m\n",
            "[2024-04-02 19:03:16] \u001b[32mTrain: [ 14/50] Step 240/520 Loss 2.562 Prec@(1,5) (49.9%, 79.9%)\u001b[0m\n",
            "[2024-04-02 19:03:16] \u001b[32mTrain: [ 14/50] Step 260/520 Loss 2.570 Prec@(1,5) (49.8%, 79.9%)\u001b[0m\n",
            "[2024-04-02 19:03:16] \u001b[32mTrain: [ 14/50] Step 280/520 Loss 2.568 Prec@(1,5) (49.7%, 79.9%)\u001b[0m\n",
            "[2024-04-02 19:03:17] \u001b[32mTrain: [ 14/50] Step 300/520 Loss 2.572 Prec@(1,5) (49.6%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:03:17] \u001b[32mTrain: [ 14/50] Step 320/520 Loss 2.570 Prec@(1,5) (49.5%, 79.9%)\u001b[0m\n",
            "[2024-04-02 19:03:18] \u001b[32mTrain: [ 14/50] Step 340/520 Loss 2.566 Prec@(1,5) (49.6%, 79.9%)\u001b[0m\n",
            "[2024-04-02 19:03:18] \u001b[32mTrain: [ 14/50] Step 360/520 Loss 2.570 Prec@(1,5) (49.6%, 79.9%)\u001b[0m\n",
            "[2024-04-02 19:03:19] \u001b[32mTrain: [ 14/50] Step 380/520 Loss 2.575 Prec@(1,5) (49.6%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:03:19] \u001b[32mTrain: [ 14/50] Step 400/520 Loss 2.572 Prec@(1,5) (49.6%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:03:20] \u001b[32mTrain: [ 14/50] Step 420/520 Loss 2.572 Prec@(1,5) (49.6%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:03:20] \u001b[32mTrain: [ 14/50] Step 440/520 Loss 2.572 Prec@(1,5) (49.6%, 79.9%)\u001b[0m\n",
            "[2024-04-02 19:03:21] \u001b[32mTrain: [ 14/50] Step 460/520 Loss 2.570 Prec@(1,5) (49.6%, 79.9%)\u001b[0m\n",
            "[2024-04-02 19:03:21] \u001b[32mTrain: [ 14/50] Step 480/520 Loss 2.567 Prec@(1,5) (49.7%, 80.0%)\u001b[0m\n",
            "[2024-04-02 19:03:22] \u001b[32mTrain: [ 14/50] Step 500/520 Loss 2.565 Prec@(1,5) (49.7%, 80.0%)\u001b[0m\n",
            "[2024-04-02 19:03:22] \u001b[32mTrain: [ 14/50] Step 520/520 Loss 2.566 Prec@(1,5) (49.7%, 80.0%)\u001b[0m\n",
            "[2024-04-02 19:03:23] \u001b[32mTrain: [ 14/50] Final Prec@1 49.6980%\u001b[0m\n",
            "[2024-04-02 19:03:26] \u001b[32mValid: [ 14/50] Step 000/104 Loss 2.311 Prec@(1,5) (51.0%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:03:26] \u001b[32mValid: [ 14/50] Step 020/104 Loss 2.714 Prec@(1,5) (46.0%, 77.5%)\u001b[0m\n",
            "[2024-04-02 19:03:26] \u001b[32mValid: [ 14/50] Step 040/104 Loss 2.667 Prec@(1,5) (46.9%, 77.5%)\u001b[0m\n",
            "[2024-04-02 19:03:27] \u001b[32mValid: [ 14/50] Step 060/104 Loss 2.614 Prec@(1,5) (47.3%, 77.9%)\u001b[0m\n",
            "[2024-04-02 19:03:27] \u001b[32mValid: [ 14/50] Step 080/104 Loss 2.621 Prec@(1,5) (47.0%, 77.9%)\u001b[0m\n",
            "[2024-04-02 19:03:27] \u001b[32mValid: [ 14/50] Step 100/104 Loss 2.608 Prec@(1,5) (47.3%, 78.0%)\u001b[0m\n",
            "[2024-04-02 19:03:27] \u001b[32mValid: [ 14/50] Step 104/104 Loss 2.612 Prec@(1,5) (47.2%, 77.9%)\u001b[0m\n",
            "[2024-04-02 19:03:27] \u001b[32mValid: [ 14/50] Final Prec@1 47.2400%\u001b[0m\n",
            "[2024-04-02 19:03:27] \u001b[32mEpoch 14 LR 0.020468\u001b[0m\n",
            "[2024-04-02 19:03:32] \u001b[32mTrain: [ 15/50] Step 000/520 Loss 2.386 Prec@(1,5) (47.9%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:03:32] \u001b[32mTrain: [ 15/50] Step 020/520 Loss 2.464 Prec@(1,5) (50.3%, 81.6%)\u001b[0m\n",
            "[2024-04-02 19:03:33] \u001b[32mTrain: [ 15/50] Step 040/520 Loss 2.471 Prec@(1,5) (51.0%, 81.7%)\u001b[0m\n",
            "[2024-04-02 19:03:33] \u001b[32mTrain: [ 15/50] Step 060/520 Loss 2.458 Prec@(1,5) (51.5%, 81.4%)\u001b[0m\n",
            "[2024-04-02 19:03:34] \u001b[32mTrain: [ 15/50] Step 080/520 Loss 2.474 Prec@(1,5) (51.0%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:03:34] \u001b[32mTrain: [ 15/50] Step 100/520 Loss 2.483 Prec@(1,5) (50.8%, 80.8%)\u001b[0m\n",
            "[2024-04-02 19:03:35] \u001b[32mTrain: [ 15/50] Step 120/520 Loss 2.485 Prec@(1,5) (50.8%, 80.8%)\u001b[0m\n",
            "[2024-04-02 19:03:35] \u001b[32mTrain: [ 15/50] Step 140/520 Loss 2.489 Prec@(1,5) (50.8%, 80.7%)\u001b[0m\n",
            "[2024-04-02 19:03:36] \u001b[32mTrain: [ 15/50] Step 160/520 Loss 2.488 Prec@(1,5) (50.8%, 80.7%)\u001b[0m\n",
            "[2024-04-02 19:03:36] \u001b[32mTrain: [ 15/50] Step 180/520 Loss 2.487 Prec@(1,5) (50.8%, 80.7%)\u001b[0m\n",
            "[2024-04-02 19:03:37] \u001b[32mTrain: [ 15/50] Step 200/520 Loss 2.495 Prec@(1,5) (50.7%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:03:37] \u001b[32mTrain: [ 15/50] Step 220/520 Loss 2.495 Prec@(1,5) (50.7%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:03:38] \u001b[32mTrain: [ 15/50] Step 240/520 Loss 2.496 Prec@(1,5) (50.7%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:03:38] \u001b[32mTrain: [ 15/50] Step 260/520 Loss 2.496 Prec@(1,5) (50.8%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:03:39] \u001b[32mTrain: [ 15/50] Step 280/520 Loss 2.498 Prec@(1,5) (50.8%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:03:39] \u001b[32mTrain: [ 15/50] Step 300/520 Loss 2.497 Prec@(1,5) (50.8%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:03:40] \u001b[32mTrain: [ 15/50] Step 320/520 Loss 2.500 Prec@(1,5) (50.8%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:03:40] \u001b[32mTrain: [ 15/50] Step 340/520 Loss 2.496 Prec@(1,5) (50.8%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:03:41] \u001b[32mTrain: [ 15/50] Step 360/520 Loss 2.501 Prec@(1,5) (50.8%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:03:41] \u001b[32mTrain: [ 15/50] Step 380/520 Loss 2.508 Prec@(1,5) (50.7%, 80.5%)\u001b[0m\n",
            "[2024-04-02 19:03:42] \u001b[32mTrain: [ 15/50] Step 400/520 Loss 2.510 Prec@(1,5) (50.7%, 80.5%)\u001b[0m\n",
            "[2024-04-02 19:03:42] \u001b[32mTrain: [ 15/50] Step 420/520 Loss 2.512 Prec@(1,5) (50.7%, 80.5%)\u001b[0m\n",
            "[2024-04-02 19:03:43] \u001b[32mTrain: [ 15/50] Step 440/520 Loss 2.514 Prec@(1,5) (50.6%, 80.5%)\u001b[0m\n",
            "[2024-04-02 19:03:43] \u001b[32mTrain: [ 15/50] Step 460/520 Loss 2.514 Prec@(1,5) (50.6%, 80.5%)\u001b[0m\n",
            "[2024-04-02 19:03:44] \u001b[32mTrain: [ 15/50] Step 480/520 Loss 2.514 Prec@(1,5) (50.6%, 80.5%)\u001b[0m\n",
            "[2024-04-02 19:03:44] \u001b[32mTrain: [ 15/50] Step 500/520 Loss 2.514 Prec@(1,5) (50.6%, 80.5%)\u001b[0m\n",
            "[2024-04-02 19:03:45] \u001b[32mTrain: [ 15/50] Step 520/520 Loss 2.514 Prec@(1,5) (50.6%, 80.5%)\u001b[0m\n",
            "[2024-04-02 19:03:45] \u001b[32mTrain: [ 15/50] Final Prec@1 50.5560%\u001b[0m\n",
            "[2024-04-02 19:03:48] \u001b[32mValid: [ 15/50] Step 000/104 Loss 2.792 Prec@(1,5) (51.0%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:03:49] \u001b[32mValid: [ 15/50] Step 020/104 Loss 2.651 Prec@(1,5) (48.5%, 78.0%)\u001b[0m\n",
            "[2024-04-02 19:03:49] \u001b[32mValid: [ 15/50] Step 040/104 Loss 2.697 Prec@(1,5) (47.2%, 77.7%)\u001b[0m\n",
            "[2024-04-02 19:03:49] \u001b[32mValid: [ 15/50] Step 060/104 Loss 2.664 Prec@(1,5) (47.4%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:03:49] \u001b[32mValid: [ 15/50] Step 080/104 Loss 2.693 Prec@(1,5) (46.5%, 78.0%)\u001b[0m\n",
            "[2024-04-02 19:03:49] \u001b[32mValid: [ 15/50] Step 100/104 Loss 2.674 Prec@(1,5) (46.7%, 78.2%)\u001b[0m\n",
            "[2024-04-02 19:03:49] \u001b[32mValid: [ 15/50] Step 104/104 Loss 2.672 Prec@(1,5) (46.7%, 78.2%)\u001b[0m\n",
            "[2024-04-02 19:03:50] \u001b[32mValid: [ 15/50] Final Prec@1 46.7400%\u001b[0m\n",
            "[2024-04-02 19:03:50] \u001b[32mEpoch 15 LR 0.019848\u001b[0m\n",
            "[2024-04-02 19:03:54] \u001b[32mTrain: [ 16/50] Step 000/520 Loss 2.355 Prec@(1,5) (57.3%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:03:55] \u001b[32mTrain: [ 16/50] Step 020/520 Loss 2.483 Prec@(1,5) (51.7%, 80.5%)\u001b[0m\n",
            "[2024-04-02 19:03:55] \u001b[32mTrain: [ 16/50] Step 040/520 Loss 2.462 Prec@(1,5) (51.9%, 80.7%)\u001b[0m\n",
            "[2024-04-02 19:03:56] \u001b[32mTrain: [ 16/50] Step 060/520 Loss 2.428 Prec@(1,5) (52.6%, 81.4%)\u001b[0m\n",
            "[2024-04-02 19:03:56] \u001b[32mTrain: [ 16/50] Step 080/520 Loss 2.411 Prec@(1,5) (52.5%, 81.7%)\u001b[0m\n",
            "[2024-04-02 19:03:57] \u001b[32mTrain: [ 16/50] Step 100/520 Loss 2.429 Prec@(1,5) (52.3%, 81.5%)\u001b[0m\n",
            "[2024-04-02 19:03:57] \u001b[32mTrain: [ 16/50] Step 120/520 Loss 2.422 Prec@(1,5) (52.4%, 81.6%)\u001b[0m\n",
            "[2024-04-02 19:03:58] \u001b[32mTrain: [ 16/50] Step 140/520 Loss 2.426 Prec@(1,5) (52.3%, 81.6%)\u001b[0m\n",
            "[2024-04-02 19:03:58] \u001b[32mTrain: [ 16/50] Step 160/520 Loss 2.433 Prec@(1,5) (52.3%, 81.5%)\u001b[0m\n",
            "[2024-04-02 19:03:59] \u001b[32mTrain: [ 16/50] Step 180/520 Loss 2.440 Prec@(1,5) (52.1%, 81.3%)\u001b[0m\n",
            "[2024-04-02 19:03:59] \u001b[32mTrain: [ 16/50] Step 200/520 Loss 2.448 Prec@(1,5) (51.9%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:04:00] \u001b[32mTrain: [ 16/50] Step 220/520 Loss 2.449 Prec@(1,5) (51.9%, 81.3%)\u001b[0m\n",
            "[2024-04-02 19:04:00] \u001b[32mTrain: [ 16/50] Step 240/520 Loss 2.452 Prec@(1,5) (51.8%, 81.3%)\u001b[0m\n",
            "[2024-04-02 19:04:01] \u001b[32mTrain: [ 16/50] Step 260/520 Loss 2.453 Prec@(1,5) (51.8%, 81.3%)\u001b[0m\n",
            "[2024-04-02 19:04:01] \u001b[32mTrain: [ 16/50] Step 280/520 Loss 2.457 Prec@(1,5) (51.6%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:04:02] \u001b[32mTrain: [ 16/50] Step 300/520 Loss 2.457 Prec@(1,5) (51.7%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:04:02] \u001b[32mTrain: [ 16/50] Step 320/520 Loss 2.459 Prec@(1,5) (51.6%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:04:03] \u001b[32mTrain: [ 16/50] Step 340/520 Loss 2.459 Prec@(1,5) (51.5%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:04:03] \u001b[32mTrain: [ 16/50] Step 360/520 Loss 2.461 Prec@(1,5) (51.5%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:04:04] \u001b[32mTrain: [ 16/50] Step 380/520 Loss 2.463 Prec@(1,5) (51.4%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:04:04] \u001b[32mTrain: [ 16/50] Step 400/520 Loss 2.467 Prec@(1,5) (51.4%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:04:05] \u001b[32mTrain: [ 16/50] Step 420/520 Loss 2.468 Prec@(1,5) (51.3%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:04:05] \u001b[32mTrain: [ 16/50] Step 440/520 Loss 2.469 Prec@(1,5) (51.2%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:04:06] \u001b[32mTrain: [ 16/50] Step 460/520 Loss 2.473 Prec@(1,5) (51.2%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:04:06] \u001b[32mTrain: [ 16/50] Step 480/520 Loss 2.474 Prec@(1,5) (51.2%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:04:07] \u001b[32mTrain: [ 16/50] Step 500/520 Loss 2.474 Prec@(1,5) (51.2%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:04:07] \u001b[32mTrain: [ 16/50] Step 520/520 Loss 2.469 Prec@(1,5) (51.3%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:04:08] \u001b[32mTrain: [ 16/50] Final Prec@1 51.2680%\u001b[0m\n",
            "[2024-04-02 19:04:11] \u001b[32mValid: [ 16/50] Step 000/104 Loss 2.576 Prec@(1,5) (54.2%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:04:11] \u001b[32mValid: [ 16/50] Step 020/104 Loss 2.582 Prec@(1,5) (48.5%, 79.0%)\u001b[0m\n",
            "[2024-04-02 19:04:11] \u001b[32mValid: [ 16/50] Step 040/104 Loss 2.578 Prec@(1,5) (47.7%, 78.7%)\u001b[0m\n",
            "[2024-04-02 19:04:12] \u001b[32mValid: [ 16/50] Step 060/104 Loss 2.539 Prec@(1,5) (48.3%, 79.1%)\u001b[0m\n",
            "[2024-04-02 19:04:12] \u001b[32mValid: [ 16/50] Step 080/104 Loss 2.556 Prec@(1,5) (48.0%, 79.0%)\u001b[0m\n",
            "[2024-04-02 19:04:12] \u001b[32mValid: [ 16/50] Step 100/104 Loss 2.547 Prec@(1,5) (48.2%, 79.0%)\u001b[0m\n",
            "[2024-04-02 19:04:12] \u001b[32mValid: [ 16/50] Step 104/104 Loss 2.547 Prec@(1,5) (48.2%, 79.0%)\u001b[0m\n",
            "[2024-04-02 19:04:12] \u001b[32mValid: [ 16/50] Final Prec@1 48.2200%\u001b[0m\n",
            "[2024-04-02 19:04:12] \u001b[32mEpoch 16 LR 0.019198\u001b[0m\n",
            "[2024-04-02 19:04:17] \u001b[32mTrain: [ 17/50] Step 000/520 Loss 2.300 Prec@(1,5) (53.1%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:04:17] \u001b[32mTrain: [ 17/50] Step 020/520 Loss 2.354 Prec@(1,5) (53.8%, 82.1%)\u001b[0m\n",
            "[2024-04-02 19:04:18] \u001b[32mTrain: [ 17/50] Step 040/520 Loss 2.391 Prec@(1,5) (52.9%, 81.5%)\u001b[0m\n",
            "[2024-04-02 19:04:18] \u001b[32mTrain: [ 17/50] Step 060/520 Loss 2.369 Prec@(1,5) (53.1%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:04:19] \u001b[32mTrain: [ 17/50] Step 080/520 Loss 2.394 Prec@(1,5) (52.5%, 81.9%)\u001b[0m\n",
            "[2024-04-02 19:04:19] \u001b[32mTrain: [ 17/50] Step 100/520 Loss 2.396 Prec@(1,5) (52.7%, 81.9%)\u001b[0m\n",
            "[2024-04-02 19:04:20] \u001b[32mTrain: [ 17/50] Step 120/520 Loss 2.398 Prec@(1,5) (52.6%, 81.9%)\u001b[0m\n",
            "[2024-04-02 19:04:20] \u001b[32mTrain: [ 17/50] Step 140/520 Loss 2.406 Prec@(1,5) (52.4%, 81.9%)\u001b[0m\n",
            "[2024-04-02 19:04:21] \u001b[32mTrain: [ 17/50] Step 160/520 Loss 2.404 Prec@(1,5) (52.5%, 81.9%)\u001b[0m\n",
            "[2024-04-02 19:04:21] \u001b[32mTrain: [ 17/50] Step 180/520 Loss 2.406 Prec@(1,5) (52.3%, 81.9%)\u001b[0m\n",
            "[2024-04-02 19:04:22] \u001b[32mTrain: [ 17/50] Step 200/520 Loss 2.410 Prec@(1,5) (52.3%, 81.8%)\u001b[0m\n",
            "[2024-04-02 19:04:22] \u001b[32mTrain: [ 17/50] Step 220/520 Loss 2.409 Prec@(1,5) (52.4%, 81.7%)\u001b[0m\n",
            "[2024-04-02 19:04:23] \u001b[32mTrain: [ 17/50] Step 240/520 Loss 2.405 Prec@(1,5) (52.3%, 81.8%)\u001b[0m\n",
            "[2024-04-02 19:04:23] \u001b[32mTrain: [ 17/50] Step 260/520 Loss 2.409 Prec@(1,5) (52.4%, 81.8%)\u001b[0m\n",
            "[2024-04-02 19:04:24] \u001b[32mTrain: [ 17/50] Step 280/520 Loss 2.413 Prec@(1,5) (52.4%, 81.7%)\u001b[0m\n",
            "[2024-04-02 19:04:24] \u001b[32mTrain: [ 17/50] Step 300/520 Loss 2.418 Prec@(1,5) (52.3%, 81.6%)\u001b[0m\n",
            "[2024-04-02 19:04:25] \u001b[32mTrain: [ 17/50] Step 320/520 Loss 2.419 Prec@(1,5) (52.2%, 81.6%)\u001b[0m\n",
            "[2024-04-02 19:04:25] \u001b[32mTrain: [ 17/50] Step 340/520 Loss 2.419 Prec@(1,5) (52.2%, 81.7%)\u001b[0m\n",
            "[2024-04-02 19:04:26] \u001b[32mTrain: [ 17/50] Step 360/520 Loss 2.415 Prec@(1,5) (52.3%, 81.7%)\u001b[0m\n",
            "[2024-04-02 19:04:26] \u001b[32mTrain: [ 17/50] Step 380/520 Loss 2.415 Prec@(1,5) (52.2%, 81.7%)\u001b[0m\n",
            "[2024-04-02 19:04:27] \u001b[32mTrain: [ 17/50] Step 400/520 Loss 2.419 Prec@(1,5) (52.1%, 81.7%)\u001b[0m\n",
            "[2024-04-02 19:04:27] \u001b[32mTrain: [ 17/50] Step 420/520 Loss 2.417 Prec@(1,5) (52.1%, 81.7%)\u001b[0m\n",
            "[2024-04-02 19:04:28] \u001b[32mTrain: [ 17/50] Step 440/520 Loss 2.415 Prec@(1,5) (52.2%, 81.7%)\u001b[0m\n",
            "[2024-04-02 19:04:28] \u001b[32mTrain: [ 17/50] Step 460/520 Loss 2.415 Prec@(1,5) (52.2%, 81.7%)\u001b[0m\n",
            "[2024-04-02 19:04:29] \u001b[32mTrain: [ 17/50] Step 480/520 Loss 2.416 Prec@(1,5) (52.1%, 81.7%)\u001b[0m\n",
            "[2024-04-02 19:04:29] \u001b[32mTrain: [ 17/50] Step 500/520 Loss 2.417 Prec@(1,5) (52.1%, 81.8%)\u001b[0m\n",
            "[2024-04-02 19:04:30] \u001b[32mTrain: [ 17/50] Step 520/520 Loss 2.418 Prec@(1,5) (52.1%, 81.8%)\u001b[0m\n",
            "[2024-04-02 19:04:30] \u001b[32mTrain: [ 17/50] Final Prec@1 52.1240%\u001b[0m\n",
            "[2024-04-02 19:04:33] \u001b[32mValid: [ 17/50] Step 000/104 Loss 2.428 Prec@(1,5) (52.1%, 80.2%)\u001b[0m\n",
            "[2024-04-02 19:04:33] \u001b[32mValid: [ 17/50] Step 020/104 Loss 2.637 Prec@(1,5) (49.5%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:04:34] \u001b[32mValid: [ 17/50] Step 040/104 Loss 2.630 Prec@(1,5) (48.5%, 78.3%)\u001b[0m\n",
            "[2024-04-02 19:04:34] \u001b[32mValid: [ 17/50] Step 060/104 Loss 2.564 Prec@(1,5) (49.2%, 78.6%)\u001b[0m\n",
            "[2024-04-02 19:04:34] \u001b[32mValid: [ 17/50] Step 080/104 Loss 2.572 Prec@(1,5) (48.7%, 78.5%)\u001b[0m\n",
            "[2024-04-02 19:04:34] \u001b[32mValid: [ 17/50] Step 100/104 Loss 2.555 Prec@(1,5) (48.8%, 78.6%)\u001b[0m\n",
            "[2024-04-02 19:04:34] \u001b[32mValid: [ 17/50] Step 104/104 Loss 2.559 Prec@(1,5) (49.0%, 78.5%)\u001b[0m\n",
            "[2024-04-02 19:04:34] \u001b[32mValid: [ 17/50] Final Prec@1 48.9500%\u001b[0m\n",
            "[2024-04-02 19:04:34] \u001b[32mEpoch 17 LR 0.018522\u001b[0m\n",
            "[2024-04-02 19:04:39] \u001b[32mTrain: [ 18/50] Step 000/520 Loss 2.488 Prec@(1,5) (54.2%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:04:39] \u001b[32mTrain: [ 18/50] Step 020/520 Loss 2.356 Prec@(1,5) (53.2%, 81.8%)\u001b[0m\n",
            "[2024-04-02 19:04:40] \u001b[32mTrain: [ 18/50] Step 040/520 Loss 2.375 Prec@(1,5) (52.3%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:04:40] \u001b[32mTrain: [ 18/50] Step 060/520 Loss 2.377 Prec@(1,5) (52.6%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:04:41] \u001b[32mTrain: [ 18/50] Step 080/520 Loss 2.380 Prec@(1,5) (52.5%, 82.5%)\u001b[0m\n",
            "[2024-04-02 19:04:41] \u001b[32mTrain: [ 18/50] Step 100/520 Loss 2.380 Prec@(1,5) (52.6%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:04:42] \u001b[32mTrain: [ 18/50] Step 120/520 Loss 2.374 Prec@(1,5) (52.8%, 82.5%)\u001b[0m\n",
            "[2024-04-02 19:04:42] \u001b[32mTrain: [ 18/50] Step 140/520 Loss 2.386 Prec@(1,5) (52.8%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:04:43] \u001b[32mTrain: [ 18/50] Step 160/520 Loss 2.392 Prec@(1,5) (52.7%, 82.2%)\u001b[0m\n",
            "[2024-04-02 19:04:43] \u001b[32mTrain: [ 18/50] Step 180/520 Loss 2.397 Prec@(1,5) (52.7%, 82.2%)\u001b[0m\n",
            "[2024-04-02 19:04:44] \u001b[32mTrain: [ 18/50] Step 200/520 Loss 2.390 Prec@(1,5) (52.9%, 82.2%)\u001b[0m\n",
            "[2024-04-02 19:04:44] \u001b[32mTrain: [ 18/50] Step 220/520 Loss 2.392 Prec@(1,5) (52.9%, 82.1%)\u001b[0m\n",
            "[2024-04-02 19:04:45] \u001b[32mTrain: [ 18/50] Step 240/520 Loss 2.400 Prec@(1,5) (52.7%, 81.9%)\u001b[0m\n",
            "[2024-04-02 19:04:45] \u001b[32mTrain: [ 18/50] Step 260/520 Loss 2.397 Prec@(1,5) (52.7%, 81.9%)\u001b[0m\n",
            "[2024-04-02 19:04:46] \u001b[32mTrain: [ 18/50] Step 280/520 Loss 2.401 Prec@(1,5) (52.6%, 81.8%)\u001b[0m\n",
            "[2024-04-02 19:04:46] \u001b[32mTrain: [ 18/50] Step 300/520 Loss 2.400 Prec@(1,5) (52.7%, 81.9%)\u001b[0m\n",
            "[2024-04-02 19:04:47] \u001b[32mTrain: [ 18/50] Step 320/520 Loss 2.397 Prec@(1,5) (52.7%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:04:47] \u001b[32mTrain: [ 18/50] Step 340/520 Loss 2.399 Prec@(1,5) (52.7%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:04:48] \u001b[32mTrain: [ 18/50] Step 360/520 Loss 2.400 Prec@(1,5) (52.7%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:04:48] \u001b[32mTrain: [ 18/50] Step 380/520 Loss 2.402 Prec@(1,5) (52.7%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:04:49] \u001b[32mTrain: [ 18/50] Step 400/520 Loss 2.402 Prec@(1,5) (52.6%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:04:49] \u001b[32mTrain: [ 18/50] Step 420/520 Loss 2.398 Prec@(1,5) (52.7%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:04:50] \u001b[32mTrain: [ 18/50] Step 440/520 Loss 2.396 Prec@(1,5) (52.8%, 82.1%)\u001b[0m\n",
            "[2024-04-02 19:04:51] \u001b[32mTrain: [ 18/50] Step 460/520 Loss 2.394 Prec@(1,5) (52.8%, 82.1%)\u001b[0m\n",
            "[2024-04-02 19:04:51] \u001b[32mTrain: [ 18/50] Step 480/520 Loss 2.394 Prec@(1,5) (52.8%, 82.1%)\u001b[0m\n",
            "[2024-04-02 19:04:52] \u001b[32mTrain: [ 18/50] Step 500/520 Loss 2.394 Prec@(1,5) (52.8%, 82.1%)\u001b[0m\n",
            "[2024-04-02 19:04:52] \u001b[32mTrain: [ 18/50] Step 520/520 Loss 2.397 Prec@(1,5) (52.8%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:04:52] \u001b[32mTrain: [ 18/50] Final Prec@1 52.7500%\u001b[0m\n",
            "[2024-04-02 19:04:56] \u001b[32mValid: [ 18/50] Step 000/104 Loss 2.230 Prec@(1,5) (58.3%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:04:56] \u001b[32mValid: [ 18/50] Step 020/104 Loss 2.607 Prec@(1,5) (49.1%, 78.4%)\u001b[0m\n",
            "[2024-04-02 19:04:56] \u001b[32mValid: [ 18/50] Step 040/104 Loss 2.616 Prec@(1,5) (47.8%, 78.6%)\u001b[0m\n",
            "[2024-04-02 19:04:56] \u001b[32mValid: [ 18/50] Step 060/104 Loss 2.564 Prec@(1,5) (48.3%, 78.9%)\u001b[0m\n",
            "[2024-04-02 19:04:56] \u001b[32mValid: [ 18/50] Step 080/104 Loss 2.587 Prec@(1,5) (47.6%, 79.0%)\u001b[0m\n",
            "[2024-04-02 19:04:57] \u001b[32mValid: [ 18/50] Step 100/104 Loss 2.567 Prec@(1,5) (47.7%, 79.1%)\u001b[0m\n",
            "[2024-04-02 19:04:57] \u001b[32mValid: [ 18/50] Step 104/104 Loss 2.570 Prec@(1,5) (47.8%, 79.0%)\u001b[0m\n",
            "[2024-04-02 19:04:57] \u001b[32mValid: [ 18/50] Final Prec@1 47.8100%\u001b[0m\n",
            "[2024-04-02 19:04:57] \u001b[32mEpoch 18 LR 0.017823\u001b[0m\n",
            "[2024-04-02 19:05:01] \u001b[32mTrain: [ 19/50] Step 000/520 Loss 2.118 Prec@(1,5) (56.2%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:05:02] \u001b[32mTrain: [ 19/50] Step 020/520 Loss 2.261 Prec@(1,5) (54.4%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:05:02] \u001b[32mTrain: [ 19/50] Step 040/520 Loss 2.312 Prec@(1,5) (54.2%, 83.4%)\u001b[0m\n",
            "[2024-04-02 19:05:03] \u001b[32mTrain: [ 19/50] Step 060/520 Loss 2.304 Prec@(1,5) (54.7%, 83.5%)\u001b[0m\n",
            "[2024-04-02 19:05:03] \u001b[32mTrain: [ 19/50] Step 080/520 Loss 2.294 Prec@(1,5) (54.6%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:05:04] \u001b[32mTrain: [ 19/50] Step 100/520 Loss 2.303 Prec@(1,5) (54.2%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:05:04] \u001b[32mTrain: [ 19/50] Step 120/520 Loss 2.308 Prec@(1,5) (53.9%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:05:05] \u001b[32mTrain: [ 19/50] Step 140/520 Loss 2.308 Prec@(1,5) (54.2%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:05:05] \u001b[32mTrain: [ 19/50] Step 160/520 Loss 2.313 Prec@(1,5) (53.9%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:05:06] \u001b[32mTrain: [ 19/50] Step 180/520 Loss 2.313 Prec@(1,5) (54.1%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:05:06] \u001b[32mTrain: [ 19/50] Step 200/520 Loss 2.310 Prec@(1,5) (54.2%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:05:07] \u001b[32mTrain: [ 19/50] Step 220/520 Loss 2.323 Prec@(1,5) (53.9%, 82.8%)\u001b[0m\n",
            "[2024-04-02 19:05:07] \u001b[32mTrain: [ 19/50] Step 240/520 Loss 2.327 Prec@(1,5) (53.8%, 82.7%)\u001b[0m\n",
            "[2024-04-02 19:05:08] \u001b[32mTrain: [ 19/50] Step 260/520 Loss 2.324 Prec@(1,5) (53.9%, 82.8%)\u001b[0m\n",
            "[2024-04-02 19:05:08] \u001b[32mTrain: [ 19/50] Step 280/520 Loss 2.329 Prec@(1,5) (53.9%, 82.8%)\u001b[0m\n",
            "[2024-04-02 19:05:09] \u001b[32mTrain: [ 19/50] Step 300/520 Loss 2.328 Prec@(1,5) (54.0%, 82.8%)\u001b[0m\n",
            "[2024-04-02 19:05:09] \u001b[32mTrain: [ 19/50] Step 320/520 Loss 2.330 Prec@(1,5) (54.0%, 82.7%)\u001b[0m\n",
            "[2024-04-02 19:05:10] \u001b[32mTrain: [ 19/50] Step 340/520 Loss 2.333 Prec@(1,5) (53.9%, 82.6%)\u001b[0m\n",
            "[2024-04-02 19:05:10] \u001b[32mTrain: [ 19/50] Step 360/520 Loss 2.334 Prec@(1,5) (54.0%, 82.6%)\u001b[0m\n",
            "[2024-04-02 19:05:11] \u001b[32mTrain: [ 19/50] Step 380/520 Loss 2.337 Prec@(1,5) (53.9%, 82.5%)\u001b[0m\n",
            "[2024-04-02 19:05:11] \u001b[32mTrain: [ 19/50] Step 400/520 Loss 2.340 Prec@(1,5) (53.8%, 82.5%)\u001b[0m\n",
            "[2024-04-02 19:05:12] \u001b[32mTrain: [ 19/50] Step 420/520 Loss 2.337 Prec@(1,5) (53.9%, 82.5%)\u001b[0m\n",
            "[2024-04-02 19:05:12] \u001b[32mTrain: [ 19/50] Step 440/520 Loss 2.337 Prec@(1,5) (53.8%, 82.5%)\u001b[0m\n",
            "[2024-04-02 19:05:13] \u001b[32mTrain: [ 19/50] Step 460/520 Loss 2.340 Prec@(1,5) (53.7%, 82.5%)\u001b[0m\n",
            "[2024-04-02 19:05:13] \u001b[32mTrain: [ 19/50] Step 480/520 Loss 2.342 Prec@(1,5) (53.7%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:05:14] \u001b[32mTrain: [ 19/50] Step 500/520 Loss 2.343 Prec@(1,5) (53.7%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:05:15] \u001b[32mTrain: [ 19/50] Step 520/520 Loss 2.343 Prec@(1,5) (53.6%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:05:15] \u001b[32mTrain: [ 19/50] Final Prec@1 53.6460%\u001b[0m\n",
            "[2024-04-02 19:05:18] \u001b[32mValid: [ 19/50] Step 000/104 Loss 2.589 Prec@(1,5) (54.2%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:05:18] \u001b[32mValid: [ 19/50] Step 020/104 Loss 2.689 Prec@(1,5) (49.8%, 78.3%)\u001b[0m\n",
            "[2024-04-02 19:05:19] \u001b[32mValid: [ 19/50] Step 040/104 Loss 2.723 Prec@(1,5) (48.4%, 77.6%)\u001b[0m\n",
            "[2024-04-02 19:05:19] \u001b[32mValid: [ 19/50] Step 060/104 Loss 2.678 Prec@(1,5) (48.6%, 77.6%)\u001b[0m\n",
            "[2024-04-02 19:05:19] \u001b[32mValid: [ 19/50] Step 080/104 Loss 2.699 Prec@(1,5) (48.3%, 77.5%)\u001b[0m\n",
            "[2024-04-02 19:05:19] \u001b[32mValid: [ 19/50] Step 100/104 Loss 2.677 Prec@(1,5) (48.7%, 77.8%)\u001b[0m\n",
            "[2024-04-02 19:05:19] \u001b[32mValid: [ 19/50] Step 104/104 Loss 2.679 Prec@(1,5) (48.7%, 77.9%)\u001b[0m\n",
            "[2024-04-02 19:05:19] \u001b[32mValid: [ 19/50] Final Prec@1 48.7200%\u001b[0m\n",
            "[2024-04-02 19:05:19] \u001b[32mEpoch 19 LR 0.017102\u001b[0m\n",
            "[2024-04-02 19:05:24] \u001b[32mTrain: [ 20/50] Step 000/520 Loss 2.558 Prec@(1,5) (51.0%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:05:24] \u001b[32mTrain: [ 20/50] Step 020/520 Loss 2.398 Prec@(1,5) (52.9%, 83.4%)\u001b[0m\n",
            "[2024-04-02 19:05:25] \u001b[32mTrain: [ 20/50] Step 040/520 Loss 2.363 Prec@(1,5) (52.8%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:05:25] \u001b[32mTrain: [ 20/50] Step 060/520 Loss 2.340 Prec@(1,5) (53.3%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:05:26] \u001b[32mTrain: [ 20/50] Step 080/520 Loss 2.333 Prec@(1,5) (53.3%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:05:26] \u001b[32mTrain: [ 20/50] Step 100/520 Loss 2.337 Prec@(1,5) (53.3%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:05:27] \u001b[32mTrain: [ 20/50] Step 120/520 Loss 2.335 Prec@(1,5) (53.3%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:05:27] \u001b[32mTrain: [ 20/50] Step 140/520 Loss 2.320 Prec@(1,5) (53.6%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:05:28] \u001b[32mTrain: [ 20/50] Step 160/520 Loss 2.321 Prec@(1,5) (53.7%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:05:29] \u001b[32mTrain: [ 20/50] Step 180/520 Loss 2.313 Prec@(1,5) (53.9%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:05:29] \u001b[32mTrain: [ 20/50] Step 200/520 Loss 2.314 Prec@(1,5) (54.0%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:05:30] \u001b[32mTrain: [ 20/50] Step 220/520 Loss 2.312 Prec@(1,5) (54.0%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:05:30] \u001b[32mTrain: [ 20/50] Step 240/520 Loss 2.311 Prec@(1,5) (54.0%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:05:31] \u001b[32mTrain: [ 20/50] Step 260/520 Loss 2.316 Prec@(1,5) (53.9%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:05:31] \u001b[32mTrain: [ 20/50] Step 280/520 Loss 2.313 Prec@(1,5) (54.1%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:05:32] \u001b[32mTrain: [ 20/50] Step 300/520 Loss 2.307 Prec@(1,5) (54.1%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:05:32] \u001b[32mTrain: [ 20/50] Step 320/520 Loss 2.310 Prec@(1,5) (54.0%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:05:33] \u001b[32mTrain: [ 20/50] Step 340/520 Loss 2.308 Prec@(1,5) (54.1%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:05:33] \u001b[32mTrain: [ 20/50] Step 360/520 Loss 2.310 Prec@(1,5) (54.0%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:05:34] \u001b[32mTrain: [ 20/50] Step 380/520 Loss 2.311 Prec@(1,5) (54.0%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:05:34] \u001b[32mTrain: [ 20/50] Step 400/520 Loss 2.315 Prec@(1,5) (54.0%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:05:35] \u001b[32mTrain: [ 20/50] Step 420/520 Loss 2.317 Prec@(1,5) (53.9%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:05:35] \u001b[32mTrain: [ 20/50] Step 440/520 Loss 2.314 Prec@(1,5) (53.9%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:05:36] \u001b[32mTrain: [ 20/50] Step 460/520 Loss 2.316 Prec@(1,5) (53.9%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:05:36] \u001b[32mTrain: [ 20/50] Step 480/520 Loss 2.319 Prec@(1,5) (53.9%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:05:37] \u001b[32mTrain: [ 20/50] Step 500/520 Loss 2.316 Prec@(1,5) (54.0%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:05:37] \u001b[32mTrain: [ 20/50] Step 520/520 Loss 2.317 Prec@(1,5) (53.9%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:05:37] \u001b[32mTrain: [ 20/50] Final Prec@1 53.9280%\u001b[0m\n",
            "[2024-04-02 19:05:41] \u001b[32mValid: [ 20/50] Step 000/104 Loss 2.207 Prec@(1,5) (52.1%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:05:41] \u001b[32mValid: [ 20/50] Step 020/104 Loss 2.336 Prec@(1,5) (52.0%, 81.3%)\u001b[0m\n",
            "[2024-04-02 19:05:41] \u001b[32mValid: [ 20/50] Step 040/104 Loss 2.333 Prec@(1,5) (50.9%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:05:41] \u001b[32mValid: [ 20/50] Step 060/104 Loss 2.299 Prec@(1,5) (51.6%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:05:41] \u001b[32mValid: [ 20/50] Step 080/104 Loss 2.323 Prec@(1,5) (51.0%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:05:42] \u001b[32mValid: [ 20/50] Step 100/104 Loss 2.324 Prec@(1,5) (51.1%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:05:42] \u001b[32mValid: [ 20/50] Step 104/104 Loss 2.321 Prec@(1,5) (51.2%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:05:42] \u001b[32mValid: [ 20/50] Final Prec@1 51.1600%\u001b[0m\n",
            "[2024-04-02 19:05:42] \u001b[32mEpoch 20 LR 0.016363\u001b[0m\n",
            "[2024-04-02 19:05:46] \u001b[32mTrain: [ 21/50] Step 000/520 Loss 2.326 Prec@(1,5) (55.2%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:05:47] \u001b[32mTrain: [ 21/50] Step 020/520 Loss 2.262 Prec@(1,5) (54.5%, 83.6%)\u001b[0m\n",
            "[2024-04-02 19:05:47] \u001b[32mTrain: [ 21/50] Step 040/520 Loss 2.223 Prec@(1,5) (55.2%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:05:48] \u001b[32mTrain: [ 21/50] Step 060/520 Loss 2.250 Prec@(1,5) (55.0%, 83.9%)\u001b[0m\n",
            "[2024-04-02 19:05:48] \u001b[32mTrain: [ 21/50] Step 080/520 Loss 2.231 Prec@(1,5) (55.5%, 84.2%)\u001b[0m\n",
            "[2024-04-02 19:05:49] \u001b[32mTrain: [ 21/50] Step 100/520 Loss 2.232 Prec@(1,5) (55.6%, 84.3%)\u001b[0m\n",
            "[2024-04-02 19:05:49] \u001b[32mTrain: [ 21/50] Step 120/520 Loss 2.241 Prec@(1,5) (55.4%, 84.2%)\u001b[0m\n",
            "[2024-04-02 19:05:50] \u001b[32mTrain: [ 21/50] Step 140/520 Loss 2.249 Prec@(1,5) (55.1%, 84.0%)\u001b[0m\n",
            "[2024-04-02 19:05:50] \u001b[32mTrain: [ 21/50] Step 160/520 Loss 2.255 Prec@(1,5) (55.1%, 83.9%)\u001b[0m\n",
            "[2024-04-02 19:05:51] \u001b[32mTrain: [ 21/50] Step 180/520 Loss 2.253 Prec@(1,5) (55.1%, 84.0%)\u001b[0m\n",
            "[2024-04-02 19:05:51] \u001b[32mTrain: [ 21/50] Step 200/520 Loss 2.262 Prec@(1,5) (54.9%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:05:52] \u001b[32mTrain: [ 21/50] Step 220/520 Loss 2.265 Prec@(1,5) (54.9%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:05:52] \u001b[32mTrain: [ 21/50] Step 240/520 Loss 2.259 Prec@(1,5) (55.1%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:05:53] \u001b[32mTrain: [ 21/50] Step 260/520 Loss 2.258 Prec@(1,5) (55.1%, 83.7%)\u001b[0m\n",
            "[2024-04-02 19:05:53] \u001b[32mTrain: [ 21/50] Step 280/520 Loss 2.259 Prec@(1,5) (55.2%, 83.7%)\u001b[0m\n",
            "[2024-04-02 19:05:54] \u001b[32mTrain: [ 21/50] Step 300/520 Loss 2.261 Prec@(1,5) (55.1%, 83.6%)\u001b[0m\n",
            "[2024-04-02 19:05:54] \u001b[32mTrain: [ 21/50] Step 320/520 Loss 2.264 Prec@(1,5) (55.0%, 83.6%)\u001b[0m\n",
            "[2024-04-02 19:05:55] \u001b[32mTrain: [ 21/50] Step 340/520 Loss 2.269 Prec@(1,5) (54.9%, 83.5%)\u001b[0m\n",
            "[2024-04-02 19:05:55] \u001b[32mTrain: [ 21/50] Step 360/520 Loss 2.275 Prec@(1,5) (54.7%, 83.4%)\u001b[0m\n",
            "[2024-04-02 19:05:56] \u001b[32mTrain: [ 21/50] Step 380/520 Loss 2.279 Prec@(1,5) (54.7%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:05:56] \u001b[32mTrain: [ 21/50] Step 400/520 Loss 2.279 Prec@(1,5) (54.7%, 83.4%)\u001b[0m\n",
            "[2024-04-02 19:05:57] \u001b[32mTrain: [ 21/50] Step 420/520 Loss 2.278 Prec@(1,5) (54.7%, 83.4%)\u001b[0m\n",
            "[2024-04-02 19:05:57] \u001b[32mTrain: [ 21/50] Step 440/520 Loss 2.277 Prec@(1,5) (54.7%, 83.4%)\u001b[0m\n",
            "[2024-04-02 19:05:58] \u001b[32mTrain: [ 21/50] Step 460/520 Loss 2.280 Prec@(1,5) (54.6%, 83.4%)\u001b[0m\n",
            "[2024-04-02 19:05:58] \u001b[32mTrain: [ 21/50] Step 480/520 Loss 2.284 Prec@(1,5) (54.6%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:05:59] \u001b[32mTrain: [ 21/50] Step 500/520 Loss 2.285 Prec@(1,5) (54.6%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:05:59] \u001b[32mTrain: [ 21/50] Step 520/520 Loss 2.284 Prec@(1,5) (54.6%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:05:59] \u001b[32mTrain: [ 21/50] Final Prec@1 54.6320%\u001b[0m\n",
            "[2024-04-02 19:06:03] \u001b[32mValid: [ 21/50] Step 000/104 Loss 2.216 Prec@(1,5) (54.2%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:06:03] \u001b[32mValid: [ 21/50] Step 020/104 Loss 2.477 Prec@(1,5) (50.2%, 80.4%)\u001b[0m\n",
            "[2024-04-02 19:06:03] \u001b[32mValid: [ 21/50] Step 040/104 Loss 2.452 Prec@(1,5) (49.7%, 80.0%)\u001b[0m\n",
            "[2024-04-02 19:06:03] \u001b[32mValid: [ 21/50] Step 060/104 Loss 2.402 Prec@(1,5) (50.5%, 80.3%)\u001b[0m\n",
            "[2024-04-02 19:06:03] \u001b[32mValid: [ 21/50] Step 080/104 Loss 2.419 Prec@(1,5) (50.0%, 80.1%)\u001b[0m\n",
            "[2024-04-02 19:06:04] \u001b[32mValid: [ 21/50] Step 100/104 Loss 2.407 Prec@(1,5) (50.2%, 80.3%)\u001b[0m\n",
            "[2024-04-02 19:06:04] \u001b[32mValid: [ 21/50] Step 104/104 Loss 2.408 Prec@(1,5) (50.2%, 80.2%)\u001b[0m\n",
            "[2024-04-02 19:06:04] \u001b[32mValid: [ 21/50] Final Prec@1 50.2400%\u001b[0m\n",
            "[2024-04-02 19:06:04] \u001b[32mEpoch 21 LR 0.015609\u001b[0m\n",
            "[2024-04-02 19:06:08] \u001b[32mTrain: [ 22/50] Step 000/520 Loss 2.138 Prec@(1,5) (63.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:06:09] \u001b[32mTrain: [ 22/50] Step 020/520 Loss 2.214 Prec@(1,5) (55.2%, 84.1%)\u001b[0m\n",
            "[2024-04-02 19:06:09] \u001b[32mTrain: [ 22/50] Step 040/520 Loss 2.212 Prec@(1,5) (55.1%, 83.9%)\u001b[0m\n",
            "[2024-04-02 19:06:10] \u001b[32mTrain: [ 22/50] Step 060/520 Loss 2.209 Prec@(1,5) (55.1%, 84.2%)\u001b[0m\n",
            "[2024-04-02 19:06:10] \u001b[32mTrain: [ 22/50] Step 080/520 Loss 2.229 Prec@(1,5) (55.0%, 84.1%)\u001b[0m\n",
            "[2024-04-02 19:06:11] \u001b[32mTrain: [ 22/50] Step 100/520 Loss 2.220 Prec@(1,5) (55.3%, 84.2%)\u001b[0m\n",
            "[2024-04-02 19:06:11] \u001b[32mTrain: [ 22/50] Step 120/520 Loss 2.229 Prec@(1,5) (55.0%, 84.0%)\u001b[0m\n",
            "[2024-04-02 19:06:12] \u001b[32mTrain: [ 22/50] Step 140/520 Loss 2.227 Prec@(1,5) (55.1%, 84.0%)\u001b[0m\n",
            "[2024-04-02 19:06:12] \u001b[32mTrain: [ 22/50] Step 160/520 Loss 2.239 Prec@(1,5) (55.1%, 83.7%)\u001b[0m\n",
            "[2024-04-02 19:06:13] \u001b[32mTrain: [ 22/50] Step 180/520 Loss 2.237 Prec@(1,5) (55.3%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:06:13] \u001b[32mTrain: [ 22/50] Step 200/520 Loss 2.234 Prec@(1,5) (55.5%, 83.9%)\u001b[0m\n",
            "[2024-04-02 19:06:14] \u001b[32mTrain: [ 22/50] Step 220/520 Loss 2.238 Prec@(1,5) (55.4%, 83.9%)\u001b[0m\n",
            "[2024-04-02 19:06:14] \u001b[32mTrain: [ 22/50] Step 240/520 Loss 2.241 Prec@(1,5) (55.4%, 83.9%)\u001b[0m\n",
            "[2024-04-02 19:06:15] \u001b[32mTrain: [ 22/50] Step 260/520 Loss 2.243 Prec@(1,5) (55.3%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:06:15] \u001b[32mTrain: [ 22/50] Step 280/520 Loss 2.245 Prec@(1,5) (55.2%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:06:16] \u001b[32mTrain: [ 22/50] Step 300/520 Loss 2.243 Prec@(1,5) (55.3%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:06:16] \u001b[32mTrain: [ 22/50] Step 320/520 Loss 2.243 Prec@(1,5) (55.3%, 83.9%)\u001b[0m\n",
            "[2024-04-02 19:06:17] \u001b[32mTrain: [ 22/50] Step 340/520 Loss 2.247 Prec@(1,5) (55.2%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:06:17] \u001b[32mTrain: [ 22/50] Step 360/520 Loss 2.245 Prec@(1,5) (55.3%, 83.9%)\u001b[0m\n",
            "[2024-04-02 19:06:18] \u001b[32mTrain: [ 22/50] Step 380/520 Loss 2.249 Prec@(1,5) (55.2%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:06:18] \u001b[32mTrain: [ 22/50] Step 400/520 Loss 2.253 Prec@(1,5) (55.2%, 83.7%)\u001b[0m\n",
            "[2024-04-02 19:06:19] \u001b[32mTrain: [ 22/50] Step 420/520 Loss 2.254 Prec@(1,5) (55.1%, 83.7%)\u001b[0m\n",
            "[2024-04-02 19:06:19] \u001b[32mTrain: [ 22/50] Step 440/520 Loss 2.252 Prec@(1,5) (55.2%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:06:20] \u001b[32mTrain: [ 22/50] Step 460/520 Loss 2.254 Prec@(1,5) (55.1%, 83.7%)\u001b[0m\n",
            "[2024-04-02 19:06:20] \u001b[32mTrain: [ 22/50] Step 480/520 Loss 2.254 Prec@(1,5) (55.1%, 83.7%)\u001b[0m\n",
            "[2024-04-02 19:06:21] \u001b[32mTrain: [ 22/50] Step 500/520 Loss 2.254 Prec@(1,5) (55.1%, 83.7%)\u001b[0m\n",
            "[2024-04-02 19:06:21] \u001b[32mTrain: [ 22/50] Step 520/520 Loss 2.255 Prec@(1,5) (55.1%, 83.7%)\u001b[0m\n",
            "[2024-04-02 19:06:21] \u001b[32mTrain: [ 22/50] Final Prec@1 55.1360%\u001b[0m\n",
            "[2024-04-02 19:06:25] \u001b[32mValid: [ 22/50] Step 000/104 Loss 2.238 Prec@(1,5) (52.1%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:06:25] \u001b[32mValid: [ 22/50] Step 020/104 Loss 2.474 Prec@(1,5) (50.4%, 80.0%)\u001b[0m\n",
            "[2024-04-02 19:06:25] \u001b[32mValid: [ 22/50] Step 040/104 Loss 2.479 Prec@(1,5) (49.6%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:06:25] \u001b[32mValid: [ 22/50] Step 060/104 Loss 2.442 Prec@(1,5) (50.7%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:06:26] \u001b[32mValid: [ 22/50] Step 080/104 Loss 2.454 Prec@(1,5) (50.2%, 80.8%)\u001b[0m\n",
            "[2024-04-02 19:06:26] \u001b[32mValid: [ 22/50] Step 100/104 Loss 2.449 Prec@(1,5) (50.3%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:06:26] \u001b[32mValid: [ 22/50] Step 104/104 Loss 2.453 Prec@(1,5) (50.3%, 80.8%)\u001b[0m\n",
            "[2024-04-02 19:06:26] \u001b[32mValid: [ 22/50] Final Prec@1 50.3000%\u001b[0m\n",
            "[2024-04-02 19:06:26] \u001b[32mEpoch 22 LR 0.014843\u001b[0m\n",
            "[2024-04-02 19:06:31] \u001b[32mTrain: [ 23/50] Step 000/520 Loss 2.370 Prec@(1,5) (47.9%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:06:31] \u001b[32mTrain: [ 23/50] Step 020/520 Loss 2.177 Prec@(1,5) (56.4%, 84.1%)\u001b[0m\n",
            "[2024-04-02 19:06:31] \u001b[32mTrain: [ 23/50] Step 040/520 Loss 2.154 Prec@(1,5) (56.7%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:06:32] \u001b[32mTrain: [ 23/50] Step 060/520 Loss 2.153 Prec@(1,5) (56.7%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:06:32] \u001b[32mTrain: [ 23/50] Step 080/520 Loss 2.162 Prec@(1,5) (56.3%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:06:33] \u001b[32mTrain: [ 23/50] Step 100/520 Loss 2.163 Prec@(1,5) (56.1%, 85.0%)\u001b[0m\n",
            "[2024-04-02 19:06:33] \u001b[32mTrain: [ 23/50] Step 120/520 Loss 2.168 Prec@(1,5) (56.5%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:06:34] \u001b[32mTrain: [ 23/50] Step 140/520 Loss 2.179 Prec@(1,5) (56.3%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:06:34] \u001b[32mTrain: [ 23/50] Step 160/520 Loss 2.191 Prec@(1,5) (56.2%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:06:35] \u001b[32mTrain: [ 23/50] Step 180/520 Loss 2.184 Prec@(1,5) (56.2%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:06:35] \u001b[32mTrain: [ 23/50] Step 200/520 Loss 2.192 Prec@(1,5) (56.1%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:06:36] \u001b[32mTrain: [ 23/50] Step 220/520 Loss 2.199 Prec@(1,5) (55.9%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:06:36] \u001b[32mTrain: [ 23/50] Step 240/520 Loss 2.203 Prec@(1,5) (55.9%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:06:37] \u001b[32mTrain: [ 23/50] Step 260/520 Loss 2.202 Prec@(1,5) (55.9%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:06:37] \u001b[32mTrain: [ 23/50] Step 280/520 Loss 2.204 Prec@(1,5) (55.9%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:06:38] \u001b[32mTrain: [ 23/50] Step 300/520 Loss 2.202 Prec@(1,5) (56.0%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:06:38] \u001b[32mTrain: [ 23/50] Step 320/520 Loss 2.208 Prec@(1,5) (55.8%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:06:39] \u001b[32mTrain: [ 23/50] Step 340/520 Loss 2.213 Prec@(1,5) (55.8%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:06:39] \u001b[32mTrain: [ 23/50] Step 360/520 Loss 2.214 Prec@(1,5) (55.7%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:06:40] \u001b[32mTrain: [ 23/50] Step 380/520 Loss 2.220 Prec@(1,5) (55.6%, 84.3%)\u001b[0m\n",
            "[2024-04-02 19:06:40] \u001b[32mTrain: [ 23/50] Step 400/520 Loss 2.218 Prec@(1,5) (55.7%, 84.3%)\u001b[0m\n",
            "[2024-04-02 19:06:41] \u001b[32mTrain: [ 23/50] Step 420/520 Loss 2.218 Prec@(1,5) (55.7%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:06:41] \u001b[32mTrain: [ 23/50] Step 440/520 Loss 2.220 Prec@(1,5) (55.6%, 84.3%)\u001b[0m\n",
            "[2024-04-02 19:06:42] \u001b[32mTrain: [ 23/50] Step 460/520 Loss 2.222 Prec@(1,5) (55.6%, 84.3%)\u001b[0m\n",
            "[2024-04-02 19:06:42] \u001b[32mTrain: [ 23/50] Step 480/520 Loss 2.224 Prec@(1,5) (55.6%, 84.3%)\u001b[0m\n",
            "[2024-04-02 19:06:43] \u001b[32mTrain: [ 23/50] Step 500/520 Loss 2.223 Prec@(1,5) (55.6%, 84.2%)\u001b[0m\n",
            "[2024-04-02 19:06:43] \u001b[32mTrain: [ 23/50] Step 520/520 Loss 2.225 Prec@(1,5) (55.6%, 84.2%)\u001b[0m\n",
            "[2024-04-02 19:06:44] \u001b[32mTrain: [ 23/50] Final Prec@1 55.5620%\u001b[0m\n",
            "[2024-04-02 19:06:47] \u001b[32mValid: [ 23/50] Step 000/104 Loss 2.258 Prec@(1,5) (54.2%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:06:47] \u001b[32mValid: [ 23/50] Step 020/104 Loss 2.344 Prec@(1,5) (52.5%, 81.4%)\u001b[0m\n",
            "[2024-04-02 19:06:47] \u001b[32mValid: [ 23/50] Step 040/104 Loss 2.351 Prec@(1,5) (51.8%, 81.7%)\u001b[0m\n",
            "[2024-04-02 19:06:48] \u001b[32mValid: [ 23/50] Step 060/104 Loss 2.315 Prec@(1,5) (52.5%, 81.8%)\u001b[0m\n",
            "[2024-04-02 19:06:48] \u001b[32mValid: [ 23/50] Step 080/104 Loss 2.334 Prec@(1,5) (51.9%, 81.6%)\u001b[0m\n",
            "[2024-04-02 19:06:48] \u001b[32mValid: [ 23/50] Step 100/104 Loss 2.337 Prec@(1,5) (51.9%, 81.7%)\u001b[0m\n",
            "[2024-04-02 19:06:48] \u001b[32mValid: [ 23/50] Step 104/104 Loss 2.336 Prec@(1,5) (51.9%, 81.6%)\u001b[0m\n",
            "[2024-04-02 19:06:48] \u001b[32mValid: [ 23/50] Final Prec@1 51.9000%\u001b[0m\n",
            "[2024-04-02 19:06:48] \u001b[32mEpoch 23 LR 0.014067\u001b[0m\n",
            "[2024-04-02 19:06:53] \u001b[32mTrain: [ 24/50] Step 000/520 Loss 2.569 Prec@(1,5) (43.8%, 80.2%)\u001b[0m\n",
            "[2024-04-02 19:06:53] \u001b[32mTrain: [ 24/50] Step 020/520 Loss 2.196 Prec@(1,5) (55.3%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:06:54] \u001b[32mTrain: [ 24/50] Step 040/520 Loss 2.200 Prec@(1,5) (55.9%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:06:54] \u001b[32mTrain: [ 24/50] Step 060/520 Loss 2.193 Prec@(1,5) (56.4%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:06:55] \u001b[32mTrain: [ 24/50] Step 080/520 Loss 2.195 Prec@(1,5) (56.1%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:06:55] \u001b[32mTrain: [ 24/50] Step 100/520 Loss 2.176 Prec@(1,5) (56.5%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:06:56] \u001b[32mTrain: [ 24/50] Step 120/520 Loss 2.174 Prec@(1,5) (56.5%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:06:56] \u001b[32mTrain: [ 24/50] Step 140/520 Loss 2.171 Prec@(1,5) (56.7%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:06:57] \u001b[32mTrain: [ 24/50] Step 160/520 Loss 2.173 Prec@(1,5) (56.7%, 85.0%)\u001b[0m\n",
            "[2024-04-02 19:06:57] \u001b[32mTrain: [ 24/50] Step 180/520 Loss 2.173 Prec@(1,5) (56.7%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:06:58] \u001b[32mTrain: [ 24/50] Step 200/520 Loss 2.175 Prec@(1,5) (56.8%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:06:58] \u001b[32mTrain: [ 24/50] Step 220/520 Loss 2.180 Prec@(1,5) (56.8%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:06:59] \u001b[32mTrain: [ 24/50] Step 240/520 Loss 2.176 Prec@(1,5) (56.7%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:06:59] \u001b[32mTrain: [ 24/50] Step 260/520 Loss 2.176 Prec@(1,5) (56.7%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:07:00] \u001b[32mTrain: [ 24/50] Step 280/520 Loss 2.173 Prec@(1,5) (56.7%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:07:00] \u001b[32mTrain: [ 24/50] Step 300/520 Loss 2.174 Prec@(1,5) (56.6%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:07:01] \u001b[32mTrain: [ 24/50] Step 320/520 Loss 2.177 Prec@(1,5) (56.5%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:07:01] \u001b[32mTrain: [ 24/50] Step 340/520 Loss 2.175 Prec@(1,5) (56.6%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:07:02] \u001b[32mTrain: [ 24/50] Step 360/520 Loss 2.175 Prec@(1,5) (56.7%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:07:02] \u001b[32mTrain: [ 24/50] Step 380/520 Loss 2.176 Prec@(1,5) (56.6%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:07:03] \u001b[32mTrain: [ 24/50] Step 400/520 Loss 2.177 Prec@(1,5) (56.6%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:07:03] \u001b[32mTrain: [ 24/50] Step 420/520 Loss 2.176 Prec@(1,5) (56.7%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:07:04] \u001b[32mTrain: [ 24/50] Step 440/520 Loss 2.180 Prec@(1,5) (56.6%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:07:04] \u001b[32mTrain: [ 24/50] Step 460/520 Loss 2.183 Prec@(1,5) (56.5%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:07:05] \u001b[32mTrain: [ 24/50] Step 480/520 Loss 2.186 Prec@(1,5) (56.5%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:07:05] \u001b[32mTrain: [ 24/50] Step 500/520 Loss 2.186 Prec@(1,5) (56.5%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:07:06] \u001b[32mTrain: [ 24/50] Step 520/520 Loss 2.186 Prec@(1,5) (56.4%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:07:06] \u001b[32mTrain: [ 24/50] Final Prec@1 56.4420%\u001b[0m\n",
            "[2024-04-02 19:07:09] \u001b[32mValid: [ 24/50] Step 000/104 Loss 2.366 Prec@(1,5) (56.2%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:07:09] \u001b[32mValid: [ 24/50] Step 020/104 Loss 2.688 Prec@(1,5) (49.7%, 79.5%)\u001b[0m\n",
            "[2024-04-02 19:07:10] \u001b[32mValid: [ 24/50] Step 040/104 Loss 2.642 Prec@(1,5) (49.8%, 78.7%)\u001b[0m\n",
            "[2024-04-02 19:07:10] \u001b[32mValid: [ 24/50] Step 060/104 Loss 2.593 Prec@(1,5) (50.4%, 79.1%)\u001b[0m\n",
            "[2024-04-02 19:07:10] \u001b[32mValid: [ 24/50] Step 080/104 Loss 2.591 Prec@(1,5) (50.1%, 79.1%)\u001b[0m\n",
            "[2024-04-02 19:07:10] \u001b[32mValid: [ 24/50] Step 100/104 Loss 2.574 Prec@(1,5) (50.3%, 79.4%)\u001b[0m\n",
            "[2024-04-02 19:07:10] \u001b[32mValid: [ 24/50] Step 104/104 Loss 2.577 Prec@(1,5) (50.2%, 79.3%)\u001b[0m\n",
            "[2024-04-02 19:07:10] \u001b[32mValid: [ 24/50] Final Prec@1 50.2100%\u001b[0m\n",
            "[2024-04-02 19:07:10] \u001b[32mEpoch 24 LR 0.013285\u001b[0m\n",
            "[2024-04-02 19:07:15] \u001b[32mTrain: [ 25/50] Step 000/520 Loss 1.834 Prec@(1,5) (68.8%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:07:15] \u001b[32mTrain: [ 25/50] Step 020/520 Loss 2.070 Prec@(1,5) (59.5%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:07:16] \u001b[32mTrain: [ 25/50] Step 040/520 Loss 2.112 Prec@(1,5) (58.6%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:07:16] \u001b[32mTrain: [ 25/50] Step 060/520 Loss 2.156 Prec@(1,5) (57.6%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:07:17] \u001b[32mTrain: [ 25/50] Step 080/520 Loss 2.148 Prec@(1,5) (57.7%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:07:17] \u001b[32mTrain: [ 25/50] Step 100/520 Loss 2.159 Prec@(1,5) (57.4%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:07:18] \u001b[32mTrain: [ 25/50] Step 120/520 Loss 2.172 Prec@(1,5) (56.8%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:07:18] \u001b[32mTrain: [ 25/50] Step 140/520 Loss 2.169 Prec@(1,5) (56.9%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:07:19] \u001b[32mTrain: [ 25/50] Step 160/520 Loss 2.169 Prec@(1,5) (57.0%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:07:19] \u001b[32mTrain: [ 25/50] Step 180/520 Loss 2.168 Prec@(1,5) (56.9%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:07:20] \u001b[32mTrain: [ 25/50] Step 200/520 Loss 2.169 Prec@(1,5) (56.9%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:07:20] \u001b[32mTrain: [ 25/50] Step 220/520 Loss 2.174 Prec@(1,5) (56.9%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:07:21] \u001b[32mTrain: [ 25/50] Step 240/520 Loss 2.179 Prec@(1,5) (56.9%, 84.3%)\u001b[0m\n",
            "[2024-04-02 19:07:21] \u001b[32mTrain: [ 25/50] Step 260/520 Loss 2.171 Prec@(1,5) (57.0%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:07:22] \u001b[32mTrain: [ 25/50] Step 280/520 Loss 2.168 Prec@(1,5) (57.1%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:07:22] \u001b[32mTrain: [ 25/50] Step 300/520 Loss 2.169 Prec@(1,5) (57.0%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:07:23] \u001b[32mTrain: [ 25/50] Step 320/520 Loss 2.171 Prec@(1,5) (57.0%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:07:23] \u001b[32mTrain: [ 25/50] Step 340/520 Loss 2.169 Prec@(1,5) (57.0%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:07:24] \u001b[32mTrain: [ 25/50] Step 360/520 Loss 2.172 Prec@(1,5) (56.9%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:07:24] \u001b[32mTrain: [ 25/50] Step 380/520 Loss 2.169 Prec@(1,5) (57.0%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:07:25] \u001b[32mTrain: [ 25/50] Step 400/520 Loss 2.172 Prec@(1,5) (56.8%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:07:25] \u001b[32mTrain: [ 25/50] Step 420/520 Loss 2.177 Prec@(1,5) (56.8%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:07:26] \u001b[32mTrain: [ 25/50] Step 440/520 Loss 2.173 Prec@(1,5) (56.8%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:07:26] \u001b[32mTrain: [ 25/50] Step 460/520 Loss 2.170 Prec@(1,5) (56.9%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:07:27] \u001b[32mTrain: [ 25/50] Step 480/520 Loss 2.172 Prec@(1,5) (56.8%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:07:27] \u001b[32mTrain: [ 25/50] Step 500/520 Loss 2.169 Prec@(1,5) (56.9%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:07:28] \u001b[32mTrain: [ 25/50] Step 520/520 Loss 2.168 Prec@(1,5) (56.9%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:07:28] \u001b[32mTrain: [ 25/50] Final Prec@1 56.8760%\u001b[0m\n",
            "[2024-04-02 19:07:31] \u001b[32mValid: [ 25/50] Step 000/104 Loss 2.287 Prec@(1,5) (58.3%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:07:32] \u001b[32mValid: [ 25/50] Step 020/104 Loss 2.322 Prec@(1,5) (54.0%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:07:32] \u001b[32mValid: [ 25/50] Step 040/104 Loss 2.343 Prec@(1,5) (52.4%, 82.2%)\u001b[0m\n",
            "[2024-04-02 19:07:32] \u001b[32mValid: [ 25/50] Step 060/104 Loss 2.282 Prec@(1,5) (53.1%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:07:32] \u001b[32mValid: [ 25/50] Step 080/104 Loss 2.292 Prec@(1,5) (52.7%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:07:32] \u001b[32mValid: [ 25/50] Step 100/104 Loss 2.288 Prec@(1,5) (52.9%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:07:32] \u001b[32mValid: [ 25/50] Step 104/104 Loss 2.285 Prec@(1,5) (53.0%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:07:32] \u001b[32mValid: [ 25/50] Final Prec@1 52.9500%\u001b[0m\n",
            "[2024-04-02 19:07:32] \u001b[32mEpoch 25 LR 0.012500\u001b[0m\n",
            "[2024-04-02 19:07:37] \u001b[32mTrain: [ 26/50] Step 000/520 Loss 2.203 Prec@(1,5) (51.0%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:07:38] \u001b[32mTrain: [ 26/50] Step 020/520 Loss 2.068 Prec@(1,5) (57.5%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:07:38] \u001b[32mTrain: [ 26/50] Step 040/520 Loss 2.060 Prec@(1,5) (57.5%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:07:39] \u001b[32mTrain: [ 26/50] Step 060/520 Loss 2.068 Prec@(1,5) (57.8%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:07:39] \u001b[32mTrain: [ 26/50] Step 080/520 Loss 2.086 Prec@(1,5) (57.6%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:07:40] \u001b[32mTrain: [ 26/50] Step 100/520 Loss 2.090 Prec@(1,5) (57.5%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:07:40] \u001b[32mTrain: [ 26/50] Step 120/520 Loss 2.111 Prec@(1,5) (57.1%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:07:41] \u001b[32mTrain: [ 26/50] Step 140/520 Loss 2.118 Prec@(1,5) (57.0%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:07:41] \u001b[32mTrain: [ 26/50] Step 160/520 Loss 2.124 Prec@(1,5) (57.0%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:07:42] \u001b[32mTrain: [ 26/50] Step 180/520 Loss 2.125 Prec@(1,5) (57.1%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:07:42] \u001b[32mTrain: [ 26/50] Step 200/520 Loss 2.119 Prec@(1,5) (57.3%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:07:43] \u001b[32mTrain: [ 26/50] Step 220/520 Loss 2.119 Prec@(1,5) (57.3%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:07:43] \u001b[32mTrain: [ 26/50] Step 240/520 Loss 2.126 Prec@(1,5) (57.3%, 85.2%)\u001b[0m\n",
            "[2024-04-02 19:07:44] \u001b[32mTrain: [ 26/50] Step 260/520 Loss 2.127 Prec@(1,5) (57.3%, 85.3%)\u001b[0m\n",
            "[2024-04-02 19:07:44] \u001b[32mTrain: [ 26/50] Step 280/520 Loss 2.129 Prec@(1,5) (57.3%, 85.2%)\u001b[0m\n",
            "[2024-04-02 19:07:45] \u001b[32mTrain: [ 26/50] Step 300/520 Loss 2.137 Prec@(1,5) (57.2%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:07:45] \u001b[32mTrain: [ 26/50] Step 320/520 Loss 2.137 Prec@(1,5) (57.2%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:07:45] \u001b[32mTrain: [ 26/50] Step 340/520 Loss 2.134 Prec@(1,5) (57.3%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:07:46] \u001b[32mTrain: [ 26/50] Step 360/520 Loss 2.136 Prec@(1,5) (57.3%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:07:46] \u001b[32mTrain: [ 26/50] Step 380/520 Loss 2.139 Prec@(1,5) (57.3%, 85.0%)\u001b[0m\n",
            "[2024-04-02 19:07:47] \u001b[32mTrain: [ 26/50] Step 400/520 Loss 2.138 Prec@(1,5) (57.3%, 85.0%)\u001b[0m\n",
            "[2024-04-02 19:07:47] \u001b[32mTrain: [ 26/50] Step 420/520 Loss 2.139 Prec@(1,5) (57.2%, 85.0%)\u001b[0m\n",
            "[2024-04-02 19:07:48] \u001b[32mTrain: [ 26/50] Step 440/520 Loss 2.136 Prec@(1,5) (57.3%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:07:48] \u001b[32mTrain: [ 26/50] Step 460/520 Loss 2.138 Prec@(1,5) (57.2%, 85.0%)\u001b[0m\n",
            "[2024-04-02 19:07:49] \u001b[32mTrain: [ 26/50] Step 480/520 Loss 2.139 Prec@(1,5) (57.2%, 85.0%)\u001b[0m\n",
            "[2024-04-02 19:07:49] \u001b[32mTrain: [ 26/50] Step 500/520 Loss 2.137 Prec@(1,5) (57.2%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:07:50] \u001b[32mTrain: [ 26/50] Step 520/520 Loss 2.138 Prec@(1,5) (57.2%, 85.0%)\u001b[0m\n",
            "[2024-04-02 19:07:50] \u001b[32mTrain: [ 26/50] Final Prec@1 57.1580%\u001b[0m\n",
            "[2024-04-02 19:07:54] \u001b[32mValid: [ 26/50] Step 000/104 Loss 2.168 Prec@(1,5) (60.4%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:07:54] \u001b[32mValid: [ 26/50] Step 020/104 Loss 2.481 Prec@(1,5) (51.8%, 80.8%)\u001b[0m\n",
            "[2024-04-02 19:07:54] \u001b[32mValid: [ 26/50] Step 040/104 Loss 2.478 Prec@(1,5) (51.3%, 80.7%)\u001b[0m\n",
            "[2024-04-02 19:07:54] \u001b[32mValid: [ 26/50] Step 060/104 Loss 2.423 Prec@(1,5) (51.7%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:07:54] \u001b[32mValid: [ 26/50] Step 080/104 Loss 2.430 Prec@(1,5) (51.4%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:07:54] \u001b[32mValid: [ 26/50] Step 100/104 Loss 2.419 Prec@(1,5) (51.5%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:07:54] \u001b[32mValid: [ 26/50] Step 104/104 Loss 2.424 Prec@(1,5) (51.5%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:07:55] \u001b[32mValid: [ 26/50] Final Prec@1 51.5200%\u001b[0m\n",
            "[2024-04-02 19:07:55] \u001b[32mEpoch 26 LR 0.011716\u001b[0m\n",
            "[2024-04-02 19:07:59] \u001b[32mTrain: [ 27/50] Step 000/520 Loss 1.910 Prec@(1,5) (62.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:08:00] \u001b[32mTrain: [ 27/50] Step 020/520 Loss 2.002 Prec@(1,5) (60.6%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:08:00] \u001b[32mTrain: [ 27/50] Step 040/520 Loss 1.989 Prec@(1,5) (59.9%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:08:01] \u001b[32mTrain: [ 27/50] Step 060/520 Loss 2.024 Prec@(1,5) (59.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:08:01] \u001b[32mTrain: [ 27/50] Step 080/520 Loss 2.057 Prec@(1,5) (59.1%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:08:02] \u001b[32mTrain: [ 27/50] Step 100/520 Loss 2.058 Prec@(1,5) (59.1%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:08:02] \u001b[32mTrain: [ 27/50] Step 120/520 Loss 2.066 Prec@(1,5) (59.1%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:08:03] \u001b[32mTrain: [ 27/50] Step 140/520 Loss 2.060 Prec@(1,5) (59.0%, 86.1%)\u001b[0m\n",
            "[2024-04-02 19:08:03] \u001b[32mTrain: [ 27/50] Step 160/520 Loss 2.062 Prec@(1,5) (58.8%, 86.1%)\u001b[0m\n",
            "[2024-04-02 19:08:04] \u001b[32mTrain: [ 27/50] Step 180/520 Loss 2.063 Prec@(1,5) (58.7%, 86.1%)\u001b[0m\n",
            "[2024-04-02 19:08:04] \u001b[32mTrain: [ 27/50] Step 200/520 Loss 2.070 Prec@(1,5) (58.6%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:08:05] \u001b[32mTrain: [ 27/50] Step 220/520 Loss 2.079 Prec@(1,5) (58.4%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:08:05] \u001b[32mTrain: [ 27/50] Step 240/520 Loss 2.082 Prec@(1,5) (58.3%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:08:06] \u001b[32mTrain: [ 27/50] Step 260/520 Loss 2.087 Prec@(1,5) (58.1%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:08:06] \u001b[32mTrain: [ 27/50] Step 280/520 Loss 2.089 Prec@(1,5) (58.0%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:08:07] \u001b[32mTrain: [ 27/50] Step 300/520 Loss 2.093 Prec@(1,5) (58.0%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:08:07] \u001b[32mTrain: [ 27/50] Step 320/520 Loss 2.092 Prec@(1,5) (57.9%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:08:08] \u001b[32mTrain: [ 27/50] Step 340/520 Loss 2.096 Prec@(1,5) (57.8%, 85.6%)\u001b[0m\n",
            "[2024-04-02 19:08:08] \u001b[32mTrain: [ 27/50] Step 360/520 Loss 2.098 Prec@(1,5) (57.9%, 85.6%)\u001b[0m\n",
            "[2024-04-02 19:08:09] \u001b[32mTrain: [ 27/50] Step 380/520 Loss 2.101 Prec@(1,5) (57.8%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:08:09] \u001b[32mTrain: [ 27/50] Step 400/520 Loss 2.103 Prec@(1,5) (57.8%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:08:10] \u001b[32mTrain: [ 27/50] Step 420/520 Loss 2.104 Prec@(1,5) (57.8%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:08:10] \u001b[32mTrain: [ 27/50] Step 440/520 Loss 2.107 Prec@(1,5) (57.8%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:08:11] \u001b[32mTrain: [ 27/50] Step 460/520 Loss 2.108 Prec@(1,5) (57.8%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:08:11] \u001b[32mTrain: [ 27/50] Step 480/520 Loss 2.110 Prec@(1,5) (57.7%, 85.3%)\u001b[0m\n",
            "[2024-04-02 19:08:12] \u001b[32mTrain: [ 27/50] Step 500/520 Loss 2.111 Prec@(1,5) (57.7%, 85.3%)\u001b[0m\n",
            "[2024-04-02 19:08:12] \u001b[32mTrain: [ 27/50] Step 520/520 Loss 2.111 Prec@(1,5) (57.7%, 85.3%)\u001b[0m\n",
            "[2024-04-02 19:08:12] \u001b[32mTrain: [ 27/50] Final Prec@1 57.7360%\u001b[0m\n",
            "[2024-04-02 19:08:16] \u001b[32mValid: [ 27/50] Step 000/104 Loss 2.288 Prec@(1,5) (56.2%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:08:16] \u001b[32mValid: [ 27/50] Step 020/104 Loss 2.306 Prec@(1,5) (54.0%, 82.7%)\u001b[0m\n",
            "[2024-04-02 19:08:16] \u001b[32mValid: [ 27/50] Step 040/104 Loss 2.288 Prec@(1,5) (53.0%, 82.8%)\u001b[0m\n",
            "[2024-04-02 19:08:16] \u001b[32mValid: [ 27/50] Step 060/104 Loss 2.256 Prec@(1,5) (53.5%, 82.6%)\u001b[0m\n",
            "[2024-04-02 19:08:16] \u001b[32mValid: [ 27/50] Step 080/104 Loss 2.277 Prec@(1,5) (53.1%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:08:17] \u001b[32mValid: [ 27/50] Step 100/104 Loss 2.275 Prec@(1,5) (53.6%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:08:17] \u001b[32mValid: [ 27/50] Step 104/104 Loss 2.280 Prec@(1,5) (53.5%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:08:17] \u001b[32mValid: [ 27/50] Final Prec@1 53.5200%\u001b[0m\n",
            "[2024-04-02 19:08:17] \u001b[32mEpoch 27 LR 0.010934\u001b[0m\n",
            "[2024-04-02 19:08:21] \u001b[32mTrain: [ 28/50] Step 000/520 Loss 2.341 Prec@(1,5) (52.1%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:08:22] \u001b[32mTrain: [ 28/50] Step 020/520 Loss 2.168 Prec@(1,5) (57.4%, 84.3%)\u001b[0m\n",
            "[2024-04-02 19:08:22] \u001b[32mTrain: [ 28/50] Step 040/520 Loss 2.117 Prec@(1,5) (58.2%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:08:23] \u001b[32mTrain: [ 28/50] Step 060/520 Loss 2.140 Prec@(1,5) (58.0%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:08:23] \u001b[32mTrain: [ 28/50] Step 080/520 Loss 2.117 Prec@(1,5) (58.3%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:08:24] \u001b[32mTrain: [ 28/50] Step 100/520 Loss 2.096 Prec@(1,5) (58.7%, 85.3%)\u001b[0m\n",
            "[2024-04-02 19:08:24] \u001b[32mTrain: [ 28/50] Step 120/520 Loss 2.110 Prec@(1,5) (58.3%, 85.2%)\u001b[0m\n",
            "[2024-04-02 19:08:25] \u001b[32mTrain: [ 28/50] Step 140/520 Loss 2.095 Prec@(1,5) (58.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:08:25] \u001b[32mTrain: [ 28/50] Step 160/520 Loss 2.086 Prec@(1,5) (58.7%, 85.6%)\u001b[0m\n",
            "[2024-04-02 19:08:26] \u001b[32mTrain: [ 28/50] Step 180/520 Loss 2.089 Prec@(1,5) (58.7%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:08:26] \u001b[32mTrain: [ 28/50] Step 200/520 Loss 2.085 Prec@(1,5) (58.7%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:08:27] \u001b[32mTrain: [ 28/50] Step 220/520 Loss 2.087 Prec@(1,5) (58.6%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:08:27] \u001b[32mTrain: [ 28/50] Step 240/520 Loss 2.091 Prec@(1,5) (58.6%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:08:28] \u001b[32mTrain: [ 28/50] Step 260/520 Loss 2.088 Prec@(1,5) (58.6%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:08:28] \u001b[32mTrain: [ 28/50] Step 280/520 Loss 2.088 Prec@(1,5) (58.6%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:08:29] \u001b[32mTrain: [ 28/50] Step 300/520 Loss 2.088 Prec@(1,5) (58.6%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:08:29] \u001b[32mTrain: [ 28/50] Step 320/520 Loss 2.086 Prec@(1,5) (58.6%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:08:30] \u001b[32mTrain: [ 28/50] Step 340/520 Loss 2.079 Prec@(1,5) (58.6%, 85.6%)\u001b[0m\n",
            "[2024-04-02 19:08:30] \u001b[32mTrain: [ 28/50] Step 360/520 Loss 2.079 Prec@(1,5) (58.6%, 85.6%)\u001b[0m\n",
            "[2024-04-02 19:08:31] \u001b[32mTrain: [ 28/50] Step 380/520 Loss 2.079 Prec@(1,5) (58.5%, 85.6%)\u001b[0m\n",
            "[2024-04-02 19:08:31] \u001b[32mTrain: [ 28/50] Step 400/520 Loss 2.080 Prec@(1,5) (58.5%, 85.6%)\u001b[0m\n",
            "[2024-04-02 19:08:32] \u001b[32mTrain: [ 28/50] Step 420/520 Loss 2.081 Prec@(1,5) (58.4%, 85.6%)\u001b[0m\n",
            "[2024-04-02 19:08:32] \u001b[32mTrain: [ 28/50] Step 440/520 Loss 2.086 Prec@(1,5) (58.3%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:08:33] \u001b[32mTrain: [ 28/50] Step 460/520 Loss 2.084 Prec@(1,5) (58.3%, 85.6%)\u001b[0m\n",
            "[2024-04-02 19:08:33] \u001b[32mTrain: [ 28/50] Step 480/520 Loss 2.084 Prec@(1,5) (58.3%, 85.6%)\u001b[0m\n",
            "[2024-04-02 19:08:34] \u001b[32mTrain: [ 28/50] Step 500/520 Loss 2.086 Prec@(1,5) (58.3%, 85.6%)\u001b[0m\n",
            "[2024-04-02 19:08:34] \u001b[32mTrain: [ 28/50] Step 520/520 Loss 2.086 Prec@(1,5) (58.3%, 85.6%)\u001b[0m\n",
            "[2024-04-02 19:08:35] \u001b[32mTrain: [ 28/50] Final Prec@1 58.2540%\u001b[0m\n",
            "[2024-04-02 19:08:38] \u001b[32mValid: [ 28/50] Step 000/104 Loss 2.204 Prec@(1,5) (54.2%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:08:38] \u001b[32mValid: [ 28/50] Step 020/104 Loss 2.307 Prec@(1,5) (54.9%, 82.6%)\u001b[0m\n",
            "[2024-04-02 19:08:38] \u001b[32mValid: [ 28/50] Step 040/104 Loss 2.319 Prec@(1,5) (53.5%, 81.9%)\u001b[0m\n",
            "[2024-04-02 19:08:39] \u001b[32mValid: [ 28/50] Step 060/104 Loss 2.264 Prec@(1,5) (53.8%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:08:39] \u001b[32mValid: [ 28/50] Step 080/104 Loss 2.273 Prec@(1,5) (53.4%, 82.2%)\u001b[0m\n",
            "[2024-04-02 19:08:39] \u001b[32mValid: [ 28/50] Step 100/104 Loss 2.251 Prec@(1,5) (53.7%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:08:39] \u001b[32mValid: [ 28/50] Step 104/104 Loss 2.253 Prec@(1,5) (53.7%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:08:39] \u001b[32mValid: [ 28/50] Final Prec@1 53.6600%\u001b[0m\n",
            "[2024-04-02 19:08:39] \u001b[32mEpoch 28 LR 0.010158\u001b[0m\n",
            "[2024-04-02 19:08:44] \u001b[32mTrain: [ 29/50] Step 000/520 Loss 2.160 Prec@(1,5) (59.4%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:08:44] \u001b[32mTrain: [ 29/50] Step 020/520 Loss 1.960 Prec@(1,5) (61.2%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:08:45] \u001b[32mTrain: [ 29/50] Step 040/520 Loss 2.040 Prec@(1,5) (59.3%, 86.1%)\u001b[0m\n",
            "[2024-04-02 19:08:45] \u001b[32mTrain: [ 29/50] Step 060/520 Loss 2.037 Prec@(1,5) (59.0%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:08:46] \u001b[32mTrain: [ 29/50] Step 080/520 Loss 2.042 Prec@(1,5) (58.9%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:08:46] \u001b[32mTrain: [ 29/50] Step 100/520 Loss 2.037 Prec@(1,5) (59.1%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:08:47] \u001b[32mTrain: [ 29/50] Step 120/520 Loss 2.036 Prec@(1,5) (58.9%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:08:47] \u001b[32mTrain: [ 29/50] Step 140/520 Loss 2.030 Prec@(1,5) (59.1%, 86.1%)\u001b[0m\n",
            "[2024-04-02 19:08:48] \u001b[32mTrain: [ 29/50] Step 160/520 Loss 2.034 Prec@(1,5) (59.1%, 86.1%)\u001b[0m\n",
            "[2024-04-02 19:08:48] \u001b[32mTrain: [ 29/50] Step 180/520 Loss 2.040 Prec@(1,5) (59.1%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:08:49] \u001b[32mTrain: [ 29/50] Step 200/520 Loss 2.036 Prec@(1,5) (59.4%, 86.1%)\u001b[0m\n",
            "[2024-04-02 19:08:49] \u001b[32mTrain: [ 29/50] Step 220/520 Loss 2.043 Prec@(1,5) (59.2%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:08:50] \u001b[32mTrain: [ 29/50] Step 240/520 Loss 2.044 Prec@(1,5) (59.2%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:08:50] \u001b[32mTrain: [ 29/50] Step 260/520 Loss 2.040 Prec@(1,5) (59.3%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:08:51] \u001b[32mTrain: [ 29/50] Step 280/520 Loss 2.045 Prec@(1,5) (59.2%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:08:51] \u001b[32mTrain: [ 29/50] Step 300/520 Loss 2.053 Prec@(1,5) (59.0%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:08:52] \u001b[32mTrain: [ 29/50] Step 320/520 Loss 2.054 Prec@(1,5) (59.1%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:08:53] \u001b[32mTrain: [ 29/50] Step 340/520 Loss 2.058 Prec@(1,5) (58.9%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:08:53] \u001b[32mTrain: [ 29/50] Step 360/520 Loss 2.054 Prec@(1,5) (59.0%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:08:54] \u001b[32mTrain: [ 29/50] Step 380/520 Loss 2.050 Prec@(1,5) (59.1%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:08:54] \u001b[32mTrain: [ 29/50] Step 400/520 Loss 2.052 Prec@(1,5) (59.0%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:08:55] \u001b[32mTrain: [ 29/50] Step 420/520 Loss 2.054 Prec@(1,5) (59.0%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:08:55] \u001b[32mTrain: [ 29/50] Step 440/520 Loss 2.054 Prec@(1,5) (59.0%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:08:56] \u001b[32mTrain: [ 29/50] Step 460/520 Loss 2.057 Prec@(1,5) (58.9%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:08:56] \u001b[32mTrain: [ 29/50] Step 480/520 Loss 2.060 Prec@(1,5) (58.9%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:08:57] \u001b[32mTrain: [ 29/50] Step 500/520 Loss 2.061 Prec@(1,5) (58.8%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:08:57] \u001b[32mTrain: [ 29/50] Step 520/520 Loss 2.062 Prec@(1,5) (58.8%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:08:57] \u001b[32mTrain: [ 29/50] Final Prec@1 58.7580%\u001b[0m\n",
            "[2024-04-02 19:09:01] \u001b[32mValid: [ 29/50] Step 000/104 Loss 2.054 Prec@(1,5) (61.5%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:09:01] \u001b[32mValid: [ 29/50] Step 020/104 Loss 2.191 Prec@(1,5) (55.2%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:09:01] \u001b[32mValid: [ 29/50] Step 040/104 Loss 2.169 Prec@(1,5) (54.5%, 83.4%)\u001b[0m\n",
            "[2024-04-02 19:09:01] \u001b[32mValid: [ 29/50] Step 060/104 Loss 2.116 Prec@(1,5) (55.4%, 83.7%)\u001b[0m\n",
            "[2024-04-02 19:09:02] \u001b[32mValid: [ 29/50] Step 080/104 Loss 2.128 Prec@(1,5) (54.8%, 83.5%)\u001b[0m\n",
            "[2024-04-02 19:09:02] \u001b[32mValid: [ 29/50] Step 100/104 Loss 2.120 Prec@(1,5) (55.2%, 83.4%)\u001b[0m\n",
            "[2024-04-02 19:09:02] \u001b[32mValid: [ 29/50] Step 104/104 Loss 2.123 Prec@(1,5) (55.3%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:09:02] \u001b[32mValid: [ 29/50] Final Prec@1 55.2800%\u001b[0m\n",
            "[2024-04-02 19:09:02] \u001b[32mEpoch 29 LR 0.009392\u001b[0m\n",
            "[2024-04-02 19:09:07] \u001b[32mTrain: [ 30/50] Step 000/520 Loss 1.670 Prec@(1,5) (67.7%, 90.6%)\u001b[0m\n",
            "[2024-04-02 19:09:07] \u001b[32mTrain: [ 30/50] Step 020/520 Loss 1.959 Prec@(1,5) (61.1%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:09:08] \u001b[32mTrain: [ 30/50] Step 040/520 Loss 1.988 Prec@(1,5) (60.0%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:09:08] \u001b[32mTrain: [ 30/50] Step 060/520 Loss 2.004 Prec@(1,5) (59.7%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:09:09] \u001b[32mTrain: [ 30/50] Step 080/520 Loss 2.020 Prec@(1,5) (59.6%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:09:09] \u001b[32mTrain: [ 30/50] Step 100/520 Loss 2.008 Prec@(1,5) (60.1%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:09:10] \u001b[32mTrain: [ 30/50] Step 120/520 Loss 2.009 Prec@(1,5) (59.9%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:09:10] \u001b[32mTrain: [ 30/50] Step 140/520 Loss 2.013 Prec@(1,5) (59.7%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:09:10] \u001b[32mTrain: [ 30/50] Step 160/520 Loss 2.010 Prec@(1,5) (59.9%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:09:11] \u001b[32mTrain: [ 30/50] Step 180/520 Loss 2.015 Prec@(1,5) (59.9%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:09:11] \u001b[32mTrain: [ 30/50] Step 200/520 Loss 2.013 Prec@(1,5) (59.8%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:09:12] \u001b[32mTrain: [ 30/50] Step 220/520 Loss 2.013 Prec@(1,5) (59.8%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:09:12] \u001b[32mTrain: [ 30/50] Step 240/520 Loss 2.015 Prec@(1,5) (59.8%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:09:13] \u001b[32mTrain: [ 30/50] Step 260/520 Loss 2.019 Prec@(1,5) (59.7%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:09:13] \u001b[32mTrain: [ 30/50] Step 280/520 Loss 2.018 Prec@(1,5) (59.6%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:09:14] \u001b[32mTrain: [ 30/50] Step 300/520 Loss 2.023 Prec@(1,5) (59.6%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:09:14] \u001b[32mTrain: [ 30/50] Step 320/520 Loss 2.019 Prec@(1,5) (59.7%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:09:15] \u001b[32mTrain: [ 30/50] Step 340/520 Loss 2.019 Prec@(1,5) (59.6%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:09:15] \u001b[32mTrain: [ 30/50] Step 360/520 Loss 2.021 Prec@(1,5) (59.6%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:09:16] \u001b[32mTrain: [ 30/50] Step 380/520 Loss 2.022 Prec@(1,5) (59.6%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:09:16] \u001b[32mTrain: [ 30/50] Step 400/520 Loss 2.023 Prec@(1,5) (59.6%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:09:17] \u001b[32mTrain: [ 30/50] Step 420/520 Loss 2.019 Prec@(1,5) (59.6%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:09:17] \u001b[32mTrain: [ 30/50] Step 440/520 Loss 2.018 Prec@(1,5) (59.6%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:09:18] \u001b[32mTrain: [ 30/50] Step 460/520 Loss 2.018 Prec@(1,5) (59.6%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:09:18] \u001b[32mTrain: [ 30/50] Step 480/520 Loss 2.023 Prec@(1,5) (59.5%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:09:19] \u001b[32mTrain: [ 30/50] Step 500/520 Loss 2.026 Prec@(1,5) (59.5%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:09:19] \u001b[32mTrain: [ 30/50] Step 520/520 Loss 2.029 Prec@(1,5) (59.5%, 86.1%)\u001b[0m\n",
            "[2024-04-02 19:09:19] \u001b[32mTrain: [ 30/50] Final Prec@1 59.4660%\u001b[0m\n",
            "[2024-04-02 19:09:23] \u001b[32mValid: [ 30/50] Step 000/104 Loss 2.083 Prec@(1,5) (59.4%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:09:23] \u001b[32mValid: [ 30/50] Step 020/104 Loss 2.236 Prec@(1,5) (54.4%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:09:23] \u001b[32mValid: [ 30/50] Step 040/104 Loss 2.203 Prec@(1,5) (54.6%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:09:24] \u001b[32mValid: [ 30/50] Step 060/104 Loss 2.145 Prec@(1,5) (55.1%, 83.6%)\u001b[0m\n",
            "[2024-04-02 19:09:24] \u001b[32mValid: [ 30/50] Step 080/104 Loss 2.156 Prec@(1,5) (54.7%, 83.5%)\u001b[0m\n",
            "[2024-04-02 19:09:24] \u001b[32mValid: [ 30/50] Step 100/104 Loss 2.137 Prec@(1,5) (55.1%, 83.7%)\u001b[0m\n",
            "[2024-04-02 19:09:24] \u001b[32mValid: [ 30/50] Step 104/104 Loss 2.138 Prec@(1,5) (55.1%, 83.6%)\u001b[0m\n",
            "[2024-04-02 19:09:24] \u001b[32mValid: [ 30/50] Final Prec@1 55.0700%\u001b[0m\n",
            "[2024-04-02 19:09:24] \u001b[32mEpoch 30 LR 0.008638\u001b[0m\n",
            "[2024-04-02 19:09:29] \u001b[32mTrain: [ 31/50] Step 000/520 Loss 2.002 Prec@(1,5) (63.5%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:09:29] \u001b[32mTrain: [ 31/50] Step 020/520 Loss 2.004 Prec@(1,5) (59.4%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:09:30] \u001b[32mTrain: [ 31/50] Step 040/520 Loss 1.985 Prec@(1,5) (59.9%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:09:30] \u001b[32mTrain: [ 31/50] Step 060/520 Loss 1.978 Prec@(1,5) (60.1%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:09:31] \u001b[32mTrain: [ 31/50] Step 080/520 Loss 1.947 Prec@(1,5) (60.8%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:09:31] \u001b[32mTrain: [ 31/50] Step 100/520 Loss 1.945 Prec@(1,5) (60.7%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:09:32] \u001b[32mTrain: [ 31/50] Step 120/520 Loss 1.958 Prec@(1,5) (60.5%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:09:32] \u001b[32mTrain: [ 31/50] Step 140/520 Loss 1.964 Prec@(1,5) (60.5%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:09:33] \u001b[32mTrain: [ 31/50] Step 160/520 Loss 1.979 Prec@(1,5) (60.3%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:09:33] \u001b[32mTrain: [ 31/50] Step 180/520 Loss 1.987 Prec@(1,5) (60.2%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:09:34] \u001b[32mTrain: [ 31/50] Step 200/520 Loss 1.991 Prec@(1,5) (60.1%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:09:34] \u001b[32mTrain: [ 31/50] Step 220/520 Loss 1.994 Prec@(1,5) (60.1%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:09:35] \u001b[32mTrain: [ 31/50] Step 240/520 Loss 1.997 Prec@(1,5) (60.0%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:09:35] \u001b[32mTrain: [ 31/50] Step 260/520 Loss 2.001 Prec@(1,5) (59.9%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:09:36] \u001b[32mTrain: [ 31/50] Step 280/520 Loss 2.000 Prec@(1,5) (60.0%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:09:36] \u001b[32mTrain: [ 31/50] Step 300/520 Loss 1.998 Prec@(1,5) (60.1%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:09:37] \u001b[32mTrain: [ 31/50] Step 320/520 Loss 1.999 Prec@(1,5) (60.0%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:09:37] \u001b[32mTrain: [ 31/50] Step 340/520 Loss 2.000 Prec@(1,5) (60.0%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:09:38] \u001b[32mTrain: [ 31/50] Step 360/520 Loss 2.001 Prec@(1,5) (60.0%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:09:38] \u001b[32mTrain: [ 31/50] Step 380/520 Loss 2.003 Prec@(1,5) (60.0%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:09:39] \u001b[32mTrain: [ 31/50] Step 400/520 Loss 2.001 Prec@(1,5) (60.0%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:09:39] \u001b[32mTrain: [ 31/50] Step 420/520 Loss 2.000 Prec@(1,5) (60.0%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:09:40] \u001b[32mTrain: [ 31/50] Step 440/520 Loss 2.001 Prec@(1,5) (59.9%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:09:40] \u001b[32mTrain: [ 31/50] Step 460/520 Loss 2.003 Prec@(1,5) (59.9%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:09:41] \u001b[32mTrain: [ 31/50] Step 480/520 Loss 2.004 Prec@(1,5) (59.8%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:09:41] \u001b[32mTrain: [ 31/50] Step 500/520 Loss 2.004 Prec@(1,5) (59.8%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:09:42] \u001b[32mTrain: [ 31/50] Step 520/520 Loss 2.007 Prec@(1,5) (59.8%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:09:42] \u001b[32mTrain: [ 31/50] Final Prec@1 59.7580%\u001b[0m\n",
            "[2024-04-02 19:09:45] \u001b[32mValid: [ 31/50] Step 000/104 Loss 1.943 Prec@(1,5) (58.3%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:09:46] \u001b[32mValid: [ 31/50] Step 020/104 Loss 2.148 Prec@(1,5) (56.9%, 84.1%)\u001b[0m\n",
            "[2024-04-02 19:09:46] \u001b[32mValid: [ 31/50] Step 040/104 Loss 2.117 Prec@(1,5) (55.9%, 84.2%)\u001b[0m\n",
            "[2024-04-02 19:09:46] \u001b[32mValid: [ 31/50] Step 060/104 Loss 2.074 Prec@(1,5) (56.6%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:09:46] \u001b[32mValid: [ 31/50] Step 080/104 Loss 2.088 Prec@(1,5) (56.1%, 84.3%)\u001b[0m\n",
            "[2024-04-02 19:09:46] \u001b[32mValid: [ 31/50] Step 100/104 Loss 2.077 Prec@(1,5) (56.5%, 84.3%)\u001b[0m\n",
            "[2024-04-02 19:09:46] \u001b[32mValid: [ 31/50] Step 104/104 Loss 2.078 Prec@(1,5) (56.6%, 84.2%)\u001b[0m\n",
            "[2024-04-02 19:09:47] \u001b[32mValid: [ 31/50] Final Prec@1 56.5800%\u001b[0m\n",
            "[2024-04-02 19:09:47] \u001b[32mEpoch 31 LR 0.007899\u001b[0m\n",
            "[2024-04-02 19:09:51] \u001b[32mTrain: [ 32/50] Step 000/520 Loss 1.727 Prec@(1,5) (67.7%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:09:52] \u001b[32mTrain: [ 32/50] Step 020/520 Loss 1.972 Prec@(1,5) (60.7%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:09:52] \u001b[32mTrain: [ 32/50] Step 040/520 Loss 1.969 Prec@(1,5) (60.2%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:09:53] \u001b[32mTrain: [ 32/50] Step 060/520 Loss 1.947 Prec@(1,5) (60.6%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:09:53] \u001b[32mTrain: [ 32/50] Step 080/520 Loss 1.945 Prec@(1,5) (60.7%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:09:54] \u001b[32mTrain: [ 32/50] Step 100/520 Loss 1.944 Prec@(1,5) (61.0%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:09:54] \u001b[32mTrain: [ 32/50] Step 120/520 Loss 1.945 Prec@(1,5) (60.9%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:09:55] \u001b[32mTrain: [ 32/50] Step 140/520 Loss 1.939 Prec@(1,5) (61.0%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:09:55] \u001b[32mTrain: [ 32/50] Step 160/520 Loss 1.944 Prec@(1,5) (60.8%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:09:56] \u001b[32mTrain: [ 32/50] Step 180/520 Loss 1.946 Prec@(1,5) (60.7%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:09:56] \u001b[32mTrain: [ 32/50] Step 200/520 Loss 1.955 Prec@(1,5) (60.7%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:09:57] \u001b[32mTrain: [ 32/50] Step 220/520 Loss 1.960 Prec@(1,5) (60.6%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:09:57] \u001b[32mTrain: [ 32/50] Step 240/520 Loss 1.960 Prec@(1,5) (60.7%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:09:58] \u001b[32mTrain: [ 32/50] Step 260/520 Loss 1.960 Prec@(1,5) (60.7%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:09:58] \u001b[32mTrain: [ 32/50] Step 280/520 Loss 1.966 Prec@(1,5) (60.6%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:09:59] \u001b[32mTrain: [ 32/50] Step 300/520 Loss 1.970 Prec@(1,5) (60.5%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:09:59] \u001b[32mTrain: [ 32/50] Step 320/520 Loss 1.970 Prec@(1,5) (60.5%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:10:00] \u001b[32mTrain: [ 32/50] Step 340/520 Loss 1.972 Prec@(1,5) (60.4%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:10:00] \u001b[32mTrain: [ 32/50] Step 360/520 Loss 1.972 Prec@(1,5) (60.4%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:10:01] \u001b[32mTrain: [ 32/50] Step 380/520 Loss 1.975 Prec@(1,5) (60.3%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:10:01] \u001b[32mTrain: [ 32/50] Step 400/520 Loss 1.977 Prec@(1,5) (60.3%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:10:02] \u001b[32mTrain: [ 32/50] Step 420/520 Loss 1.980 Prec@(1,5) (60.2%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:10:02] \u001b[32mTrain: [ 32/50] Step 440/520 Loss 1.981 Prec@(1,5) (60.2%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:10:03] \u001b[32mTrain: [ 32/50] Step 460/520 Loss 1.980 Prec@(1,5) (60.2%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:10:03] \u001b[32mTrain: [ 32/50] Step 480/520 Loss 1.981 Prec@(1,5) (60.2%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:10:04] \u001b[32mTrain: [ 32/50] Step 500/520 Loss 1.982 Prec@(1,5) (60.2%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:10:04] \u001b[32mTrain: [ 32/50] Step 520/520 Loss 1.983 Prec@(1,5) (60.2%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:10:04] \u001b[32mTrain: [ 32/50] Final Prec@1 60.1800%\u001b[0m\n",
            "[2024-04-02 19:10:08] \u001b[32mValid: [ 32/50] Step 000/104 Loss 2.069 Prec@(1,5) (60.4%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:10:08] \u001b[32mValid: [ 32/50] Step 020/104 Loss 2.170 Prec@(1,5) (56.4%, 84.0%)\u001b[0m\n",
            "[2024-04-02 19:10:08] \u001b[32mValid: [ 32/50] Step 040/104 Loss 2.175 Prec@(1,5) (55.4%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:10:08] \u001b[32mValid: [ 32/50] Step 060/104 Loss 2.144 Prec@(1,5) (55.8%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:10:09] \u001b[32mValid: [ 32/50] Step 080/104 Loss 2.164 Prec@(1,5) (55.6%, 84.1%)\u001b[0m\n",
            "[2024-04-02 19:10:09] \u001b[32mValid: [ 32/50] Step 100/104 Loss 2.141 Prec@(1,5) (55.9%, 84.2%)\u001b[0m\n",
            "[2024-04-02 19:10:09] \u001b[32mValid: [ 32/50] Step 104/104 Loss 2.144 Prec@(1,5) (55.9%, 84.1%)\u001b[0m\n",
            "[2024-04-02 19:10:09] \u001b[32mValid: [ 32/50] Final Prec@1 55.9300%\u001b[0m\n",
            "[2024-04-02 19:10:09] \u001b[32mEpoch 32 LR 0.007178\u001b[0m\n",
            "[2024-04-02 19:10:14] \u001b[32mTrain: [ 33/50] Step 000/520 Loss 1.804 Prec@(1,5) (63.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:10:14] \u001b[32mTrain: [ 33/50] Step 020/520 Loss 1.946 Prec@(1,5) (60.6%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:10:15] \u001b[32mTrain: [ 33/50] Step 040/520 Loss 1.933 Prec@(1,5) (61.1%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:10:15] \u001b[32mTrain: [ 33/50] Step 060/520 Loss 1.896 Prec@(1,5) (61.9%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:10:16] \u001b[32mTrain: [ 33/50] Step 080/520 Loss 1.907 Prec@(1,5) (61.9%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:10:16] \u001b[32mTrain: [ 33/50] Step 100/520 Loss 1.916 Prec@(1,5) (61.6%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:10:17] \u001b[32mTrain: [ 33/50] Step 120/520 Loss 1.912 Prec@(1,5) (61.6%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:10:17] \u001b[32mTrain: [ 33/50] Step 140/520 Loss 1.921 Prec@(1,5) (61.5%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:10:18] \u001b[32mTrain: [ 33/50] Step 160/520 Loss 1.916 Prec@(1,5) (61.5%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:10:18] \u001b[32mTrain: [ 33/50] Step 180/520 Loss 1.919 Prec@(1,5) (61.5%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:10:19] \u001b[32mTrain: [ 33/50] Step 200/520 Loss 1.921 Prec@(1,5) (61.4%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:10:19] \u001b[32mTrain: [ 33/50] Step 220/520 Loss 1.924 Prec@(1,5) (61.3%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:10:20] \u001b[32mTrain: [ 33/50] Step 240/520 Loss 1.928 Prec@(1,5) (61.1%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:10:20] \u001b[32mTrain: [ 33/50] Step 260/520 Loss 1.931 Prec@(1,5) (61.2%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:10:21] \u001b[32mTrain: [ 33/50] Step 280/520 Loss 1.939 Prec@(1,5) (61.0%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:10:21] \u001b[32mTrain: [ 33/50] Step 300/520 Loss 1.942 Prec@(1,5) (60.9%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:10:22] \u001b[32mTrain: [ 33/50] Step 320/520 Loss 1.942 Prec@(1,5) (60.9%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:10:22] \u001b[32mTrain: [ 33/50] Step 340/520 Loss 1.936 Prec@(1,5) (61.1%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:10:22] \u001b[32mTrain: [ 33/50] Step 360/520 Loss 1.932 Prec@(1,5) (61.1%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:10:23] \u001b[32mTrain: [ 33/50] Step 380/520 Loss 1.933 Prec@(1,5) (61.1%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:10:23] \u001b[32mTrain: [ 33/50] Step 400/520 Loss 1.934 Prec@(1,5) (61.1%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:10:24] \u001b[32mTrain: [ 33/50] Step 420/520 Loss 1.938 Prec@(1,5) (61.1%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:10:24] \u001b[32mTrain: [ 33/50] Step 440/520 Loss 1.940 Prec@(1,5) (61.0%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:10:25] \u001b[32mTrain: [ 33/50] Step 460/520 Loss 1.945 Prec@(1,5) (60.8%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:10:25] \u001b[32mTrain: [ 33/50] Step 480/520 Loss 1.945 Prec@(1,5) (60.8%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:10:26] \u001b[32mTrain: [ 33/50] Step 500/520 Loss 1.947 Prec@(1,5) (60.7%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:10:26] \u001b[32mTrain: [ 33/50] Step 520/520 Loss 1.948 Prec@(1,5) (60.7%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:10:27] \u001b[32mTrain: [ 33/50] Final Prec@1 60.7240%\u001b[0m\n",
            "[2024-04-02 19:10:30] \u001b[32mValid: [ 33/50] Step 000/104 Loss 1.892 Prec@(1,5) (63.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:10:30] \u001b[32mValid: [ 33/50] Step 020/104 Loss 2.016 Prec@(1,5) (57.9%, 85.0%)\u001b[0m\n",
            "[2024-04-02 19:10:30] \u001b[32mValid: [ 33/50] Step 040/104 Loss 1.995 Prec@(1,5) (57.4%, 85.2%)\u001b[0m\n",
            "[2024-04-02 19:10:31] \u001b[32mValid: [ 33/50] Step 060/104 Loss 1.958 Prec@(1,5) (57.6%, 85.2%)\u001b[0m\n",
            "[2024-04-02 19:10:31] \u001b[32mValid: [ 33/50] Step 080/104 Loss 1.958 Prec@(1,5) (57.7%, 85.3%)\u001b[0m\n",
            "[2024-04-02 19:10:31] \u001b[32mValid: [ 33/50] Step 100/104 Loss 1.942 Prec@(1,5) (58.1%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:10:31] \u001b[32mValid: [ 33/50] Step 104/104 Loss 1.946 Prec@(1,5) (58.1%, 85.3%)\u001b[0m\n",
            "[2024-04-02 19:10:31] \u001b[32mValid: [ 33/50] Final Prec@1 58.1200%\u001b[0m\n",
            "[2024-04-02 19:10:31] \u001b[32mEpoch 33 LR 0.006479\u001b[0m\n",
            "[2024-04-02 19:10:36] \u001b[32mTrain: [ 34/50] Step 000/520 Loss 2.316 Prec@(1,5) (56.2%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:10:36] \u001b[32mTrain: [ 34/50] Step 020/520 Loss 1.960 Prec@(1,5) (61.0%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:10:37] \u001b[32mTrain: [ 34/50] Step 040/520 Loss 1.937 Prec@(1,5) (61.2%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:10:37] \u001b[32mTrain: [ 34/50] Step 060/520 Loss 1.950 Prec@(1,5) (61.0%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:10:38] \u001b[32mTrain: [ 34/50] Step 080/520 Loss 1.953 Prec@(1,5) (60.9%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:10:38] \u001b[32mTrain: [ 34/50] Step 100/520 Loss 1.940 Prec@(1,5) (61.1%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:10:39] \u001b[32mTrain: [ 34/50] Step 120/520 Loss 1.933 Prec@(1,5) (61.0%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:10:39] \u001b[32mTrain: [ 34/50] Step 140/520 Loss 1.936 Prec@(1,5) (60.9%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:10:40] \u001b[32mTrain: [ 34/50] Step 160/520 Loss 1.937 Prec@(1,5) (61.0%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:10:40] \u001b[32mTrain: [ 34/50] Step 180/520 Loss 1.939 Prec@(1,5) (60.9%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:10:41] \u001b[32mTrain: [ 34/50] Step 200/520 Loss 1.936 Prec@(1,5) (61.0%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:10:41] \u001b[32mTrain: [ 34/50] Step 220/520 Loss 1.931 Prec@(1,5) (61.0%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:10:42] \u001b[32mTrain: [ 34/50] Step 240/520 Loss 1.932 Prec@(1,5) (61.1%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:10:42] \u001b[32mTrain: [ 34/50] Step 260/520 Loss 1.937 Prec@(1,5) (60.9%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:10:43] \u001b[32mTrain: [ 34/50] Step 280/520 Loss 1.937 Prec@(1,5) (60.9%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:10:43] \u001b[32mTrain: [ 34/50] Step 300/520 Loss 1.943 Prec@(1,5) (60.8%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:10:44] \u001b[32mTrain: [ 34/50] Step 320/520 Loss 1.940 Prec@(1,5) (60.9%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:10:44] \u001b[32mTrain: [ 34/50] Step 340/520 Loss 1.940 Prec@(1,5) (60.9%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:10:45] \u001b[32mTrain: [ 34/50] Step 360/520 Loss 1.938 Prec@(1,5) (60.9%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:10:45] \u001b[32mTrain: [ 34/50] Step 380/520 Loss 1.938 Prec@(1,5) (60.9%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:10:46] \u001b[32mTrain: [ 34/50] Step 400/520 Loss 1.939 Prec@(1,5) (60.8%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:10:46] \u001b[32mTrain: [ 34/50] Step 420/520 Loss 1.945 Prec@(1,5) (60.7%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:10:47] \u001b[32mTrain: [ 34/50] Step 440/520 Loss 1.948 Prec@(1,5) (60.7%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:10:47] \u001b[32mTrain: [ 34/50] Step 460/520 Loss 1.947 Prec@(1,5) (60.7%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:10:48] \u001b[32mTrain: [ 34/50] Step 480/520 Loss 1.946 Prec@(1,5) (60.7%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:10:48] \u001b[32mTrain: [ 34/50] Step 500/520 Loss 1.947 Prec@(1,5) (60.7%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:10:49] \u001b[32mTrain: [ 34/50] Step 520/520 Loss 1.946 Prec@(1,5) (60.7%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:10:49] \u001b[32mTrain: [ 34/50] Final Prec@1 60.6520%\u001b[0m\n",
            "[2024-04-02 19:10:53] \u001b[32mValid: [ 34/50] Step 000/104 Loss 2.019 Prec@(1,5) (60.4%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:10:53] \u001b[32mValid: [ 34/50] Step 020/104 Loss 2.059 Prec@(1,5) (57.0%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:10:53] \u001b[32mValid: [ 34/50] Step 040/104 Loss 2.061 Prec@(1,5) (56.1%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:10:53] \u001b[32mValid: [ 34/50] Step 060/104 Loss 2.012 Prec@(1,5) (57.0%, 85.2%)\u001b[0m\n",
            "[2024-04-02 19:10:53] \u001b[32mValid: [ 34/50] Step 080/104 Loss 2.023 Prec@(1,5) (56.8%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:10:54] \u001b[32mValid: [ 34/50] Step 100/104 Loss 2.009 Prec@(1,5) (57.1%, 85.0%)\u001b[0m\n",
            "[2024-04-02 19:10:54] \u001b[32mValid: [ 34/50] Step 104/104 Loss 2.009 Prec@(1,5) (57.2%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:10:54] \u001b[32mValid: [ 34/50] Final Prec@1 57.2100%\u001b[0m\n",
            "[2024-04-02 19:10:54] \u001b[32mEpoch 34 LR 0.005803\u001b[0m\n",
            "[2024-04-02 19:10:58] \u001b[32mTrain: [ 35/50] Step 000/520 Loss 1.660 Prec@(1,5) (64.6%, 91.7%)\u001b[0m\n",
            "[2024-04-02 19:10:59] \u001b[32mTrain: [ 35/50] Step 020/520 Loss 1.932 Prec@(1,5) (60.6%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:10:59] \u001b[32mTrain: [ 35/50] Step 040/520 Loss 1.915 Prec@(1,5) (60.4%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:11:00] \u001b[32mTrain: [ 35/50] Step 060/520 Loss 1.920 Prec@(1,5) (60.3%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:11:00] \u001b[32mTrain: [ 35/50] Step 080/520 Loss 1.913 Prec@(1,5) (60.6%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:11:01] \u001b[32mTrain: [ 35/50] Step 100/520 Loss 1.904 Prec@(1,5) (60.8%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:01] \u001b[32mTrain: [ 35/50] Step 120/520 Loss 1.906 Prec@(1,5) (61.0%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:02] \u001b[32mTrain: [ 35/50] Step 140/520 Loss 1.913 Prec@(1,5) (61.0%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:11:02] \u001b[32mTrain: [ 35/50] Step 160/520 Loss 1.900 Prec@(1,5) (61.2%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:03] \u001b[32mTrain: [ 35/50] Step 180/520 Loss 1.903 Prec@(1,5) (61.2%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:03] \u001b[32mTrain: [ 35/50] Step 200/520 Loss 1.906 Prec@(1,5) (61.2%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:11:04] \u001b[32mTrain: [ 35/50] Step 220/520 Loss 1.900 Prec@(1,5) (61.3%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:04] \u001b[32mTrain: [ 35/50] Step 240/520 Loss 1.901 Prec@(1,5) (61.3%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:05] \u001b[32mTrain: [ 35/50] Step 260/520 Loss 1.902 Prec@(1,5) (61.2%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:11:05] \u001b[32mTrain: [ 35/50] Step 280/520 Loss 1.907 Prec@(1,5) (61.2%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:11:06] \u001b[32mTrain: [ 35/50] Step 300/520 Loss 1.906 Prec@(1,5) (61.2%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:06] \u001b[32mTrain: [ 35/50] Step 320/520 Loss 1.906 Prec@(1,5) (61.2%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:11:07] \u001b[32mTrain: [ 35/50] Step 340/520 Loss 1.904 Prec@(1,5) (61.3%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:11:08] \u001b[32mTrain: [ 35/50] Step 360/520 Loss 1.907 Prec@(1,5) (61.3%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:11:08] \u001b[32mTrain: [ 35/50] Step 380/520 Loss 1.911 Prec@(1,5) (61.3%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:11:09] \u001b[32mTrain: [ 35/50] Step 400/520 Loss 1.914 Prec@(1,5) (61.2%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:11:09] \u001b[32mTrain: [ 35/50] Step 420/520 Loss 1.911 Prec@(1,5) (61.3%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:11:10] \u001b[32mTrain: [ 35/50] Step 440/520 Loss 1.912 Prec@(1,5) (61.3%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:11:10] \u001b[32mTrain: [ 35/50] Step 460/520 Loss 1.909 Prec@(1,5) (61.4%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:11:11] \u001b[32mTrain: [ 35/50] Step 480/520 Loss 1.909 Prec@(1,5) (61.3%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:11:11] \u001b[32mTrain: [ 35/50] Step 500/520 Loss 1.908 Prec@(1,5) (61.3%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:11:12] \u001b[32mTrain: [ 35/50] Step 520/520 Loss 1.910 Prec@(1,5) (61.3%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:11:12] \u001b[32mTrain: [ 35/50] Final Prec@1 61.2780%\u001b[0m\n",
            "[2024-04-02 19:11:15] \u001b[32mValid: [ 35/50] Step 000/104 Loss 1.949 Prec@(1,5) (59.4%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:11:15] \u001b[32mValid: [ 35/50] Step 020/104 Loss 2.249 Prec@(1,5) (55.4%, 82.6%)\u001b[0m\n",
            "[2024-04-02 19:11:16] \u001b[32mValid: [ 35/50] Step 040/104 Loss 2.213 Prec@(1,5) (55.2%, 83.7%)\u001b[0m\n",
            "[2024-04-02 19:11:16] \u001b[32mValid: [ 35/50] Step 060/104 Loss 2.165 Prec@(1,5) (56.0%, 84.0%)\u001b[0m\n",
            "[2024-04-02 19:11:16] \u001b[32mValid: [ 35/50] Step 080/104 Loss 2.162 Prec@(1,5) (55.9%, 84.0%)\u001b[0m\n",
            "[2024-04-02 19:11:16] \u001b[32mValid: [ 35/50] Step 100/104 Loss 2.145 Prec@(1,5) (56.3%, 84.1%)\u001b[0m\n",
            "[2024-04-02 19:11:16] \u001b[32mValid: [ 35/50] Step 104/104 Loss 2.148 Prec@(1,5) (56.3%, 84.1%)\u001b[0m\n",
            "[2024-04-02 19:11:16] \u001b[32mValid: [ 35/50] Final Prec@1 56.2500%\u001b[0m\n",
            "[2024-04-02 19:11:16] \u001b[32mEpoch 35 LR 0.005153\u001b[0m\n",
            "[2024-04-02 19:11:21] \u001b[32mTrain: [ 36/50] Step 000/520 Loss 2.117 Prec@(1,5) (57.3%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:11:22] \u001b[32mTrain: [ 36/50] Step 020/520 Loss 1.884 Prec@(1,5) (62.2%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:11:22] \u001b[32mTrain: [ 36/50] Step 040/520 Loss 1.869 Prec@(1,5) (61.9%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:11:23] \u001b[32mTrain: [ 36/50] Step 060/520 Loss 1.894 Prec@(1,5) (61.3%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:23] \u001b[32mTrain: [ 36/50] Step 080/520 Loss 1.912 Prec@(1,5) (61.2%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:24] \u001b[32mTrain: [ 36/50] Step 100/520 Loss 1.910 Prec@(1,5) (61.2%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:11:24] \u001b[32mTrain: [ 36/50] Step 120/520 Loss 1.899 Prec@(1,5) (61.5%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:11:25] \u001b[32mTrain: [ 36/50] Step 140/520 Loss 1.891 Prec@(1,5) (61.9%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:11:25] \u001b[32mTrain: [ 36/50] Step 160/520 Loss 1.883 Prec@(1,5) (61.9%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:11:26] \u001b[32mTrain: [ 36/50] Step 180/520 Loss 1.884 Prec@(1,5) (61.9%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:11:26] \u001b[32mTrain: [ 36/50] Step 200/520 Loss 1.882 Prec@(1,5) (62.0%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:11:27] \u001b[32mTrain: [ 36/50] Step 220/520 Loss 1.878 Prec@(1,5) (62.0%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:11:27] \u001b[32mTrain: [ 36/50] Step 240/520 Loss 1.876 Prec@(1,5) (62.1%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:11:28] \u001b[32mTrain: [ 36/50] Step 260/520 Loss 1.875 Prec@(1,5) (62.1%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:11:28] \u001b[32mTrain: [ 36/50] Step 280/520 Loss 1.880 Prec@(1,5) (62.0%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:11:29] \u001b[32mTrain: [ 36/50] Step 300/520 Loss 1.886 Prec@(1,5) (61.9%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:11:29] \u001b[32mTrain: [ 36/50] Step 320/520 Loss 1.883 Prec@(1,5) (62.0%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:11:30] \u001b[32mTrain: [ 36/50] Step 340/520 Loss 1.881 Prec@(1,5) (62.0%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:11:30] \u001b[32mTrain: [ 36/50] Step 360/520 Loss 1.882 Prec@(1,5) (62.0%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:11:31] \u001b[32mTrain: [ 36/50] Step 380/520 Loss 1.882 Prec@(1,5) (62.0%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:11:31] \u001b[32mTrain: [ 36/50] Step 400/520 Loss 1.881 Prec@(1,5) (62.0%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:11:32] \u001b[32mTrain: [ 36/50] Step 420/520 Loss 1.880 Prec@(1,5) (62.0%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:11:32] \u001b[32mTrain: [ 36/50] Step 440/520 Loss 1.879 Prec@(1,5) (62.0%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:11:33] \u001b[32mTrain: [ 36/50] Step 460/520 Loss 1.883 Prec@(1,5) (62.0%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:33] \u001b[32mTrain: [ 36/50] Step 480/520 Loss 1.886 Prec@(1,5) (62.0%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:34] \u001b[32mTrain: [ 36/50] Step 500/520 Loss 1.887 Prec@(1,5) (62.0%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:11:34] \u001b[32mTrain: [ 36/50] Step 520/520 Loss 1.888 Prec@(1,5) (61.9%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:11:34] \u001b[32mTrain: [ 36/50] Final Prec@1 61.8940%\u001b[0m\n",
            "[2024-04-02 19:11:38] \u001b[32mValid: [ 36/50] Step 000/104 Loss 1.977 Prec@(1,5) (57.3%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:11:38] \u001b[32mValid: [ 36/50] Step 020/104 Loss 2.004 Prec@(1,5) (58.0%, 85.6%)\u001b[0m\n",
            "[2024-04-02 19:11:38] \u001b[32mValid: [ 36/50] Step 040/104 Loss 2.002 Prec@(1,5) (57.2%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:11:38] \u001b[32mValid: [ 36/50] Step 060/104 Loss 1.954 Prec@(1,5) (57.7%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:11:39] \u001b[32mValid: [ 36/50] Step 080/104 Loss 1.973 Prec@(1,5) (57.5%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:11:39] \u001b[32mValid: [ 36/50] Step 100/104 Loss 1.957 Prec@(1,5) (57.8%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:11:39] \u001b[32mValid: [ 36/50] Step 104/104 Loss 1.959 Prec@(1,5) (57.9%, 85.6%)\u001b[0m\n",
            "[2024-04-02 19:11:39] \u001b[32mValid: [ 36/50] Final Prec@1 57.8600%\u001b[0m\n",
            "[2024-04-02 19:11:39] \u001b[32mEpoch 36 LR 0.004533\u001b[0m\n",
            "[2024-04-02 19:11:44] \u001b[32mTrain: [ 37/50] Step 000/520 Loss 1.890 Prec@(1,5) (62.5%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:11:44] \u001b[32mTrain: [ 37/50] Step 020/520 Loss 1.903 Prec@(1,5) (61.3%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:11:45] \u001b[32mTrain: [ 37/50] Step 040/520 Loss 1.882 Prec@(1,5) (62.2%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:11:45] \u001b[32mTrain: [ 37/50] Step 060/520 Loss 1.871 Prec@(1,5) (62.5%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:11:46] \u001b[32mTrain: [ 37/50] Step 080/520 Loss 1.899 Prec@(1,5) (61.9%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:11:46] \u001b[32mTrain: [ 37/50] Step 100/520 Loss 1.881 Prec@(1,5) (62.0%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:47] \u001b[32mTrain: [ 37/50] Step 120/520 Loss 1.879 Prec@(1,5) (62.1%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:47] \u001b[32mTrain: [ 37/50] Step 140/520 Loss 1.882 Prec@(1,5) (62.0%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:48] \u001b[32mTrain: [ 37/50] Step 160/520 Loss 1.880 Prec@(1,5) (62.0%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:48] \u001b[32mTrain: [ 37/50] Step 180/520 Loss 1.883 Prec@(1,5) (61.9%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:49] \u001b[32mTrain: [ 37/50] Step 200/520 Loss 1.877 Prec@(1,5) (62.0%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:11:49] \u001b[32mTrain: [ 37/50] Step 220/520 Loss 1.876 Prec@(1,5) (61.9%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:11:50] \u001b[32mTrain: [ 37/50] Step 240/520 Loss 1.872 Prec@(1,5) (62.0%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:11:50] \u001b[32mTrain: [ 37/50] Step 260/520 Loss 1.870 Prec@(1,5) (62.1%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:51] \u001b[32mTrain: [ 37/50] Step 280/520 Loss 1.870 Prec@(1,5) (62.2%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:51] \u001b[32mTrain: [ 37/50] Step 300/520 Loss 1.864 Prec@(1,5) (62.3%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:52] \u001b[32mTrain: [ 37/50] Step 320/520 Loss 1.863 Prec@(1,5) (62.2%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:52] \u001b[32mTrain: [ 37/50] Step 340/520 Loss 1.860 Prec@(1,5) (62.3%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:53] \u001b[32mTrain: [ 37/50] Step 360/520 Loss 1.862 Prec@(1,5) (62.2%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:53] \u001b[32mTrain: [ 37/50] Step 380/520 Loss 1.861 Prec@(1,5) (62.2%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:11:54] \u001b[32mTrain: [ 37/50] Step 400/520 Loss 1.863 Prec@(1,5) (62.2%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:54] \u001b[32mTrain: [ 37/50] Step 420/520 Loss 1.864 Prec@(1,5) (62.2%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:11:55] \u001b[32mTrain: [ 37/50] Step 440/520 Loss 1.862 Prec@(1,5) (62.2%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:55] \u001b[32mTrain: [ 37/50] Step 460/520 Loss 1.860 Prec@(1,5) (62.3%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:55] \u001b[32mTrain: [ 37/50] Step 480/520 Loss 1.864 Prec@(1,5) (62.3%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:56] \u001b[32mTrain: [ 37/50] Step 500/520 Loss 1.866 Prec@(1,5) (62.2%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:56] \u001b[32mTrain: [ 37/50] Step 520/520 Loss 1.865 Prec@(1,5) (62.2%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:11:57] \u001b[32mTrain: [ 37/50] Final Prec@1 62.2420%\u001b[0m\n",
            "[2024-04-02 19:12:00] \u001b[32mValid: [ 37/50] Step 000/104 Loss 1.918 Prec@(1,5) (62.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:12:00] \u001b[32mValid: [ 37/50] Step 020/104 Loss 1.959 Prec@(1,5) (58.8%, 85.3%)\u001b[0m\n",
            "[2024-04-02 19:12:01] \u001b[32mValid: [ 37/50] Step 040/104 Loss 1.958 Prec@(1,5) (57.7%, 85.6%)\u001b[0m\n",
            "[2024-04-02 19:12:01] \u001b[32mValid: [ 37/50] Step 060/104 Loss 1.927 Prec@(1,5) (58.1%, 85.6%)\u001b[0m\n",
            "[2024-04-02 19:12:01] \u001b[32mValid: [ 37/50] Step 080/104 Loss 1.941 Prec@(1,5) (57.9%, 85.3%)\u001b[0m\n",
            "[2024-04-02 19:12:01] \u001b[32mValid: [ 37/50] Step 100/104 Loss 1.917 Prec@(1,5) (58.5%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:12:01] \u001b[32mValid: [ 37/50] Step 104/104 Loss 1.919 Prec@(1,5) (58.6%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:12:01] \u001b[32mValid: [ 37/50] Final Prec@1 58.5600%\u001b[0m\n",
            "[2024-04-02 19:12:01] \u001b[32mEpoch 37 LR 0.003944\u001b[0m\n",
            "[2024-04-02 19:12:06] \u001b[32mTrain: [ 38/50] Step 000/520 Loss 2.200 Prec@(1,5) (58.3%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:12:06] \u001b[32mTrain: [ 38/50] Step 020/520 Loss 1.831 Prec@(1,5) (63.3%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:12:07] \u001b[32mTrain: [ 38/50] Step 040/520 Loss 1.814 Prec@(1,5) (63.2%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:12:07] \u001b[32mTrain: [ 38/50] Step 060/520 Loss 1.831 Prec@(1,5) (62.8%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:12:08] \u001b[32mTrain: [ 38/50] Step 080/520 Loss 1.824 Prec@(1,5) (62.9%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:12:08] \u001b[32mTrain: [ 38/50] Step 100/520 Loss 1.828 Prec@(1,5) (62.8%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:12:09] \u001b[32mTrain: [ 38/50] Step 120/520 Loss 1.829 Prec@(1,5) (62.8%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:12:09] \u001b[32mTrain: [ 38/50] Step 140/520 Loss 1.841 Prec@(1,5) (62.7%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:12:10] \u001b[32mTrain: [ 38/50] Step 160/520 Loss 1.843 Prec@(1,5) (62.6%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:12:10] \u001b[32mTrain: [ 38/50] Step 180/520 Loss 1.846 Prec@(1,5) (62.5%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:12:11] \u001b[32mTrain: [ 38/50] Step 200/520 Loss 1.841 Prec@(1,5) (62.6%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:12:11] \u001b[32mTrain: [ 38/50] Step 220/520 Loss 1.849 Prec@(1,5) (62.6%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:12:12] \u001b[32mTrain: [ 38/50] Step 240/520 Loss 1.856 Prec@(1,5) (62.4%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:12:12] \u001b[32mTrain: [ 38/50] Step 260/520 Loss 1.858 Prec@(1,5) (62.3%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:12:13] \u001b[32mTrain: [ 38/50] Step 280/520 Loss 1.855 Prec@(1,5) (62.4%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:12:13] \u001b[32mTrain: [ 38/50] Step 300/520 Loss 1.860 Prec@(1,5) (62.4%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:12:14] \u001b[32mTrain: [ 38/50] Step 320/520 Loss 1.856 Prec@(1,5) (62.5%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:12:14] \u001b[32mTrain: [ 38/50] Step 340/520 Loss 1.856 Prec@(1,5) (62.5%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:12:15] \u001b[32mTrain: [ 38/50] Step 360/520 Loss 1.854 Prec@(1,5) (62.5%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:12:15] \u001b[32mTrain: [ 38/50] Step 380/520 Loss 1.852 Prec@(1,5) (62.5%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:12:16] \u001b[32mTrain: [ 38/50] Step 400/520 Loss 1.851 Prec@(1,5) (62.6%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:12:16] \u001b[32mTrain: [ 38/50] Step 420/520 Loss 1.847 Prec@(1,5) (62.6%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:12:17] \u001b[32mTrain: [ 38/50] Step 440/520 Loss 1.846 Prec@(1,5) (62.6%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:12:17] \u001b[32mTrain: [ 38/50] Step 460/520 Loss 1.846 Prec@(1,5) (62.6%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:12:18] \u001b[32mTrain: [ 38/50] Step 480/520 Loss 1.846 Prec@(1,5) (62.7%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:12:18] \u001b[32mTrain: [ 38/50] Step 500/520 Loss 1.845 Prec@(1,5) (62.7%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:12:19] \u001b[32mTrain: [ 38/50] Step 520/520 Loss 1.843 Prec@(1,5) (62.7%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:12:19] \u001b[32mTrain: [ 38/50] Final Prec@1 62.7260%\u001b[0m\n",
            "[2024-04-02 19:12:22] \u001b[32mValid: [ 38/50] Step 000/104 Loss 1.952 Prec@(1,5) (61.5%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:12:22] \u001b[32mValid: [ 38/50] Step 020/104 Loss 2.059 Prec@(1,5) (58.6%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:12:23] \u001b[32mValid: [ 38/50] Step 040/104 Loss 2.055 Prec@(1,5) (57.6%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:12:23] \u001b[32mValid: [ 38/50] Step 060/104 Loss 1.996 Prec@(1,5) (58.0%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:12:23] \u001b[32mValid: [ 38/50] Step 080/104 Loss 1.995 Prec@(1,5) (57.7%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:12:23] \u001b[32mValid: [ 38/50] Step 100/104 Loss 1.976 Prec@(1,5) (58.0%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:12:23] \u001b[32mValid: [ 38/50] Step 104/104 Loss 1.976 Prec@(1,5) (58.1%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:12:23] \u001b[32mValid: [ 38/50] Final Prec@1 58.0900%\u001b[0m\n",
            "[2024-04-02 19:12:23] \u001b[32mEpoch 38 LR 0.003389\u001b[0m\n",
            "[2024-04-02 19:12:28] \u001b[32mTrain: [ 39/50] Step 000/520 Loss 2.061 Prec@(1,5) (59.4%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:12:29] \u001b[32mTrain: [ 39/50] Step 020/520 Loss 1.846 Prec@(1,5) (63.1%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:12:29] \u001b[32mTrain: [ 39/50] Step 040/520 Loss 1.817 Prec@(1,5) (63.4%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:12:30] \u001b[32mTrain: [ 39/50] Step 060/520 Loss 1.818 Prec@(1,5) (63.3%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:12:30] \u001b[32mTrain: [ 39/50] Step 080/520 Loss 1.821 Prec@(1,5) (63.3%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:12:30] \u001b[32mTrain: [ 39/50] Step 100/520 Loss 1.799 Prec@(1,5) (63.7%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:12:31] \u001b[32mTrain: [ 39/50] Step 120/520 Loss 1.806 Prec@(1,5) (63.6%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:12:31] \u001b[32mTrain: [ 39/50] Step 140/520 Loss 1.806 Prec@(1,5) (63.7%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:12:32] \u001b[32mTrain: [ 39/50] Step 160/520 Loss 1.809 Prec@(1,5) (63.6%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:12:32] \u001b[32mTrain: [ 39/50] Step 180/520 Loss 1.802 Prec@(1,5) (63.7%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:12:33] \u001b[32mTrain: [ 39/50] Step 200/520 Loss 1.802 Prec@(1,5) (63.7%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:12:33] \u001b[32mTrain: [ 39/50] Step 220/520 Loss 1.794 Prec@(1,5) (63.9%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:12:34] \u001b[32mTrain: [ 39/50] Step 240/520 Loss 1.795 Prec@(1,5) (63.9%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:12:34] \u001b[32mTrain: [ 39/50] Step 260/520 Loss 1.801 Prec@(1,5) (63.6%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:12:35] \u001b[32mTrain: [ 39/50] Step 280/520 Loss 1.806 Prec@(1,5) (63.5%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:12:35] \u001b[32mTrain: [ 39/50] Step 300/520 Loss 1.810 Prec@(1,5) (63.4%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:12:36] \u001b[32mTrain: [ 39/50] Step 320/520 Loss 1.808 Prec@(1,5) (63.5%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:12:36] \u001b[32mTrain: [ 39/50] Step 340/520 Loss 1.806 Prec@(1,5) (63.6%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:12:37] \u001b[32mTrain: [ 39/50] Step 360/520 Loss 1.812 Prec@(1,5) (63.5%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:12:37] \u001b[32mTrain: [ 39/50] Step 380/520 Loss 1.815 Prec@(1,5) (63.4%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:12:38] \u001b[32mTrain: [ 39/50] Step 400/520 Loss 1.818 Prec@(1,5) (63.3%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:12:39] \u001b[32mTrain: [ 39/50] Step 420/520 Loss 1.820 Prec@(1,5) (63.3%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:12:39] \u001b[32mTrain: [ 39/50] Step 440/520 Loss 1.820 Prec@(1,5) (63.2%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:12:39] \u001b[32mTrain: [ 39/50] Step 460/520 Loss 1.819 Prec@(1,5) (63.2%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:12:40] \u001b[32mTrain: [ 39/50] Step 480/520 Loss 1.819 Prec@(1,5) (63.2%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:12:40] \u001b[32mTrain: [ 39/50] Step 500/520 Loss 1.818 Prec@(1,5) (63.2%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:12:41] \u001b[32mTrain: [ 39/50] Step 520/520 Loss 1.817 Prec@(1,5) (63.3%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:12:41] \u001b[32mTrain: [ 39/50] Final Prec@1 63.3280%\u001b[0m\n",
            "[2024-04-02 19:12:45] \u001b[32mValid: [ 39/50] Step 000/104 Loss 1.803 Prec@(1,5) (61.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:12:45] \u001b[32mValid: [ 39/50] Step 020/104 Loss 1.893 Prec@(1,5) (60.2%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:12:45] \u001b[32mValid: [ 39/50] Step 040/104 Loss 1.905 Prec@(1,5) (59.2%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:12:45] \u001b[32mValid: [ 39/50] Step 060/104 Loss 1.849 Prec@(1,5) (59.9%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:12:45] \u001b[32mValid: [ 39/50] Step 080/104 Loss 1.860 Prec@(1,5) (59.5%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:12:46] \u001b[32mValid: [ 39/50] Step 100/104 Loss 1.845 Prec@(1,5) (60.1%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:12:46] \u001b[32mValid: [ 39/50] Step 104/104 Loss 1.843 Prec@(1,5) (60.2%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:12:46] \u001b[32mValid: [ 39/50] Final Prec@1 60.1900%\u001b[0m\n",
            "[2024-04-02 19:12:46] \u001b[32mEpoch 39 LR 0.002869\u001b[0m\n",
            "[2024-04-02 19:12:50] \u001b[32mTrain: [ 40/50] Step 000/520 Loss 1.400 Prec@(1,5) (69.8%, 91.7%)\u001b[0m\n",
            "[2024-04-02 19:12:51] \u001b[32mTrain: [ 40/50] Step 020/520 Loss 1.740 Prec@(1,5) (64.8%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:12:51] \u001b[32mTrain: [ 40/50] Step 040/520 Loss 1.756 Prec@(1,5) (64.5%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:12:52] \u001b[32mTrain: [ 40/50] Step 060/520 Loss 1.754 Prec@(1,5) (64.7%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:12:52] \u001b[32mTrain: [ 40/50] Step 080/520 Loss 1.759 Prec@(1,5) (64.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:12:53] \u001b[32mTrain: [ 40/50] Step 100/520 Loss 1.765 Prec@(1,5) (64.5%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:12:53] \u001b[32mTrain: [ 40/50] Step 120/520 Loss 1.773 Prec@(1,5) (64.3%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:12:54] \u001b[32mTrain: [ 40/50] Step 140/520 Loss 1.775 Prec@(1,5) (64.2%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:12:54] \u001b[32mTrain: [ 40/50] Step 160/520 Loss 1.778 Prec@(1,5) (64.0%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:12:55] \u001b[32mTrain: [ 40/50] Step 180/520 Loss 1.779 Prec@(1,5) (64.0%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:12:55] \u001b[32mTrain: [ 40/50] Step 200/520 Loss 1.779 Prec@(1,5) (64.1%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:12:56] \u001b[32mTrain: [ 40/50] Step 220/520 Loss 1.772 Prec@(1,5) (64.2%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:12:56] \u001b[32mTrain: [ 40/50] Step 240/520 Loss 1.771 Prec@(1,5) (64.2%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:12:57] \u001b[32mTrain: [ 40/50] Step 260/520 Loss 1.782 Prec@(1,5) (64.0%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:12:57] \u001b[32mTrain: [ 40/50] Step 280/520 Loss 1.786 Prec@(1,5) (64.0%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:12:58] \u001b[32mTrain: [ 40/50] Step 300/520 Loss 1.796 Prec@(1,5) (63.8%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:12:58] \u001b[32mTrain: [ 40/50] Step 320/520 Loss 1.797 Prec@(1,5) (63.8%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:12:59] \u001b[32mTrain: [ 40/50] Step 340/520 Loss 1.798 Prec@(1,5) (63.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:12:59] \u001b[32mTrain: [ 40/50] Step 360/520 Loss 1.798 Prec@(1,5) (63.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:13:00] \u001b[32mTrain: [ 40/50] Step 380/520 Loss 1.798 Prec@(1,5) (63.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:13:00] \u001b[32mTrain: [ 40/50] Step 400/520 Loss 1.800 Prec@(1,5) (63.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:13:01] \u001b[32mTrain: [ 40/50] Step 420/520 Loss 1.801 Prec@(1,5) (63.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:13:01] \u001b[32mTrain: [ 40/50] Step 440/520 Loss 1.799 Prec@(1,5) (63.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:13:02] \u001b[32mTrain: [ 40/50] Step 460/520 Loss 1.801 Prec@(1,5) (63.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:13:02] \u001b[32mTrain: [ 40/50] Step 480/520 Loss 1.800 Prec@(1,5) (63.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:13:03] \u001b[32mTrain: [ 40/50] Step 500/520 Loss 1.800 Prec@(1,5) (63.6%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:13:03] \u001b[32mTrain: [ 40/50] Step 520/520 Loss 1.799 Prec@(1,5) (63.7%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:13:03] \u001b[32mTrain: [ 40/50] Final Prec@1 63.6620%\u001b[0m\n",
            "[2024-04-02 19:13:07] \u001b[32mValid: [ 40/50] Step 000/104 Loss 1.800 Prec@(1,5) (61.5%, 90.6%)\u001b[0m\n",
            "[2024-04-02 19:13:07] \u001b[32mValid: [ 40/50] Step 020/104 Loss 1.940 Prec@(1,5) (59.6%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:13:07] \u001b[32mValid: [ 40/50] Step 040/104 Loss 1.920 Prec@(1,5) (58.9%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:13:07] \u001b[32mValid: [ 40/50] Step 060/104 Loss 1.868 Prec@(1,5) (59.5%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:13:07] \u001b[32mValid: [ 40/50] Step 080/104 Loss 1.883 Prec@(1,5) (59.2%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:13:08] \u001b[32mValid: [ 40/50] Step 100/104 Loss 1.865 Prec@(1,5) (59.6%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:13:08] \u001b[32mValid: [ 40/50] Step 104/104 Loss 1.867 Prec@(1,5) (59.6%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:13:08] \u001b[32mValid: [ 40/50] Final Prec@1 59.5900%\u001b[0m\n",
            "[2024-04-02 19:13:08] \u001b[32mEpoch 40 LR 0.002388\u001b[0m\n",
            "[2024-04-02 19:13:12] \u001b[32mTrain: [ 41/50] Step 000/520 Loss 1.552 Prec@(1,5) (69.8%, 93.8%)\u001b[0m\n",
            "[2024-04-02 19:13:13] \u001b[32mTrain: [ 41/50] Step 020/520 Loss 1.744 Prec@(1,5) (64.4%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:13:13] \u001b[32mTrain: [ 41/50] Step 040/520 Loss 1.744 Prec@(1,5) (64.8%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:13:14] \u001b[32mTrain: [ 41/50] Step 060/520 Loss 1.768 Prec@(1,5) (64.5%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:13:14] \u001b[32mTrain: [ 41/50] Step 080/520 Loss 1.766 Prec@(1,5) (64.1%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:13:15] \u001b[32mTrain: [ 41/50] Step 100/520 Loss 1.766 Prec@(1,5) (64.2%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:13:15] \u001b[32mTrain: [ 41/50] Step 120/520 Loss 1.777 Prec@(1,5) (64.1%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:13:16] \u001b[32mTrain: [ 41/50] Step 140/520 Loss 1.765 Prec@(1,5) (64.3%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:13:16] \u001b[32mTrain: [ 41/50] Step 160/520 Loss 1.770 Prec@(1,5) (64.2%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:13:17] \u001b[32mTrain: [ 41/50] Step 180/520 Loss 1.764 Prec@(1,5) (64.2%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:13:17] \u001b[32mTrain: [ 41/50] Step 200/520 Loss 1.771 Prec@(1,5) (64.0%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:13:18] \u001b[32mTrain: [ 41/50] Step 220/520 Loss 1.776 Prec@(1,5) (64.0%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:13:18] \u001b[32mTrain: [ 41/50] Step 240/520 Loss 1.780 Prec@(1,5) (63.9%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:13:19] \u001b[32mTrain: [ 41/50] Step 260/520 Loss 1.787 Prec@(1,5) (63.8%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:13:19] \u001b[32mTrain: [ 41/50] Step 280/520 Loss 1.789 Prec@(1,5) (63.7%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:13:20] \u001b[32mTrain: [ 41/50] Step 300/520 Loss 1.795 Prec@(1,5) (63.5%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:13:20] \u001b[32mTrain: [ 41/50] Step 320/520 Loss 1.795 Prec@(1,5) (63.6%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:13:21] \u001b[32mTrain: [ 41/50] Step 340/520 Loss 1.795 Prec@(1,5) (63.6%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:13:21] \u001b[32mTrain: [ 41/50] Step 360/520 Loss 1.797 Prec@(1,5) (63.6%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:13:22] \u001b[32mTrain: [ 41/50] Step 380/520 Loss 1.795 Prec@(1,5) (63.6%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:13:22] \u001b[32mTrain: [ 41/50] Step 400/520 Loss 1.791 Prec@(1,5) (63.7%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:13:23] \u001b[32mTrain: [ 41/50] Step 420/520 Loss 1.795 Prec@(1,5) (63.7%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:13:23] \u001b[32mTrain: [ 41/50] Step 440/520 Loss 1.794 Prec@(1,5) (63.6%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:13:24] \u001b[32mTrain: [ 41/50] Step 460/520 Loss 1.792 Prec@(1,5) (63.7%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:13:24] \u001b[32mTrain: [ 41/50] Step 480/520 Loss 1.793 Prec@(1,5) (63.7%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:13:25] \u001b[32mTrain: [ 41/50] Step 500/520 Loss 1.791 Prec@(1,5) (63.6%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:13:25] \u001b[32mTrain: [ 41/50] Step 520/520 Loss 1.789 Prec@(1,5) (63.7%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:13:25] \u001b[32mTrain: [ 41/50] Final Prec@1 63.6720%\u001b[0m\n",
            "[2024-04-02 19:13:29] \u001b[32mValid: [ 41/50] Step 000/104 Loss 1.881 Prec@(1,5) (65.6%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:13:29] \u001b[32mValid: [ 41/50] Step 020/104 Loss 1.880 Prec@(1,5) (60.3%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:13:29] \u001b[32mValid: [ 41/50] Step 040/104 Loss 1.880 Prec@(1,5) (59.4%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:13:29] \u001b[32mValid: [ 41/50] Step 060/104 Loss 1.831 Prec@(1,5) (60.1%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:13:30] \u001b[32mValid: [ 41/50] Step 080/104 Loss 1.840 Prec@(1,5) (59.7%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:13:30] \u001b[32mValid: [ 41/50] Step 100/104 Loss 1.822 Prec@(1,5) (60.2%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:13:30] \u001b[32mValid: [ 41/50] Step 104/104 Loss 1.824 Prec@(1,5) (60.2%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:13:30] \u001b[32mValid: [ 41/50] Final Prec@1 60.2200%\u001b[0m\n",
            "[2024-04-02 19:13:30] \u001b[32mEpoch 41 LR 0.001947\u001b[0m\n",
            "[2024-04-02 19:13:35] \u001b[32mTrain: [ 42/50] Step 000/520 Loss 1.858 Prec@(1,5) (66.7%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:13:35] \u001b[32mTrain: [ 42/50] Step 020/520 Loss 1.723 Prec@(1,5) (65.7%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:13:36] \u001b[32mTrain: [ 42/50] Step 040/520 Loss 1.722 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:13:36] \u001b[32mTrain: [ 42/50] Step 060/520 Loss 1.723 Prec@(1,5) (65.1%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:13:37] \u001b[32mTrain: [ 42/50] Step 080/520 Loss 1.730 Prec@(1,5) (65.0%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:13:37] \u001b[32mTrain: [ 42/50] Step 100/520 Loss 1.734 Prec@(1,5) (64.9%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:13:38] \u001b[32mTrain: [ 42/50] Step 120/520 Loss 1.746 Prec@(1,5) (64.8%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:13:38] \u001b[32mTrain: [ 42/50] Step 140/520 Loss 1.735 Prec@(1,5) (65.1%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:13:39] \u001b[32mTrain: [ 42/50] Step 160/520 Loss 1.739 Prec@(1,5) (65.0%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:13:39] \u001b[32mTrain: [ 42/50] Step 180/520 Loss 1.745 Prec@(1,5) (64.8%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:13:40] \u001b[32mTrain: [ 42/50] Step 200/520 Loss 1.748 Prec@(1,5) (64.7%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:13:40] \u001b[32mTrain: [ 42/50] Step 220/520 Loss 1.745 Prec@(1,5) (64.8%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:13:41] \u001b[32mTrain: [ 42/50] Step 240/520 Loss 1.748 Prec@(1,5) (64.7%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:13:41] \u001b[32mTrain: [ 42/50] Step 260/520 Loss 1.754 Prec@(1,5) (64.7%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:13:42] \u001b[32mTrain: [ 42/50] Step 280/520 Loss 1.757 Prec@(1,5) (64.6%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:13:42] \u001b[32mTrain: [ 42/50] Step 300/520 Loss 1.755 Prec@(1,5) (64.6%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:13:43] \u001b[32mTrain: [ 42/50] Step 320/520 Loss 1.757 Prec@(1,5) (64.6%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:13:43] \u001b[32mTrain: [ 42/50] Step 340/520 Loss 1.758 Prec@(1,5) (64.6%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:13:44] \u001b[32mTrain: [ 42/50] Step 360/520 Loss 1.754 Prec@(1,5) (64.7%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:13:44] \u001b[32mTrain: [ 42/50] Step 380/520 Loss 1.755 Prec@(1,5) (64.7%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:13:45] \u001b[32mTrain: [ 42/50] Step 400/520 Loss 1.754 Prec@(1,5) (64.7%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:13:45] \u001b[32mTrain: [ 42/50] Step 420/520 Loss 1.755 Prec@(1,5) (64.7%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:13:46] \u001b[32mTrain: [ 42/50] Step 440/520 Loss 1.755 Prec@(1,5) (64.6%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:13:46] \u001b[32mTrain: [ 42/50] Step 460/520 Loss 1.759 Prec@(1,5) (64.6%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:13:46] \u001b[32mTrain: [ 42/50] Step 480/520 Loss 1.759 Prec@(1,5) (64.6%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:13:47] \u001b[32mTrain: [ 42/50] Step 500/520 Loss 1.756 Prec@(1,5) (64.7%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:13:47] \u001b[32mTrain: [ 42/50] Step 520/520 Loss 1.758 Prec@(1,5) (64.6%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:13:48] \u001b[32mTrain: [ 42/50] Final Prec@1 64.5940%\u001b[0m\n",
            "[2024-04-02 19:13:51] \u001b[32mValid: [ 42/50] Step 000/104 Loss 1.892 Prec@(1,5) (64.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:13:51] \u001b[32mValid: [ 42/50] Step 020/104 Loss 1.881 Prec@(1,5) (60.6%, 86.1%)\u001b[0m\n",
            "[2024-04-02 19:13:51] \u001b[32mValid: [ 42/50] Step 040/104 Loss 1.879 Prec@(1,5) (59.8%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:13:52] \u001b[32mValid: [ 42/50] Step 060/104 Loss 1.827 Prec@(1,5) (60.4%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:13:52] \u001b[32mValid: [ 42/50] Step 080/104 Loss 1.837 Prec@(1,5) (60.2%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:13:52] \u001b[32mValid: [ 42/50] Step 100/104 Loss 1.817 Prec@(1,5) (60.6%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:13:52] \u001b[32mValid: [ 42/50] Step 104/104 Loss 1.819 Prec@(1,5) (60.6%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:13:52] \u001b[32mValid: [ 42/50] Final Prec@1 60.6400%\u001b[0m\n",
            "[2024-04-02 19:13:52] \u001b[32mEpoch 42 LR 0.001547\u001b[0m\n",
            "[2024-04-02 19:13:57] \u001b[32mTrain: [ 43/50] Step 000/520 Loss 1.474 Prec@(1,5) (69.8%, 93.8%)\u001b[0m\n",
            "[2024-04-02 19:13:57] \u001b[32mTrain: [ 43/50] Step 020/520 Loss 1.677 Prec@(1,5) (67.1%, 90.3%)\u001b[0m\n",
            "[2024-04-02 19:13:58] \u001b[32mTrain: [ 43/50] Step 040/520 Loss 1.741 Prec@(1,5) (65.3%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:13:58] \u001b[32mTrain: [ 43/50] Step 060/520 Loss 1.749 Prec@(1,5) (64.9%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:13:59] \u001b[32mTrain: [ 43/50] Step 080/520 Loss 1.749 Prec@(1,5) (64.8%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:13:59] \u001b[32mTrain: [ 43/50] Step 100/520 Loss 1.751 Prec@(1,5) (64.7%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:14:00] \u001b[32mTrain: [ 43/50] Step 120/520 Loss 1.752 Prec@(1,5) (64.5%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:14:00] \u001b[32mTrain: [ 43/50] Step 140/520 Loss 1.751 Prec@(1,5) (64.5%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:14:01] \u001b[32mTrain: [ 43/50] Step 160/520 Loss 1.760 Prec@(1,5) (64.4%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:14:01] \u001b[32mTrain: [ 43/50] Step 180/520 Loss 1.759 Prec@(1,5) (64.4%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:14:02] \u001b[32mTrain: [ 43/50] Step 200/520 Loss 1.761 Prec@(1,5) (64.4%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:14:02] \u001b[32mTrain: [ 43/50] Step 220/520 Loss 1.757 Prec@(1,5) (64.6%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:14:03] \u001b[32mTrain: [ 43/50] Step 240/520 Loss 1.757 Prec@(1,5) (64.5%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:14:03] \u001b[32mTrain: [ 43/50] Step 260/520 Loss 1.757 Prec@(1,5) (64.5%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:14:04] \u001b[32mTrain: [ 43/50] Step 280/520 Loss 1.751 Prec@(1,5) (64.6%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:14:04] \u001b[32mTrain: [ 43/50] Step 300/520 Loss 1.749 Prec@(1,5) (64.6%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:14:05] \u001b[32mTrain: [ 43/50] Step 320/520 Loss 1.751 Prec@(1,5) (64.6%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:14:05] \u001b[32mTrain: [ 43/50] Step 340/520 Loss 1.756 Prec@(1,5) (64.5%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:14:06] \u001b[32mTrain: [ 43/50] Step 360/520 Loss 1.752 Prec@(1,5) (64.6%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:14:06] \u001b[32mTrain: [ 43/50] Step 380/520 Loss 1.754 Prec@(1,5) (64.6%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:14:07] \u001b[32mTrain: [ 43/50] Step 400/520 Loss 1.754 Prec@(1,5) (64.5%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:14:07] \u001b[32mTrain: [ 43/50] Step 420/520 Loss 1.755 Prec@(1,5) (64.5%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:14:08] \u001b[32mTrain: [ 43/50] Step 440/520 Loss 1.754 Prec@(1,5) (64.5%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:14:08] \u001b[32mTrain: [ 43/50] Step 460/520 Loss 1.758 Prec@(1,5) (64.5%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:14:09] \u001b[32mTrain: [ 43/50] Step 480/520 Loss 1.763 Prec@(1,5) (64.4%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:14:09] \u001b[32mTrain: [ 43/50] Step 500/520 Loss 1.763 Prec@(1,5) (64.4%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:14:10] \u001b[32mTrain: [ 43/50] Step 520/520 Loss 1.761 Prec@(1,5) (64.5%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:14:10] \u001b[32mTrain: [ 43/50] Final Prec@1 64.5260%\u001b[0m\n",
            "[2024-04-02 19:14:13] \u001b[32mValid: [ 43/50] Step 000/104 Loss 1.861 Prec@(1,5) (64.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:14:14] \u001b[32mValid: [ 43/50] Step 020/104 Loss 1.900 Prec@(1,5) (60.6%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:14:14] \u001b[32mValid: [ 43/50] Step 040/104 Loss 1.890 Prec@(1,5) (59.7%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:14:14] \u001b[32mValid: [ 43/50] Step 060/104 Loss 1.834 Prec@(1,5) (60.3%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:14:14] \u001b[32mValid: [ 43/50] Step 080/104 Loss 1.840 Prec@(1,5) (59.9%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:14:14] \u001b[32mValid: [ 43/50] Step 100/104 Loss 1.824 Prec@(1,5) (60.3%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:14:14] \u001b[32mValid: [ 43/50] Step 104/104 Loss 1.825 Prec@(1,5) (60.3%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:14:14] \u001b[32mValid: [ 43/50] Final Prec@1 60.3100%\u001b[0m\n",
            "[2024-04-02 19:14:14] \u001b[32mEpoch 43 LR 0.001191\u001b[0m\n",
            "[2024-04-02 19:14:19] \u001b[32mTrain: [ 44/50] Step 000/520 Loss 2.272 Prec@(1,5) (55.2%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:14:20] \u001b[32mTrain: [ 44/50] Step 020/520 Loss 1.735 Prec@(1,5) (65.0%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:14:20] \u001b[32mTrain: [ 44/50] Step 040/520 Loss 1.732 Prec@(1,5) (64.8%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:14:21] \u001b[32mTrain: [ 44/50] Step 060/520 Loss 1.745 Prec@(1,5) (64.6%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:14:21] \u001b[32mTrain: [ 44/50] Step 080/520 Loss 1.743 Prec@(1,5) (64.6%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:14:22] \u001b[32mTrain: [ 44/50] Step 100/520 Loss 1.734 Prec@(1,5) (64.9%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:14:22] \u001b[32mTrain: [ 44/50] Step 120/520 Loss 1.722 Prec@(1,5) (64.9%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:14:23] \u001b[32mTrain: [ 44/50] Step 140/520 Loss 1.729 Prec@(1,5) (64.8%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:14:23] \u001b[32mTrain: [ 44/50] Step 160/520 Loss 1.740 Prec@(1,5) (64.6%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:14:24] \u001b[32mTrain: [ 44/50] Step 180/520 Loss 1.744 Prec@(1,5) (64.5%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:14:24] \u001b[32mTrain: [ 44/50] Step 200/520 Loss 1.751 Prec@(1,5) (64.5%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:14:25] \u001b[32mTrain: [ 44/50] Step 220/520 Loss 1.752 Prec@(1,5) (64.4%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:14:25] \u001b[32mTrain: [ 44/50] Step 240/520 Loss 1.753 Prec@(1,5) (64.5%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:14:26] \u001b[32mTrain: [ 44/50] Step 260/520 Loss 1.754 Prec@(1,5) (64.4%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:14:26] \u001b[32mTrain: [ 44/50] Step 280/520 Loss 1.751 Prec@(1,5) (64.5%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:14:27] \u001b[32mTrain: [ 44/50] Step 300/520 Loss 1.749 Prec@(1,5) (64.5%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:14:27] \u001b[32mTrain: [ 44/50] Step 320/520 Loss 1.748 Prec@(1,5) (64.5%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:14:27] \u001b[32mTrain: [ 44/50] Step 340/520 Loss 1.751 Prec@(1,5) (64.5%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:14:28] \u001b[32mTrain: [ 44/50] Step 360/520 Loss 1.750 Prec@(1,5) (64.6%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:14:28] \u001b[32mTrain: [ 44/50] Step 380/520 Loss 1.746 Prec@(1,5) (64.7%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:14:29] \u001b[32mTrain: [ 44/50] Step 400/520 Loss 1.748 Prec@(1,5) (64.6%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:14:29] \u001b[32mTrain: [ 44/50] Step 420/520 Loss 1.750 Prec@(1,5) (64.6%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:14:30] \u001b[32mTrain: [ 44/50] Step 440/520 Loss 1.748 Prec@(1,5) (64.7%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:14:30] \u001b[32mTrain: [ 44/50] Step 460/520 Loss 1.746 Prec@(1,5) (64.7%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:14:31] \u001b[32mTrain: [ 44/50] Step 480/520 Loss 1.747 Prec@(1,5) (64.7%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:14:31] \u001b[32mTrain: [ 44/50] Step 500/520 Loss 1.748 Prec@(1,5) (64.7%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:14:32] \u001b[32mTrain: [ 44/50] Step 520/520 Loss 1.749 Prec@(1,5) (64.7%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:14:32] \u001b[32mTrain: [ 44/50] Final Prec@1 64.6560%\u001b[0m\n",
            "[2024-04-02 19:14:36] \u001b[32mValid: [ 44/50] Step 000/104 Loss 1.790 Prec@(1,5) (62.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:14:36] \u001b[32mValid: [ 44/50] Step 020/104 Loss 1.904 Prec@(1,5) (60.1%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:14:36] \u001b[32mValid: [ 44/50] Step 040/104 Loss 1.884 Prec@(1,5) (59.4%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:14:36] \u001b[32mValid: [ 44/50] Step 060/104 Loss 1.822 Prec@(1,5) (60.0%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:14:36] \u001b[32mValid: [ 44/50] Step 080/104 Loss 1.827 Prec@(1,5) (59.9%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:14:37] \u001b[32mValid: [ 44/50] Step 100/104 Loss 1.811 Prec@(1,5) (60.3%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:14:37] \u001b[32mValid: [ 44/50] Step 104/104 Loss 1.813 Prec@(1,5) (60.4%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:14:37] \u001b[32mValid: [ 44/50] Final Prec@1 60.3600%\u001b[0m\n",
            "[2024-04-02 19:14:37] \u001b[32mEpoch 44 LR 0.000879\u001b[0m\n",
            "[2024-04-02 19:14:41] \u001b[32mTrain: [ 45/50] Step 000/520 Loss 1.565 Prec@(1,5) (69.8%, 91.7%)\u001b[0m\n",
            "[2024-04-02 19:14:42] \u001b[32mTrain: [ 45/50] Step 020/520 Loss 1.748 Prec@(1,5) (64.5%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:14:42] \u001b[32mTrain: [ 45/50] Step 040/520 Loss 1.729 Prec@(1,5) (65.4%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:14:43] \u001b[32mTrain: [ 45/50] Step 060/520 Loss 1.747 Prec@(1,5) (64.8%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:14:43] \u001b[32mTrain: [ 45/50] Step 080/520 Loss 1.739 Prec@(1,5) (64.9%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:14:44] \u001b[32mTrain: [ 45/50] Step 100/520 Loss 1.749 Prec@(1,5) (64.8%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:14:44] \u001b[32mTrain: [ 45/50] Step 120/520 Loss 1.744 Prec@(1,5) (64.7%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:14:45] \u001b[32mTrain: [ 45/50] Step 140/520 Loss 1.745 Prec@(1,5) (64.7%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:14:45] \u001b[32mTrain: [ 45/50] Step 160/520 Loss 1.747 Prec@(1,5) (64.8%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:14:46] \u001b[32mTrain: [ 45/50] Step 180/520 Loss 1.737 Prec@(1,5) (65.0%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:14:47] \u001b[32mTrain: [ 45/50] Step 200/520 Loss 1.738 Prec@(1,5) (65.0%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:14:47] \u001b[32mTrain: [ 45/50] Step 220/520 Loss 1.736 Prec@(1,5) (65.0%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:14:48] \u001b[32mTrain: [ 45/50] Step 240/520 Loss 1.736 Prec@(1,5) (65.0%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:14:48] \u001b[32mTrain: [ 45/50] Step 260/520 Loss 1.735 Prec@(1,5) (65.0%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:14:49] \u001b[32mTrain: [ 45/50] Step 280/520 Loss 1.732 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:14:49] \u001b[32mTrain: [ 45/50] Step 300/520 Loss 1.731 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:14:50] \u001b[32mTrain: [ 45/50] Step 320/520 Loss 1.725 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:14:50] \u001b[32mTrain: [ 45/50] Step 340/520 Loss 1.728 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:14:51] \u001b[32mTrain: [ 45/50] Step 360/520 Loss 1.726 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:14:51] \u001b[32mTrain: [ 45/50] Step 380/520 Loss 1.727 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:14:52] \u001b[32mTrain: [ 45/50] Step 400/520 Loss 1.727 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:14:52] \u001b[32mTrain: [ 45/50] Step 420/520 Loss 1.725 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:14:53] \u001b[32mTrain: [ 45/50] Step 440/520 Loss 1.730 Prec@(1,5) (65.1%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:14:53] \u001b[32mTrain: [ 45/50] Step 460/520 Loss 1.730 Prec@(1,5) (65.1%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:14:54] \u001b[32mTrain: [ 45/50] Step 480/520 Loss 1.728 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:14:54] \u001b[32mTrain: [ 45/50] Step 500/520 Loss 1.727 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:14:55] \u001b[32mTrain: [ 45/50] Step 520/520 Loss 1.726 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:14:55] \u001b[32mTrain: [ 45/50] Final Prec@1 65.1980%\u001b[0m\n",
            "[2024-04-02 19:14:58] \u001b[32mValid: [ 45/50] Step 000/104 Loss 1.820 Prec@(1,5) (61.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:14:59] \u001b[32mValid: [ 45/50] Step 020/104 Loss 1.856 Prec@(1,5) (60.8%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:14:59] \u001b[32mValid: [ 45/50] Step 040/104 Loss 1.844 Prec@(1,5) (60.5%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:14:59] \u001b[32mValid: [ 45/50] Step 060/104 Loss 1.792 Prec@(1,5) (60.6%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:14:59] \u001b[32mValid: [ 45/50] Step 080/104 Loss 1.805 Prec@(1,5) (60.5%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:14:59] \u001b[32mValid: [ 45/50] Step 100/104 Loss 1.788 Prec@(1,5) (61.0%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:14:59] \u001b[32mValid: [ 45/50] Step 104/104 Loss 1.789 Prec@(1,5) (61.0%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:14:59] \u001b[32mValid: [ 45/50] Final Prec@1 60.9700%\u001b[0m\n",
            "[2024-04-02 19:14:59] \u001b[32mEpoch 45 LR 0.000613\u001b[0m\n",
            "[2024-04-02 19:15:04] \u001b[32mTrain: [ 46/50] Step 000/520 Loss 1.763 Prec@(1,5) (64.6%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:15:05] \u001b[32mTrain: [ 46/50] Step 020/520 Loss 1.681 Prec@(1,5) (65.6%, 90.2%)\u001b[0m\n",
            "[2024-04-02 19:15:05] \u001b[32mTrain: [ 46/50] Step 040/520 Loss 1.708 Prec@(1,5) (64.8%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:15:06] \u001b[32mTrain: [ 46/50] Step 060/520 Loss 1.707 Prec@(1,5) (65.1%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:15:06] \u001b[32mTrain: [ 46/50] Step 080/520 Loss 1.718 Prec@(1,5) (65.1%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:15:07] \u001b[32mTrain: [ 46/50] Step 100/520 Loss 1.707 Prec@(1,5) (65.1%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:15:07] \u001b[32mTrain: [ 46/50] Step 120/520 Loss 1.720 Prec@(1,5) (64.9%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:15:08] \u001b[32mTrain: [ 46/50] Step 140/520 Loss 1.718 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:15:08] \u001b[32mTrain: [ 46/50] Step 160/520 Loss 1.721 Prec@(1,5) (64.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:15:09] \u001b[32mTrain: [ 46/50] Step 180/520 Loss 1.712 Prec@(1,5) (65.1%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:15:09] \u001b[32mTrain: [ 46/50] Step 200/520 Loss 1.717 Prec@(1,5) (65.0%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:15:10] \u001b[32mTrain: [ 46/50] Step 220/520 Loss 1.720 Prec@(1,5) (64.9%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:15:10] \u001b[32mTrain: [ 46/50] Step 240/520 Loss 1.717 Prec@(1,5) (65.0%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:15:10] \u001b[32mTrain: [ 46/50] Step 260/520 Loss 1.715 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:15:11] \u001b[32mTrain: [ 46/50] Step 280/520 Loss 1.717 Prec@(1,5) (65.1%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:15:11] \u001b[32mTrain: [ 46/50] Step 300/520 Loss 1.726 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:15:12] \u001b[32mTrain: [ 46/50] Step 320/520 Loss 1.724 Prec@(1,5) (65.1%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:15:12] \u001b[32mTrain: [ 46/50] Step 340/520 Loss 1.722 Prec@(1,5) (65.0%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:15:13] \u001b[32mTrain: [ 46/50] Step 360/520 Loss 1.723 Prec@(1,5) (65.0%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:15:13] \u001b[32mTrain: [ 46/50] Step 380/520 Loss 1.722 Prec@(1,5) (65.1%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:15:14] \u001b[32mTrain: [ 46/50] Step 400/520 Loss 1.723 Prec@(1,5) (65.0%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:15:14] \u001b[32mTrain: [ 46/50] Step 420/520 Loss 1.724 Prec@(1,5) (65.0%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:15:15] \u001b[32mTrain: [ 46/50] Step 440/520 Loss 1.724 Prec@(1,5) (65.0%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:15:15] \u001b[32mTrain: [ 46/50] Step 460/520 Loss 1.724 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:15:16] \u001b[32mTrain: [ 46/50] Step 480/520 Loss 1.726 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:15:16] \u001b[32mTrain: [ 46/50] Step 500/520 Loss 1.726 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:15:17] \u001b[32mTrain: [ 46/50] Step 520/520 Loss 1.724 Prec@(1,5) (65.1%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:15:17] \u001b[32mTrain: [ 46/50] Final Prec@1 65.0680%\u001b[0m\n",
            "[2024-04-02 19:15:21] \u001b[32mValid: [ 46/50] Step 000/104 Loss 1.734 Prec@(1,5) (63.5%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:15:21] \u001b[32mValid: [ 46/50] Step 020/104 Loss 1.843 Prec@(1,5) (61.5%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:15:21] \u001b[32mValid: [ 46/50] Step 040/104 Loss 1.837 Prec@(1,5) (60.5%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:15:21] \u001b[32mValid: [ 46/50] Step 060/104 Loss 1.783 Prec@(1,5) (60.9%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:15:21] \u001b[32mValid: [ 46/50] Step 080/104 Loss 1.794 Prec@(1,5) (60.5%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:15:21] \u001b[32mValid: [ 46/50] Step 100/104 Loss 1.775 Prec@(1,5) (61.0%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:15:21] \u001b[32mValid: [ 46/50] Step 104/104 Loss 1.777 Prec@(1,5) (61.0%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:15:22] \u001b[32mValid: [ 46/50] Final Prec@1 61.0200%\u001b[0m\n",
            "[2024-04-02 19:15:22] \u001b[32mEpoch 46 LR 0.000394\u001b[0m\n",
            "[2024-04-02 19:15:26] \u001b[32mTrain: [ 47/50] Step 000/520 Loss 1.251 Prec@(1,5) (80.2%, 95.8%)\u001b[0m\n",
            "[2024-04-02 19:15:27] \u001b[32mTrain: [ 47/50] Step 020/520 Loss 1.718 Prec@(1,5) (64.8%, 90.4%)\u001b[0m\n",
            "[2024-04-02 19:15:27] \u001b[32mTrain: [ 47/50] Step 040/520 Loss 1.696 Prec@(1,5) (66.1%, 90.3%)\u001b[0m\n",
            "[2024-04-02 19:15:28] \u001b[32mTrain: [ 47/50] Step 060/520 Loss 1.736 Prec@(1,5) (65.2%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:15:28] \u001b[32mTrain: [ 47/50] Step 080/520 Loss 1.721 Prec@(1,5) (65.4%, 89.9%)\u001b[0m\n",
            "[2024-04-02 19:15:29] \u001b[32mTrain: [ 47/50] Step 100/520 Loss 1.723 Prec@(1,5) (65.5%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:15:29] \u001b[32mTrain: [ 47/50] Step 120/520 Loss 1.723 Prec@(1,5) (65.5%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:15:30] \u001b[32mTrain: [ 47/50] Step 140/520 Loss 1.718 Prec@(1,5) (65.6%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:15:30] \u001b[32mTrain: [ 47/50] Step 160/520 Loss 1.719 Prec@(1,5) (65.7%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:15:31] \u001b[32mTrain: [ 47/50] Step 180/520 Loss 1.720 Prec@(1,5) (65.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:15:31] \u001b[32mTrain: [ 47/50] Step 200/520 Loss 1.717 Prec@(1,5) (65.8%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:15:32] \u001b[32mTrain: [ 47/50] Step 220/520 Loss 1.717 Prec@(1,5) (65.8%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:15:32] \u001b[32mTrain: [ 47/50] Step 240/520 Loss 1.717 Prec@(1,5) (65.8%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:15:33] \u001b[32mTrain: [ 47/50] Step 260/520 Loss 1.717 Prec@(1,5) (65.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:15:33] \u001b[32mTrain: [ 47/50] Step 280/520 Loss 1.723 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:15:34] \u001b[32mTrain: [ 47/50] Step 300/520 Loss 1.720 Prec@(1,5) (65.7%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:15:34] \u001b[32mTrain: [ 47/50] Step 320/520 Loss 1.721 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:15:35] \u001b[32mTrain: [ 47/50] Step 340/520 Loss 1.724 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:15:35] \u001b[32mTrain: [ 47/50] Step 360/520 Loss 1.727 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:15:36] \u001b[32mTrain: [ 47/50] Step 380/520 Loss 1.730 Prec@(1,5) (65.3%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:15:36] \u001b[32mTrain: [ 47/50] Step 400/520 Loss 1.731 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:15:37] \u001b[32mTrain: [ 47/50] Step 420/520 Loss 1.735 Prec@(1,5) (65.2%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:15:37] \u001b[32mTrain: [ 47/50] Step 440/520 Loss 1.732 Prec@(1,5) (65.3%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:15:38] \u001b[32mTrain: [ 47/50] Step 460/520 Loss 1.731 Prec@(1,5) (65.3%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:15:38] \u001b[32mTrain: [ 47/50] Step 480/520 Loss 1.727 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:15:39] \u001b[32mTrain: [ 47/50] Step 500/520 Loss 1.728 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:15:39] \u001b[32mTrain: [ 47/50] Step 520/520 Loss 1.729 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:15:39] \u001b[32mTrain: [ 47/50] Final Prec@1 65.3500%\u001b[0m\n",
            "[2024-04-02 19:15:43] \u001b[32mValid: [ 47/50] Step 000/104 Loss 1.821 Prec@(1,5) (63.5%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:15:43] \u001b[32mValid: [ 47/50] Step 020/104 Loss 1.857 Prec@(1,5) (61.5%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:15:43] \u001b[32mValid: [ 47/50] Step 040/104 Loss 1.849 Prec@(1,5) (60.3%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:15:43] \u001b[32mValid: [ 47/50] Step 060/104 Loss 1.795 Prec@(1,5) (60.6%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:15:43] \u001b[32mValid: [ 47/50] Step 080/104 Loss 1.804 Prec@(1,5) (60.4%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:15:44] \u001b[32mValid: [ 47/50] Step 100/104 Loss 1.786 Prec@(1,5) (61.0%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:15:44] \u001b[32mValid: [ 47/50] Step 104/104 Loss 1.787 Prec@(1,5) (61.0%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:15:44] \u001b[32mValid: [ 47/50] Final Prec@1 61.0100%\u001b[0m\n",
            "[2024-04-02 19:15:44] \u001b[32mEpoch 47 LR 0.000222\u001b[0m\n",
            "[2024-04-02 19:15:49] \u001b[32mTrain: [ 48/50] Step 000/520 Loss 1.613 Prec@(1,5) (68.8%, 91.7%)\u001b[0m\n",
            "[2024-04-02 19:15:49] \u001b[32mTrain: [ 48/50] Step 020/520 Loss 1.676 Prec@(1,5) (66.6%, 90.8%)\u001b[0m\n",
            "[2024-04-02 19:15:50] \u001b[32mTrain: [ 48/50] Step 040/520 Loss 1.716 Prec@(1,5) (66.0%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:15:50] \u001b[32mTrain: [ 48/50] Step 060/520 Loss 1.712 Prec@(1,5) (65.4%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:15:51] \u001b[32mTrain: [ 48/50] Step 080/520 Loss 1.703 Prec@(1,5) (65.7%, 89.9%)\u001b[0m\n",
            "[2024-04-02 19:15:51] \u001b[32mTrain: [ 48/50] Step 100/520 Loss 1.693 Prec@(1,5) (65.9%, 90.0%)\u001b[0m\n",
            "[2024-04-02 19:15:52] \u001b[32mTrain: [ 48/50] Step 120/520 Loss 1.706 Prec@(1,5) (65.6%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:15:52] \u001b[32mTrain: [ 48/50] Step 140/520 Loss 1.695 Prec@(1,5) (66.0%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:15:53] \u001b[32mTrain: [ 48/50] Step 160/520 Loss 1.701 Prec@(1,5) (65.7%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:15:53] \u001b[32mTrain: [ 48/50] Step 180/520 Loss 1.700 Prec@(1,5) (65.8%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:15:54] \u001b[32mTrain: [ 48/50] Step 200/520 Loss 1.702 Prec@(1,5) (65.5%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:15:54] \u001b[32mTrain: [ 48/50] Step 220/520 Loss 1.707 Prec@(1,5) (65.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:15:55] \u001b[32mTrain: [ 48/50] Step 240/520 Loss 1.709 Prec@(1,5) (65.4%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:15:55] \u001b[32mTrain: [ 48/50] Step 260/520 Loss 1.713 Prec@(1,5) (65.4%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:15:56] \u001b[32mTrain: [ 48/50] Step 280/520 Loss 1.713 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:15:56] \u001b[32mTrain: [ 48/50] Step 300/520 Loss 1.718 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:15:57] \u001b[32mTrain: [ 48/50] Step 320/520 Loss 1.716 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:15:57] \u001b[32mTrain: [ 48/50] Step 340/520 Loss 1.717 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:15:58] \u001b[32mTrain: [ 48/50] Step 360/520 Loss 1.720 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:15:58] \u001b[32mTrain: [ 48/50] Step 380/520 Loss 1.721 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:15:59] \u001b[32mTrain: [ 48/50] Step 400/520 Loss 1.720 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:15:59] \u001b[32mTrain: [ 48/50] Step 420/520 Loss 1.719 Prec@(1,5) (65.3%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:16:00] \u001b[32mTrain: [ 48/50] Step 440/520 Loss 1.718 Prec@(1,5) (65.3%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:16:00] \u001b[32mTrain: [ 48/50] Step 460/520 Loss 1.719 Prec@(1,5) (65.3%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:16:01] \u001b[32mTrain: [ 48/50] Step 480/520 Loss 1.717 Prec@(1,5) (65.3%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:16:01] \u001b[32mTrain: [ 48/50] Step 500/520 Loss 1.718 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:16:02] \u001b[32mTrain: [ 48/50] Step 520/520 Loss 1.720 Prec@(1,5) (65.3%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:16:02] \u001b[32mTrain: [ 48/50] Final Prec@1 65.2560%\u001b[0m\n",
            "[2024-04-02 19:16:05] \u001b[32mValid: [ 48/50] Step 000/104 Loss 1.795 Prec@(1,5) (62.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:16:06] \u001b[32mValid: [ 48/50] Step 020/104 Loss 1.850 Prec@(1,5) (61.0%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:16:06] \u001b[32mValid: [ 48/50] Step 040/104 Loss 1.843 Prec@(1,5) (60.0%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:16:06] \u001b[32mValid: [ 48/50] Step 060/104 Loss 1.787 Prec@(1,5) (60.6%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:16:06] \u001b[32mValid: [ 48/50] Step 080/104 Loss 1.796 Prec@(1,5) (60.5%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:16:06] \u001b[32mValid: [ 48/50] Step 100/104 Loss 1.777 Prec@(1,5) (60.9%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:16:06] \u001b[32mValid: [ 48/50] Step 104/104 Loss 1.779 Prec@(1,5) (61.0%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:16:07] \u001b[32mValid: [ 48/50] Final Prec@1 60.9500%\u001b[0m\n",
            "[2024-04-02 19:16:07] \u001b[32mEpoch 48 LR 0.000100\u001b[0m\n",
            "[2024-04-02 19:16:11] \u001b[32mTrain: [ 49/50] Step 000/520 Loss 1.801 Prec@(1,5) (62.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:16:12] \u001b[32mTrain: [ 49/50] Step 020/520 Loss 1.718 Prec@(1,5) (65.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:16:12] \u001b[32mTrain: [ 49/50] Step 040/520 Loss 1.767 Prec@(1,5) (63.9%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:16:13] \u001b[32mTrain: [ 49/50] Step 060/520 Loss 1.742 Prec@(1,5) (64.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:16:13] \u001b[32mTrain: [ 49/50] Step 080/520 Loss 1.735 Prec@(1,5) (64.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:16:14] \u001b[32mTrain: [ 49/50] Step 100/520 Loss 1.741 Prec@(1,5) (64.9%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:16:14] \u001b[32mTrain: [ 49/50] Step 120/520 Loss 1.726 Prec@(1,5) (65.2%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:16:15] \u001b[32mTrain: [ 49/50] Step 140/520 Loss 1.723 Prec@(1,5) (65.3%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:16:15] \u001b[32mTrain: [ 49/50] Step 160/520 Loss 1.718 Prec@(1,5) (65.3%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:16:16] \u001b[32mTrain: [ 49/50] Step 180/520 Loss 1.714 Prec@(1,5) (65.3%, 89.9%)\u001b[0m\n",
            "[2024-04-02 19:16:16] \u001b[32mTrain: [ 49/50] Step 200/520 Loss 1.713 Prec@(1,5) (65.5%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:16:17] \u001b[32mTrain: [ 49/50] Step 220/520 Loss 1.714 Prec@(1,5) (65.3%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:16:17] \u001b[32mTrain: [ 49/50] Step 240/520 Loss 1.714 Prec@(1,5) (65.4%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:16:18] \u001b[32mTrain: [ 49/50] Step 260/520 Loss 1.712 Prec@(1,5) (65.4%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:16:18] \u001b[32mTrain: [ 49/50] Step 280/520 Loss 1.717 Prec@(1,5) (65.4%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:16:19] \u001b[32mTrain: [ 49/50] Step 300/520 Loss 1.718 Prec@(1,5) (65.3%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:16:19] \u001b[32mTrain: [ 49/50] Step 320/520 Loss 1.716 Prec@(1,5) (65.3%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:16:20] \u001b[32mTrain: [ 49/50] Step 340/520 Loss 1.715 Prec@(1,5) (65.3%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:16:20] \u001b[32mTrain: [ 49/50] Step 360/520 Loss 1.715 Prec@(1,5) (65.3%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:16:21] \u001b[32mTrain: [ 49/50] Step 380/520 Loss 1.716 Prec@(1,5) (65.3%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:16:21] \u001b[32mTrain: [ 49/50] Step 400/520 Loss 1.722 Prec@(1,5) (65.2%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:16:21] \u001b[32mTrain: [ 49/50] Step 420/520 Loss 1.722 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:16:22] \u001b[32mTrain: [ 49/50] Step 440/520 Loss 1.722 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:16:22] \u001b[32mTrain: [ 49/50] Step 460/520 Loss 1.722 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:16:23] \u001b[32mTrain: [ 49/50] Step 480/520 Loss 1.721 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:16:23] \u001b[32mTrain: [ 49/50] Step 500/520 Loss 1.719 Prec@(1,5) (65.3%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:16:24] \u001b[32mTrain: [ 49/50] Step 520/520 Loss 1.718 Prec@(1,5) (65.3%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:16:24] \u001b[32mTrain: [ 49/50] Final Prec@1 65.3160%\u001b[0m\n",
            "[2024-04-02 19:16:28] \u001b[32mValid: [ 49/50] Step 000/104 Loss 1.776 Prec@(1,5) (63.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:16:28] \u001b[32mValid: [ 49/50] Step 020/104 Loss 1.844 Prec@(1,5) (61.9%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:16:28] \u001b[32mValid: [ 49/50] Step 040/104 Loss 1.838 Prec@(1,5) (60.7%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:16:28] \u001b[32mValid: [ 49/50] Step 060/104 Loss 1.782 Prec@(1,5) (61.1%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:16:28] \u001b[32mValid: [ 49/50] Step 080/104 Loss 1.792 Prec@(1,5) (61.0%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:16:28] \u001b[32mValid: [ 49/50] Step 100/104 Loss 1.775 Prec@(1,5) (61.4%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:16:28] \u001b[32mValid: [ 49/50] Step 104/104 Loss 1.777 Prec@(1,5) (61.4%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:16:29] \u001b[32mValid: [ 49/50] Final Prec@1 61.3800%\u001b[0m\n",
            "[2024-04-02 19:16:29] \u001b[32mEpoch 49 LR 0.000026\u001b[0m\n",
            "[2024-04-02 19:16:33] \u001b[32mTrain: [ 50/50] Step 000/520 Loss 1.494 Prec@(1,5) (70.8%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:16:34] \u001b[32mTrain: [ 50/50] Step 020/520 Loss 1.726 Prec@(1,5) (64.9%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:16:34] \u001b[32mTrain: [ 50/50] Step 040/520 Loss 1.724 Prec@(1,5) (64.9%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:16:35] \u001b[32mTrain: [ 50/50] Step 060/520 Loss 1.717 Prec@(1,5) (65.0%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:16:35] \u001b[32mTrain: [ 50/50] Step 080/520 Loss 1.727 Prec@(1,5) (65.0%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:16:36] \u001b[32mTrain: [ 50/50] Step 100/520 Loss 1.731 Prec@(1,5) (65.1%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:16:36] \u001b[32mTrain: [ 50/50] Step 120/520 Loss 1.723 Prec@(1,5) (65.2%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:16:37] \u001b[32mTrain: [ 50/50] Step 140/520 Loss 1.741 Prec@(1,5) (64.9%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:16:37] \u001b[32mTrain: [ 50/50] Step 160/520 Loss 1.734 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:16:38] \u001b[32mTrain: [ 50/50] Step 180/520 Loss 1.734 Prec@(1,5) (65.1%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:16:38] \u001b[32mTrain: [ 50/50] Step 200/520 Loss 1.730 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:16:39] \u001b[32mTrain: [ 50/50] Step 220/520 Loss 1.728 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:16:39] \u001b[32mTrain: [ 50/50] Step 240/520 Loss 1.724 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:16:40] \u001b[32mTrain: [ 50/50] Step 260/520 Loss 1.721 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:16:40] \u001b[32mTrain: [ 50/50] Step 280/520 Loss 1.717 Prec@(1,5) (65.4%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:16:41] \u001b[32mTrain: [ 50/50] Step 300/520 Loss 1.721 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:16:41] \u001b[32mTrain: [ 50/50] Step 320/520 Loss 1.720 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:16:42] \u001b[32mTrain: [ 50/50] Step 340/520 Loss 1.723 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:16:42] \u001b[32mTrain: [ 50/50] Step 360/520 Loss 1.724 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:16:43] \u001b[32mTrain: [ 50/50] Step 380/520 Loss 1.723 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:16:43] \u001b[32mTrain: [ 50/50] Step 400/520 Loss 1.721 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:16:44] \u001b[32mTrain: [ 50/50] Step 420/520 Loss 1.722 Prec@(1,5) (65.2%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:16:44] \u001b[32mTrain: [ 50/50] Step 440/520 Loss 1.723 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:16:45] \u001b[32mTrain: [ 50/50] Step 460/520 Loss 1.723 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:16:46] \u001b[32mTrain: [ 50/50] Step 480/520 Loss 1.719 Prec@(1,5) (65.2%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:16:46] \u001b[32mTrain: [ 50/50] Step 500/520 Loss 1.720 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:16:47] \u001b[32mTrain: [ 50/50] Step 520/520 Loss 1.719 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:16:47] \u001b[32mTrain: [ 50/50] Final Prec@1 65.2300%\u001b[0m\n",
            "[2024-04-02 19:16:50] \u001b[32mValid: [ 50/50] Step 000/104 Loss 1.797 Prec@(1,5) (63.5%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:16:50] \u001b[32mValid: [ 50/50] Step 020/104 Loss 1.860 Prec@(1,5) (61.6%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:16:51] \u001b[32mValid: [ 50/50] Step 040/104 Loss 1.849 Prec@(1,5) (60.5%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:16:51] \u001b[32mValid: [ 50/50] Step 060/104 Loss 1.794 Prec@(1,5) (60.9%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:16:51] \u001b[32mValid: [ 50/50] Step 080/104 Loss 1.804 Prec@(1,5) (60.7%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:16:51] \u001b[32mValid: [ 50/50] Step 100/104 Loss 1.785 Prec@(1,5) (61.2%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:16:51] \u001b[32mValid: [ 50/50] Step 104/104 Loss 1.787 Prec@(1,5) (61.2%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:16:51] \u001b[32mValid: [ 50/50] Final Prec@1 61.2200%\u001b[0m\n",
            "Final best Prec@1 = 61.3800%\n",
            "{'lambd=1.263157894736842': 0.6138000170707703}\n",
            "random_edges/lambd=1.6842105263157894/\n",
            "[2024-04-02 19:16:51] \u001b[32mFixed architecture: {'reduce_n2_p0': 'sepconv5x5', 'reduce_n2_p1': 'sepconv5x5', 'reduce_n3_p0': 'dilconv5x5', 'reduce_n3_p1': 'sepconv5x5', 'reduce_n3_p2': 'sepconv5x5', 'reduce_n4_p0': 'sepconv3x3', 'reduce_n4_p1': 'sepconv5x5', 'reduce_n4_p2': 'sepconv5x5', 'reduce_n4_p3': 'sepconv5x5', 'reduce_n5_p0': 'maxpool', 'reduce_n5_p1': 'sepconv3x3', 'reduce_n5_p2': 'sepconv5x5', 'reduce_n5_p3': 'sepconv5x5', 'reduce_n5_p4': 'maxpool', 'reduce_n2_switch': [1], 'reduce_n3_switch': [1], 'reduce_n4_switch': [0], 'reduce_n5_switch': [4]}\u001b[0m\n",
            "[2024-04-02 19:16:51] \u001b[32mEpoch 0 LR 0.025000\u001b[0m\n",
            "[2024-04-02 19:16:56] \u001b[32mTrain: [  1/50] Step 000/520 Loss 6.503 Prec@(1,5) (2.1%, 6.2%)\u001b[0m\n",
            "[2024-04-02 19:16:56] \u001b[32mTrain: [  1/50] Step 020/520 Loss 6.383 Prec@(1,5) (2.3%, 8.6%)\u001b[0m\n",
            "[2024-04-02 19:16:57] \u001b[32mTrain: [  1/50] Step 040/520 Loss 6.257 Prec@(1,5) (3.0%, 11.8%)\u001b[0m\n",
            "[2024-04-02 19:16:57] \u001b[32mTrain: [  1/50] Step 060/520 Loss 6.160 Prec@(1,5) (3.9%, 14.4%)\u001b[0m\n",
            "[2024-04-02 19:16:58] \u001b[32mTrain: [  1/50] Step 080/520 Loss 6.068 Prec@(1,5) (4.6%, 16.4%)\u001b[0m\n",
            "[2024-04-02 19:16:58] \u001b[32mTrain: [  1/50] Step 100/520 Loss 5.991 Prec@(1,5) (5.1%, 18.0%)\u001b[0m\n",
            "[2024-04-02 19:16:59] \u001b[32mTrain: [  1/50] Step 120/520 Loss 5.926 Prec@(1,5) (5.7%, 19.5%)\u001b[0m\n",
            "[2024-04-02 19:16:59] \u001b[32mTrain: [  1/50] Step 140/520 Loss 5.870 Prec@(1,5) (6.0%, 20.7%)\u001b[0m\n",
            "[2024-04-02 19:17:00] \u001b[32mTrain: [  1/50] Step 160/520 Loss 5.813 Prec@(1,5) (6.5%, 21.9%)\u001b[0m\n",
            "[2024-04-02 19:17:00] \u001b[32mTrain: [  1/50] Step 180/520 Loss 5.767 Prec@(1,5) (6.9%, 22.8%)\u001b[0m\n",
            "[2024-04-02 19:17:01] \u001b[32mTrain: [  1/50] Step 200/520 Loss 5.722 Prec@(1,5) (7.3%, 23.7%)\u001b[0m\n",
            "[2024-04-02 19:17:01] \u001b[32mTrain: [  1/50] Step 220/520 Loss 5.679 Prec@(1,5) (7.7%, 24.6%)\u001b[0m\n",
            "[2024-04-02 19:17:02] \u001b[32mTrain: [  1/50] Step 240/520 Loss 5.645 Prec@(1,5) (8.1%, 25.3%)\u001b[0m\n",
            "[2024-04-02 19:17:02] \u001b[32mTrain: [  1/50] Step 260/520 Loss 5.613 Prec@(1,5) (8.4%, 26.0%)\u001b[0m\n",
            "[2024-04-02 19:17:03] \u001b[32mTrain: [  1/50] Step 280/520 Loss 5.583 Prec@(1,5) (8.7%, 26.7%)\u001b[0m\n",
            "[2024-04-02 19:17:03] \u001b[32mTrain: [  1/50] Step 300/520 Loss 5.553 Prec@(1,5) (8.9%, 27.3%)\u001b[0m\n",
            "[2024-04-02 19:17:04] \u001b[32mTrain: [  1/50] Step 320/520 Loss 5.527 Prec@(1,5) (9.2%, 27.8%)\u001b[0m\n",
            "[2024-04-02 19:17:04] \u001b[32mTrain: [  1/50] Step 340/520 Loss 5.500 Prec@(1,5) (9.5%, 28.4%)\u001b[0m\n",
            "[2024-04-02 19:17:05] \u001b[32mTrain: [  1/50] Step 360/520 Loss 5.478 Prec@(1,5) (9.6%, 28.9%)\u001b[0m\n",
            "[2024-04-02 19:17:05] \u001b[32mTrain: [  1/50] Step 380/520 Loss 5.459 Prec@(1,5) (9.8%, 29.3%)\u001b[0m\n",
            "[2024-04-02 19:17:06] \u001b[32mTrain: [  1/50] Step 400/520 Loss 5.433 Prec@(1,5) (10.0%, 29.8%)\u001b[0m\n",
            "[2024-04-02 19:17:06] \u001b[32mTrain: [  1/50] Step 420/520 Loss 5.407 Prec@(1,5) (10.3%, 30.4%)\u001b[0m\n",
            "[2024-04-02 19:17:07] \u001b[32mTrain: [  1/50] Step 440/520 Loss 5.381 Prec@(1,5) (10.5%, 30.9%)\u001b[0m\n",
            "[2024-04-02 19:17:07] \u001b[32mTrain: [  1/50] Step 460/520 Loss 5.359 Prec@(1,5) (10.8%, 31.4%)\u001b[0m\n",
            "[2024-04-02 19:17:08] \u001b[32mTrain: [  1/50] Step 480/520 Loss 5.333 Prec@(1,5) (11.1%, 31.9%)\u001b[0m\n",
            "[2024-04-02 19:17:08] \u001b[32mTrain: [  1/50] Step 500/520 Loss 5.309 Prec@(1,5) (11.4%, 32.5%)\u001b[0m\n",
            "[2024-04-02 19:17:09] \u001b[32mTrain: [  1/50] Step 520/520 Loss 5.290 Prec@(1,5) (11.6%, 32.9%)\u001b[0m\n",
            "[2024-04-02 19:17:09] \u001b[32mTrain: [  1/50] Final Prec@1 11.5900%\u001b[0m\n",
            "[2024-04-02 19:17:12] \u001b[32mValid: [  1/50] Step 000/104 Loss 4.423 Prec@(1,5) (15.6%, 36.5%)\u001b[0m\n",
            "[2024-04-02 19:17:12] \u001b[32mValid: [  1/50] Step 020/104 Loss 4.261 Prec@(1,5) (17.6%, 41.0%)\u001b[0m\n",
            "[2024-04-02 19:17:13] \u001b[32mValid: [  1/50] Step 040/104 Loss 4.237 Prec@(1,5) (17.3%, 41.8%)\u001b[0m\n",
            "[2024-04-02 19:17:13] \u001b[32mValid: [  1/50] Step 060/104 Loss 4.230 Prec@(1,5) (17.2%, 42.2%)\u001b[0m\n",
            "[2024-04-02 19:17:13] \u001b[32mValid: [  1/50] Step 080/104 Loss 4.237 Prec@(1,5) (17.1%, 42.5%)\u001b[0m\n",
            "[2024-04-02 19:17:13] \u001b[32mValid: [  1/50] Step 100/104 Loss 4.244 Prec@(1,5) (17.0%, 42.5%)\u001b[0m\n",
            "[2024-04-02 19:17:13] \u001b[32mValid: [  1/50] Step 104/104 Loss 4.241 Prec@(1,5) (17.0%, 42.6%)\u001b[0m\n",
            "[2024-04-02 19:17:13] \u001b[32mValid: [  1/50] Final Prec@1 16.9900%\u001b[0m\n",
            "[2024-04-02 19:17:13] \u001b[32mEpoch 1 LR 0.024975\u001b[0m\n",
            "[2024-04-02 19:17:18] \u001b[32mTrain: [  2/50] Step 000/520 Loss 4.871 Prec@(1,5) (15.6%, 39.6%)\u001b[0m\n",
            "[2024-04-02 19:17:18] \u001b[32mTrain: [  2/50] Step 020/520 Loss 4.735 Prec@(1,5) (17.8%, 45.2%)\u001b[0m\n",
            "[2024-04-02 19:17:19] \u001b[32mTrain: [  2/50] Step 040/520 Loss 4.670 Prec@(1,5) (18.3%, 45.8%)\u001b[0m\n",
            "[2024-04-02 19:17:20] \u001b[32mTrain: [  2/50] Step 060/520 Loss 4.664 Prec@(1,5) (18.5%, 46.1%)\u001b[0m\n",
            "[2024-04-02 19:17:20] \u001b[32mTrain: [  2/50] Step 080/520 Loss 4.639 Prec@(1,5) (18.8%, 46.7%)\u001b[0m\n",
            "[2024-04-02 19:17:21] \u001b[32mTrain: [  2/50] Step 100/520 Loss 4.620 Prec@(1,5) (19.1%, 47.1%)\u001b[0m\n",
            "[2024-04-02 19:17:21] \u001b[32mTrain: [  2/50] Step 120/520 Loss 4.606 Prec@(1,5) (19.3%, 47.3%)\u001b[0m\n",
            "[2024-04-02 19:17:22] \u001b[32mTrain: [  2/50] Step 140/520 Loss 4.598 Prec@(1,5) (19.5%, 47.4%)\u001b[0m\n",
            "[2024-04-02 19:17:22] \u001b[32mTrain: [  2/50] Step 160/520 Loss 4.588 Prec@(1,5) (19.4%, 47.6%)\u001b[0m\n",
            "[2024-04-02 19:17:23] \u001b[32mTrain: [  2/50] Step 180/520 Loss 4.575 Prec@(1,5) (19.7%, 47.8%)\u001b[0m\n",
            "[2024-04-02 19:17:23] \u001b[32mTrain: [  2/50] Step 200/520 Loss 4.564 Prec@(1,5) (19.9%, 48.1%)\u001b[0m\n",
            "[2024-04-02 19:17:24] \u001b[32mTrain: [  2/50] Step 220/520 Loss 4.552 Prec@(1,5) (20.1%, 48.3%)\u001b[0m\n",
            "[2024-04-02 19:17:24] \u001b[32mTrain: [  2/50] Step 240/520 Loss 4.536 Prec@(1,5) (20.3%, 48.6%)\u001b[0m\n",
            "[2024-04-02 19:17:25] \u001b[32mTrain: [  2/50] Step 260/520 Loss 4.533 Prec@(1,5) (20.3%, 48.6%)\u001b[0m\n",
            "[2024-04-02 19:17:25] \u001b[32mTrain: [  2/50] Step 280/520 Loss 4.520 Prec@(1,5) (20.4%, 48.9%)\u001b[0m\n",
            "[2024-04-02 19:17:26] \u001b[32mTrain: [  2/50] Step 300/520 Loss 4.520 Prec@(1,5) (20.3%, 48.9%)\u001b[0m\n",
            "[2024-04-02 19:17:26] \u001b[32mTrain: [  2/50] Step 320/520 Loss 4.512 Prec@(1,5) (20.4%, 49.0%)\u001b[0m\n",
            "[2024-04-02 19:17:27] \u001b[32mTrain: [  2/50] Step 340/520 Loss 4.499 Prec@(1,5) (20.7%, 49.3%)\u001b[0m\n",
            "[2024-04-02 19:17:27] \u001b[32mTrain: [  2/50] Step 360/520 Loss 4.482 Prec@(1,5) (20.9%, 49.6%)\u001b[0m\n",
            "[2024-04-02 19:17:28] \u001b[32mTrain: [  2/50] Step 380/520 Loss 4.474 Prec@(1,5) (21.0%, 49.8%)\u001b[0m\n",
            "[2024-04-02 19:17:28] \u001b[32mTrain: [  2/50] Step 400/520 Loss 4.463 Prec@(1,5) (21.1%, 50.0%)\u001b[0m\n",
            "[2024-04-02 19:17:29] \u001b[32mTrain: [  2/50] Step 420/520 Loss 4.455 Prec@(1,5) (21.2%, 50.1%)\u001b[0m\n",
            "[2024-04-02 19:17:29] \u001b[32mTrain: [  2/50] Step 440/520 Loss 4.446 Prec@(1,5) (21.3%, 50.3%)\u001b[0m\n",
            "[2024-04-02 19:17:30] \u001b[32mTrain: [  2/50] Step 460/520 Loss 4.437 Prec@(1,5) (21.4%, 50.3%)\u001b[0m\n",
            "[2024-04-02 19:17:30] \u001b[32mTrain: [  2/50] Step 480/520 Loss 4.431 Prec@(1,5) (21.4%, 50.5%)\u001b[0m\n",
            "[2024-04-02 19:17:31] \u001b[32mTrain: [  2/50] Step 500/520 Loss 4.419 Prec@(1,5) (21.5%, 50.7%)\u001b[0m\n",
            "[2024-04-02 19:17:31] \u001b[32mTrain: [  2/50] Step 520/520 Loss 4.407 Prec@(1,5) (21.7%, 50.8%)\u001b[0m\n",
            "[2024-04-02 19:17:31] \u001b[32mTrain: [  2/50] Final Prec@1 21.7400%\u001b[0m\n",
            "[2024-04-02 19:17:35] \u001b[32mValid: [  2/50] Step 000/104 Loss 4.261 Prec@(1,5) (24.0%, 52.1%)\u001b[0m\n",
            "[2024-04-02 19:17:35] \u001b[32mValid: [  2/50] Step 020/104 Loss 4.011 Prec@(1,5) (23.1%, 54.2%)\u001b[0m\n",
            "[2024-04-02 19:17:35] \u001b[32mValid: [  2/50] Step 040/104 Loss 3.945 Prec@(1,5) (23.3%, 54.3%)\u001b[0m\n",
            "[2024-04-02 19:17:35] \u001b[32mValid: [  2/50] Step 060/104 Loss 3.901 Prec@(1,5) (24.0%, 54.4%)\u001b[0m\n",
            "[2024-04-02 19:17:36] \u001b[32mValid: [  2/50] Step 080/104 Loss 3.924 Prec@(1,5) (23.9%, 54.3%)\u001b[0m\n",
            "[2024-04-02 19:17:36] \u001b[32mValid: [  2/50] Step 100/104 Loss 3.938 Prec@(1,5) (23.6%, 54.0%)\u001b[0m\n",
            "[2024-04-02 19:17:36] \u001b[32mValid: [  2/50] Step 104/104 Loss 3.937 Prec@(1,5) (23.6%, 54.0%)\u001b[0m\n",
            "[2024-04-02 19:17:36] \u001b[32mValid: [  2/50] Final Prec@1 23.6400%\u001b[0m\n",
            "[2024-04-02 19:17:36] \u001b[32mEpoch 2 LR 0.024901\u001b[0m\n",
            "[2024-04-02 19:17:41] \u001b[32mTrain: [  3/50] Step 000/520 Loss 4.068 Prec@(1,5) (18.8%, 65.6%)\u001b[0m\n",
            "[2024-04-02 19:17:41] \u001b[32mTrain: [  3/50] Step 020/520 Loss 4.041 Prec@(1,5) (26.3%, 58.5%)\u001b[0m\n",
            "[2024-04-02 19:17:42] \u001b[32mTrain: [  3/50] Step 040/520 Loss 4.043 Prec@(1,5) (26.1%, 58.0%)\u001b[0m\n",
            "[2024-04-02 19:17:42] \u001b[32mTrain: [  3/50] Step 060/520 Loss 4.034 Prec@(1,5) (26.5%, 58.1%)\u001b[0m\n",
            "[2024-04-02 19:17:43] \u001b[32mTrain: [  3/50] Step 080/520 Loss 4.012 Prec@(1,5) (27.0%, 58.6%)\u001b[0m\n",
            "[2024-04-02 19:17:43] \u001b[32mTrain: [  3/50] Step 100/520 Loss 4.021 Prec@(1,5) (27.1%, 58.6%)\u001b[0m\n",
            "[2024-04-02 19:17:44] \u001b[32mTrain: [  3/50] Step 120/520 Loss 4.032 Prec@(1,5) (26.9%, 58.1%)\u001b[0m\n",
            "[2024-04-02 19:17:44] \u001b[32mTrain: [  3/50] Step 140/520 Loss 4.038 Prec@(1,5) (26.7%, 58.0%)\u001b[0m\n",
            "[2024-04-02 19:17:45] \u001b[32mTrain: [  3/50] Step 160/520 Loss 4.039 Prec@(1,5) (26.6%, 57.9%)\u001b[0m\n",
            "[2024-04-02 19:17:45] \u001b[32mTrain: [  3/50] Step 180/520 Loss 4.039 Prec@(1,5) (26.5%, 57.9%)\u001b[0m\n",
            "[2024-04-02 19:17:46] \u001b[32mTrain: [  3/50] Step 200/520 Loss 4.036 Prec@(1,5) (26.5%, 57.9%)\u001b[0m\n",
            "[2024-04-02 19:17:46] \u001b[32mTrain: [  3/50] Step 220/520 Loss 4.039 Prec@(1,5) (26.4%, 57.9%)\u001b[0m\n",
            "[2024-04-02 19:17:47] \u001b[32mTrain: [  3/50] Step 240/520 Loss 4.027 Prec@(1,5) (26.5%, 58.0%)\u001b[0m\n",
            "[2024-04-02 19:17:47] \u001b[32mTrain: [  3/50] Step 260/520 Loss 4.023 Prec@(1,5) (26.7%, 57.9%)\u001b[0m\n",
            "[2024-04-02 19:17:48] \u001b[32mTrain: [  3/50] Step 280/520 Loss 4.022 Prec@(1,5) (26.7%, 58.0%)\u001b[0m\n",
            "[2024-04-02 19:17:48] \u001b[32mTrain: [  3/50] Step 300/520 Loss 4.016 Prec@(1,5) (26.9%, 58.0%)\u001b[0m\n",
            "[2024-04-02 19:17:49] \u001b[32mTrain: [  3/50] Step 320/520 Loss 4.010 Prec@(1,5) (26.9%, 58.1%)\u001b[0m\n",
            "[2024-04-02 19:17:49] \u001b[32mTrain: [  3/50] Step 340/520 Loss 4.004 Prec@(1,5) (27.1%, 58.2%)\u001b[0m\n",
            "[2024-04-02 19:17:50] \u001b[32mTrain: [  3/50] Step 360/520 Loss 4.004 Prec@(1,5) (27.1%, 58.2%)\u001b[0m\n",
            "[2024-04-02 19:17:50] \u001b[32mTrain: [  3/50] Step 380/520 Loss 4.000 Prec@(1,5) (27.2%, 58.3%)\u001b[0m\n",
            "[2024-04-02 19:17:51] \u001b[32mTrain: [  3/50] Step 400/520 Loss 3.996 Prec@(1,5) (27.4%, 58.4%)\u001b[0m\n",
            "[2024-04-02 19:17:51] \u001b[32mTrain: [  3/50] Step 420/520 Loss 3.990 Prec@(1,5) (27.5%, 58.5%)\u001b[0m\n",
            "[2024-04-02 19:17:52] \u001b[32mTrain: [  3/50] Step 440/520 Loss 3.984 Prec@(1,5) (27.6%, 58.6%)\u001b[0m\n",
            "[2024-04-02 19:17:52] \u001b[32mTrain: [  3/50] Step 460/520 Loss 3.982 Prec@(1,5) (27.6%, 58.6%)\u001b[0m\n",
            "[2024-04-02 19:17:53] \u001b[32mTrain: [  3/50] Step 480/520 Loss 3.977 Prec@(1,5) (27.7%, 58.7%)\u001b[0m\n",
            "[2024-04-02 19:17:53] \u001b[32mTrain: [  3/50] Step 500/520 Loss 3.972 Prec@(1,5) (27.8%, 58.8%)\u001b[0m\n",
            "[2024-04-02 19:17:54] \u001b[32mTrain: [  3/50] Step 520/520 Loss 3.968 Prec@(1,5) (27.9%, 58.9%)\u001b[0m\n",
            "[2024-04-02 19:17:54] \u001b[32mTrain: [  3/50] Final Prec@1 27.8880%\u001b[0m\n",
            "[2024-04-02 19:17:57] \u001b[32mValid: [  3/50] Step 000/104 Loss 4.414 Prec@(1,5) (24.0%, 57.3%)\u001b[0m\n",
            "[2024-04-02 19:17:57] \u001b[32mValid: [  3/50] Step 020/104 Loss 4.179 Prec@(1,5) (26.2%, 57.3%)\u001b[0m\n",
            "[2024-04-02 19:17:58] \u001b[32mValid: [  3/50] Step 040/104 Loss 4.077 Prec@(1,5) (26.4%, 57.2%)\u001b[0m\n",
            "[2024-04-02 19:17:58] \u001b[32mValid: [  3/50] Step 060/104 Loss 4.028 Prec@(1,5) (26.6%, 57.4%)\u001b[0m\n",
            "[2024-04-02 19:17:58] \u001b[32mValid: [  3/50] Step 080/104 Loss 4.060 Prec@(1,5) (26.5%, 57.0%)\u001b[0m\n",
            "[2024-04-02 19:17:58] \u001b[32mValid: [  3/50] Step 100/104 Loss 4.074 Prec@(1,5) (26.2%, 56.8%)\u001b[0m\n",
            "[2024-04-02 19:17:58] \u001b[32mValid: [  3/50] Step 104/104 Loss 4.075 Prec@(1,5) (26.2%, 56.8%)\u001b[0m\n",
            "[2024-04-02 19:17:58] \u001b[32mValid: [  3/50] Final Prec@1 26.1800%\u001b[0m\n",
            "[2024-04-02 19:17:58] \u001b[32mEpoch 3 LR 0.024779\u001b[0m\n",
            "[2024-04-02 19:18:03] \u001b[32mTrain: [  4/50] Step 000/520 Loss 3.545 Prec@(1,5) (28.1%, 65.6%)\u001b[0m\n",
            "[2024-04-02 19:18:03] \u001b[32mTrain: [  4/50] Step 020/520 Loss 3.709 Prec@(1,5) (31.3%, 62.8%)\u001b[0m\n",
            "[2024-04-02 19:18:04] \u001b[32mTrain: [  4/50] Step 040/520 Loss 3.739 Prec@(1,5) (30.4%, 61.9%)\u001b[0m\n",
            "[2024-04-02 19:18:04] \u001b[32mTrain: [  4/50] Step 060/520 Loss 3.731 Prec@(1,5) (30.7%, 62.2%)\u001b[0m\n",
            "[2024-04-02 19:18:05] \u001b[32mTrain: [  4/50] Step 080/520 Loss 3.749 Prec@(1,5) (30.3%, 61.8%)\u001b[0m\n",
            "[2024-04-02 19:18:05] \u001b[32mTrain: [  4/50] Step 100/520 Loss 3.738 Prec@(1,5) (30.5%, 62.2%)\u001b[0m\n",
            "[2024-04-02 19:18:06] \u001b[32mTrain: [  4/50] Step 120/520 Loss 3.736 Prec@(1,5) (30.6%, 62.1%)\u001b[0m\n",
            "[2024-04-02 19:18:06] \u001b[32mTrain: [  4/50] Step 140/520 Loss 3.741 Prec@(1,5) (30.5%, 62.2%)\u001b[0m\n",
            "[2024-04-02 19:18:07] \u001b[32mTrain: [  4/50] Step 160/520 Loss 3.737 Prec@(1,5) (30.5%, 62.3%)\u001b[0m\n",
            "[2024-04-02 19:18:07] \u001b[32mTrain: [  4/50] Step 180/520 Loss 3.739 Prec@(1,5) (30.6%, 62.3%)\u001b[0m\n",
            "[2024-04-02 19:18:08] \u001b[32mTrain: [  4/50] Step 200/520 Loss 3.740 Prec@(1,5) (30.6%, 62.4%)\u001b[0m\n",
            "[2024-04-02 19:18:08] \u001b[32mTrain: [  4/50] Step 220/520 Loss 3.740 Prec@(1,5) (30.6%, 62.4%)\u001b[0m\n",
            "[2024-04-02 19:18:09] \u001b[32mTrain: [  4/50] Step 240/520 Loss 3.734 Prec@(1,5) (30.7%, 62.5%)\u001b[0m\n",
            "[2024-04-02 19:18:09] \u001b[32mTrain: [  4/50] Step 260/520 Loss 3.732 Prec@(1,5) (30.7%, 62.5%)\u001b[0m\n",
            "[2024-04-02 19:18:10] \u001b[32mTrain: [  4/50] Step 280/520 Loss 3.726 Prec@(1,5) (30.7%, 62.7%)\u001b[0m\n",
            "[2024-04-02 19:18:10] \u001b[32mTrain: [  4/50] Step 300/520 Loss 3.726 Prec@(1,5) (30.7%, 62.6%)\u001b[0m\n",
            "[2024-04-02 19:18:11] \u001b[32mTrain: [  4/50] Step 320/520 Loss 3.722 Prec@(1,5) (30.8%, 62.8%)\u001b[0m\n",
            "[2024-04-02 19:18:11] \u001b[32mTrain: [  4/50] Step 340/520 Loss 3.718 Prec@(1,5) (30.8%, 62.8%)\u001b[0m\n",
            "[2024-04-02 19:18:12] \u001b[32mTrain: [  4/50] Step 360/520 Loss 3.716 Prec@(1,5) (30.8%, 62.8%)\u001b[0m\n",
            "[2024-04-02 19:18:12] \u001b[32mTrain: [  4/50] Step 380/520 Loss 3.714 Prec@(1,5) (30.9%, 62.8%)\u001b[0m\n",
            "[2024-04-02 19:18:13] \u001b[32mTrain: [  4/50] Step 400/520 Loss 3.707 Prec@(1,5) (31.0%, 62.9%)\u001b[0m\n",
            "[2024-04-02 19:18:13] \u001b[32mTrain: [  4/50] Step 420/520 Loss 3.701 Prec@(1,5) (31.1%, 63.0%)\u001b[0m\n",
            "[2024-04-02 19:18:14] \u001b[32mTrain: [  4/50] Step 440/520 Loss 3.699 Prec@(1,5) (31.1%, 63.1%)\u001b[0m\n",
            "[2024-04-02 19:18:14] \u001b[32mTrain: [  4/50] Step 460/520 Loss 3.695 Prec@(1,5) (31.2%, 63.1%)\u001b[0m\n",
            "[2024-04-02 19:18:15] \u001b[32mTrain: [  4/50] Step 480/520 Loss 3.691 Prec@(1,5) (31.3%, 63.2%)\u001b[0m\n",
            "[2024-04-02 19:18:15] \u001b[32mTrain: [  4/50] Step 500/520 Loss 3.685 Prec@(1,5) (31.4%, 63.3%)\u001b[0m\n",
            "[2024-04-02 19:18:16] \u001b[32mTrain: [  4/50] Step 520/520 Loss 3.682 Prec@(1,5) (31.4%, 63.3%)\u001b[0m\n",
            "[2024-04-02 19:18:16] \u001b[32mTrain: [  4/50] Final Prec@1 31.4360%\u001b[0m\n",
            "[2024-04-02 19:18:19] \u001b[32mValid: [  4/50] Step 000/104 Loss 3.572 Prec@(1,5) (31.2%, 61.5%)\u001b[0m\n",
            "[2024-04-02 19:18:20] \u001b[32mValid: [  4/50] Step 020/104 Loss 3.748 Prec@(1,5) (30.4%, 61.5%)\u001b[0m\n",
            "[2024-04-02 19:18:20] \u001b[32mValid: [  4/50] Step 040/104 Loss 3.718 Prec@(1,5) (30.6%, 61.6%)\u001b[0m\n",
            "[2024-04-02 19:18:20] \u001b[32mValid: [  4/50] Step 060/104 Loss 3.682 Prec@(1,5) (31.1%, 62.2%)\u001b[0m\n",
            "[2024-04-02 19:18:20] \u001b[32mValid: [  4/50] Step 080/104 Loss 3.699 Prec@(1,5) (30.8%, 62.0%)\u001b[0m\n",
            "[2024-04-02 19:18:20] \u001b[32mValid: [  4/50] Step 100/104 Loss 3.700 Prec@(1,5) (30.8%, 61.9%)\u001b[0m\n",
            "[2024-04-02 19:18:20] \u001b[32mValid: [  4/50] Step 104/104 Loss 3.700 Prec@(1,5) (30.8%, 61.8%)\u001b[0m\n",
            "[2024-04-02 19:18:20] \u001b[32mValid: [  4/50] Final Prec@1 30.7600%\u001b[0m\n",
            "[2024-04-02 19:18:20] \u001b[32mEpoch 4 LR 0.024607\u001b[0m\n",
            "[2024-04-02 19:18:25] \u001b[32mTrain: [  5/50] Step 000/520 Loss 3.527 Prec@(1,5) (38.5%, 64.6%)\u001b[0m\n",
            "[2024-04-02 19:18:26] \u001b[32mTrain: [  5/50] Step 020/520 Loss 3.555 Prec@(1,5) (33.5%, 66.6%)\u001b[0m\n",
            "[2024-04-02 19:18:26] \u001b[32mTrain: [  5/50] Step 040/520 Loss 3.544 Prec@(1,5) (34.3%, 66.8%)\u001b[0m\n",
            "[2024-04-02 19:18:27] \u001b[32mTrain: [  5/50] Step 060/520 Loss 3.544 Prec@(1,5) (34.3%, 66.4%)\u001b[0m\n",
            "[2024-04-02 19:18:27] \u001b[32mTrain: [  5/50] Step 080/520 Loss 3.523 Prec@(1,5) (34.7%, 66.6%)\u001b[0m\n",
            "[2024-04-02 19:18:28] \u001b[32mTrain: [  5/50] Step 100/520 Loss 3.536 Prec@(1,5) (34.1%, 66.4%)\u001b[0m\n",
            "[2024-04-02 19:18:28] \u001b[32mTrain: [  5/50] Step 120/520 Loss 3.526 Prec@(1,5) (34.2%, 66.5%)\u001b[0m\n",
            "[2024-04-02 19:18:29] \u001b[32mTrain: [  5/50] Step 140/520 Loss 3.513 Prec@(1,5) (34.5%, 66.7%)\u001b[0m\n",
            "[2024-04-02 19:18:29] \u001b[32mTrain: [  5/50] Step 160/520 Loss 3.504 Prec@(1,5) (34.6%, 66.9%)\u001b[0m\n",
            "[2024-04-02 19:18:30] \u001b[32mTrain: [  5/50] Step 180/520 Loss 3.502 Prec@(1,5) (34.5%, 67.0%)\u001b[0m\n",
            "[2024-04-02 19:18:30] \u001b[32mTrain: [  5/50] Step 200/520 Loss 3.503 Prec@(1,5) (34.5%, 66.8%)\u001b[0m\n",
            "[2024-04-02 19:18:30] \u001b[32mTrain: [  5/50] Step 220/520 Loss 3.499 Prec@(1,5) (34.5%, 66.9%)\u001b[0m\n",
            "[2024-04-02 19:18:31] \u001b[32mTrain: [  5/50] Step 240/520 Loss 3.500 Prec@(1,5) (34.5%, 66.8%)\u001b[0m\n",
            "[2024-04-02 19:18:31] \u001b[32mTrain: [  5/50] Step 260/520 Loss 3.495 Prec@(1,5) (34.5%, 66.9%)\u001b[0m\n",
            "[2024-04-02 19:18:32] \u001b[32mTrain: [  5/50] Step 280/520 Loss 3.492 Prec@(1,5) (34.6%, 66.9%)\u001b[0m\n",
            "[2024-04-02 19:18:32] \u001b[32mTrain: [  5/50] Step 300/520 Loss 3.492 Prec@(1,5) (34.6%, 66.9%)\u001b[0m\n",
            "[2024-04-02 19:18:33] \u001b[32mTrain: [  5/50] Step 320/520 Loss 3.489 Prec@(1,5) (34.6%, 66.8%)\u001b[0m\n",
            "[2024-04-02 19:18:33] \u001b[32mTrain: [  5/50] Step 340/520 Loss 3.486 Prec@(1,5) (34.6%, 66.9%)\u001b[0m\n",
            "[2024-04-02 19:18:34] \u001b[32mTrain: [  5/50] Step 360/520 Loss 3.485 Prec@(1,5) (34.7%, 66.9%)\u001b[0m\n",
            "[2024-04-02 19:18:34] \u001b[32mTrain: [  5/50] Step 380/520 Loss 3.483 Prec@(1,5) (34.7%, 66.8%)\u001b[0m\n",
            "[2024-04-02 19:18:35] \u001b[32mTrain: [  5/50] Step 400/520 Loss 3.481 Prec@(1,5) (34.8%, 66.8%)\u001b[0m\n",
            "[2024-04-02 19:18:35] \u001b[32mTrain: [  5/50] Step 420/520 Loss 3.477 Prec@(1,5) (34.8%, 66.9%)\u001b[0m\n",
            "[2024-04-02 19:18:36] \u001b[32mTrain: [  5/50] Step 440/520 Loss 3.474 Prec@(1,5) (34.9%, 67.0%)\u001b[0m\n",
            "[2024-04-02 19:18:36] \u001b[32mTrain: [  5/50] Step 460/520 Loss 3.474 Prec@(1,5) (34.9%, 67.0%)\u001b[0m\n",
            "[2024-04-02 19:18:37] \u001b[32mTrain: [  5/50] Step 480/520 Loss 3.471 Prec@(1,5) (34.9%, 67.0%)\u001b[0m\n",
            "[2024-04-02 19:18:37] \u001b[32mTrain: [  5/50] Step 500/520 Loss 3.471 Prec@(1,5) (34.9%, 67.0%)\u001b[0m\n",
            "[2024-04-02 19:18:38] \u001b[32mTrain: [  5/50] Step 520/520 Loss 3.468 Prec@(1,5) (35.0%, 67.1%)\u001b[0m\n",
            "[2024-04-02 19:18:38] \u001b[32mTrain: [  5/50] Final Prec@1 34.9780%\u001b[0m\n",
            "[2024-04-02 19:18:42] \u001b[32mValid: [  5/50] Step 000/104 Loss 3.643 Prec@(1,5) (35.4%, 67.7%)\u001b[0m\n",
            "[2024-04-02 19:18:42] \u001b[32mValid: [  5/50] Step 020/104 Loss 3.837 Prec@(1,5) (32.6%, 62.8%)\u001b[0m\n",
            "[2024-04-02 19:18:42] \u001b[32mValid: [  5/50] Step 040/104 Loss 3.804 Prec@(1,5) (31.8%, 62.7%)\u001b[0m\n",
            "[2024-04-02 19:18:42] \u001b[32mValid: [  5/50] Step 060/104 Loss 3.757 Prec@(1,5) (32.1%, 63.1%)\u001b[0m\n",
            "[2024-04-02 19:18:42] \u001b[32mValid: [  5/50] Step 080/104 Loss 3.755 Prec@(1,5) (32.0%, 62.9%)\u001b[0m\n",
            "[2024-04-02 19:18:42] \u001b[32mValid: [  5/50] Step 100/104 Loss 3.748 Prec@(1,5) (31.8%, 63.0%)\u001b[0m\n",
            "[2024-04-02 19:18:42] \u001b[32mValid: [  5/50] Step 104/104 Loss 3.752 Prec@(1,5) (31.8%, 62.9%)\u001b[0m\n",
            "[2024-04-02 19:18:43] \u001b[32mValid: [  5/50] Final Prec@1 31.8400%\u001b[0m\n",
            "[2024-04-02 19:18:43] \u001b[32mEpoch 5 LR 0.024388\u001b[0m\n",
            "[2024-04-02 19:18:47] \u001b[32mTrain: [  6/50] Step 000/520 Loss 3.413 Prec@(1,5) (36.5%, 69.8%)\u001b[0m\n",
            "[2024-04-02 19:18:48] \u001b[32mTrain: [  6/50] Step 020/520 Loss 3.268 Prec@(1,5) (37.9%, 70.2%)\u001b[0m\n",
            "[2024-04-02 19:18:48] \u001b[32mTrain: [  6/50] Step 040/520 Loss 3.293 Prec@(1,5) (37.9%, 70.0%)\u001b[0m\n",
            "[2024-04-02 19:18:49] \u001b[32mTrain: [  6/50] Step 060/520 Loss 3.320 Prec@(1,5) (37.8%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:18:49] \u001b[32mTrain: [  6/50] Step 080/520 Loss 3.322 Prec@(1,5) (37.5%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:18:50] \u001b[32mTrain: [  6/50] Step 100/520 Loss 3.326 Prec@(1,5) (37.3%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:18:50] \u001b[32mTrain: [  6/50] Step 120/520 Loss 3.321 Prec@(1,5) (37.4%, 69.6%)\u001b[0m\n",
            "[2024-04-02 19:18:51] \u001b[32mTrain: [  6/50] Step 140/520 Loss 3.309 Prec@(1,5) (37.6%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:18:51] \u001b[32mTrain: [  6/50] Step 160/520 Loss 3.308 Prec@(1,5) (37.6%, 69.8%)\u001b[0m\n",
            "[2024-04-02 19:18:52] \u001b[32mTrain: [  6/50] Step 180/520 Loss 3.306 Prec@(1,5) (37.5%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:18:52] \u001b[32mTrain: [  6/50] Step 200/520 Loss 3.312 Prec@(1,5) (37.4%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:18:53] \u001b[32mTrain: [  6/50] Step 220/520 Loss 3.307 Prec@(1,5) (37.5%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:18:53] \u001b[32mTrain: [  6/50] Step 240/520 Loss 3.306 Prec@(1,5) (37.5%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:18:54] \u001b[32mTrain: [  6/50] Step 260/520 Loss 3.308 Prec@(1,5) (37.5%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:18:54] \u001b[32mTrain: [  6/50] Step 280/520 Loss 3.309 Prec@(1,5) (37.4%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:18:55] \u001b[32mTrain: [  6/50] Step 300/520 Loss 3.310 Prec@(1,5) (37.4%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:18:55] \u001b[32mTrain: [  6/50] Step 320/520 Loss 3.310 Prec@(1,5) (37.3%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:18:56] \u001b[32mTrain: [  6/50] Step 340/520 Loss 3.304 Prec@(1,5) (37.5%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:18:56] \u001b[32mTrain: [  6/50] Step 360/520 Loss 3.303 Prec@(1,5) (37.4%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:18:57] \u001b[32mTrain: [  6/50] Step 380/520 Loss 3.302 Prec@(1,5) (37.5%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:18:57] \u001b[32mTrain: [  6/50] Step 400/520 Loss 3.302 Prec@(1,5) (37.5%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:18:58] \u001b[32mTrain: [  6/50] Step 420/520 Loss 3.300 Prec@(1,5) (37.6%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:18:58] \u001b[32mTrain: [  6/50] Step 440/520 Loss 3.300 Prec@(1,5) (37.6%, 69.6%)\u001b[0m\n",
            "[2024-04-02 19:18:59] \u001b[32mTrain: [  6/50] Step 460/520 Loss 3.295 Prec@(1,5) (37.7%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:18:59] \u001b[32mTrain: [  6/50] Step 480/520 Loss 3.291 Prec@(1,5) (37.7%, 69.8%)\u001b[0m\n",
            "[2024-04-02 19:19:00] \u001b[32mTrain: [  6/50] Step 500/520 Loss 3.288 Prec@(1,5) (37.8%, 69.8%)\u001b[0m\n",
            "[2024-04-02 19:19:00] \u001b[32mTrain: [  6/50] Step 520/520 Loss 3.288 Prec@(1,5) (37.7%, 69.8%)\u001b[0m\n",
            "[2024-04-02 19:19:00] \u001b[32mTrain: [  6/50] Final Prec@1 37.7300%\u001b[0m\n",
            "[2024-04-02 19:19:04] \u001b[32mValid: [  6/50] Step 000/104 Loss 3.377 Prec@(1,5) (44.8%, 70.8%)\u001b[0m\n",
            "[2024-04-02 19:19:04] \u001b[32mValid: [  6/50] Step 020/104 Loss 3.512 Prec@(1,5) (35.6%, 66.8%)\u001b[0m\n",
            "[2024-04-02 19:19:04] \u001b[32mValid: [  6/50] Step 040/104 Loss 3.511 Prec@(1,5) (35.6%, 67.0%)\u001b[0m\n",
            "[2024-04-02 19:19:04] \u001b[32mValid: [  6/50] Step 060/104 Loss 3.471 Prec@(1,5) (35.9%, 67.0%)\u001b[0m\n",
            "[2024-04-02 19:19:05] \u001b[32mValid: [  6/50] Step 080/104 Loss 3.471 Prec@(1,5) (35.3%, 66.9%)\u001b[0m\n",
            "[2024-04-02 19:19:05] \u001b[32mValid: [  6/50] Step 100/104 Loss 3.456 Prec@(1,5) (35.4%, 67.2%)\u001b[0m\n",
            "[2024-04-02 19:19:05] \u001b[32mValid: [  6/50] Step 104/104 Loss 3.461 Prec@(1,5) (35.4%, 67.1%)\u001b[0m\n",
            "[2024-04-02 19:19:05] \u001b[32mValid: [  6/50] Final Prec@1 35.3800%\u001b[0m\n",
            "[2024-04-02 19:19:05] \u001b[32mEpoch 6 LR 0.024122\u001b[0m\n",
            "[2024-04-02 19:19:10] \u001b[32mTrain: [  7/50] Step 000/520 Loss 3.215 Prec@(1,5) (37.5%, 77.1%)\u001b[0m\n",
            "[2024-04-02 19:19:10] \u001b[32mTrain: [  7/50] Step 020/520 Loss 3.123 Prec@(1,5) (39.0%, 72.4%)\u001b[0m\n",
            "[2024-04-02 19:19:11] \u001b[32mTrain: [  7/50] Step 040/520 Loss 3.144 Prec@(1,5) (39.2%, 72.1%)\u001b[0m\n",
            "[2024-04-02 19:19:11] \u001b[32mTrain: [  7/50] Step 060/520 Loss 3.146 Prec@(1,5) (39.2%, 71.9%)\u001b[0m\n",
            "[2024-04-02 19:19:12] \u001b[32mTrain: [  7/50] Step 080/520 Loss 3.143 Prec@(1,5) (39.5%, 71.5%)\u001b[0m\n",
            "[2024-04-02 19:19:12] \u001b[32mTrain: [  7/50] Step 100/520 Loss 3.129 Prec@(1,5) (39.9%, 71.9%)\u001b[0m\n",
            "[2024-04-02 19:19:13] \u001b[32mTrain: [  7/50] Step 120/520 Loss 3.133 Prec@(1,5) (39.9%, 71.9%)\u001b[0m\n",
            "[2024-04-02 19:19:13] \u001b[32mTrain: [  7/50] Step 140/520 Loss 3.134 Prec@(1,5) (39.8%, 71.9%)\u001b[0m\n",
            "[2024-04-02 19:19:13] \u001b[32mTrain: [  7/50] Step 160/520 Loss 3.138 Prec@(1,5) (39.8%, 72.0%)\u001b[0m\n",
            "[2024-04-02 19:19:14] \u001b[32mTrain: [  7/50] Step 180/520 Loss 3.149 Prec@(1,5) (39.8%, 71.7%)\u001b[0m\n",
            "[2024-04-02 19:19:14] \u001b[32mTrain: [  7/50] Step 200/520 Loss 3.155 Prec@(1,5) (39.8%, 71.7%)\u001b[0m\n",
            "[2024-04-02 19:19:15] \u001b[32mTrain: [  7/50] Step 220/520 Loss 3.159 Prec@(1,5) (39.7%, 71.6%)\u001b[0m\n",
            "[2024-04-02 19:19:15] \u001b[32mTrain: [  7/50] Step 240/520 Loss 3.162 Prec@(1,5) (39.7%, 71.6%)\u001b[0m\n",
            "[2024-04-02 19:19:16] \u001b[32mTrain: [  7/50] Step 260/520 Loss 3.157 Prec@(1,5) (39.8%, 71.7%)\u001b[0m\n",
            "[2024-04-02 19:19:16] \u001b[32mTrain: [  7/50] Step 280/520 Loss 3.161 Prec@(1,5) (39.7%, 71.7%)\u001b[0m\n",
            "[2024-04-02 19:19:17] \u001b[32mTrain: [  7/50] Step 300/520 Loss 3.161 Prec@(1,5) (39.7%, 71.7%)\u001b[0m\n",
            "[2024-04-02 19:19:17] \u001b[32mTrain: [  7/50] Step 320/520 Loss 3.154 Prec@(1,5) (39.8%, 71.7%)\u001b[0m\n",
            "[2024-04-02 19:19:18] \u001b[32mTrain: [  7/50] Step 340/520 Loss 3.154 Prec@(1,5) (39.7%, 71.7%)\u001b[0m\n",
            "[2024-04-02 19:19:18] \u001b[32mTrain: [  7/50] Step 360/520 Loss 3.149 Prec@(1,5) (39.9%, 71.8%)\u001b[0m\n",
            "[2024-04-02 19:19:19] \u001b[32mTrain: [  7/50] Step 380/520 Loss 3.146 Prec@(1,5) (40.0%, 71.8%)\u001b[0m\n",
            "[2024-04-02 19:19:19] \u001b[32mTrain: [  7/50] Step 400/520 Loss 3.146 Prec@(1,5) (40.0%, 71.8%)\u001b[0m\n",
            "[2024-04-02 19:19:20] \u001b[32mTrain: [  7/50] Step 420/520 Loss 3.142 Prec@(1,5) (40.0%, 71.8%)\u001b[0m\n",
            "[2024-04-02 19:19:20] \u001b[32mTrain: [  7/50] Step 440/520 Loss 3.140 Prec@(1,5) (40.0%, 71.9%)\u001b[0m\n",
            "[2024-04-02 19:19:21] \u001b[32mTrain: [  7/50] Step 460/520 Loss 3.139 Prec@(1,5) (40.1%, 71.9%)\u001b[0m\n",
            "[2024-04-02 19:19:21] \u001b[32mTrain: [  7/50] Step 480/520 Loss 3.138 Prec@(1,5) (40.1%, 71.9%)\u001b[0m\n",
            "[2024-04-02 19:19:22] \u001b[32mTrain: [  7/50] Step 500/520 Loss 3.140 Prec@(1,5) (40.0%, 71.9%)\u001b[0m\n",
            "[2024-04-02 19:19:22] \u001b[32mTrain: [  7/50] Step 520/520 Loss 3.137 Prec@(1,5) (40.1%, 72.0%)\u001b[0m\n",
            "[2024-04-02 19:19:23] \u001b[32mTrain: [  7/50] Final Prec@1 40.0900%\u001b[0m\n",
            "[2024-04-02 19:19:26] \u001b[32mValid: [  7/50] Step 000/104 Loss 3.503 Prec@(1,5) (37.5%, 72.9%)\u001b[0m\n",
            "[2024-04-02 19:19:26] \u001b[32mValid: [  7/50] Step 020/104 Loss 3.352 Prec@(1,5) (37.6%, 70.5%)\u001b[0m\n",
            "[2024-04-02 19:19:26] \u001b[32mValid: [  7/50] Step 040/104 Loss 3.335 Prec@(1,5) (37.0%, 70.2%)\u001b[0m\n",
            "[2024-04-02 19:19:27] \u001b[32mValid: [  7/50] Step 060/104 Loss 3.295 Prec@(1,5) (37.3%, 70.3%)\u001b[0m\n",
            "[2024-04-02 19:19:27] \u001b[32mValid: [  7/50] Step 080/104 Loss 3.303 Prec@(1,5) (37.0%, 70.4%)\u001b[0m\n",
            "[2024-04-02 19:19:27] \u001b[32mValid: [  7/50] Step 100/104 Loss 3.292 Prec@(1,5) (36.9%, 70.2%)\u001b[0m\n",
            "[2024-04-02 19:19:27] \u001b[32mValid: [  7/50] Step 104/104 Loss 3.290 Prec@(1,5) (36.9%, 70.1%)\u001b[0m\n",
            "[2024-04-02 19:19:27] \u001b[32mValid: [  7/50] Final Prec@1 36.9200%\u001b[0m\n",
            "[2024-04-02 19:19:27] \u001b[32mEpoch 7 LR 0.023810\u001b[0m\n",
            "[2024-04-02 19:19:32] \u001b[32mTrain: [  8/50] Step 000/520 Loss 3.030 Prec@(1,5) (39.6%, 74.0%)\u001b[0m\n",
            "[2024-04-02 19:19:32] \u001b[32mTrain: [  8/50] Step 020/520 Loss 3.062 Prec@(1,5) (41.5%, 72.8%)\u001b[0m\n",
            "[2024-04-02 19:19:33] \u001b[32mTrain: [  8/50] Step 040/520 Loss 3.039 Prec@(1,5) (42.5%, 73.0%)\u001b[0m\n",
            "[2024-04-02 19:19:33] \u001b[32mTrain: [  8/50] Step 060/520 Loss 3.055 Prec@(1,5) (42.3%, 72.6%)\u001b[0m\n",
            "[2024-04-02 19:19:34] \u001b[32mTrain: [  8/50] Step 080/520 Loss 3.044 Prec@(1,5) (42.0%, 72.9%)\u001b[0m\n",
            "[2024-04-02 19:19:34] \u001b[32mTrain: [  8/50] Step 100/520 Loss 3.050 Prec@(1,5) (41.7%, 72.7%)\u001b[0m\n",
            "[2024-04-02 19:19:35] \u001b[32mTrain: [  8/50] Step 120/520 Loss 3.048 Prec@(1,5) (41.9%, 72.9%)\u001b[0m\n",
            "[2024-04-02 19:19:35] \u001b[32mTrain: [  8/50] Step 140/520 Loss 3.058 Prec@(1,5) (41.8%, 72.9%)\u001b[0m\n",
            "[2024-04-02 19:19:36] \u001b[32mTrain: [  8/50] Step 160/520 Loss 3.040 Prec@(1,5) (42.1%, 73.2%)\u001b[0m\n",
            "[2024-04-02 19:19:36] \u001b[32mTrain: [  8/50] Step 180/520 Loss 3.040 Prec@(1,5) (41.9%, 73.2%)\u001b[0m\n",
            "[2024-04-02 19:19:37] \u001b[32mTrain: [  8/50] Step 200/520 Loss 3.040 Prec@(1,5) (41.8%, 73.3%)\u001b[0m\n",
            "[2024-04-02 19:19:37] \u001b[32mTrain: [  8/50] Step 220/520 Loss 3.039 Prec@(1,5) (41.7%, 73.4%)\u001b[0m\n",
            "[2024-04-02 19:19:38] \u001b[32mTrain: [  8/50] Step 240/520 Loss 3.038 Prec@(1,5) (41.8%, 73.4%)\u001b[0m\n",
            "[2024-04-02 19:19:38] \u001b[32mTrain: [  8/50] Step 260/520 Loss 3.034 Prec@(1,5) (41.8%, 73.5%)\u001b[0m\n",
            "[2024-04-02 19:19:39] \u001b[32mTrain: [  8/50] Step 280/520 Loss 3.037 Prec@(1,5) (41.9%, 73.5%)\u001b[0m\n",
            "[2024-04-02 19:19:39] \u001b[32mTrain: [  8/50] Step 300/520 Loss 3.035 Prec@(1,5) (42.0%, 73.5%)\u001b[0m\n",
            "[2024-04-02 19:19:40] \u001b[32mTrain: [  8/50] Step 320/520 Loss 3.031 Prec@(1,5) (42.0%, 73.6%)\u001b[0m\n",
            "[2024-04-02 19:19:40] \u001b[32mTrain: [  8/50] Step 340/520 Loss 3.026 Prec@(1,5) (42.2%, 73.6%)\u001b[0m\n",
            "[2024-04-02 19:19:41] \u001b[32mTrain: [  8/50] Step 360/520 Loss 3.024 Prec@(1,5) (42.3%, 73.6%)\u001b[0m\n",
            "[2024-04-02 19:19:41] \u001b[32mTrain: [  8/50] Step 380/520 Loss 3.024 Prec@(1,5) (42.3%, 73.6%)\u001b[0m\n",
            "[2024-04-02 19:19:42] \u001b[32mTrain: [  8/50] Step 400/520 Loss 3.022 Prec@(1,5) (42.3%, 73.6%)\u001b[0m\n",
            "[2024-04-02 19:19:42] \u001b[32mTrain: [  8/50] Step 420/520 Loss 3.024 Prec@(1,5) (42.3%, 73.6%)\u001b[0m\n",
            "[2024-04-02 19:19:43] \u001b[32mTrain: [  8/50] Step 440/520 Loss 3.020 Prec@(1,5) (42.4%, 73.6%)\u001b[0m\n",
            "[2024-04-02 19:19:43] \u001b[32mTrain: [  8/50] Step 460/520 Loss 3.018 Prec@(1,5) (42.4%, 73.6%)\u001b[0m\n",
            "[2024-04-02 19:19:44] \u001b[32mTrain: [  8/50] Step 480/520 Loss 3.022 Prec@(1,5) (42.3%, 73.5%)\u001b[0m\n",
            "[2024-04-02 19:19:44] \u001b[32mTrain: [  8/50] Step 500/520 Loss 3.022 Prec@(1,5) (42.3%, 73.5%)\u001b[0m\n",
            "[2024-04-02 19:19:45] \u001b[32mTrain: [  8/50] Step 520/520 Loss 3.020 Prec@(1,5) (42.4%, 73.6%)\u001b[0m\n",
            "[2024-04-02 19:19:45] \u001b[32mTrain: [  8/50] Final Prec@1 42.3740%\u001b[0m\n",
            "[2024-04-02 19:19:48] \u001b[32mValid: [  8/50] Step 000/104 Loss 3.056 Prec@(1,5) (40.6%, 72.9%)\u001b[0m\n",
            "[2024-04-02 19:19:48] \u001b[32mValid: [  8/50] Step 020/104 Loss 3.034 Prec@(1,5) (40.9%, 71.8%)\u001b[0m\n",
            "[2024-04-02 19:19:49] \u001b[32mValid: [  8/50] Step 040/104 Loss 3.021 Prec@(1,5) (40.6%, 72.2%)\u001b[0m\n",
            "[2024-04-02 19:19:49] \u001b[32mValid: [  8/50] Step 060/104 Loss 3.004 Prec@(1,5) (40.5%, 72.4%)\u001b[0m\n",
            "[2024-04-02 19:19:49] \u001b[32mValid: [  8/50] Step 080/104 Loss 3.004 Prec@(1,5) (40.1%, 72.4%)\u001b[0m\n",
            "[2024-04-02 19:19:49] \u001b[32mValid: [  8/50] Step 100/104 Loss 3.001 Prec@(1,5) (40.1%, 72.3%)\u001b[0m\n",
            "[2024-04-02 19:19:49] \u001b[32mValid: [  8/50] Step 104/104 Loss 2.998 Prec@(1,5) (40.1%, 72.3%)\u001b[0m\n",
            "[2024-04-02 19:19:49] \u001b[32mValid: [  8/50] Final Prec@1 40.1100%\u001b[0m\n",
            "[2024-04-02 19:19:49] \u001b[32mEpoch 8 LR 0.023454\u001b[0m\n",
            "[2024-04-02 19:19:54] \u001b[32mTrain: [  9/50] Step 000/520 Loss 2.800 Prec@(1,5) (51.0%, 71.9%)\u001b[0m\n",
            "[2024-04-02 19:19:54] \u001b[32mTrain: [  9/50] Step 020/520 Loss 2.890 Prec@(1,5) (44.1%, 75.7%)\u001b[0m\n",
            "[2024-04-02 19:19:55] \u001b[32mTrain: [  9/50] Step 040/520 Loss 2.929 Prec@(1,5) (43.8%, 74.8%)\u001b[0m\n",
            "[2024-04-02 19:19:55] \u001b[32mTrain: [  9/50] Step 060/520 Loss 2.910 Prec@(1,5) (44.2%, 75.2%)\u001b[0m\n",
            "[2024-04-02 19:19:56] \u001b[32mTrain: [  9/50] Step 080/520 Loss 2.924 Prec@(1,5) (43.8%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:19:56] \u001b[32mTrain: [  9/50] Step 100/520 Loss 2.922 Prec@(1,5) (43.6%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:19:57] \u001b[32mTrain: [  9/50] Step 120/520 Loss 2.921 Prec@(1,5) (43.7%, 75.1%)\u001b[0m\n",
            "[2024-04-02 19:19:57] \u001b[32mTrain: [  9/50] Step 140/520 Loss 2.934 Prec@(1,5) (43.5%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:19:58] \u001b[32mTrain: [  9/50] Step 160/520 Loss 2.950 Prec@(1,5) (43.2%, 74.7%)\u001b[0m\n",
            "[2024-04-02 19:19:58] \u001b[32mTrain: [  9/50] Step 180/520 Loss 2.941 Prec@(1,5) (43.3%, 74.8%)\u001b[0m\n",
            "[2024-04-02 19:19:59] \u001b[32mTrain: [  9/50] Step 200/520 Loss 2.933 Prec@(1,5) (43.4%, 74.9%)\u001b[0m\n",
            "[2024-04-02 19:19:59] \u001b[32mTrain: [  9/50] Step 220/520 Loss 2.931 Prec@(1,5) (43.4%, 74.9%)\u001b[0m\n",
            "[2024-04-02 19:20:00] \u001b[32mTrain: [  9/50] Step 240/520 Loss 2.936 Prec@(1,5) (43.4%, 74.8%)\u001b[0m\n",
            "[2024-04-02 19:20:00] \u001b[32mTrain: [  9/50] Step 260/520 Loss 2.934 Prec@(1,5) (43.4%, 74.9%)\u001b[0m\n",
            "[2024-04-02 19:20:01] \u001b[32mTrain: [  9/50] Step 280/520 Loss 2.935 Prec@(1,5) (43.4%, 74.9%)\u001b[0m\n",
            "[2024-04-02 19:20:01] \u001b[32mTrain: [  9/50] Step 300/520 Loss 2.932 Prec@(1,5) (43.4%, 74.9%)\u001b[0m\n",
            "[2024-04-02 19:20:02] \u001b[32mTrain: [  9/50] Step 320/520 Loss 2.927 Prec@(1,5) (43.5%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:20:02] \u001b[32mTrain: [  9/50] Step 340/520 Loss 2.928 Prec@(1,5) (43.5%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:20:03] \u001b[32mTrain: [  9/50] Step 360/520 Loss 2.927 Prec@(1,5) (43.5%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:20:03] \u001b[32mTrain: [  9/50] Step 380/520 Loss 2.928 Prec@(1,5) (43.5%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:20:04] \u001b[32mTrain: [  9/50] Step 400/520 Loss 2.922 Prec@(1,5) (43.6%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:20:04] \u001b[32mTrain: [  9/50] Step 420/520 Loss 2.925 Prec@(1,5) (43.5%, 75.1%)\u001b[0m\n",
            "[2024-04-02 19:20:05] \u001b[32mTrain: [  9/50] Step 440/520 Loss 2.922 Prec@(1,5) (43.6%, 75.1%)\u001b[0m\n",
            "[2024-04-02 19:20:05] \u001b[32mTrain: [  9/50] Step 460/520 Loss 2.919 Prec@(1,5) (43.7%, 75.2%)\u001b[0m\n",
            "[2024-04-02 19:20:06] \u001b[32mTrain: [  9/50] Step 480/520 Loss 2.918 Prec@(1,5) (43.7%, 75.1%)\u001b[0m\n",
            "[2024-04-02 19:20:06] \u001b[32mTrain: [  9/50] Step 500/520 Loss 2.916 Prec@(1,5) (43.8%, 75.2%)\u001b[0m\n",
            "[2024-04-02 19:20:07] \u001b[32mTrain: [  9/50] Step 520/520 Loss 2.915 Prec@(1,5) (43.8%, 75.2%)\u001b[0m\n",
            "[2024-04-02 19:20:07] \u001b[32mTrain: [  9/50] Final Prec@1 43.7940%\u001b[0m\n",
            "[2024-04-02 19:20:10] \u001b[32mValid: [  9/50] Step 000/104 Loss 2.966 Prec@(1,5) (47.9%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:20:10] \u001b[32mValid: [  9/50] Step 020/104 Loss 3.120 Prec@(1,5) (41.6%, 73.1%)\u001b[0m\n",
            "[2024-04-02 19:20:11] \u001b[32mValid: [  9/50] Step 040/104 Loss 3.093 Prec@(1,5) (41.1%, 72.7%)\u001b[0m\n",
            "[2024-04-02 19:20:11] \u001b[32mValid: [  9/50] Step 060/104 Loss 3.042 Prec@(1,5) (41.5%, 73.4%)\u001b[0m\n",
            "[2024-04-02 19:20:11] \u001b[32mValid: [  9/50] Step 080/104 Loss 3.058 Prec@(1,5) (41.0%, 73.1%)\u001b[0m\n",
            "[2024-04-02 19:20:11] \u001b[32mValid: [  9/50] Step 100/104 Loss 3.050 Prec@(1,5) (40.9%, 72.9%)\u001b[0m\n",
            "[2024-04-02 19:20:11] \u001b[32mValid: [  9/50] Step 104/104 Loss 3.051 Prec@(1,5) (40.9%, 73.0%)\u001b[0m\n",
            "[2024-04-02 19:20:11] \u001b[32mValid: [  9/50] Final Prec@1 40.8500%\u001b[0m\n",
            "[2024-04-02 19:20:11] \u001b[32mEpoch 9 LR 0.023054\u001b[0m\n",
            "[2024-04-02 19:20:16] \u001b[32mTrain: [ 10/50] Step 000/520 Loss 2.821 Prec@(1,5) (37.5%, 76.0%)\u001b[0m\n",
            "[2024-04-02 19:20:16] \u001b[32mTrain: [ 10/50] Step 020/520 Loss 2.867 Prec@(1,5) (43.6%, 76.7%)\u001b[0m\n",
            "[2024-04-02 19:20:17] \u001b[32mTrain: [ 10/50] Step 040/520 Loss 2.811 Prec@(1,5) (45.0%, 77.0%)\u001b[0m\n",
            "[2024-04-02 19:20:17] \u001b[32mTrain: [ 10/50] Step 060/520 Loss 2.844 Prec@(1,5) (44.9%, 76.2%)\u001b[0m\n",
            "[2024-04-02 19:20:18] \u001b[32mTrain: [ 10/50] Step 080/520 Loss 2.830 Prec@(1,5) (45.0%, 76.6%)\u001b[0m\n",
            "[2024-04-02 19:20:18] \u001b[32mTrain: [ 10/50] Step 100/520 Loss 2.829 Prec@(1,5) (45.2%, 76.6%)\u001b[0m\n",
            "[2024-04-02 19:20:19] \u001b[32mTrain: [ 10/50] Step 120/520 Loss 2.817 Prec@(1,5) (45.6%, 76.8%)\u001b[0m\n",
            "[2024-04-02 19:20:19] \u001b[32mTrain: [ 10/50] Step 140/520 Loss 2.819 Prec@(1,5) (45.6%, 76.8%)\u001b[0m\n",
            "[2024-04-02 19:20:20] \u001b[32mTrain: [ 10/50] Step 160/520 Loss 2.829 Prec@(1,5) (45.4%, 76.8%)\u001b[0m\n",
            "[2024-04-02 19:20:20] \u001b[32mTrain: [ 10/50] Step 180/520 Loss 2.823 Prec@(1,5) (45.6%, 76.7%)\u001b[0m\n",
            "[2024-04-02 19:20:21] \u001b[32mTrain: [ 10/50] Step 200/520 Loss 2.837 Prec@(1,5) (45.4%, 76.5%)\u001b[0m\n",
            "[2024-04-02 19:20:21] \u001b[32mTrain: [ 10/50] Step 220/520 Loss 2.845 Prec@(1,5) (45.2%, 76.4%)\u001b[0m\n",
            "[2024-04-02 19:20:22] \u001b[32mTrain: [ 10/50] Step 240/520 Loss 2.845 Prec@(1,5) (45.2%, 76.4%)\u001b[0m\n",
            "[2024-04-02 19:20:22] \u001b[32mTrain: [ 10/50] Step 260/520 Loss 2.844 Prec@(1,5) (45.2%, 76.3%)\u001b[0m\n",
            "[2024-04-02 19:20:23] \u001b[32mTrain: [ 10/50] Step 280/520 Loss 2.848 Prec@(1,5) (45.1%, 76.3%)\u001b[0m\n",
            "[2024-04-02 19:20:23] \u001b[32mTrain: [ 10/50] Step 300/520 Loss 2.852 Prec@(1,5) (45.0%, 76.2%)\u001b[0m\n",
            "[2024-04-02 19:20:24] \u001b[32mTrain: [ 10/50] Step 320/520 Loss 2.849 Prec@(1,5) (45.1%, 76.2%)\u001b[0m\n",
            "[2024-04-02 19:20:24] \u001b[32mTrain: [ 10/50] Step 340/520 Loss 2.846 Prec@(1,5) (45.2%, 76.2%)\u001b[0m\n",
            "[2024-04-02 19:20:25] \u001b[32mTrain: [ 10/50] Step 360/520 Loss 2.842 Prec@(1,5) (45.2%, 76.3%)\u001b[0m\n",
            "[2024-04-02 19:20:25] \u001b[32mTrain: [ 10/50] Step 380/520 Loss 2.837 Prec@(1,5) (45.3%, 76.4%)\u001b[0m\n",
            "[2024-04-02 19:20:26] \u001b[32mTrain: [ 10/50] Step 400/520 Loss 2.840 Prec@(1,5) (45.3%, 76.3%)\u001b[0m\n",
            "[2024-04-02 19:20:26] \u001b[32mTrain: [ 10/50] Step 420/520 Loss 2.842 Prec@(1,5) (45.2%, 76.3%)\u001b[0m\n",
            "[2024-04-02 19:20:27] \u001b[32mTrain: [ 10/50] Step 440/520 Loss 2.842 Prec@(1,5) (45.2%, 76.2%)\u001b[0m\n",
            "[2024-04-02 19:20:27] \u001b[32mTrain: [ 10/50] Step 460/520 Loss 2.841 Prec@(1,5) (45.2%, 76.2%)\u001b[0m\n",
            "[2024-04-02 19:20:28] \u001b[32mTrain: [ 10/50] Step 480/520 Loss 2.843 Prec@(1,5) (45.1%, 76.2%)\u001b[0m\n",
            "[2024-04-02 19:20:28] \u001b[32mTrain: [ 10/50] Step 500/520 Loss 2.840 Prec@(1,5) (45.2%, 76.2%)\u001b[0m\n",
            "[2024-04-02 19:20:29] \u001b[32mTrain: [ 10/50] Step 520/520 Loss 2.840 Prec@(1,5) (45.2%, 76.2%)\u001b[0m\n",
            "[2024-04-02 19:20:29] \u001b[32mTrain: [ 10/50] Final Prec@1 45.1600%\u001b[0m\n",
            "[2024-04-02 19:20:33] \u001b[32mValid: [ 10/50] Step 000/104 Loss 2.854 Prec@(1,5) (51.0%, 74.0%)\u001b[0m\n",
            "[2024-04-02 19:20:33] \u001b[32mValid: [ 10/50] Step 020/104 Loss 3.043 Prec@(1,5) (41.8%, 73.9%)\u001b[0m\n",
            "[2024-04-02 19:20:33] \u001b[32mValid: [ 10/50] Step 040/104 Loss 3.012 Prec@(1,5) (41.6%, 73.7%)\u001b[0m\n",
            "[2024-04-02 19:20:33] \u001b[32mValid: [ 10/50] Step 060/104 Loss 2.963 Prec@(1,5) (42.3%, 73.9%)\u001b[0m\n",
            "[2024-04-02 19:20:33] \u001b[32mValid: [ 10/50] Step 080/104 Loss 2.957 Prec@(1,5) (42.0%, 73.8%)\u001b[0m\n",
            "[2024-04-02 19:20:33] \u001b[32mValid: [ 10/50] Step 100/104 Loss 2.950 Prec@(1,5) (42.0%, 73.9%)\u001b[0m\n",
            "[2024-04-02 19:20:33] \u001b[32mValid: [ 10/50] Step 104/104 Loss 2.950 Prec@(1,5) (42.0%, 73.8%)\u001b[0m\n",
            "[2024-04-02 19:20:34] \u001b[32mValid: [ 10/50] Final Prec@1 41.9600%\u001b[0m\n",
            "[2024-04-02 19:20:34] \u001b[32mEpoch 10 LR 0.022613\u001b[0m\n",
            "[2024-04-02 19:20:38] \u001b[32mTrain: [ 11/50] Step 000/520 Loss 2.996 Prec@(1,5) (43.8%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:20:39] \u001b[32mTrain: [ 11/50] Step 020/520 Loss 2.732 Prec@(1,5) (47.2%, 77.6%)\u001b[0m\n",
            "[2024-04-02 19:20:39] \u001b[32mTrain: [ 11/50] Step 040/520 Loss 2.760 Prec@(1,5) (46.2%, 77.4%)\u001b[0m\n",
            "[2024-04-02 19:20:40] \u001b[32mTrain: [ 11/50] Step 060/520 Loss 2.752 Prec@(1,5) (46.6%, 77.4%)\u001b[0m\n",
            "[2024-04-02 19:20:40] \u001b[32mTrain: [ 11/50] Step 080/520 Loss 2.734 Prec@(1,5) (47.1%, 77.6%)\u001b[0m\n",
            "[2024-04-02 19:20:41] \u001b[32mTrain: [ 11/50] Step 100/520 Loss 2.742 Prec@(1,5) (47.2%, 77.5%)\u001b[0m\n",
            "[2024-04-02 19:20:41] \u001b[32mTrain: [ 11/50] Step 120/520 Loss 2.762 Prec@(1,5) (46.9%, 77.3%)\u001b[0m\n",
            "[2024-04-02 19:20:42] \u001b[32mTrain: [ 11/50] Step 140/520 Loss 2.748 Prec@(1,5) (47.1%, 77.6%)\u001b[0m\n",
            "[2024-04-02 19:20:42] \u001b[32mTrain: [ 11/50] Step 160/520 Loss 2.744 Prec@(1,5) (46.9%, 77.5%)\u001b[0m\n",
            "[2024-04-02 19:20:43] \u001b[32mTrain: [ 11/50] Step 180/520 Loss 2.739 Prec@(1,5) (47.0%, 77.6%)\u001b[0m\n",
            "[2024-04-02 19:20:43] \u001b[32mTrain: [ 11/50] Step 200/520 Loss 2.742 Prec@(1,5) (46.9%, 77.6%)\u001b[0m\n",
            "[2024-04-02 19:20:44] \u001b[32mTrain: [ 11/50] Step 220/520 Loss 2.740 Prec@(1,5) (46.9%, 77.6%)\u001b[0m\n",
            "[2024-04-02 19:20:44] \u001b[32mTrain: [ 11/50] Step 240/520 Loss 2.746 Prec@(1,5) (46.7%, 77.5%)\u001b[0m\n",
            "[2024-04-02 19:20:45] \u001b[32mTrain: [ 11/50] Step 260/520 Loss 2.738 Prec@(1,5) (46.9%, 77.7%)\u001b[0m\n",
            "[2024-04-02 19:20:45] \u001b[32mTrain: [ 11/50] Step 280/520 Loss 2.741 Prec@(1,5) (46.9%, 77.6%)\u001b[0m\n",
            "[2024-04-02 19:20:46] \u001b[32mTrain: [ 11/50] Step 300/520 Loss 2.743 Prec@(1,5) (46.9%, 77.6%)\u001b[0m\n",
            "[2024-04-02 19:20:46] \u001b[32mTrain: [ 11/50] Step 320/520 Loss 2.742 Prec@(1,5) (46.9%, 77.6%)\u001b[0m\n",
            "[2024-04-02 19:20:47] \u001b[32mTrain: [ 11/50] Step 340/520 Loss 2.746 Prec@(1,5) (46.8%, 77.6%)\u001b[0m\n",
            "[2024-04-02 19:20:47] \u001b[32mTrain: [ 11/50] Step 360/520 Loss 2.748 Prec@(1,5) (46.8%, 77.6%)\u001b[0m\n",
            "[2024-04-02 19:20:48] \u001b[32mTrain: [ 11/50] Step 380/520 Loss 2.748 Prec@(1,5) (46.9%, 77.5%)\u001b[0m\n",
            "[2024-04-02 19:20:49] \u001b[32mTrain: [ 11/50] Step 400/520 Loss 2.749 Prec@(1,5) (46.8%, 77.5%)\u001b[0m\n",
            "[2024-04-02 19:20:49] \u001b[32mTrain: [ 11/50] Step 420/520 Loss 2.752 Prec@(1,5) (46.8%, 77.4%)\u001b[0m\n",
            "[2024-04-02 19:20:50] \u001b[32mTrain: [ 11/50] Step 440/520 Loss 2.754 Prec@(1,5) (46.8%, 77.4%)\u001b[0m\n",
            "[2024-04-02 19:20:50] \u001b[32mTrain: [ 11/50] Step 460/520 Loss 2.756 Prec@(1,5) (46.7%, 77.4%)\u001b[0m\n",
            "[2024-04-02 19:20:51] \u001b[32mTrain: [ 11/50] Step 480/520 Loss 2.759 Prec@(1,5) (46.6%, 77.3%)\u001b[0m\n",
            "[2024-04-02 19:20:51] \u001b[32mTrain: [ 11/50] Step 500/520 Loss 2.762 Prec@(1,5) (46.6%, 77.3%)\u001b[0m\n",
            "[2024-04-02 19:20:52] \u001b[32mTrain: [ 11/50] Step 520/520 Loss 2.766 Prec@(1,5) (46.5%, 77.2%)\u001b[0m\n",
            "[2024-04-02 19:20:52] \u001b[32mTrain: [ 11/50] Final Prec@1 46.5180%\u001b[0m\n",
            "[2024-04-02 19:20:55] \u001b[32mValid: [ 11/50] Step 000/104 Loss 2.995 Prec@(1,5) (41.7%, 77.1%)\u001b[0m\n",
            "[2024-04-02 19:20:56] \u001b[32mValid: [ 11/50] Step 020/104 Loss 2.899 Prec@(1,5) (43.5%, 74.9%)\u001b[0m\n",
            "[2024-04-02 19:20:56] \u001b[32mValid: [ 11/50] Step 040/104 Loss 2.928 Prec@(1,5) (43.1%, 74.4%)\u001b[0m\n",
            "[2024-04-02 19:20:56] \u001b[32mValid: [ 11/50] Step 060/104 Loss 2.857 Prec@(1,5) (43.9%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:20:56] \u001b[32mValid: [ 11/50] Step 080/104 Loss 2.855 Prec@(1,5) (43.4%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:20:56] \u001b[32mValid: [ 11/50] Step 100/104 Loss 2.837 Prec@(1,5) (43.2%, 75.1%)\u001b[0m\n",
            "[2024-04-02 19:20:56] \u001b[32mValid: [ 11/50] Step 104/104 Loss 2.839 Prec@(1,5) (43.1%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:20:56] \u001b[32mValid: [ 11/50] Final Prec@1 43.1300%\u001b[0m\n",
            "[2024-04-02 19:20:56] \u001b[32mEpoch 11 LR 0.022132\u001b[0m\n",
            "[2024-04-02 19:21:01] \u001b[32mTrain: [ 12/50] Step 000/520 Loss 2.731 Prec@(1,5) (51.0%, 76.0%)\u001b[0m\n",
            "[2024-04-02 19:21:02] \u001b[32mTrain: [ 12/50] Step 020/520 Loss 2.698 Prec@(1,5) (47.7%, 79.1%)\u001b[0m\n",
            "[2024-04-02 19:21:02] \u001b[32mTrain: [ 12/50] Step 040/520 Loss 2.704 Prec@(1,5) (47.9%, 78.4%)\u001b[0m\n",
            "[2024-04-02 19:21:03] \u001b[32mTrain: [ 12/50] Step 060/520 Loss 2.687 Prec@(1,5) (48.1%, 78.0%)\u001b[0m\n",
            "[2024-04-02 19:21:03] \u001b[32mTrain: [ 12/50] Step 080/520 Loss 2.701 Prec@(1,5) (47.7%, 77.8%)\u001b[0m\n",
            "[2024-04-02 19:21:04] \u001b[32mTrain: [ 12/50] Step 100/520 Loss 2.705 Prec@(1,5) (47.7%, 77.6%)\u001b[0m\n",
            "[2024-04-02 19:21:04] \u001b[32mTrain: [ 12/50] Step 120/520 Loss 2.714 Prec@(1,5) (47.6%, 77.6%)\u001b[0m\n",
            "[2024-04-02 19:21:05] \u001b[32mTrain: [ 12/50] Step 140/520 Loss 2.713 Prec@(1,5) (47.5%, 77.7%)\u001b[0m\n",
            "[2024-04-02 19:21:05] \u001b[32mTrain: [ 12/50] Step 160/520 Loss 2.710 Prec@(1,5) (47.4%, 77.8%)\u001b[0m\n",
            "[2024-04-02 19:21:06] \u001b[32mTrain: [ 12/50] Step 180/520 Loss 2.706 Prec@(1,5) (47.4%, 77.9%)\u001b[0m\n",
            "[2024-04-02 19:21:06] \u001b[32mTrain: [ 12/50] Step 200/520 Loss 2.704 Prec@(1,5) (47.4%, 78.0%)\u001b[0m\n",
            "[2024-04-02 19:21:07] \u001b[32mTrain: [ 12/50] Step 220/520 Loss 2.697 Prec@(1,5) (47.4%, 78.0%)\u001b[0m\n",
            "[2024-04-02 19:21:07] \u001b[32mTrain: [ 12/50] Step 240/520 Loss 2.692 Prec@(1,5) (47.5%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:21:08] \u001b[32mTrain: [ 12/50] Step 260/520 Loss 2.682 Prec@(1,5) (47.8%, 78.3%)\u001b[0m\n",
            "[2024-04-02 19:21:08] \u001b[32mTrain: [ 12/50] Step 280/520 Loss 2.685 Prec@(1,5) (47.7%, 78.3%)\u001b[0m\n",
            "[2024-04-02 19:21:09] \u001b[32mTrain: [ 12/50] Step 300/520 Loss 2.691 Prec@(1,5) (47.6%, 78.2%)\u001b[0m\n",
            "[2024-04-02 19:21:09] \u001b[32mTrain: [ 12/50] Step 320/520 Loss 2.687 Prec@(1,5) (47.7%, 78.2%)\u001b[0m\n",
            "[2024-04-02 19:21:10] \u001b[32mTrain: [ 12/50] Step 340/520 Loss 2.687 Prec@(1,5) (47.7%, 78.3%)\u001b[0m\n",
            "[2024-04-02 19:21:10] \u001b[32mTrain: [ 12/50] Step 360/520 Loss 2.691 Prec@(1,5) (47.6%, 78.2%)\u001b[0m\n",
            "[2024-04-02 19:21:11] \u001b[32mTrain: [ 12/50] Step 380/520 Loss 2.694 Prec@(1,5) (47.5%, 78.2%)\u001b[0m\n",
            "[2024-04-02 19:21:11] \u001b[32mTrain: [ 12/50] Step 400/520 Loss 2.694 Prec@(1,5) (47.6%, 78.2%)\u001b[0m\n",
            "[2024-04-02 19:21:12] \u001b[32mTrain: [ 12/50] Step 420/520 Loss 2.695 Prec@(1,5) (47.5%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:21:12] \u001b[32mTrain: [ 12/50] Step 440/520 Loss 2.695 Prec@(1,5) (47.6%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:21:12] \u001b[32mTrain: [ 12/50] Step 460/520 Loss 2.692 Prec@(1,5) (47.7%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:21:13] \u001b[32mTrain: [ 12/50] Step 480/520 Loss 2.690 Prec@(1,5) (47.7%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:21:13] \u001b[32mTrain: [ 12/50] Step 500/520 Loss 2.688 Prec@(1,5) (47.8%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:21:14] \u001b[32mTrain: [ 12/50] Step 520/520 Loss 2.687 Prec@(1,5) (47.8%, 78.2%)\u001b[0m\n",
            "[2024-04-02 19:21:14] \u001b[32mTrain: [ 12/50] Final Prec@1 47.7780%\u001b[0m\n",
            "[2024-04-02 19:21:18] \u001b[32mValid: [ 12/50] Step 000/104 Loss 2.955 Prec@(1,5) (44.8%, 72.9%)\u001b[0m\n",
            "[2024-04-02 19:21:18] \u001b[32mValid: [ 12/50] Step 020/104 Loss 2.921 Prec@(1,5) (43.9%, 75.3%)\u001b[0m\n",
            "[2024-04-02 19:21:18] \u001b[32mValid: [ 12/50] Step 040/104 Loss 2.898 Prec@(1,5) (43.2%, 75.2%)\u001b[0m\n",
            "[2024-04-02 19:21:18] \u001b[32mValid: [ 12/50] Step 060/104 Loss 2.869 Prec@(1,5) (43.9%, 75.1%)\u001b[0m\n",
            "[2024-04-02 19:21:18] \u001b[32mValid: [ 12/50] Step 080/104 Loss 2.876 Prec@(1,5) (43.6%, 75.1%)\u001b[0m\n",
            "[2024-04-02 19:21:19] \u001b[32mValid: [ 12/50] Step 100/104 Loss 2.854 Prec@(1,5) (43.5%, 75.1%)\u001b[0m\n",
            "[2024-04-02 19:21:19] \u001b[32mValid: [ 12/50] Step 104/104 Loss 2.859 Prec@(1,5) (43.4%, 75.1%)\u001b[0m\n",
            "[2024-04-02 19:21:19] \u001b[32mValid: [ 12/50] Final Prec@1 43.3700%\u001b[0m\n",
            "[2024-04-02 19:21:19] \u001b[32mEpoch 12 LR 0.021612\u001b[0m\n",
            "[2024-04-02 19:21:23] \u001b[32mTrain: [ 13/50] Step 000/520 Loss 2.698 Prec@(1,5) (52.1%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:21:24] \u001b[32mTrain: [ 13/50] Step 020/520 Loss 2.663 Prec@(1,5) (48.0%, 79.3%)\u001b[0m\n",
            "[2024-04-02 19:21:24] \u001b[32mTrain: [ 13/50] Step 040/520 Loss 2.655 Prec@(1,5) (48.2%, 78.4%)\u001b[0m\n",
            "[2024-04-02 19:21:25] \u001b[32mTrain: [ 13/50] Step 060/520 Loss 2.666 Prec@(1,5) (48.0%, 78.6%)\u001b[0m\n",
            "[2024-04-02 19:21:25] \u001b[32mTrain: [ 13/50] Step 080/520 Loss 2.644 Prec@(1,5) (48.4%, 78.7%)\u001b[0m\n",
            "[2024-04-02 19:21:26] \u001b[32mTrain: [ 13/50] Step 100/520 Loss 2.651 Prec@(1,5) (48.2%, 78.8%)\u001b[0m\n",
            "[2024-04-02 19:21:26] \u001b[32mTrain: [ 13/50] Step 120/520 Loss 2.649 Prec@(1,5) (48.5%, 78.7%)\u001b[0m\n",
            "[2024-04-02 19:21:27] \u001b[32mTrain: [ 13/50] Step 140/520 Loss 2.636 Prec@(1,5) (48.6%, 79.0%)\u001b[0m\n",
            "[2024-04-02 19:21:27] \u001b[32mTrain: [ 13/50] Step 160/520 Loss 2.634 Prec@(1,5) (48.6%, 79.0%)\u001b[0m\n",
            "[2024-04-02 19:21:28] \u001b[32mTrain: [ 13/50] Step 180/520 Loss 2.628 Prec@(1,5) (48.7%, 79.1%)\u001b[0m\n",
            "[2024-04-02 19:21:28] \u001b[32mTrain: [ 13/50] Step 200/520 Loss 2.636 Prec@(1,5) (48.6%, 78.9%)\u001b[0m\n",
            "[2024-04-02 19:21:29] \u001b[32mTrain: [ 13/50] Step 220/520 Loss 2.637 Prec@(1,5) (48.5%, 78.9%)\u001b[0m\n",
            "[2024-04-02 19:21:29] \u001b[32mTrain: [ 13/50] Step 240/520 Loss 2.634 Prec@(1,5) (48.5%, 79.0%)\u001b[0m\n",
            "[2024-04-02 19:21:30] \u001b[32mTrain: [ 13/50] Step 260/520 Loss 2.626 Prec@(1,5) (48.7%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:21:30] \u001b[32mTrain: [ 13/50] Step 280/520 Loss 2.626 Prec@(1,5) (48.6%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:21:31] \u001b[32mTrain: [ 13/50] Step 300/520 Loss 2.632 Prec@(1,5) (48.5%, 79.1%)\u001b[0m\n",
            "[2024-04-02 19:21:31] \u001b[32mTrain: [ 13/50] Step 320/520 Loss 2.631 Prec@(1,5) (48.5%, 79.0%)\u001b[0m\n",
            "[2024-04-02 19:21:32] \u001b[32mTrain: [ 13/50] Step 340/520 Loss 2.627 Prec@(1,5) (48.5%, 79.1%)\u001b[0m\n",
            "[2024-04-02 19:21:32] \u001b[32mTrain: [ 13/50] Step 360/520 Loss 2.628 Prec@(1,5) (48.5%, 79.1%)\u001b[0m\n",
            "[2024-04-02 19:21:33] \u001b[32mTrain: [ 13/50] Step 380/520 Loss 2.628 Prec@(1,5) (48.6%, 79.1%)\u001b[0m\n",
            "[2024-04-02 19:21:33] \u001b[32mTrain: [ 13/50] Step 400/520 Loss 2.627 Prec@(1,5) (48.6%, 79.1%)\u001b[0m\n",
            "[2024-04-02 19:21:34] \u001b[32mTrain: [ 13/50] Step 420/520 Loss 2.626 Prec@(1,5) (48.6%, 79.1%)\u001b[0m\n",
            "[2024-04-02 19:21:34] \u001b[32mTrain: [ 13/50] Step 440/520 Loss 2.625 Prec@(1,5) (48.6%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:21:35] \u001b[32mTrain: [ 13/50] Step 460/520 Loss 2.625 Prec@(1,5) (48.6%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:21:35] \u001b[32mTrain: [ 13/50] Step 480/520 Loss 2.624 Prec@(1,5) (48.6%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:21:36] \u001b[32mTrain: [ 13/50] Step 500/520 Loss 2.626 Prec@(1,5) (48.6%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:21:36] \u001b[32mTrain: [ 13/50] Step 520/520 Loss 2.629 Prec@(1,5) (48.6%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:21:36] \u001b[32mTrain: [ 13/50] Final Prec@1 48.5560%\u001b[0m\n",
            "[2024-04-02 19:21:40] \u001b[32mValid: [ 13/50] Step 000/104 Loss 2.520 Prec@(1,5) (49.0%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:21:40] \u001b[32mValid: [ 13/50] Step 020/104 Loss 2.759 Prec@(1,5) (44.1%, 77.8%)\u001b[0m\n",
            "[2024-04-02 19:21:40] \u001b[32mValid: [ 13/50] Step 040/104 Loss 2.752 Prec@(1,5) (44.5%, 77.1%)\u001b[0m\n",
            "[2024-04-02 19:21:40] \u001b[32mValid: [ 13/50] Step 060/104 Loss 2.728 Prec@(1,5) (45.1%, 77.0%)\u001b[0m\n",
            "[2024-04-02 19:21:40] \u001b[32mValid: [ 13/50] Step 080/104 Loss 2.731 Prec@(1,5) (44.7%, 77.0%)\u001b[0m\n",
            "[2024-04-02 19:21:41] \u001b[32mValid: [ 13/50] Step 100/104 Loss 2.712 Prec@(1,5) (44.9%, 77.1%)\u001b[0m\n",
            "[2024-04-02 19:21:41] \u001b[32mValid: [ 13/50] Step 104/104 Loss 2.710 Prec@(1,5) (44.9%, 77.1%)\u001b[0m\n",
            "[2024-04-02 19:21:41] \u001b[32mValid: [ 13/50] Final Prec@1 44.8900%\u001b[0m\n",
            "[2024-04-02 19:21:41] \u001b[32mEpoch 13 LR 0.021057\u001b[0m\n",
            "[2024-04-02 19:21:45] \u001b[32mTrain: [ 14/50] Step 000/520 Loss 3.071 Prec@(1,5) (39.6%, 71.9%)\u001b[0m\n",
            "[2024-04-02 19:21:46] \u001b[32mTrain: [ 14/50] Step 020/520 Loss 2.632 Prec@(1,5) (48.0%, 78.6%)\u001b[0m\n",
            "[2024-04-02 19:21:46] \u001b[32mTrain: [ 14/50] Step 040/520 Loss 2.597 Prec@(1,5) (48.7%, 79.4%)\u001b[0m\n",
            "[2024-04-02 19:21:47] \u001b[32mTrain: [ 14/50] Step 060/520 Loss 2.598 Prec@(1,5) (48.7%, 79.4%)\u001b[0m\n",
            "[2024-04-02 19:21:47] \u001b[32mTrain: [ 14/50] Step 080/520 Loss 2.593 Prec@(1,5) (48.7%, 79.7%)\u001b[0m\n",
            "[2024-04-02 19:21:48] \u001b[32mTrain: [ 14/50] Step 100/520 Loss 2.583 Prec@(1,5) (48.9%, 80.0%)\u001b[0m\n",
            "[2024-04-02 19:21:48] \u001b[32mTrain: [ 14/50] Step 120/520 Loss 2.579 Prec@(1,5) (48.9%, 79.9%)\u001b[0m\n",
            "[2024-04-02 19:21:49] \u001b[32mTrain: [ 14/50] Step 140/520 Loss 2.586 Prec@(1,5) (48.9%, 79.9%)\u001b[0m\n",
            "[2024-04-02 19:21:49] \u001b[32mTrain: [ 14/50] Step 160/520 Loss 2.585 Prec@(1,5) (49.1%, 79.9%)\u001b[0m\n",
            "[2024-04-02 19:21:50] \u001b[32mTrain: [ 14/50] Step 180/520 Loss 2.592 Prec@(1,5) (49.1%, 79.7%)\u001b[0m\n",
            "[2024-04-02 19:21:51] \u001b[32mTrain: [ 14/50] Step 200/520 Loss 2.590 Prec@(1,5) (49.0%, 79.7%)\u001b[0m\n",
            "[2024-04-02 19:21:51] \u001b[32mTrain: [ 14/50] Step 220/520 Loss 2.591 Prec@(1,5) (49.0%, 79.7%)\u001b[0m\n",
            "[2024-04-02 19:21:52] \u001b[32mTrain: [ 14/50] Step 240/520 Loss 2.584 Prec@(1,5) (49.1%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:21:52] \u001b[32mTrain: [ 14/50] Step 260/520 Loss 2.584 Prec@(1,5) (49.2%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:21:53] \u001b[32mTrain: [ 14/50] Step 280/520 Loss 2.583 Prec@(1,5) (49.2%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:21:53] \u001b[32mTrain: [ 14/50] Step 300/520 Loss 2.585 Prec@(1,5) (49.1%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:21:54] \u001b[32mTrain: [ 14/50] Step 320/520 Loss 2.584 Prec@(1,5) (49.2%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:21:54] \u001b[32mTrain: [ 14/50] Step 340/520 Loss 2.581 Prec@(1,5) (49.3%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:21:55] \u001b[32mTrain: [ 14/50] Step 360/520 Loss 2.582 Prec@(1,5) (49.3%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:21:55] \u001b[32mTrain: [ 14/50] Step 380/520 Loss 2.586 Prec@(1,5) (49.2%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:21:56] \u001b[32mTrain: [ 14/50] Step 400/520 Loss 2.586 Prec@(1,5) (49.2%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:21:56] \u001b[32mTrain: [ 14/50] Step 420/520 Loss 2.589 Prec@(1,5) (49.1%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:21:57] \u001b[32mTrain: [ 14/50] Step 440/520 Loss 2.589 Prec@(1,5) (49.1%, 79.7%)\u001b[0m\n",
            "[2024-04-02 19:21:57] \u001b[32mTrain: [ 14/50] Step 460/520 Loss 2.586 Prec@(1,5) (49.3%, 79.7%)\u001b[0m\n",
            "[2024-04-02 19:21:58] \u001b[32mTrain: [ 14/50] Step 480/520 Loss 2.583 Prec@(1,5) (49.3%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:21:58] \u001b[32mTrain: [ 14/50] Step 500/520 Loss 2.583 Prec@(1,5) (49.3%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:21:59] \u001b[32mTrain: [ 14/50] Step 520/520 Loss 2.582 Prec@(1,5) (49.3%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:21:59] \u001b[32mTrain: [ 14/50] Final Prec@1 49.3280%\u001b[0m\n",
            "[2024-04-02 19:22:02] \u001b[32mValid: [ 14/50] Step 000/104 Loss 2.714 Prec@(1,5) (49.0%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:22:03] \u001b[32mValid: [ 14/50] Step 020/104 Loss 2.559 Prec@(1,5) (47.8%, 78.2%)\u001b[0m\n",
            "[2024-04-02 19:22:03] \u001b[32mValid: [ 14/50] Step 040/104 Loss 2.537 Prec@(1,5) (48.0%, 78.2%)\u001b[0m\n",
            "[2024-04-02 19:22:03] \u001b[32mValid: [ 14/50] Step 060/104 Loss 2.497 Prec@(1,5) (48.0%, 78.3%)\u001b[0m\n",
            "[2024-04-02 19:22:03] \u001b[32mValid: [ 14/50] Step 080/104 Loss 2.506 Prec@(1,5) (47.9%, 78.3%)\u001b[0m\n",
            "[2024-04-02 19:22:03] \u001b[32mValid: [ 14/50] Step 100/104 Loss 2.486 Prec@(1,5) (48.0%, 78.3%)\u001b[0m\n",
            "[2024-04-02 19:22:03] \u001b[32mValid: [ 14/50] Step 104/104 Loss 2.485 Prec@(1,5) (48.1%, 78.4%)\u001b[0m\n",
            "[2024-04-02 19:22:03] \u001b[32mValid: [ 14/50] Final Prec@1 48.0700%\u001b[0m\n",
            "[2024-04-02 19:22:03] \u001b[32mEpoch 14 LR 0.020468\u001b[0m\n",
            "[2024-04-02 19:22:08] \u001b[32mTrain: [ 15/50] Step 000/520 Loss 2.364 Prec@(1,5) (53.1%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:22:09] \u001b[32mTrain: [ 15/50] Step 020/520 Loss 2.500 Prec@(1,5) (50.1%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:22:09] \u001b[32mTrain: [ 15/50] Step 040/520 Loss 2.475 Prec@(1,5) (51.0%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:22:10] \u001b[32mTrain: [ 15/50] Step 060/520 Loss 2.464 Prec@(1,5) (51.7%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:22:10] \u001b[32mTrain: [ 15/50] Step 080/520 Loss 2.481 Prec@(1,5) (51.3%, 80.7%)\u001b[0m\n",
            "[2024-04-02 19:22:11] \u001b[32mTrain: [ 15/50] Step 100/520 Loss 2.480 Prec@(1,5) (51.0%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:22:11] \u001b[32mTrain: [ 15/50] Step 120/520 Loss 2.472 Prec@(1,5) (51.1%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:22:12] \u001b[32mTrain: [ 15/50] Step 140/520 Loss 2.476 Prec@(1,5) (51.0%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:22:12] \u001b[32mTrain: [ 15/50] Step 160/520 Loss 2.467 Prec@(1,5) (51.2%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:22:13] \u001b[32mTrain: [ 15/50] Step 180/520 Loss 2.479 Prec@(1,5) (50.9%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:22:13] \u001b[32mTrain: [ 15/50] Step 200/520 Loss 2.487 Prec@(1,5) (50.9%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:22:13] \u001b[32mTrain: [ 15/50] Step 220/520 Loss 2.486 Prec@(1,5) (51.0%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:22:14] \u001b[32mTrain: [ 15/50] Step 240/520 Loss 2.495 Prec@(1,5) (50.8%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:22:14] \u001b[32mTrain: [ 15/50] Step 260/520 Loss 2.500 Prec@(1,5) (50.7%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:22:15] \u001b[32mTrain: [ 15/50] Step 280/520 Loss 2.503 Prec@(1,5) (50.5%, 80.8%)\u001b[0m\n",
            "[2024-04-02 19:22:15] \u001b[32mTrain: [ 15/50] Step 300/520 Loss 2.509 Prec@(1,5) (50.5%, 80.8%)\u001b[0m\n",
            "[2024-04-02 19:22:16] \u001b[32mTrain: [ 15/50] Step 320/520 Loss 2.509 Prec@(1,5) (50.5%, 80.8%)\u001b[0m\n",
            "[2024-04-02 19:22:16] \u001b[32mTrain: [ 15/50] Step 340/520 Loss 2.514 Prec@(1,5) (50.5%, 80.7%)\u001b[0m\n",
            "[2024-04-02 19:22:17] \u001b[32mTrain: [ 15/50] Step 360/520 Loss 2.516 Prec@(1,5) (50.4%, 80.7%)\u001b[0m\n",
            "[2024-04-02 19:22:17] \u001b[32mTrain: [ 15/50] Step 380/520 Loss 2.512 Prec@(1,5) (50.5%, 80.7%)\u001b[0m\n",
            "[2024-04-02 19:22:18] \u001b[32mTrain: [ 15/50] Step 400/520 Loss 2.512 Prec@(1,5) (50.6%, 80.7%)\u001b[0m\n",
            "[2024-04-02 19:22:18] \u001b[32mTrain: [ 15/50] Step 420/520 Loss 2.513 Prec@(1,5) (50.6%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:22:19] \u001b[32mTrain: [ 15/50] Step 440/520 Loss 2.517 Prec@(1,5) (50.5%, 80.5%)\u001b[0m\n",
            "[2024-04-02 19:22:19] \u001b[32mTrain: [ 15/50] Step 460/520 Loss 2.518 Prec@(1,5) (50.4%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:22:20] \u001b[32mTrain: [ 15/50] Step 480/520 Loss 2.520 Prec@(1,5) (50.4%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:22:20] \u001b[32mTrain: [ 15/50] Step 500/520 Loss 2.520 Prec@(1,5) (50.3%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:22:21] \u001b[32mTrain: [ 15/50] Step 520/520 Loss 2.522 Prec@(1,5) (50.3%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:22:21] \u001b[32mTrain: [ 15/50] Final Prec@1 50.2960%\u001b[0m\n",
            "[2024-04-02 19:22:24] \u001b[32mValid: [ 15/50] Step 000/104 Loss 2.576 Prec@(1,5) (49.0%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:22:25] \u001b[32mValid: [ 15/50] Step 020/104 Loss 2.800 Prec@(1,5) (45.9%, 76.4%)\u001b[0m\n",
            "[2024-04-02 19:22:25] \u001b[32mValid: [ 15/50] Step 040/104 Loss 2.727 Prec@(1,5) (46.3%, 77.0%)\u001b[0m\n",
            "[2024-04-02 19:22:25] \u001b[32mValid: [ 15/50] Step 060/104 Loss 2.688 Prec@(1,5) (46.8%, 77.4%)\u001b[0m\n",
            "[2024-04-02 19:22:25] \u001b[32mValid: [ 15/50] Step 080/104 Loss 2.707 Prec@(1,5) (46.3%, 77.1%)\u001b[0m\n",
            "[2024-04-02 19:22:25] \u001b[32mValid: [ 15/50] Step 100/104 Loss 2.700 Prec@(1,5) (46.4%, 77.2%)\u001b[0m\n",
            "[2024-04-02 19:22:25] \u001b[32mValid: [ 15/50] Step 104/104 Loss 2.699 Prec@(1,5) (46.3%, 77.2%)\u001b[0m\n",
            "[2024-04-02 19:22:26] \u001b[32mValid: [ 15/50] Final Prec@1 46.3400%\u001b[0m\n",
            "[2024-04-02 19:22:26] \u001b[32mEpoch 15 LR 0.019848\u001b[0m\n",
            "[2024-04-02 19:22:30] \u001b[32mTrain: [ 16/50] Step 000/520 Loss 2.289 Prec@(1,5) (58.3%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:22:31] \u001b[32mTrain: [ 16/50] Step 020/520 Loss 2.370 Prec@(1,5) (51.9%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:22:31] \u001b[32mTrain: [ 16/50] Step 040/520 Loss 2.396 Prec@(1,5) (52.6%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:22:32] \u001b[32mTrain: [ 16/50] Step 060/520 Loss 2.446 Prec@(1,5) (52.0%, 81.3%)\u001b[0m\n",
            "[2024-04-02 19:22:32] \u001b[32mTrain: [ 16/50] Step 080/520 Loss 2.452 Prec@(1,5) (51.8%, 81.5%)\u001b[0m\n",
            "[2024-04-02 19:22:33] \u001b[32mTrain: [ 16/50] Step 100/520 Loss 2.461 Prec@(1,5) (51.6%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:22:33] \u001b[32mTrain: [ 16/50] Step 120/520 Loss 2.458 Prec@(1,5) (51.6%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:22:34] \u001b[32mTrain: [ 16/50] Step 140/520 Loss 2.453 Prec@(1,5) (51.6%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:22:34] \u001b[32mTrain: [ 16/50] Step 160/520 Loss 2.458 Prec@(1,5) (51.6%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:22:35] \u001b[32mTrain: [ 16/50] Step 180/520 Loss 2.461 Prec@(1,5) (51.5%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:22:35] \u001b[32mTrain: [ 16/50] Step 200/520 Loss 2.455 Prec@(1,5) (51.6%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:22:36] \u001b[32mTrain: [ 16/50] Step 220/520 Loss 2.449 Prec@(1,5) (51.8%, 81.3%)\u001b[0m\n",
            "[2024-04-02 19:22:36] \u001b[32mTrain: [ 16/50] Step 240/520 Loss 2.447 Prec@(1,5) (51.8%, 81.3%)\u001b[0m\n",
            "[2024-04-02 19:22:37] \u001b[32mTrain: [ 16/50] Step 260/520 Loss 2.448 Prec@(1,5) (51.8%, 81.3%)\u001b[0m\n",
            "[2024-04-02 19:22:37] \u001b[32mTrain: [ 16/50] Step 280/520 Loss 2.456 Prec@(1,5) (51.7%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:22:38] \u001b[32mTrain: [ 16/50] Step 300/520 Loss 2.460 Prec@(1,5) (51.7%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:22:38] \u001b[32mTrain: [ 16/50] Step 320/520 Loss 2.462 Prec@(1,5) (51.7%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:22:39] \u001b[32mTrain: [ 16/50] Step 340/520 Loss 2.462 Prec@(1,5) (51.6%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:22:39] \u001b[32mTrain: [ 16/50] Step 360/520 Loss 2.466 Prec@(1,5) (51.6%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:22:40] \u001b[32mTrain: [ 16/50] Step 380/520 Loss 2.467 Prec@(1,5) (51.5%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:22:40] \u001b[32mTrain: [ 16/50] Step 400/520 Loss 2.468 Prec@(1,5) (51.6%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:22:41] \u001b[32mTrain: [ 16/50] Step 420/520 Loss 2.469 Prec@(1,5) (51.6%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:22:41] \u001b[32mTrain: [ 16/50] Step 440/520 Loss 2.474 Prec@(1,5) (51.5%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:22:42] \u001b[32mTrain: [ 16/50] Step 460/520 Loss 2.481 Prec@(1,5) (51.4%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:22:42] \u001b[32mTrain: [ 16/50] Step 480/520 Loss 2.483 Prec@(1,5) (51.3%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:22:43] \u001b[32mTrain: [ 16/50] Step 500/520 Loss 2.481 Prec@(1,5) (51.3%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:22:43] \u001b[32mTrain: [ 16/50] Step 520/520 Loss 2.478 Prec@(1,5) (51.3%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:22:43] \u001b[32mTrain: [ 16/50] Final Prec@1 51.3460%\u001b[0m\n",
            "[2024-04-02 19:22:47] \u001b[32mValid: [ 16/50] Step 000/104 Loss 2.419 Prec@(1,5) (53.1%, 80.2%)\u001b[0m\n",
            "[2024-04-02 19:22:47] \u001b[32mValid: [ 16/50] Step 020/104 Loss 2.440 Prec@(1,5) (48.9%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:22:47] \u001b[32mValid: [ 16/50] Step 040/104 Loss 2.438 Prec@(1,5) (48.4%, 79.3%)\u001b[0m\n",
            "[2024-04-02 19:22:47] \u001b[32mValid: [ 16/50] Step 060/104 Loss 2.408 Prec@(1,5) (48.9%, 79.5%)\u001b[0m\n",
            "[2024-04-02 19:22:48] \u001b[32mValid: [ 16/50] Step 080/104 Loss 2.433 Prec@(1,5) (48.6%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:22:48] \u001b[32mValid: [ 16/50] Step 100/104 Loss 2.423 Prec@(1,5) (48.8%, 79.4%)\u001b[0m\n",
            "[2024-04-02 19:22:48] \u001b[32mValid: [ 16/50] Step 104/104 Loss 2.423 Prec@(1,5) (48.8%, 79.4%)\u001b[0m\n",
            "[2024-04-02 19:22:48] \u001b[32mValid: [ 16/50] Final Prec@1 48.7900%\u001b[0m\n",
            "[2024-04-02 19:22:48] \u001b[32mEpoch 16 LR 0.019198\u001b[0m\n",
            "[2024-04-02 19:22:53] \u001b[32mTrain: [ 17/50] Step 000/520 Loss 2.608 Prec@(1,5) (49.0%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:22:53] \u001b[32mTrain: [ 17/50] Step 020/520 Loss 2.515 Prec@(1,5) (52.0%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:22:54] \u001b[32mTrain: [ 17/50] Step 040/520 Loss 2.446 Prec@(1,5) (52.8%, 81.4%)\u001b[0m\n",
            "[2024-04-02 19:22:54] \u001b[32mTrain: [ 17/50] Step 060/520 Loss 2.432 Prec@(1,5) (52.3%, 81.5%)\u001b[0m\n",
            "[2024-04-02 19:22:55] \u001b[32mTrain: [ 17/50] Step 080/520 Loss 2.415 Prec@(1,5) (52.6%, 81.6%)\u001b[0m\n",
            "[2024-04-02 19:22:55] \u001b[32mTrain: [ 17/50] Step 100/520 Loss 2.427 Prec@(1,5) (52.2%, 81.6%)\u001b[0m\n",
            "[2024-04-02 19:22:56] \u001b[32mTrain: [ 17/50] Step 120/520 Loss 2.416 Prec@(1,5) (52.6%, 81.8%)\u001b[0m\n",
            "[2024-04-02 19:22:56] \u001b[32mTrain: [ 17/50] Step 140/520 Loss 2.419 Prec@(1,5) (52.5%, 81.6%)\u001b[0m\n",
            "[2024-04-02 19:22:57] \u001b[32mTrain: [ 17/50] Step 160/520 Loss 2.414 Prec@(1,5) (52.5%, 81.8%)\u001b[0m\n",
            "[2024-04-02 19:22:57] \u001b[32mTrain: [ 17/50] Step 180/520 Loss 2.421 Prec@(1,5) (52.4%, 81.6%)\u001b[0m\n",
            "[2024-04-02 19:22:58] \u001b[32mTrain: [ 17/50] Step 200/520 Loss 2.417 Prec@(1,5) (52.4%, 81.6%)\u001b[0m\n",
            "[2024-04-02 19:22:58] \u001b[32mTrain: [ 17/50] Step 220/520 Loss 2.407 Prec@(1,5) (52.5%, 81.7%)\u001b[0m\n",
            "[2024-04-02 19:22:59] \u001b[32mTrain: [ 17/50] Step 240/520 Loss 2.411 Prec@(1,5) (52.5%, 81.6%)\u001b[0m\n",
            "[2024-04-02 19:22:59] \u001b[32mTrain: [ 17/50] Step 260/520 Loss 2.415 Prec@(1,5) (52.4%, 81.6%)\u001b[0m\n",
            "[2024-04-02 19:23:00] \u001b[32mTrain: [ 17/50] Step 280/520 Loss 2.419 Prec@(1,5) (52.3%, 81.6%)\u001b[0m\n",
            "[2024-04-02 19:23:00] \u001b[32mTrain: [ 17/50] Step 300/520 Loss 2.422 Prec@(1,5) (52.2%, 81.5%)\u001b[0m\n",
            "[2024-04-02 19:23:01] \u001b[32mTrain: [ 17/50] Step 320/520 Loss 2.423 Prec@(1,5) (52.2%, 81.6%)\u001b[0m\n",
            "[2024-04-02 19:23:01] \u001b[32mTrain: [ 17/50] Step 340/520 Loss 2.423 Prec@(1,5) (52.1%, 81.6%)\u001b[0m\n",
            "[2024-04-02 19:23:02] \u001b[32mTrain: [ 17/50] Step 360/520 Loss 2.430 Prec@(1,5) (52.0%, 81.5%)\u001b[0m\n",
            "[2024-04-02 19:23:02] \u001b[32mTrain: [ 17/50] Step 380/520 Loss 2.425 Prec@(1,5) (52.1%, 81.6%)\u001b[0m\n",
            "[2024-04-02 19:23:03] \u001b[32mTrain: [ 17/50] Step 400/520 Loss 2.425 Prec@(1,5) (52.1%, 81.6%)\u001b[0m\n",
            "[2024-04-02 19:23:03] \u001b[32mTrain: [ 17/50] Step 420/520 Loss 2.427 Prec@(1,5) (52.0%, 81.6%)\u001b[0m\n",
            "[2024-04-02 19:23:04] \u001b[32mTrain: [ 17/50] Step 440/520 Loss 2.428 Prec@(1,5) (52.1%, 81.6%)\u001b[0m\n",
            "[2024-04-02 19:23:04] \u001b[32mTrain: [ 17/50] Step 460/520 Loss 2.429 Prec@(1,5) (52.0%, 81.6%)\u001b[0m\n",
            "[2024-04-02 19:23:05] \u001b[32mTrain: [ 17/50] Step 480/520 Loss 2.431 Prec@(1,5) (52.1%, 81.5%)\u001b[0m\n",
            "[2024-04-02 19:23:05] \u001b[32mTrain: [ 17/50] Step 500/520 Loss 2.433 Prec@(1,5) (52.0%, 81.5%)\u001b[0m\n",
            "[2024-04-02 19:23:06] \u001b[32mTrain: [ 17/50] Step 520/520 Loss 2.437 Prec@(1,5) (51.9%, 81.5%)\u001b[0m\n",
            "[2024-04-02 19:23:06] \u001b[32mTrain: [ 17/50] Final Prec@1 51.9300%\u001b[0m\n",
            "[2024-04-02 19:23:09] \u001b[32mValid: [ 17/50] Step 000/104 Loss 2.234 Prec@(1,5) (60.4%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:23:10] \u001b[32mValid: [ 17/50] Step 020/104 Loss 2.343 Prec@(1,5) (50.9%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:23:10] \u001b[32mValid: [ 17/50] Step 040/104 Loss 2.354 Prec@(1,5) (49.8%, 80.3%)\u001b[0m\n",
            "[2024-04-02 19:23:10] \u001b[32mValid: [ 17/50] Step 060/104 Loss 2.333 Prec@(1,5) (50.3%, 80.5%)\u001b[0m\n",
            "[2024-04-02 19:23:10] \u001b[32mValid: [ 17/50] Step 080/104 Loss 2.350 Prec@(1,5) (50.1%, 80.3%)\u001b[0m\n",
            "[2024-04-02 19:23:10] \u001b[32mValid: [ 17/50] Step 100/104 Loss 2.329 Prec@(1,5) (50.3%, 80.5%)\u001b[0m\n",
            "[2024-04-02 19:23:10] \u001b[32mValid: [ 17/50] Step 104/104 Loss 2.326 Prec@(1,5) (50.3%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:23:11] \u001b[32mValid: [ 17/50] Final Prec@1 50.3000%\u001b[0m\n",
            "[2024-04-02 19:23:11] \u001b[32mEpoch 17 LR 0.018522\u001b[0m\n",
            "[2024-04-02 19:23:15] \u001b[32mTrain: [ 18/50] Step 000/520 Loss 2.400 Prec@(1,5) (55.2%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:23:16] \u001b[32mTrain: [ 18/50] Step 020/520 Loss 2.335 Prec@(1,5) (54.6%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:23:16] \u001b[32mTrain: [ 18/50] Step 040/520 Loss 2.301 Prec@(1,5) (55.3%, 82.7%)\u001b[0m\n",
            "[2024-04-02 19:23:17] \u001b[32mTrain: [ 18/50] Step 060/520 Loss 2.341 Prec@(1,5) (54.3%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:23:17] \u001b[32mTrain: [ 18/50] Step 080/520 Loss 2.335 Prec@(1,5) (54.1%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:23:18] \u001b[32mTrain: [ 18/50] Step 100/520 Loss 2.346 Prec@(1,5) (53.7%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:23:18] \u001b[32mTrain: [ 18/50] Step 120/520 Loss 2.357 Prec@(1,5) (53.7%, 82.2%)\u001b[0m\n",
            "[2024-04-02 19:23:19] \u001b[32mTrain: [ 18/50] Step 140/520 Loss 2.357 Prec@(1,5) (53.7%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:23:19] \u001b[32mTrain: [ 18/50] Step 160/520 Loss 2.366 Prec@(1,5) (53.4%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:23:20] \u001b[32mTrain: [ 18/50] Step 180/520 Loss 2.378 Prec@(1,5) (53.1%, 82.2%)\u001b[0m\n",
            "[2024-04-02 19:23:20] \u001b[32mTrain: [ 18/50] Step 200/520 Loss 2.383 Prec@(1,5) (53.0%, 82.1%)\u001b[0m\n",
            "[2024-04-02 19:23:21] \u001b[32mTrain: [ 18/50] Step 220/520 Loss 2.382 Prec@(1,5) (53.0%, 82.2%)\u001b[0m\n",
            "[2024-04-02 19:23:21] \u001b[32mTrain: [ 18/50] Step 240/520 Loss 2.382 Prec@(1,5) (52.9%, 82.2%)\u001b[0m\n",
            "[2024-04-02 19:23:22] \u001b[32mTrain: [ 18/50] Step 260/520 Loss 2.380 Prec@(1,5) (53.0%, 82.2%)\u001b[0m\n",
            "[2024-04-02 19:23:22] \u001b[32mTrain: [ 18/50] Step 280/520 Loss 2.377 Prec@(1,5) (53.0%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:23:23] \u001b[32mTrain: [ 18/50] Step 300/520 Loss 2.386 Prec@(1,5) (52.9%, 82.1%)\u001b[0m\n",
            "[2024-04-02 19:23:23] \u001b[32mTrain: [ 18/50] Step 320/520 Loss 2.386 Prec@(1,5) (52.8%, 82.1%)\u001b[0m\n",
            "[2024-04-02 19:23:24] \u001b[32mTrain: [ 18/50] Step 340/520 Loss 2.391 Prec@(1,5) (52.7%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:23:24] \u001b[32mTrain: [ 18/50] Step 360/520 Loss 2.393 Prec@(1,5) (52.7%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:23:25] \u001b[32mTrain: [ 18/50] Step 380/520 Loss 2.390 Prec@(1,5) (52.8%, 82.1%)\u001b[0m\n",
            "[2024-04-02 19:23:25] \u001b[32mTrain: [ 18/50] Step 400/520 Loss 2.394 Prec@(1,5) (52.7%, 82.1%)\u001b[0m\n",
            "[2024-04-02 19:23:26] \u001b[32mTrain: [ 18/50] Step 420/520 Loss 2.393 Prec@(1,5) (52.7%, 82.1%)\u001b[0m\n",
            "[2024-04-02 19:23:26] \u001b[32mTrain: [ 18/50] Step 440/520 Loss 2.397 Prec@(1,5) (52.7%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:23:27] \u001b[32mTrain: [ 18/50] Step 460/520 Loss 2.399 Prec@(1,5) (52.7%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:23:27] \u001b[32mTrain: [ 18/50] Step 480/520 Loss 2.400 Prec@(1,5) (52.7%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:23:28] \u001b[32mTrain: [ 18/50] Step 500/520 Loss 2.400 Prec@(1,5) (52.7%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:23:28] \u001b[32mTrain: [ 18/50] Step 520/520 Loss 2.397 Prec@(1,5) (52.7%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:23:29] \u001b[32mTrain: [ 18/50] Final Prec@1 52.6940%\u001b[0m\n",
            "[2024-04-02 19:23:32] \u001b[32mValid: [ 18/50] Step 000/104 Loss 2.316 Prec@(1,5) (53.1%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:23:32] \u001b[32mValid: [ 18/50] Step 020/104 Loss 2.528 Prec@(1,5) (49.2%, 79.7%)\u001b[0m\n",
            "[2024-04-02 19:23:32] \u001b[32mValid: [ 18/50] Step 040/104 Loss 2.521 Prec@(1,5) (49.6%, 79.4%)\u001b[0m\n",
            "[2024-04-02 19:23:33] \u001b[32mValid: [ 18/50] Step 060/104 Loss 2.496 Prec@(1,5) (49.9%, 79.4%)\u001b[0m\n",
            "[2024-04-02 19:23:33] \u001b[32mValid: [ 18/50] Step 080/104 Loss 2.506 Prec@(1,5) (49.6%, 79.6%)\u001b[0m\n",
            "[2024-04-02 19:23:33] \u001b[32mValid: [ 18/50] Step 100/104 Loss 2.490 Prec@(1,5) (49.5%, 79.7%)\u001b[0m\n",
            "[2024-04-02 19:23:33] \u001b[32mValid: [ 18/50] Step 104/104 Loss 2.491 Prec@(1,5) (49.4%, 79.7%)\u001b[0m\n",
            "[2024-04-02 19:23:33] \u001b[32mValid: [ 18/50] Final Prec@1 49.4300%\u001b[0m\n",
            "[2024-04-02 19:23:33] \u001b[32mEpoch 18 LR 0.017823\u001b[0m\n",
            "[2024-04-02 19:23:38] \u001b[32mTrain: [ 19/50] Step 000/520 Loss 2.034 Prec@(1,5) (58.3%, 90.6%)\u001b[0m\n",
            "[2024-04-02 19:23:38] \u001b[32mTrain: [ 19/50] Step 020/520 Loss 2.292 Prec@(1,5) (53.8%, 83.4%)\u001b[0m\n",
            "[2024-04-02 19:23:39] \u001b[32mTrain: [ 19/50] Step 040/520 Loss 2.324 Prec@(1,5) (53.4%, 82.8%)\u001b[0m\n",
            "[2024-04-02 19:23:39] \u001b[32mTrain: [ 19/50] Step 060/520 Loss 2.350 Prec@(1,5) (53.2%, 82.5%)\u001b[0m\n",
            "[2024-04-02 19:23:40] \u001b[32mTrain: [ 19/50] Step 080/520 Loss 2.314 Prec@(1,5) (53.6%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:23:40] \u001b[32mTrain: [ 19/50] Step 100/520 Loss 2.325 Prec@(1,5) (53.8%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:23:41] \u001b[32mTrain: [ 19/50] Step 120/520 Loss 2.340 Prec@(1,5) (53.5%, 82.8%)\u001b[0m\n",
            "[2024-04-02 19:23:41] \u001b[32mTrain: [ 19/50] Step 140/520 Loss 2.339 Prec@(1,5) (53.6%, 82.8%)\u001b[0m\n",
            "[2024-04-02 19:23:42] \u001b[32mTrain: [ 19/50] Step 160/520 Loss 2.344 Prec@(1,5) (53.6%, 82.7%)\u001b[0m\n",
            "[2024-04-02 19:23:42] \u001b[32mTrain: [ 19/50] Step 180/520 Loss 2.345 Prec@(1,5) (53.6%, 82.6%)\u001b[0m\n",
            "[2024-04-02 19:23:43] \u001b[32mTrain: [ 19/50] Step 200/520 Loss 2.341 Prec@(1,5) (53.6%, 82.7%)\u001b[0m\n",
            "[2024-04-02 19:23:43] \u001b[32mTrain: [ 19/50] Step 220/520 Loss 2.345 Prec@(1,5) (53.5%, 82.7%)\u001b[0m\n",
            "[2024-04-02 19:23:44] \u001b[32mTrain: [ 19/50] Step 240/520 Loss 2.344 Prec@(1,5) (53.5%, 82.7%)\u001b[0m\n",
            "[2024-04-02 19:23:44] \u001b[32mTrain: [ 19/50] Step 260/520 Loss 2.350 Prec@(1,5) (53.3%, 82.6%)\u001b[0m\n",
            "[2024-04-02 19:23:45] \u001b[32mTrain: [ 19/50] Step 280/520 Loss 2.353 Prec@(1,5) (53.3%, 82.5%)\u001b[0m\n",
            "[2024-04-02 19:23:45] \u001b[32mTrain: [ 19/50] Step 300/520 Loss 2.356 Prec@(1,5) (53.2%, 82.5%)\u001b[0m\n",
            "[2024-04-02 19:23:46] \u001b[32mTrain: [ 19/50] Step 320/520 Loss 2.359 Prec@(1,5) (53.1%, 82.5%)\u001b[0m\n",
            "[2024-04-02 19:23:46] \u001b[32mTrain: [ 19/50] Step 340/520 Loss 2.363 Prec@(1,5) (53.0%, 82.5%)\u001b[0m\n",
            "[2024-04-02 19:23:47] \u001b[32mTrain: [ 19/50] Step 360/520 Loss 2.365 Prec@(1,5) (53.0%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:23:47] \u001b[32mTrain: [ 19/50] Step 380/520 Loss 2.360 Prec@(1,5) (53.1%, 82.5%)\u001b[0m\n",
            "[2024-04-02 19:23:48] \u001b[32mTrain: [ 19/50] Step 400/520 Loss 2.356 Prec@(1,5) (53.1%, 82.6%)\u001b[0m\n",
            "[2024-04-02 19:23:48] \u001b[32mTrain: [ 19/50] Step 420/520 Loss 2.357 Prec@(1,5) (53.2%, 82.5%)\u001b[0m\n",
            "[2024-04-02 19:23:49] \u001b[32mTrain: [ 19/50] Step 440/520 Loss 2.357 Prec@(1,5) (53.2%, 82.6%)\u001b[0m\n",
            "[2024-04-02 19:23:49] \u001b[32mTrain: [ 19/50] Step 460/520 Loss 2.357 Prec@(1,5) (53.3%, 82.5%)\u001b[0m\n",
            "[2024-04-02 19:23:50] \u001b[32mTrain: [ 19/50] Step 480/520 Loss 2.355 Prec@(1,5) (53.3%, 82.6%)\u001b[0m\n",
            "[2024-04-02 19:23:50] \u001b[32mTrain: [ 19/50] Step 500/520 Loss 2.354 Prec@(1,5) (53.3%, 82.6%)\u001b[0m\n",
            "[2024-04-02 19:23:51] \u001b[32mTrain: [ 19/50] Step 520/520 Loss 2.353 Prec@(1,5) (53.4%, 82.6%)\u001b[0m\n",
            "[2024-04-02 19:23:51] \u001b[32mTrain: [ 19/50] Final Prec@1 53.4020%\u001b[0m\n",
            "[2024-04-02 19:23:54] \u001b[32mValid: [ 19/50] Step 000/104 Loss 2.349 Prec@(1,5) (56.2%, 77.1%)\u001b[0m\n",
            "[2024-04-02 19:23:55] \u001b[32mValid: [ 19/50] Step 020/104 Loss 2.553 Prec@(1,5) (49.1%, 80.0%)\u001b[0m\n",
            "[2024-04-02 19:23:55] \u001b[32mValid: [ 19/50] Step 040/104 Loss 2.488 Prec@(1,5) (48.9%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:23:55] \u001b[32mValid: [ 19/50] Step 060/104 Loss 2.459 Prec@(1,5) (49.3%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:23:55] \u001b[32mValid: [ 19/50] Step 080/104 Loss 2.475 Prec@(1,5) (48.8%, 79.9%)\u001b[0m\n",
            "[2024-04-02 19:23:55] \u001b[32mValid: [ 19/50] Step 100/104 Loss 2.456 Prec@(1,5) (49.2%, 80.0%)\u001b[0m\n",
            "[2024-04-02 19:23:55] \u001b[32mValid: [ 19/50] Step 104/104 Loss 2.458 Prec@(1,5) (49.1%, 79.9%)\u001b[0m\n",
            "[2024-04-02 19:23:55] \u001b[32mValid: [ 19/50] Final Prec@1 49.0900%\u001b[0m\n",
            "[2024-04-02 19:23:55] \u001b[32mEpoch 19 LR 0.017102\u001b[0m\n",
            "[2024-04-02 19:24:00] \u001b[32mTrain: [ 20/50] Step 000/520 Loss 2.403 Prec@(1,5) (54.2%, 80.2%)\u001b[0m\n",
            "[2024-04-02 19:24:01] \u001b[32mTrain: [ 20/50] Step 020/520 Loss 2.240 Prec@(1,5) (54.3%, 84.1%)\u001b[0m\n",
            "[2024-04-02 19:24:01] \u001b[32mTrain: [ 20/50] Step 040/520 Loss 2.330 Prec@(1,5) (53.3%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:24:01] \u001b[32mTrain: [ 20/50] Step 060/520 Loss 2.303 Prec@(1,5) (54.2%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:24:02] \u001b[32mTrain: [ 20/50] Step 080/520 Loss 2.312 Prec@(1,5) (53.9%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:24:02] \u001b[32mTrain: [ 20/50] Step 100/520 Loss 2.305 Prec@(1,5) (54.1%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:24:03] \u001b[32mTrain: [ 20/50] Step 120/520 Loss 2.301 Prec@(1,5) (54.3%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:24:03] \u001b[32mTrain: [ 20/50] Step 140/520 Loss 2.301 Prec@(1,5) (54.2%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:24:04] \u001b[32mTrain: [ 20/50] Step 160/520 Loss 2.304 Prec@(1,5) (54.1%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:24:04] \u001b[32mTrain: [ 20/50] Step 180/520 Loss 2.304 Prec@(1,5) (54.2%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:24:05] \u001b[32mTrain: [ 20/50] Step 200/520 Loss 2.307 Prec@(1,5) (54.3%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:24:05] \u001b[32mTrain: [ 20/50] Step 220/520 Loss 2.312 Prec@(1,5) (54.2%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:24:06] \u001b[32mTrain: [ 20/50] Step 240/520 Loss 2.310 Prec@(1,5) (54.2%, 82.9%)\u001b[0m\n",
            "[2024-04-02 19:24:06] \u001b[32mTrain: [ 20/50] Step 260/520 Loss 2.311 Prec@(1,5) (54.3%, 82.9%)\u001b[0m\n",
            "[2024-04-02 19:24:07] \u001b[32mTrain: [ 20/50] Step 280/520 Loss 2.314 Prec@(1,5) (54.2%, 82.9%)\u001b[0m\n",
            "[2024-04-02 19:24:07] \u001b[32mTrain: [ 20/50] Step 300/520 Loss 2.314 Prec@(1,5) (54.1%, 82.9%)\u001b[0m\n",
            "[2024-04-02 19:24:08] \u001b[32mTrain: [ 20/50] Step 320/520 Loss 2.319 Prec@(1,5) (54.0%, 82.9%)\u001b[0m\n",
            "[2024-04-02 19:24:08] \u001b[32mTrain: [ 20/50] Step 340/520 Loss 2.321 Prec@(1,5) (54.0%, 82.9%)\u001b[0m\n",
            "[2024-04-02 19:24:09] \u001b[32mTrain: [ 20/50] Step 360/520 Loss 2.318 Prec@(1,5) (54.1%, 82.9%)\u001b[0m\n",
            "[2024-04-02 19:24:09] \u001b[32mTrain: [ 20/50] Step 380/520 Loss 2.318 Prec@(1,5) (54.1%, 82.9%)\u001b[0m\n",
            "[2024-04-02 19:24:10] \u001b[32mTrain: [ 20/50] Step 400/520 Loss 2.320 Prec@(1,5) (54.1%, 82.9%)\u001b[0m\n",
            "[2024-04-02 19:24:10] \u001b[32mTrain: [ 20/50] Step 420/520 Loss 2.320 Prec@(1,5) (54.0%, 82.8%)\u001b[0m\n",
            "[2024-04-02 19:24:11] \u001b[32mTrain: [ 20/50] Step 440/520 Loss 2.322 Prec@(1,5) (54.0%, 82.8%)\u001b[0m\n",
            "[2024-04-02 19:24:11] \u001b[32mTrain: [ 20/50] Step 460/520 Loss 2.325 Prec@(1,5) (54.0%, 82.8%)\u001b[0m\n",
            "[2024-04-02 19:24:12] \u001b[32mTrain: [ 20/50] Step 480/520 Loss 2.326 Prec@(1,5) (54.0%, 82.8%)\u001b[0m\n",
            "[2024-04-02 19:24:12] \u001b[32mTrain: [ 20/50] Step 500/520 Loss 2.323 Prec@(1,5) (54.0%, 82.8%)\u001b[0m\n",
            "[2024-04-02 19:24:13] \u001b[32mTrain: [ 20/50] Step 520/520 Loss 2.325 Prec@(1,5) (54.0%, 82.8%)\u001b[0m\n",
            "[2024-04-02 19:24:13] \u001b[32mTrain: [ 20/50] Final Prec@1 54.0300%\u001b[0m\n",
            "[2024-04-02 19:24:17] \u001b[32mValid: [ 20/50] Step 000/104 Loss 2.291 Prec@(1,5) (58.3%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:24:17] \u001b[32mValid: [ 20/50] Step 020/104 Loss 2.342 Prec@(1,5) (50.8%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:24:17] \u001b[32mValid: [ 20/50] Step 040/104 Loss 2.299 Prec@(1,5) (51.0%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:24:17] \u001b[32mValid: [ 20/50] Step 060/104 Loss 2.275 Prec@(1,5) (51.3%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:24:17] \u001b[32mValid: [ 20/50] Step 080/104 Loss 2.288 Prec@(1,5) (50.8%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:24:17] \u001b[32mValid: [ 20/50] Step 100/104 Loss 2.293 Prec@(1,5) (50.7%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:24:17] \u001b[32mValid: [ 20/50] Step 104/104 Loss 2.298 Prec@(1,5) (50.6%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:24:18] \u001b[32mValid: [ 20/50] Final Prec@1 50.6300%\u001b[0m\n",
            "[2024-04-02 19:24:18] \u001b[32mEpoch 20 LR 0.016363\u001b[0m\n",
            "[2024-04-02 19:24:22] \u001b[32mTrain: [ 21/50] Step 000/520 Loss 2.321 Prec@(1,5) (50.0%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:24:23] \u001b[32mTrain: [ 21/50] Step 020/520 Loss 2.329 Prec@(1,5) (53.8%, 81.8%)\u001b[0m\n",
            "[2024-04-02 19:24:23] \u001b[32mTrain: [ 21/50] Step 040/520 Loss 2.316 Prec@(1,5) (54.0%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:24:24] \u001b[32mTrain: [ 21/50] Step 060/520 Loss 2.278 Prec@(1,5) (54.6%, 82.9%)\u001b[0m\n",
            "[2024-04-02 19:24:24] \u001b[32mTrain: [ 21/50] Step 080/520 Loss 2.281 Prec@(1,5) (54.7%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:24:25] \u001b[32mTrain: [ 21/50] Step 100/520 Loss 2.285 Prec@(1,5) (54.5%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:24:25] \u001b[32mTrain: [ 21/50] Step 120/520 Loss 2.299 Prec@(1,5) (54.3%, 82.6%)\u001b[0m\n",
            "[2024-04-02 19:24:26] \u001b[32mTrain: [ 21/50] Step 140/520 Loss 2.301 Prec@(1,5) (54.3%, 82.7%)\u001b[0m\n",
            "[2024-04-02 19:24:26] \u001b[32mTrain: [ 21/50] Step 160/520 Loss 2.295 Prec@(1,5) (54.4%, 82.8%)\u001b[0m\n",
            "[2024-04-02 19:24:27] \u001b[32mTrain: [ 21/50] Step 180/520 Loss 2.291 Prec@(1,5) (54.4%, 82.9%)\u001b[0m\n",
            "[2024-04-02 19:24:27] \u001b[32mTrain: [ 21/50] Step 200/520 Loss 2.295 Prec@(1,5) (54.4%, 82.9%)\u001b[0m\n",
            "[2024-04-02 19:24:28] \u001b[32mTrain: [ 21/50] Step 220/520 Loss 2.291 Prec@(1,5) (54.4%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:24:28] \u001b[32mTrain: [ 21/50] Step 240/520 Loss 2.288 Prec@(1,5) (54.5%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:24:29] \u001b[32mTrain: [ 21/50] Step 260/520 Loss 2.292 Prec@(1,5) (54.5%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:24:29] \u001b[32mTrain: [ 21/50] Step 280/520 Loss 2.293 Prec@(1,5) (54.6%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:24:30] \u001b[32mTrain: [ 21/50] Step 300/520 Loss 2.291 Prec@(1,5) (54.6%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:24:30] \u001b[32mTrain: [ 21/50] Step 320/520 Loss 2.297 Prec@(1,5) (54.5%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:24:31] \u001b[32mTrain: [ 21/50] Step 340/520 Loss 2.296 Prec@(1,5) (54.6%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:24:31] \u001b[32mTrain: [ 21/50] Step 360/520 Loss 2.295 Prec@(1,5) (54.6%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:24:32] \u001b[32mTrain: [ 21/50] Step 380/520 Loss 2.296 Prec@(1,5) (54.6%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:24:32] \u001b[32mTrain: [ 21/50] Step 400/520 Loss 2.295 Prec@(1,5) (54.5%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:24:33] \u001b[32mTrain: [ 21/50] Step 420/520 Loss 2.295 Prec@(1,5) (54.5%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:24:33] \u001b[32mTrain: [ 21/50] Step 440/520 Loss 2.297 Prec@(1,5) (54.4%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:24:34] \u001b[32mTrain: [ 21/50] Step 460/520 Loss 2.294 Prec@(1,5) (54.5%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:24:34] \u001b[32mTrain: [ 21/50] Step 480/520 Loss 2.296 Prec@(1,5) (54.4%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:24:35] \u001b[32mTrain: [ 21/50] Step 500/520 Loss 2.295 Prec@(1,5) (54.4%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:24:35] \u001b[32mTrain: [ 21/50] Step 520/520 Loss 2.296 Prec@(1,5) (54.4%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:24:35] \u001b[32mTrain: [ 21/50] Final Prec@1 54.4480%\u001b[0m\n",
            "[2024-04-02 19:24:39] \u001b[32mValid: [ 21/50] Step 000/104 Loss 2.196 Prec@(1,5) (58.3%, 80.2%)\u001b[0m\n",
            "[2024-04-02 19:24:39] \u001b[32mValid: [ 21/50] Step 020/104 Loss 2.490 Prec@(1,5) (51.0%, 80.3%)\u001b[0m\n",
            "[2024-04-02 19:24:39] \u001b[32mValid: [ 21/50] Step 040/104 Loss 2.480 Prec@(1,5) (50.4%, 80.1%)\u001b[0m\n",
            "[2024-04-02 19:24:39] \u001b[32mValid: [ 21/50] Step 060/104 Loss 2.470 Prec@(1,5) (50.7%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:24:40] \u001b[32mValid: [ 21/50] Step 080/104 Loss 2.489 Prec@(1,5) (50.3%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:24:40] \u001b[32mValid: [ 21/50] Step 100/104 Loss 2.467 Prec@(1,5) (50.5%, 80.0%)\u001b[0m\n",
            "[2024-04-02 19:24:40] \u001b[32mValid: [ 21/50] Step 104/104 Loss 2.470 Prec@(1,5) (50.6%, 79.9%)\u001b[0m\n",
            "[2024-04-02 19:24:40] \u001b[32mValid: [ 21/50] Final Prec@1 50.5700%\u001b[0m\n",
            "[2024-04-02 19:24:40] \u001b[32mEpoch 21 LR 0.015609\u001b[0m\n",
            "[2024-04-02 19:24:45] \u001b[32mTrain: [ 22/50] Step 000/520 Loss 2.460 Prec@(1,5) (45.8%, 80.2%)\u001b[0m\n",
            "[2024-04-02 19:24:45] \u001b[32mTrain: [ 22/50] Step 020/520 Loss 2.309 Prec@(1,5) (53.9%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:24:46] \u001b[32mTrain: [ 22/50] Step 040/520 Loss 2.237 Prec@(1,5) (54.9%, 84.3%)\u001b[0m\n",
            "[2024-04-02 19:24:46] \u001b[32mTrain: [ 22/50] Step 060/520 Loss 2.236 Prec@(1,5) (55.7%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:24:47] \u001b[32mTrain: [ 22/50] Step 080/520 Loss 2.231 Prec@(1,5) (55.6%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:24:47] \u001b[32mTrain: [ 22/50] Step 100/520 Loss 2.241 Prec@(1,5) (55.2%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:24:48] \u001b[32mTrain: [ 22/50] Step 120/520 Loss 2.242 Prec@(1,5) (55.2%, 84.1%)\u001b[0m\n",
            "[2024-04-02 19:24:48] \u001b[32mTrain: [ 22/50] Step 140/520 Loss 2.243 Prec@(1,5) (55.5%, 84.1%)\u001b[0m\n",
            "[2024-04-02 19:24:49] \u001b[32mTrain: [ 22/50] Step 160/520 Loss 2.232 Prec@(1,5) (55.7%, 84.1%)\u001b[0m\n",
            "[2024-04-02 19:24:49] \u001b[32mTrain: [ 22/50] Step 180/520 Loss 2.240 Prec@(1,5) (55.5%, 84.0%)\u001b[0m\n",
            "[2024-04-02 19:24:50] \u001b[32mTrain: [ 22/50] Step 200/520 Loss 2.237 Prec@(1,5) (55.6%, 84.0%)\u001b[0m\n",
            "[2024-04-02 19:24:50] \u001b[32mTrain: [ 22/50] Step 220/520 Loss 2.240 Prec@(1,5) (55.5%, 84.0%)\u001b[0m\n",
            "[2024-04-02 19:24:51] \u001b[32mTrain: [ 22/50] Step 240/520 Loss 2.248 Prec@(1,5) (55.5%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:24:51] \u001b[32mTrain: [ 22/50] Step 260/520 Loss 2.250 Prec@(1,5) (55.4%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:24:52] \u001b[32mTrain: [ 22/50] Step 280/520 Loss 2.245 Prec@(1,5) (55.4%, 83.9%)\u001b[0m\n",
            "[2024-04-02 19:24:52] \u001b[32mTrain: [ 22/50] Step 300/520 Loss 2.246 Prec@(1,5) (55.4%, 83.9%)\u001b[0m\n",
            "[2024-04-02 19:24:53] \u001b[32mTrain: [ 22/50] Step 320/520 Loss 2.247 Prec@(1,5) (55.4%, 83.9%)\u001b[0m\n",
            "[2024-04-02 19:24:53] \u001b[32mTrain: [ 22/50] Step 340/520 Loss 2.250 Prec@(1,5) (55.3%, 83.9%)\u001b[0m\n",
            "[2024-04-02 19:24:54] \u001b[32mTrain: [ 22/50] Step 360/520 Loss 2.251 Prec@(1,5) (55.3%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:24:54] \u001b[32mTrain: [ 22/50] Step 380/520 Loss 2.246 Prec@(1,5) (55.4%, 83.9%)\u001b[0m\n",
            "[2024-04-02 19:24:55] \u001b[32mTrain: [ 22/50] Step 400/520 Loss 2.249 Prec@(1,5) (55.3%, 84.0%)\u001b[0m\n",
            "[2024-04-02 19:24:55] \u001b[32mTrain: [ 22/50] Step 420/520 Loss 2.248 Prec@(1,5) (55.3%, 84.0%)\u001b[0m\n",
            "[2024-04-02 19:24:56] \u001b[32mTrain: [ 22/50] Step 440/520 Loss 2.243 Prec@(1,5) (55.4%, 84.0%)\u001b[0m\n",
            "[2024-04-02 19:24:56] \u001b[32mTrain: [ 22/50] Step 460/520 Loss 2.246 Prec@(1,5) (55.4%, 84.0%)\u001b[0m\n",
            "[2024-04-02 19:24:57] \u001b[32mTrain: [ 22/50] Step 480/520 Loss 2.252 Prec@(1,5) (55.2%, 83.9%)\u001b[0m\n",
            "[2024-04-02 19:24:57] \u001b[32mTrain: [ 22/50] Step 500/520 Loss 2.255 Prec@(1,5) (55.1%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:24:58] \u001b[32mTrain: [ 22/50] Step 520/520 Loss 2.257 Prec@(1,5) (55.1%, 83.9%)\u001b[0m\n",
            "[2024-04-02 19:24:58] \u001b[32mTrain: [ 22/50] Final Prec@1 55.1460%\u001b[0m\n",
            "[2024-04-02 19:25:01] \u001b[32mValid: [ 22/50] Step 000/104 Loss 2.325 Prec@(1,5) (53.1%, 77.1%)\u001b[0m\n",
            "[2024-04-02 19:25:01] \u001b[32mValid: [ 22/50] Step 020/104 Loss 2.414 Prec@(1,5) (50.7%, 81.3%)\u001b[0m\n",
            "[2024-04-02 19:25:02] \u001b[32mValid: [ 22/50] Step 040/104 Loss 2.373 Prec@(1,5) (50.7%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:25:02] \u001b[32mValid: [ 22/50] Step 060/104 Loss 2.344 Prec@(1,5) (51.1%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:25:02] \u001b[32mValid: [ 22/50] Step 080/104 Loss 2.344 Prec@(1,5) (51.0%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:25:02] \u001b[32mValid: [ 22/50] Step 100/104 Loss 2.343 Prec@(1,5) (50.9%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:25:02] \u001b[32mValid: [ 22/50] Step 104/104 Loss 2.342 Prec@(1,5) (50.8%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:25:02] \u001b[32mValid: [ 22/50] Final Prec@1 50.8200%\u001b[0m\n",
            "[2024-04-02 19:25:02] \u001b[32mEpoch 22 LR 0.014843\u001b[0m\n",
            "[2024-04-02 19:25:07] \u001b[32mTrain: [ 23/50] Step 000/520 Loss 2.150 Prec@(1,5) (57.3%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:25:08] \u001b[32mTrain: [ 23/50] Step 020/520 Loss 2.194 Prec@(1,5) (56.3%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:25:08] \u001b[32mTrain: [ 23/50] Step 040/520 Loss 2.167 Prec@(1,5) (56.6%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:25:08] \u001b[32mTrain: [ 23/50] Step 060/520 Loss 2.193 Prec@(1,5) (56.2%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:25:09] \u001b[32mTrain: [ 23/50] Step 080/520 Loss 2.192 Prec@(1,5) (56.5%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:25:09] \u001b[32mTrain: [ 23/50] Step 100/520 Loss 2.173 Prec@(1,5) (56.7%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:25:10] \u001b[32mTrain: [ 23/50] Step 120/520 Loss 2.179 Prec@(1,5) (56.4%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:25:10] \u001b[32mTrain: [ 23/50] Step 140/520 Loss 2.188 Prec@(1,5) (56.3%, 84.3%)\u001b[0m\n",
            "[2024-04-02 19:25:11] \u001b[32mTrain: [ 23/50] Step 160/520 Loss 2.201 Prec@(1,5) (56.2%, 84.2%)\u001b[0m\n",
            "[2024-04-02 19:25:11] \u001b[32mTrain: [ 23/50] Step 180/520 Loss 2.196 Prec@(1,5) (56.3%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:25:12] \u001b[32mTrain: [ 23/50] Step 200/520 Loss 2.205 Prec@(1,5) (56.0%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:25:12] \u001b[32mTrain: [ 23/50] Step 220/520 Loss 2.202 Prec@(1,5) (56.0%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:25:13] \u001b[32mTrain: [ 23/50] Step 240/520 Loss 2.210 Prec@(1,5) (55.9%, 84.3%)\u001b[0m\n",
            "[2024-04-02 19:25:13] \u001b[32mTrain: [ 23/50] Step 260/520 Loss 2.213 Prec@(1,5) (55.9%, 84.3%)\u001b[0m\n",
            "[2024-04-02 19:25:14] \u001b[32mTrain: [ 23/50] Step 280/520 Loss 2.212 Prec@(1,5) (56.0%, 84.3%)\u001b[0m\n",
            "[2024-04-02 19:25:14] \u001b[32mTrain: [ 23/50] Step 300/520 Loss 2.213 Prec@(1,5) (56.0%, 84.2%)\u001b[0m\n",
            "[2024-04-02 19:25:15] \u001b[32mTrain: [ 23/50] Step 320/520 Loss 2.215 Prec@(1,5) (56.0%, 84.1%)\u001b[0m\n",
            "[2024-04-02 19:25:15] \u001b[32mTrain: [ 23/50] Step 340/520 Loss 2.220 Prec@(1,5) (55.8%, 84.0%)\u001b[0m\n",
            "[2024-04-02 19:25:16] \u001b[32mTrain: [ 23/50] Step 360/520 Loss 2.221 Prec@(1,5) (55.8%, 84.0%)\u001b[0m\n",
            "[2024-04-02 19:25:16] \u001b[32mTrain: [ 23/50] Step 380/520 Loss 2.216 Prec@(1,5) (55.9%, 84.1%)\u001b[0m\n",
            "[2024-04-02 19:25:17] \u001b[32mTrain: [ 23/50] Step 400/520 Loss 2.216 Prec@(1,5) (55.9%, 84.1%)\u001b[0m\n",
            "[2024-04-02 19:25:17] \u001b[32mTrain: [ 23/50] Step 420/520 Loss 2.220 Prec@(1,5) (55.8%, 84.0%)\u001b[0m\n",
            "[2024-04-02 19:25:18] \u001b[32mTrain: [ 23/50] Step 440/520 Loss 2.223 Prec@(1,5) (55.8%, 84.0%)\u001b[0m\n",
            "[2024-04-02 19:25:18] \u001b[32mTrain: [ 23/50] Step 460/520 Loss 2.220 Prec@(1,5) (55.9%, 84.0%)\u001b[0m\n",
            "[2024-04-02 19:25:19] \u001b[32mTrain: [ 23/50] Step 480/520 Loss 2.218 Prec@(1,5) (55.9%, 84.1%)\u001b[0m\n",
            "[2024-04-02 19:25:19] \u001b[32mTrain: [ 23/50] Step 500/520 Loss 2.219 Prec@(1,5) (55.8%, 84.1%)\u001b[0m\n",
            "[2024-04-02 19:25:20] \u001b[32mTrain: [ 23/50] Step 520/520 Loss 2.219 Prec@(1,5) (55.9%, 84.1%)\u001b[0m\n",
            "[2024-04-02 19:25:20] \u001b[32mTrain: [ 23/50] Final Prec@1 55.8820%\u001b[0m\n",
            "[2024-04-02 19:25:23] \u001b[32mValid: [ 23/50] Step 000/104 Loss 2.160 Prec@(1,5) (56.2%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:25:24] \u001b[32mValid: [ 23/50] Step 020/104 Loss 2.495 Prec@(1,5) (49.4%, 80.0%)\u001b[0m\n",
            "[2024-04-02 19:25:24] \u001b[32mValid: [ 23/50] Step 040/104 Loss 2.440 Prec@(1,5) (50.1%, 80.5%)\u001b[0m\n",
            "[2024-04-02 19:25:24] \u001b[32mValid: [ 23/50] Step 060/104 Loss 2.412 Prec@(1,5) (50.5%, 80.8%)\u001b[0m\n",
            "[2024-04-02 19:25:24] \u001b[32mValid: [ 23/50] Step 080/104 Loss 2.411 Prec@(1,5) (50.4%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:25:24] \u001b[32mValid: [ 23/50] Step 100/104 Loss 2.404 Prec@(1,5) (50.6%, 80.7%)\u001b[0m\n",
            "[2024-04-02 19:25:24] \u001b[32mValid: [ 23/50] Step 104/104 Loss 2.408 Prec@(1,5) (50.5%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:25:25] \u001b[32mValid: [ 23/50] Final Prec@1 50.5200%\u001b[0m\n",
            "[2024-04-02 19:25:25] \u001b[32mEpoch 23 LR 0.014067\u001b[0m\n",
            "[2024-04-02 19:25:29] \u001b[32mTrain: [ 24/50] Step 000/520 Loss 2.430 Prec@(1,5) (54.2%, 80.2%)\u001b[0m\n",
            "[2024-04-02 19:25:30] \u001b[32mTrain: [ 24/50] Step 020/520 Loss 2.083 Prec@(1,5) (59.0%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:25:30] \u001b[32mTrain: [ 24/50] Step 040/520 Loss 2.160 Prec@(1,5) (57.4%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:25:31] \u001b[32mTrain: [ 24/50] Step 060/520 Loss 2.175 Prec@(1,5) (56.7%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:25:31] \u001b[32mTrain: [ 24/50] Step 080/520 Loss 2.187 Prec@(1,5) (56.6%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:25:32] \u001b[32mTrain: [ 24/50] Step 100/520 Loss 2.182 Prec@(1,5) (56.8%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:25:32] \u001b[32mTrain: [ 24/50] Step 120/520 Loss 2.176 Prec@(1,5) (56.9%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:25:33] \u001b[32mTrain: [ 24/50] Step 140/520 Loss 2.175 Prec@(1,5) (56.9%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:25:33] \u001b[32mTrain: [ 24/50] Step 160/520 Loss 2.182 Prec@(1,5) (56.6%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:25:34] \u001b[32mTrain: [ 24/50] Step 180/520 Loss 2.190 Prec@(1,5) (56.4%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:25:34] \u001b[32mTrain: [ 24/50] Step 200/520 Loss 2.190 Prec@(1,5) (56.4%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:25:35] \u001b[32mTrain: [ 24/50] Step 220/520 Loss 2.190 Prec@(1,5) (56.4%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:25:35] \u001b[32mTrain: [ 24/50] Step 240/520 Loss 2.192 Prec@(1,5) (56.4%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:25:36] \u001b[32mTrain: [ 24/50] Step 260/520 Loss 2.196 Prec@(1,5) (56.3%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:25:36] \u001b[32mTrain: [ 24/50] Step 280/520 Loss 2.197 Prec@(1,5) (56.3%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:25:37] \u001b[32mTrain: [ 24/50] Step 300/520 Loss 2.198 Prec@(1,5) (56.3%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:25:37] \u001b[32mTrain: [ 24/50] Step 320/520 Loss 2.198 Prec@(1,5) (56.2%, 84.3%)\u001b[0m\n",
            "[2024-04-02 19:25:38] \u001b[32mTrain: [ 24/50] Step 340/520 Loss 2.196 Prec@(1,5) (56.2%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:25:38] \u001b[32mTrain: [ 24/50] Step 360/520 Loss 2.200 Prec@(1,5) (56.2%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:25:39] \u001b[32mTrain: [ 24/50] Step 380/520 Loss 2.202 Prec@(1,5) (56.1%, 84.3%)\u001b[0m\n",
            "[2024-04-02 19:25:39] \u001b[32mTrain: [ 24/50] Step 400/520 Loss 2.202 Prec@(1,5) (56.0%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:25:40] \u001b[32mTrain: [ 24/50] Step 420/520 Loss 2.205 Prec@(1,5) (56.0%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:25:40] \u001b[32mTrain: [ 24/50] Step 440/520 Loss 2.202 Prec@(1,5) (56.0%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:25:41] \u001b[32mTrain: [ 24/50] Step 460/520 Loss 2.201 Prec@(1,5) (56.0%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:25:41] \u001b[32mTrain: [ 24/50] Step 480/520 Loss 2.200 Prec@(1,5) (56.0%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:25:42] \u001b[32mTrain: [ 24/50] Step 500/520 Loss 2.198 Prec@(1,5) (56.1%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:25:42] \u001b[32mTrain: [ 24/50] Step 520/520 Loss 2.197 Prec@(1,5) (56.1%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:25:42] \u001b[32mTrain: [ 24/50] Final Prec@1 56.1140%\u001b[0m\n",
            "[2024-04-02 19:25:46] \u001b[32mValid: [ 24/50] Step 000/104 Loss 2.314 Prec@(1,5) (56.2%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:25:46] \u001b[32mValid: [ 24/50] Step 020/104 Loss 2.424 Prec@(1,5) (50.8%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:25:46] \u001b[32mValid: [ 24/50] Step 040/104 Loss 2.410 Prec@(1,5) (50.9%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:25:46] \u001b[32mValid: [ 24/50] Step 060/104 Loss 2.361 Prec@(1,5) (51.6%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:25:46] \u001b[32mValid: [ 24/50] Step 080/104 Loss 2.366 Prec@(1,5) (51.2%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:25:47] \u001b[32mValid: [ 24/50] Step 100/104 Loss 2.368 Prec@(1,5) (51.2%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:25:47] \u001b[32mValid: [ 24/50] Step 104/104 Loss 2.367 Prec@(1,5) (51.3%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:25:47] \u001b[32mValid: [ 24/50] Final Prec@1 51.2600%\u001b[0m\n",
            "[2024-04-02 19:25:47] \u001b[32mEpoch 24 LR 0.013285\u001b[0m\n",
            "[2024-04-02 19:25:51] \u001b[32mTrain: [ 25/50] Step 000/520 Loss 2.147 Prec@(1,5) (55.2%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:25:52] \u001b[32mTrain: [ 25/50] Step 020/520 Loss 2.199 Prec@(1,5) (57.1%, 84.1%)\u001b[0m\n",
            "[2024-04-02 19:25:52] \u001b[32mTrain: [ 25/50] Step 040/520 Loss 2.169 Prec@(1,5) (56.9%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:25:53] \u001b[32mTrain: [ 25/50] Step 060/520 Loss 2.156 Prec@(1,5) (57.1%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:25:53] \u001b[32mTrain: [ 25/50] Step 080/520 Loss 2.144 Prec@(1,5) (57.6%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:25:54] \u001b[32mTrain: [ 25/50] Step 100/520 Loss 2.167 Prec@(1,5) (57.1%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:25:54] \u001b[32mTrain: [ 25/50] Step 120/520 Loss 2.161 Prec@(1,5) (57.2%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:25:55] \u001b[32mTrain: [ 25/50] Step 140/520 Loss 2.149 Prec@(1,5) (57.2%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:25:55] \u001b[32mTrain: [ 25/50] Step 160/520 Loss 2.147 Prec@(1,5) (57.3%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:25:56] \u001b[32mTrain: [ 25/50] Step 180/520 Loss 2.148 Prec@(1,5) (57.3%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:25:56] \u001b[32mTrain: [ 25/50] Step 200/520 Loss 2.144 Prec@(1,5) (57.3%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:25:57] \u001b[32mTrain: [ 25/50] Step 220/520 Loss 2.147 Prec@(1,5) (57.2%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:25:57] \u001b[32mTrain: [ 25/50] Step 240/520 Loss 2.159 Prec@(1,5) (57.0%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:25:58] \u001b[32mTrain: [ 25/50] Step 260/520 Loss 2.156 Prec@(1,5) (57.0%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:25:58] \u001b[32mTrain: [ 25/50] Step 280/520 Loss 2.157 Prec@(1,5) (57.0%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:25:59] \u001b[32mTrain: [ 25/50] Step 300/520 Loss 2.159 Prec@(1,5) (57.0%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:25:59] \u001b[32mTrain: [ 25/50] Step 320/520 Loss 2.162 Prec@(1,5) (56.9%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:26:00] \u001b[32mTrain: [ 25/50] Step 340/520 Loss 2.163 Prec@(1,5) (56.9%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:26:00] \u001b[32mTrain: [ 25/50] Step 360/520 Loss 2.163 Prec@(1,5) (56.9%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:26:01] \u001b[32mTrain: [ 25/50] Step 380/520 Loss 2.165 Prec@(1,5) (56.9%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:26:01] \u001b[32mTrain: [ 25/50] Step 400/520 Loss 2.167 Prec@(1,5) (56.8%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:26:02] \u001b[32mTrain: [ 25/50] Step 420/520 Loss 2.170 Prec@(1,5) (56.7%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:26:02] \u001b[32mTrain: [ 25/50] Step 440/520 Loss 2.168 Prec@(1,5) (56.8%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:26:03] \u001b[32mTrain: [ 25/50] Step 460/520 Loss 2.167 Prec@(1,5) (56.8%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:26:03] \u001b[32mTrain: [ 25/50] Step 480/520 Loss 2.168 Prec@(1,5) (56.8%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:26:04] \u001b[32mTrain: [ 25/50] Step 500/520 Loss 2.172 Prec@(1,5) (56.7%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:26:04] \u001b[32mTrain: [ 25/50] Step 520/520 Loss 2.172 Prec@(1,5) (56.7%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:26:04] \u001b[32mTrain: [ 25/50] Final Prec@1 56.6640%\u001b[0m\n",
            "[2024-04-02 19:26:08] \u001b[32mValid: [ 25/50] Step 000/104 Loss 2.405 Prec@(1,5) (55.2%, 80.2%)\u001b[0m\n",
            "[2024-04-02 19:26:08] \u001b[32mValid: [ 25/50] Step 020/104 Loss 2.410 Prec@(1,5) (51.7%, 81.9%)\u001b[0m\n",
            "[2024-04-02 19:26:08] \u001b[32mValid: [ 25/50] Step 040/104 Loss 2.389 Prec@(1,5) (51.8%, 81.4%)\u001b[0m\n",
            "[2024-04-02 19:26:08] \u001b[32mValid: [ 25/50] Step 060/104 Loss 2.342 Prec@(1,5) (52.3%, 81.3%)\u001b[0m\n",
            "[2024-04-02 19:26:09] \u001b[32mValid: [ 25/50] Step 080/104 Loss 2.347 Prec@(1,5) (52.1%, 81.4%)\u001b[0m\n",
            "[2024-04-02 19:26:09] \u001b[32mValid: [ 25/50] Step 100/104 Loss 2.323 Prec@(1,5) (52.2%, 81.7%)\u001b[0m\n",
            "[2024-04-02 19:26:09] \u001b[32mValid: [ 25/50] Step 104/104 Loss 2.322 Prec@(1,5) (52.3%, 81.7%)\u001b[0m\n",
            "[2024-04-02 19:26:09] \u001b[32mValid: [ 25/50] Final Prec@1 52.2500%\u001b[0m\n",
            "[2024-04-02 19:26:09] \u001b[32mEpoch 25 LR 0.012500\u001b[0m\n",
            "[2024-04-02 19:26:14] \u001b[32mTrain: [ 26/50] Step 000/520 Loss 2.030 Prec@(1,5) (54.2%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:26:14] \u001b[32mTrain: [ 26/50] Step 020/520 Loss 2.094 Prec@(1,5) (58.5%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:26:15] \u001b[32mTrain: [ 26/50] Step 040/520 Loss 2.063 Prec@(1,5) (58.8%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:26:15] \u001b[32mTrain: [ 26/50] Step 060/520 Loss 2.104 Prec@(1,5) (57.9%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:26:16] \u001b[32mTrain: [ 26/50] Step 080/520 Loss 2.122 Prec@(1,5) (57.4%, 85.3%)\u001b[0m\n",
            "[2024-04-02 19:26:16] \u001b[32mTrain: [ 26/50] Step 100/520 Loss 2.131 Prec@(1,5) (57.1%, 85.3%)\u001b[0m\n",
            "[2024-04-02 19:26:17] \u001b[32mTrain: [ 26/50] Step 120/520 Loss 2.108 Prec@(1,5) (57.8%, 85.6%)\u001b[0m\n",
            "[2024-04-02 19:26:17] \u001b[32mTrain: [ 26/50] Step 140/520 Loss 2.114 Prec@(1,5) (57.6%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:26:17] \u001b[32mTrain: [ 26/50] Step 160/520 Loss 2.116 Prec@(1,5) (57.7%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:26:18] \u001b[32mTrain: [ 26/50] Step 180/520 Loss 2.115 Prec@(1,5) (57.7%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:26:18] \u001b[32mTrain: [ 26/50] Step 200/520 Loss 2.118 Prec@(1,5) (57.7%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:26:19] \u001b[32mTrain: [ 26/50] Step 220/520 Loss 2.124 Prec@(1,5) (57.6%, 85.3%)\u001b[0m\n",
            "[2024-04-02 19:26:19] \u001b[32mTrain: [ 26/50] Step 240/520 Loss 2.122 Prec@(1,5) (57.6%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:26:20] \u001b[32mTrain: [ 26/50] Step 260/520 Loss 2.121 Prec@(1,5) (57.7%, 85.3%)\u001b[0m\n",
            "[2024-04-02 19:26:20] \u001b[32mTrain: [ 26/50] Step 280/520 Loss 2.127 Prec@(1,5) (57.5%, 85.3%)\u001b[0m\n",
            "[2024-04-02 19:26:21] \u001b[32mTrain: [ 26/50] Step 300/520 Loss 2.126 Prec@(1,5) (57.6%, 85.3%)\u001b[0m\n",
            "[2024-04-02 19:26:21] \u001b[32mTrain: [ 26/50] Step 320/520 Loss 2.134 Prec@(1,5) (57.5%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:26:22] \u001b[32mTrain: [ 26/50] Step 340/520 Loss 2.135 Prec@(1,5) (57.4%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:26:22] \u001b[32mTrain: [ 26/50] Step 360/520 Loss 2.135 Prec@(1,5) (57.4%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:26:23] \u001b[32mTrain: [ 26/50] Step 380/520 Loss 2.132 Prec@(1,5) (57.5%, 85.2%)\u001b[0m\n",
            "[2024-04-02 19:26:23] \u001b[32mTrain: [ 26/50] Step 400/520 Loss 2.133 Prec@(1,5) (57.5%, 85.2%)\u001b[0m\n",
            "[2024-04-02 19:26:24] \u001b[32mTrain: [ 26/50] Step 420/520 Loss 2.131 Prec@(1,5) (57.5%, 85.2%)\u001b[0m\n",
            "[2024-04-02 19:26:24] \u001b[32mTrain: [ 26/50] Step 440/520 Loss 2.135 Prec@(1,5) (57.5%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:26:25] \u001b[32mTrain: [ 26/50] Step 460/520 Loss 2.138 Prec@(1,5) (57.4%, 85.0%)\u001b[0m\n",
            "[2024-04-02 19:26:25] \u001b[32mTrain: [ 26/50] Step 480/520 Loss 2.138 Prec@(1,5) (57.3%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:26:26] \u001b[32mTrain: [ 26/50] Step 500/520 Loss 2.137 Prec@(1,5) (57.3%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:26:26] \u001b[32mTrain: [ 26/50] Step 520/520 Loss 2.139 Prec@(1,5) (57.3%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:26:27] \u001b[32mTrain: [ 26/50] Final Prec@1 57.3460%\u001b[0m\n",
            "[2024-04-02 19:26:30] \u001b[32mValid: [ 26/50] Step 000/104 Loss 2.246 Prec@(1,5) (56.2%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:26:30] \u001b[32mValid: [ 26/50] Step 020/104 Loss 2.357 Prec@(1,5) (51.8%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:26:30] \u001b[32mValid: [ 26/50] Step 040/104 Loss 2.354 Prec@(1,5) (51.9%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:26:31] \u001b[32mValid: [ 26/50] Step 060/104 Loss 2.319 Prec@(1,5) (52.7%, 81.4%)\u001b[0m\n",
            "[2024-04-02 19:26:31] \u001b[32mValid: [ 26/50] Step 080/104 Loss 2.326 Prec@(1,5) (52.5%, 81.4%)\u001b[0m\n",
            "[2024-04-02 19:26:31] \u001b[32mValid: [ 26/50] Step 100/104 Loss 2.320 Prec@(1,5) (52.7%, 81.3%)\u001b[0m\n",
            "[2024-04-02 19:26:31] \u001b[32mValid: [ 26/50] Step 104/104 Loss 2.317 Prec@(1,5) (52.7%, 81.3%)\u001b[0m\n",
            "[2024-04-02 19:26:31] \u001b[32mValid: [ 26/50] Final Prec@1 52.7300%\u001b[0m\n",
            "[2024-04-02 19:26:31] \u001b[32mEpoch 26 LR 0.011716\u001b[0m\n",
            "[2024-04-02 19:26:36] \u001b[32mTrain: [ 27/50] Step 000/520 Loss 2.054 Prec@(1,5) (55.2%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:26:36] \u001b[32mTrain: [ 27/50] Step 020/520 Loss 2.108 Prec@(1,5) (58.6%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:26:37] \u001b[32mTrain: [ 27/50] Step 040/520 Loss 2.125 Prec@(1,5) (57.8%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:26:37] \u001b[32mTrain: [ 27/50] Step 060/520 Loss 2.123 Prec@(1,5) (57.4%, 85.0%)\u001b[0m\n",
            "[2024-04-02 19:26:38] \u001b[32mTrain: [ 27/50] Step 080/520 Loss 2.122 Prec@(1,5) (57.5%, 85.3%)\u001b[0m\n",
            "[2024-04-02 19:26:38] \u001b[32mTrain: [ 27/50] Step 100/520 Loss 2.108 Prec@(1,5) (57.8%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:26:39] \u001b[32mTrain: [ 27/50] Step 120/520 Loss 2.096 Prec@(1,5) (58.1%, 85.6%)\u001b[0m\n",
            "[2024-04-02 19:26:39] \u001b[32mTrain: [ 27/50] Step 140/520 Loss 2.092 Prec@(1,5) (58.2%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:26:40] \u001b[32mTrain: [ 27/50] Step 160/520 Loss 2.097 Prec@(1,5) (58.0%, 85.6%)\u001b[0m\n",
            "[2024-04-02 19:26:40] \u001b[32mTrain: [ 27/50] Step 180/520 Loss 2.092 Prec@(1,5) (57.9%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:26:41] \u001b[32mTrain: [ 27/50] Step 200/520 Loss 2.094 Prec@(1,5) (57.9%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:26:41] \u001b[32mTrain: [ 27/50] Step 220/520 Loss 2.095 Prec@(1,5) (57.8%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:26:42] \u001b[32mTrain: [ 27/50] Step 240/520 Loss 2.093 Prec@(1,5) (57.8%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:26:42] \u001b[32mTrain: [ 27/50] Step 260/520 Loss 2.087 Prec@(1,5) (58.0%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:26:43] \u001b[32mTrain: [ 27/50] Step 280/520 Loss 2.085 Prec@(1,5) (58.0%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:26:44] \u001b[32mTrain: [ 27/50] Step 300/520 Loss 2.085 Prec@(1,5) (58.0%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:26:44] \u001b[32mTrain: [ 27/50] Step 320/520 Loss 2.089 Prec@(1,5) (58.0%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:26:45] \u001b[32mTrain: [ 27/50] Step 340/520 Loss 2.091 Prec@(1,5) (57.9%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:26:45] \u001b[32mTrain: [ 27/50] Step 360/520 Loss 2.095 Prec@(1,5) (57.8%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:26:46] \u001b[32mTrain: [ 27/50] Step 380/520 Loss 2.097 Prec@(1,5) (57.8%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:26:46] \u001b[32mTrain: [ 27/50] Step 400/520 Loss 2.098 Prec@(1,5) (57.8%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:26:47] \u001b[32mTrain: [ 27/50] Step 420/520 Loss 2.099 Prec@(1,5) (57.8%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:26:47] \u001b[32mTrain: [ 27/50] Step 440/520 Loss 2.098 Prec@(1,5) (57.8%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:26:48] \u001b[32mTrain: [ 27/50] Step 460/520 Loss 2.101 Prec@(1,5) (57.7%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:26:48] \u001b[32mTrain: [ 27/50] Step 480/520 Loss 2.101 Prec@(1,5) (57.8%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:26:49] \u001b[32mTrain: [ 27/50] Step 500/520 Loss 2.103 Prec@(1,5) (57.7%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:26:49] \u001b[32mTrain: [ 27/50] Step 520/520 Loss 2.104 Prec@(1,5) (57.7%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:26:49] \u001b[32mTrain: [ 27/50] Final Prec@1 57.7120%\u001b[0m\n",
            "[2024-04-02 19:26:53] \u001b[32mValid: [ 27/50] Step 000/104 Loss 2.198 Prec@(1,5) (57.3%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:26:53] \u001b[32mValid: [ 27/50] Step 020/104 Loss 2.117 Prec@(1,5) (54.3%, 83.5%)\u001b[0m\n",
            "[2024-04-02 19:26:53] \u001b[32mValid: [ 27/50] Step 040/104 Loss 2.085 Prec@(1,5) (54.0%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:26:53] \u001b[32mValid: [ 27/50] Step 060/104 Loss 2.069 Prec@(1,5) (54.6%, 83.9%)\u001b[0m\n",
            "[2024-04-02 19:26:54] \u001b[32mValid: [ 27/50] Step 080/104 Loss 2.070 Prec@(1,5) (54.6%, 84.0%)\u001b[0m\n",
            "[2024-04-02 19:26:54] \u001b[32mValid: [ 27/50] Step 100/104 Loss 2.054 Prec@(1,5) (54.7%, 84.0%)\u001b[0m\n",
            "[2024-04-02 19:26:54] \u001b[32mValid: [ 27/50] Step 104/104 Loss 2.055 Prec@(1,5) (54.8%, 83.9%)\u001b[0m\n",
            "[2024-04-02 19:26:54] \u001b[32mValid: [ 27/50] Final Prec@1 54.7500%\u001b[0m\n",
            "[2024-04-02 19:26:54] \u001b[32mEpoch 27 LR 0.010934\u001b[0m\n",
            "[2024-04-02 19:26:59] \u001b[32mTrain: [ 28/50] Step 000/520 Loss 2.218 Prec@(1,5) (55.2%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:26:59] \u001b[32mTrain: [ 28/50] Step 020/520 Loss 2.053 Prec@(1,5) (59.4%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:27:00] \u001b[32mTrain: [ 28/50] Step 040/520 Loss 2.105 Prec@(1,5) (57.8%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:27:00] \u001b[32mTrain: [ 28/50] Step 060/520 Loss 2.103 Prec@(1,5) (57.7%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:27:01] \u001b[32mTrain: [ 28/50] Step 080/520 Loss 2.096 Prec@(1,5) (57.6%, 85.6%)\u001b[0m\n",
            "[2024-04-02 19:27:01] \u001b[32mTrain: [ 28/50] Step 100/520 Loss 2.094 Prec@(1,5) (57.9%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:27:02] \u001b[32mTrain: [ 28/50] Step 120/520 Loss 2.077 Prec@(1,5) (58.3%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:27:02] \u001b[32mTrain: [ 28/50] Step 140/520 Loss 2.072 Prec@(1,5) (58.4%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:27:03] \u001b[32mTrain: [ 28/50] Step 160/520 Loss 2.073 Prec@(1,5) (58.3%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:27:03] \u001b[32mTrain: [ 28/50] Step 180/520 Loss 2.072 Prec@(1,5) (58.3%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:27:04] \u001b[32mTrain: [ 28/50] Step 200/520 Loss 2.072 Prec@(1,5) (58.3%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:27:04] \u001b[32mTrain: [ 28/50] Step 220/520 Loss 2.075 Prec@(1,5) (58.3%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:27:05] \u001b[32mTrain: [ 28/50] Step 240/520 Loss 2.080 Prec@(1,5) (58.2%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:27:05] \u001b[32mTrain: [ 28/50] Step 260/520 Loss 2.075 Prec@(1,5) (58.3%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:27:06] \u001b[32mTrain: [ 28/50] Step 280/520 Loss 2.075 Prec@(1,5) (58.4%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:27:06] \u001b[32mTrain: [ 28/50] Step 300/520 Loss 2.076 Prec@(1,5) (58.4%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:27:07] \u001b[32mTrain: [ 28/50] Step 320/520 Loss 2.073 Prec@(1,5) (58.3%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:27:07] \u001b[32mTrain: [ 28/50] Step 340/520 Loss 2.071 Prec@(1,5) (58.4%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:27:08] \u001b[32mTrain: [ 28/50] Step 360/520 Loss 2.074 Prec@(1,5) (58.3%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:27:08] \u001b[32mTrain: [ 28/50] Step 380/520 Loss 2.074 Prec@(1,5) (58.4%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:27:09] \u001b[32mTrain: [ 28/50] Step 400/520 Loss 2.077 Prec@(1,5) (58.4%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:27:09] \u001b[32mTrain: [ 28/50] Step 420/520 Loss 2.077 Prec@(1,5) (58.3%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:27:10] \u001b[32mTrain: [ 28/50] Step 440/520 Loss 2.078 Prec@(1,5) (58.3%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:27:10] \u001b[32mTrain: [ 28/50] Step 460/520 Loss 2.078 Prec@(1,5) (58.3%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:27:11] \u001b[32mTrain: [ 28/50] Step 480/520 Loss 2.075 Prec@(1,5) (58.3%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:27:11] \u001b[32mTrain: [ 28/50] Step 500/520 Loss 2.076 Prec@(1,5) (58.3%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:27:12] \u001b[32mTrain: [ 28/50] Step 520/520 Loss 2.073 Prec@(1,5) (58.4%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:27:12] \u001b[32mTrain: [ 28/50] Final Prec@1 58.4280%\u001b[0m\n",
            "[2024-04-02 19:27:15] \u001b[32mValid: [ 28/50] Step 000/104 Loss 2.466 Prec@(1,5) (55.2%, 80.2%)\u001b[0m\n",
            "[2024-04-02 19:27:15] \u001b[32mValid: [ 28/50] Step 020/104 Loss 2.363 Prec@(1,5) (52.5%, 81.7%)\u001b[0m\n",
            "[2024-04-02 19:27:16] \u001b[32mValid: [ 28/50] Step 040/104 Loss 2.335 Prec@(1,5) (52.3%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:27:16] \u001b[32mValid: [ 28/50] Step 060/104 Loss 2.307 Prec@(1,5) (52.8%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:27:16] \u001b[32mValid: [ 28/50] Step 080/104 Loss 2.313 Prec@(1,5) (52.6%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:27:16] \u001b[32mValid: [ 28/50] Step 100/104 Loss 2.315 Prec@(1,5) (52.6%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:27:16] \u001b[32mValid: [ 28/50] Step 104/104 Loss 2.318 Prec@(1,5) (52.6%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:27:16] \u001b[32mValid: [ 28/50] Final Prec@1 52.6000%\u001b[0m\n",
            "[2024-04-02 19:27:16] \u001b[32mEpoch 28 LR 0.010158\u001b[0m\n",
            "[2024-04-02 19:27:21] \u001b[32mTrain: [ 29/50] Step 000/520 Loss 1.990 Prec@(1,5) (64.6%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:27:21] \u001b[32mTrain: [ 29/50] Step 020/520 Loss 2.054 Prec@(1,5) (59.6%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:27:22] \u001b[32mTrain: [ 29/50] Step 040/520 Loss 2.034 Prec@(1,5) (60.0%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:27:22] \u001b[32mTrain: [ 29/50] Step 060/520 Loss 2.052 Prec@(1,5) (59.2%, 85.6%)\u001b[0m\n",
            "[2024-04-02 19:27:23] \u001b[32mTrain: [ 29/50] Step 080/520 Loss 2.043 Prec@(1,5) (59.2%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:27:23] \u001b[32mTrain: [ 29/50] Step 100/520 Loss 2.035 Prec@(1,5) (59.4%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:27:24] \u001b[32mTrain: [ 29/50] Step 120/520 Loss 2.026 Prec@(1,5) (59.4%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:27:24] \u001b[32mTrain: [ 29/50] Step 140/520 Loss 2.013 Prec@(1,5) (59.6%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:27:25] \u001b[32mTrain: [ 29/50] Step 160/520 Loss 2.017 Prec@(1,5) (59.5%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:27:25] \u001b[32mTrain: [ 29/50] Step 180/520 Loss 2.019 Prec@(1,5) (59.4%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:27:26] \u001b[32mTrain: [ 29/50] Step 200/520 Loss 2.029 Prec@(1,5) (59.3%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:27:26] \u001b[32mTrain: [ 29/50] Step 220/520 Loss 2.037 Prec@(1,5) (59.2%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:27:27] \u001b[32mTrain: [ 29/50] Step 240/520 Loss 2.046 Prec@(1,5) (59.0%, 86.1%)\u001b[0m\n",
            "[2024-04-02 19:27:27] \u001b[32mTrain: [ 29/50] Step 260/520 Loss 2.047 Prec@(1,5) (59.1%, 86.1%)\u001b[0m\n",
            "[2024-04-02 19:27:28] \u001b[32mTrain: [ 29/50] Step 280/520 Loss 2.045 Prec@(1,5) (59.1%, 86.1%)\u001b[0m\n",
            "[2024-04-02 19:27:28] \u001b[32mTrain: [ 29/50] Step 300/520 Loss 2.044 Prec@(1,5) (59.0%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:27:29] \u001b[32mTrain: [ 29/50] Step 320/520 Loss 2.044 Prec@(1,5) (58.9%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:27:29] \u001b[32mTrain: [ 29/50] Step 340/520 Loss 2.044 Prec@(1,5) (58.9%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:27:30] \u001b[32mTrain: [ 29/50] Step 360/520 Loss 2.045 Prec@(1,5) (58.9%, 86.1%)\u001b[0m\n",
            "[2024-04-02 19:27:30] \u001b[32mTrain: [ 29/50] Step 380/520 Loss 2.047 Prec@(1,5) (58.8%, 86.1%)\u001b[0m\n",
            "[2024-04-02 19:27:31] \u001b[32mTrain: [ 29/50] Step 400/520 Loss 2.048 Prec@(1,5) (58.8%, 86.1%)\u001b[0m\n",
            "[2024-04-02 19:27:31] \u001b[32mTrain: [ 29/50] Step 420/520 Loss 2.049 Prec@(1,5) (58.8%, 86.1%)\u001b[0m\n",
            "[2024-04-02 19:27:32] \u001b[32mTrain: [ 29/50] Step 440/520 Loss 2.048 Prec@(1,5) (58.8%, 86.1%)\u001b[0m\n",
            "[2024-04-02 19:27:32] \u001b[32mTrain: [ 29/50] Step 460/520 Loss 2.053 Prec@(1,5) (58.7%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:27:33] \u001b[32mTrain: [ 29/50] Step 480/520 Loss 2.055 Prec@(1,5) (58.7%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:27:33] \u001b[32mTrain: [ 29/50] Step 500/520 Loss 2.054 Prec@(1,5) (58.7%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:27:34] \u001b[32mTrain: [ 29/50] Step 520/520 Loss 2.052 Prec@(1,5) (58.7%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:27:34] \u001b[32mTrain: [ 29/50] Final Prec@1 58.7400%\u001b[0m\n",
            "[2024-04-02 19:27:37] \u001b[32mValid: [ 29/50] Step 000/104 Loss 1.836 Prec@(1,5) (61.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:27:38] \u001b[32mValid: [ 29/50] Step 020/104 Loss 2.236 Prec@(1,5) (54.1%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:27:38] \u001b[32mValid: [ 29/50] Step 040/104 Loss 2.212 Prec@(1,5) (53.4%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:27:38] \u001b[32mValid: [ 29/50] Step 060/104 Loss 2.179 Prec@(1,5) (54.1%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:27:38] \u001b[32mValid: [ 29/50] Step 080/104 Loss 2.174 Prec@(1,5) (53.8%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:27:38] \u001b[32mValid: [ 29/50] Step 100/104 Loss 2.169 Prec@(1,5) (54.1%, 83.4%)\u001b[0m\n",
            "[2024-04-02 19:27:38] \u001b[32mValid: [ 29/50] Step 104/104 Loss 2.171 Prec@(1,5) (54.1%, 83.4%)\u001b[0m\n",
            "[2024-04-02 19:27:39] \u001b[32mValid: [ 29/50] Final Prec@1 54.0700%\u001b[0m\n",
            "[2024-04-02 19:27:39] \u001b[32mEpoch 29 LR 0.009392\u001b[0m\n",
            "[2024-04-02 19:27:43] \u001b[32mTrain: [ 30/50] Step 000/520 Loss 1.844 Prec@(1,5) (66.7%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:27:44] \u001b[32mTrain: [ 30/50] Step 020/520 Loss 1.976 Prec@(1,5) (61.2%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:27:44] \u001b[32mTrain: [ 30/50] Step 040/520 Loss 1.989 Prec@(1,5) (60.6%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:27:45] \u001b[32mTrain: [ 30/50] Step 060/520 Loss 1.985 Prec@(1,5) (60.5%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:27:45] \u001b[32mTrain: [ 30/50] Step 080/520 Loss 1.977 Prec@(1,5) (60.5%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:27:46] \u001b[32mTrain: [ 30/50] Step 100/520 Loss 1.970 Prec@(1,5) (60.4%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:27:46] \u001b[32mTrain: [ 30/50] Step 120/520 Loss 1.989 Prec@(1,5) (59.9%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:27:47] \u001b[32mTrain: [ 30/50] Step 140/520 Loss 1.986 Prec@(1,5) (59.9%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:27:47] \u001b[32mTrain: [ 30/50] Step 160/520 Loss 1.996 Prec@(1,5) (59.9%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:27:48] \u001b[32mTrain: [ 30/50] Step 180/520 Loss 1.999 Prec@(1,5) (59.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:27:48] \u001b[32mTrain: [ 30/50] Step 200/520 Loss 2.009 Prec@(1,5) (59.5%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:27:49] \u001b[32mTrain: [ 30/50] Step 220/520 Loss 2.005 Prec@(1,5) (59.5%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:27:49] \u001b[32mTrain: [ 30/50] Step 240/520 Loss 2.010 Prec@(1,5) (59.4%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:27:50] \u001b[32mTrain: [ 30/50] Step 260/520 Loss 2.012 Prec@(1,5) (59.3%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:27:50] \u001b[32mTrain: [ 30/50] Step 280/520 Loss 2.012 Prec@(1,5) (59.3%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:27:51] \u001b[32mTrain: [ 30/50] Step 300/520 Loss 2.016 Prec@(1,5) (59.3%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:27:51] \u001b[32mTrain: [ 30/50] Step 320/520 Loss 2.013 Prec@(1,5) (59.3%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:27:52] \u001b[32mTrain: [ 30/50] Step 340/520 Loss 2.011 Prec@(1,5) (59.4%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:27:52] \u001b[32mTrain: [ 30/50] Step 360/520 Loss 2.013 Prec@(1,5) (59.4%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:27:53] \u001b[32mTrain: [ 30/50] Step 380/520 Loss 2.010 Prec@(1,5) (59.4%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:27:53] \u001b[32mTrain: [ 30/50] Step 400/520 Loss 2.014 Prec@(1,5) (59.3%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:27:54] \u001b[32mTrain: [ 30/50] Step 420/520 Loss 2.011 Prec@(1,5) (59.5%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:27:54] \u001b[32mTrain: [ 30/50] Step 440/520 Loss 2.016 Prec@(1,5) (59.4%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:27:55] \u001b[32mTrain: [ 30/50] Step 460/520 Loss 2.020 Prec@(1,5) (59.3%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:27:55] \u001b[32mTrain: [ 30/50] Step 480/520 Loss 2.020 Prec@(1,5) (59.3%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:27:56] \u001b[32mTrain: [ 30/50] Step 500/520 Loss 2.024 Prec@(1,5) (59.2%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:27:56] \u001b[32mTrain: [ 30/50] Step 520/520 Loss 2.025 Prec@(1,5) (59.1%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:27:57] \u001b[32mTrain: [ 30/50] Final Prec@1 59.1320%\u001b[0m\n",
            "[2024-04-02 19:28:00] \u001b[32mValid: [ 30/50] Step 000/104 Loss 1.954 Prec@(1,5) (64.6%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:28:00] \u001b[32mValid: [ 30/50] Step 020/104 Loss 2.194 Prec@(1,5) (55.3%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:28:00] \u001b[32mValid: [ 30/50] Step 040/104 Loss 2.162 Prec@(1,5) (55.1%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:28:01] \u001b[32mValid: [ 30/50] Step 060/104 Loss 2.117 Prec@(1,5) (55.4%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:28:01] \u001b[32mValid: [ 30/50] Step 080/104 Loss 2.127 Prec@(1,5) (55.1%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:28:01] \u001b[32mValid: [ 30/50] Step 100/104 Loss 2.121 Prec@(1,5) (55.3%, 83.6%)\u001b[0m\n",
            "[2024-04-02 19:28:01] \u001b[32mValid: [ 30/50] Step 104/104 Loss 2.124 Prec@(1,5) (55.3%, 83.6%)\u001b[0m\n",
            "[2024-04-02 19:28:01] \u001b[32mValid: [ 30/50] Final Prec@1 55.3000%\u001b[0m\n",
            "[2024-04-02 19:28:01] \u001b[32mEpoch 30 LR 0.008638\u001b[0m\n",
            "[2024-04-02 19:28:06] \u001b[32mTrain: [ 31/50] Step 000/520 Loss 2.162 Prec@(1,5) (53.1%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:28:06] \u001b[32mTrain: [ 31/50] Step 020/520 Loss 1.959 Prec@(1,5) (60.3%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:28:07] \u001b[32mTrain: [ 31/50] Step 040/520 Loss 2.001 Prec@(1,5) (59.5%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:28:07] \u001b[32mTrain: [ 31/50] Step 060/520 Loss 2.019 Prec@(1,5) (58.9%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:28:08] \u001b[32mTrain: [ 31/50] Step 080/520 Loss 2.008 Prec@(1,5) (59.5%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:28:08] \u001b[32mTrain: [ 31/50] Step 100/520 Loss 2.000 Prec@(1,5) (59.7%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:28:09] \u001b[32mTrain: [ 31/50] Step 120/520 Loss 2.001 Prec@(1,5) (59.6%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:28:09] \u001b[32mTrain: [ 31/50] Step 140/520 Loss 2.008 Prec@(1,5) (59.4%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:28:10] \u001b[32mTrain: [ 31/50] Step 160/520 Loss 2.003 Prec@(1,5) (59.5%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:28:10] \u001b[32mTrain: [ 31/50] Step 180/520 Loss 2.004 Prec@(1,5) (59.6%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:28:11] \u001b[32mTrain: [ 31/50] Step 200/520 Loss 2.003 Prec@(1,5) (59.5%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:28:11] \u001b[32mTrain: [ 31/50] Step 220/520 Loss 2.002 Prec@(1,5) (59.6%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:28:12] \u001b[32mTrain: [ 31/50] Step 240/520 Loss 2.004 Prec@(1,5) (59.8%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:28:12] \u001b[32mTrain: [ 31/50] Step 260/520 Loss 2.003 Prec@(1,5) (59.7%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:28:13] \u001b[32mTrain: [ 31/50] Step 280/520 Loss 2.005 Prec@(1,5) (59.6%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:28:13] \u001b[32mTrain: [ 31/50] Step 300/520 Loss 2.009 Prec@(1,5) (59.6%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:28:14] \u001b[32mTrain: [ 31/50] Step 320/520 Loss 2.011 Prec@(1,5) (59.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:28:14] \u001b[32mTrain: [ 31/50] Step 340/520 Loss 2.014 Prec@(1,5) (59.3%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:28:15] \u001b[32mTrain: [ 31/50] Step 360/520 Loss 2.009 Prec@(1,5) (59.4%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:28:15] \u001b[32mTrain: [ 31/50] Step 380/520 Loss 2.004 Prec@(1,5) (59.4%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:28:16] \u001b[32mTrain: [ 31/50] Step 400/520 Loss 2.004 Prec@(1,5) (59.6%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:28:16] \u001b[32mTrain: [ 31/50] Step 420/520 Loss 2.003 Prec@(1,5) (59.6%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:28:17] \u001b[32mTrain: [ 31/50] Step 440/520 Loss 2.004 Prec@(1,5) (59.6%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:28:17] \u001b[32mTrain: [ 31/50] Step 460/520 Loss 2.001 Prec@(1,5) (59.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:28:18] \u001b[32mTrain: [ 31/50] Step 480/520 Loss 1.998 Prec@(1,5) (59.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:28:18] \u001b[32mTrain: [ 31/50] Step 500/520 Loss 1.998 Prec@(1,5) (59.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:28:19] \u001b[32mTrain: [ 31/50] Step 520/520 Loss 1.998 Prec@(1,5) (59.8%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:28:19] \u001b[32mTrain: [ 31/50] Final Prec@1 59.7880%\u001b[0m\n",
            "[2024-04-02 19:28:22] \u001b[32mValid: [ 31/50] Step 000/104 Loss 2.141 Prec@(1,5) (56.2%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:28:22] \u001b[32mValid: [ 31/50] Step 020/104 Loss 2.240 Prec@(1,5) (54.1%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:28:23] \u001b[32mValid: [ 31/50] Step 040/104 Loss 2.187 Prec@(1,5) (54.5%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:28:23] \u001b[32mValid: [ 31/50] Step 060/104 Loss 2.145 Prec@(1,5) (55.2%, 83.4%)\u001b[0m\n",
            "[2024-04-02 19:28:23] \u001b[32mValid: [ 31/50] Step 080/104 Loss 2.154 Prec@(1,5) (54.9%, 83.5%)\u001b[0m\n",
            "[2024-04-02 19:28:23] \u001b[32mValid: [ 31/50] Step 100/104 Loss 2.133 Prec@(1,5) (55.1%, 83.6%)\u001b[0m\n",
            "[2024-04-02 19:28:23] \u001b[32mValid: [ 31/50] Step 104/104 Loss 2.134 Prec@(1,5) (55.1%, 83.7%)\u001b[0m\n",
            "[2024-04-02 19:28:23] \u001b[32mValid: [ 31/50] Final Prec@1 55.1100%\u001b[0m\n",
            "[2024-04-02 19:28:23] \u001b[32mEpoch 31 LR 0.007899\u001b[0m\n",
            "[2024-04-02 19:28:28] \u001b[32mTrain: [ 32/50] Step 000/520 Loss 2.037 Prec@(1,5) (55.2%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:28:28] \u001b[32mTrain: [ 32/50] Step 020/520 Loss 1.962 Prec@(1,5) (59.4%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:28:29] \u001b[32mTrain: [ 32/50] Step 040/520 Loss 1.970 Prec@(1,5) (59.6%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:28:29] \u001b[32mTrain: [ 32/50] Step 060/520 Loss 1.981 Prec@(1,5) (59.5%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:28:30] \u001b[32mTrain: [ 32/50] Step 080/520 Loss 1.980 Prec@(1,5) (59.7%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:28:30] \u001b[32mTrain: [ 32/50] Step 100/520 Loss 1.966 Prec@(1,5) (60.3%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:28:31] \u001b[32mTrain: [ 32/50] Step 120/520 Loss 1.962 Prec@(1,5) (60.2%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:28:31] \u001b[32mTrain: [ 32/50] Step 140/520 Loss 1.967 Prec@(1,5) (60.0%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:28:32] \u001b[32mTrain: [ 32/50] Step 160/520 Loss 1.970 Prec@(1,5) (60.0%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:28:32] \u001b[32mTrain: [ 32/50] Step 180/520 Loss 1.967 Prec@(1,5) (60.2%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:28:33] \u001b[32mTrain: [ 32/50] Step 200/520 Loss 1.972 Prec@(1,5) (60.2%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:28:33] \u001b[32mTrain: [ 32/50] Step 220/520 Loss 1.977 Prec@(1,5) (60.1%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:28:34] \u001b[32mTrain: [ 32/50] Step 240/520 Loss 1.984 Prec@(1,5) (59.9%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:28:34] \u001b[32mTrain: [ 32/50] Step 260/520 Loss 1.981 Prec@(1,5) (59.9%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:28:35] \u001b[32mTrain: [ 32/50] Step 280/520 Loss 1.986 Prec@(1,5) (59.9%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:28:35] \u001b[32mTrain: [ 32/50] Step 300/520 Loss 1.983 Prec@(1,5) (59.9%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:28:36] \u001b[32mTrain: [ 32/50] Step 320/520 Loss 1.984 Prec@(1,5) (59.9%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:28:36] \u001b[32mTrain: [ 32/50] Step 340/520 Loss 1.984 Prec@(1,5) (60.0%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:28:37] \u001b[32mTrain: [ 32/50] Step 360/520 Loss 1.986 Prec@(1,5) (60.0%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:28:37] \u001b[32mTrain: [ 32/50] Step 380/520 Loss 1.983 Prec@(1,5) (60.0%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:28:38] \u001b[32mTrain: [ 32/50] Step 400/520 Loss 1.984 Prec@(1,5) (60.0%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:28:38] \u001b[32mTrain: [ 32/50] Step 420/520 Loss 1.982 Prec@(1,5) (60.1%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:28:39] \u001b[32mTrain: [ 32/50] Step 440/520 Loss 1.980 Prec@(1,5) (60.1%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:28:39] \u001b[32mTrain: [ 32/50] Step 460/520 Loss 1.984 Prec@(1,5) (60.0%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:28:40] \u001b[32mTrain: [ 32/50] Step 480/520 Loss 1.986 Prec@(1,5) (60.0%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:28:40] \u001b[32mTrain: [ 32/50] Step 500/520 Loss 1.985 Prec@(1,5) (60.0%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:28:41] \u001b[32mTrain: [ 32/50] Step 520/520 Loss 1.987 Prec@(1,5) (59.9%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:28:41] \u001b[32mTrain: [ 32/50] Final Prec@1 59.9400%\u001b[0m\n",
            "[2024-04-02 19:28:45] \u001b[32mValid: [ 32/50] Step 000/104 Loss 2.030 Prec@(1,5) (62.5%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:28:45] \u001b[32mValid: [ 32/50] Step 020/104 Loss 2.039 Prec@(1,5) (57.3%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:28:45] \u001b[32mValid: [ 32/50] Step 040/104 Loss 2.013 Prec@(1,5) (56.7%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:28:45] \u001b[32mValid: [ 32/50] Step 060/104 Loss 1.985 Prec@(1,5) (57.3%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:28:45] \u001b[32mValid: [ 32/50] Step 080/104 Loss 1.988 Prec@(1,5) (57.4%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:28:45] \u001b[32mValid: [ 32/50] Step 100/104 Loss 1.970 Prec@(1,5) (57.8%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:28:45] \u001b[32mValid: [ 32/50] Step 104/104 Loss 1.973 Prec@(1,5) (57.7%, 85.0%)\u001b[0m\n",
            "[2024-04-02 19:28:46] \u001b[32mValid: [ 32/50] Final Prec@1 57.6900%\u001b[0m\n",
            "[2024-04-02 19:28:46] \u001b[32mEpoch 32 LR 0.007178\u001b[0m\n",
            "[2024-04-02 19:28:50] \u001b[32mTrain: [ 33/50] Step 000/520 Loss 2.378 Prec@(1,5) (57.3%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:28:51] \u001b[32mTrain: [ 33/50] Step 020/520 Loss 2.023 Prec@(1,5) (60.1%, 85.2%)\u001b[0m\n",
            "[2024-04-02 19:28:51] \u001b[32mTrain: [ 33/50] Step 040/520 Loss 2.051 Prec@(1,5) (58.7%, 85.6%)\u001b[0m\n",
            "[2024-04-02 19:28:52] \u001b[32mTrain: [ 33/50] Step 060/520 Loss 2.014 Prec@(1,5) (59.4%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:28:52] \u001b[32mTrain: [ 33/50] Step 080/520 Loss 1.981 Prec@(1,5) (60.1%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:28:53] \u001b[32mTrain: [ 33/50] Step 100/520 Loss 1.964 Prec@(1,5) (60.6%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:28:53] \u001b[32mTrain: [ 33/50] Step 120/520 Loss 1.965 Prec@(1,5) (60.6%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:28:54] \u001b[32mTrain: [ 33/50] Step 140/520 Loss 1.954 Prec@(1,5) (60.7%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:28:54] \u001b[32mTrain: [ 33/50] Step 160/520 Loss 1.940 Prec@(1,5) (60.9%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:28:55] \u001b[32mTrain: [ 33/50] Step 180/520 Loss 1.942 Prec@(1,5) (61.0%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:28:55] \u001b[32mTrain: [ 33/50] Step 200/520 Loss 1.940 Prec@(1,5) (61.1%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:28:56] \u001b[32mTrain: [ 33/50] Step 220/520 Loss 1.940 Prec@(1,5) (61.0%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:28:56] \u001b[32mTrain: [ 33/50] Step 240/520 Loss 1.944 Prec@(1,5) (60.9%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:28:57] \u001b[32mTrain: [ 33/50] Step 260/520 Loss 1.943 Prec@(1,5) (60.9%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:28:57] \u001b[32mTrain: [ 33/50] Step 280/520 Loss 1.945 Prec@(1,5) (60.8%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:28:58] \u001b[32mTrain: [ 33/50] Step 300/520 Loss 1.951 Prec@(1,5) (60.6%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:28:58] \u001b[32mTrain: [ 33/50] Step 320/520 Loss 1.950 Prec@(1,5) (60.6%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:28:59] \u001b[32mTrain: [ 33/50] Step 340/520 Loss 1.954 Prec@(1,5) (60.5%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:29:00] \u001b[32mTrain: [ 33/50] Step 360/520 Loss 1.955 Prec@(1,5) (60.6%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:29:00] \u001b[32mTrain: [ 33/50] Step 380/520 Loss 1.955 Prec@(1,5) (60.6%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:29:01] \u001b[32mTrain: [ 33/50] Step 400/520 Loss 1.957 Prec@(1,5) (60.6%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:29:01] \u001b[32mTrain: [ 33/50] Step 420/520 Loss 1.958 Prec@(1,5) (60.6%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:29:02] \u001b[32mTrain: [ 33/50] Step 440/520 Loss 1.959 Prec@(1,5) (60.6%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:29:02] \u001b[32mTrain: [ 33/50] Step 460/520 Loss 1.958 Prec@(1,5) (60.6%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:29:03] \u001b[32mTrain: [ 33/50] Step 480/520 Loss 1.959 Prec@(1,5) (60.5%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:29:03] \u001b[32mTrain: [ 33/50] Step 500/520 Loss 1.959 Prec@(1,5) (60.5%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:29:04] \u001b[32mTrain: [ 33/50] Step 520/520 Loss 1.957 Prec@(1,5) (60.6%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:29:04] \u001b[32mTrain: [ 33/50] Final Prec@1 60.5540%\u001b[0m\n",
            "[2024-04-02 19:29:07] \u001b[32mValid: [ 33/50] Step 000/104 Loss 2.025 Prec@(1,5) (63.5%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:29:07] \u001b[32mValid: [ 33/50] Step 020/104 Loss 2.070 Prec@(1,5) (56.8%, 84.3%)\u001b[0m\n",
            "[2024-04-02 19:29:08] \u001b[32mValid: [ 33/50] Step 040/104 Loss 2.056 Prec@(1,5) (56.3%, 84.2%)\u001b[0m\n",
            "[2024-04-02 19:29:08] \u001b[32mValid: [ 33/50] Step 060/104 Loss 2.020 Prec@(1,5) (56.9%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:29:08] \u001b[32mValid: [ 33/50] Step 080/104 Loss 2.032 Prec@(1,5) (56.7%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:29:08] \u001b[32mValid: [ 33/50] Step 100/104 Loss 2.009 Prec@(1,5) (57.2%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:29:08] \u001b[32mValid: [ 33/50] Step 104/104 Loss 2.015 Prec@(1,5) (57.2%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:29:08] \u001b[32mValid: [ 33/50] Final Prec@1 57.2200%\u001b[0m\n",
            "[2024-04-02 19:29:08] \u001b[32mEpoch 33 LR 0.006479\u001b[0m\n",
            "[2024-04-02 19:29:13] \u001b[32mTrain: [ 34/50] Step 000/520 Loss 1.837 Prec@(1,5) (62.5%, 90.6%)\u001b[0m\n",
            "[2024-04-02 19:29:14] \u001b[32mTrain: [ 34/50] Step 020/520 Loss 1.909 Prec@(1,5) (61.6%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:29:14] \u001b[32mTrain: [ 34/50] Step 040/520 Loss 1.911 Prec@(1,5) (61.1%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:29:15] \u001b[32mTrain: [ 34/50] Step 060/520 Loss 1.951 Prec@(1,5) (60.0%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:29:15] \u001b[32mTrain: [ 34/50] Step 080/520 Loss 1.940 Prec@(1,5) (60.5%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:29:16] \u001b[32mTrain: [ 34/50] Step 100/520 Loss 1.935 Prec@(1,5) (60.7%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:29:16] \u001b[32mTrain: [ 34/50] Step 120/520 Loss 1.929 Prec@(1,5) (61.0%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:29:17] \u001b[32mTrain: [ 34/50] Step 140/520 Loss 1.931 Prec@(1,5) (60.9%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:29:17] \u001b[32mTrain: [ 34/50] Step 160/520 Loss 1.912 Prec@(1,5) (61.2%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:29:18] \u001b[32mTrain: [ 34/50] Step 180/520 Loss 1.918 Prec@(1,5) (61.2%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:29:18] \u001b[32mTrain: [ 34/50] Step 200/520 Loss 1.918 Prec@(1,5) (61.1%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:29:19] \u001b[32mTrain: [ 34/50] Step 220/520 Loss 1.911 Prec@(1,5) (61.4%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:29:19] \u001b[32mTrain: [ 34/50] Step 240/520 Loss 1.906 Prec@(1,5) (61.5%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:29:20] \u001b[32mTrain: [ 34/50] Step 260/520 Loss 1.912 Prec@(1,5) (61.4%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:29:20] \u001b[32mTrain: [ 34/50] Step 280/520 Loss 1.912 Prec@(1,5) (61.3%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:29:21] \u001b[32mTrain: [ 34/50] Step 300/520 Loss 1.913 Prec@(1,5) (61.3%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:29:21] \u001b[32mTrain: [ 34/50] Step 320/520 Loss 1.911 Prec@(1,5) (61.4%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:29:22] \u001b[32mTrain: [ 34/50] Step 340/520 Loss 1.911 Prec@(1,5) (61.5%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:29:22] \u001b[32mTrain: [ 34/50] Step 360/520 Loss 1.917 Prec@(1,5) (61.4%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:29:23] \u001b[32mTrain: [ 34/50] Step 380/520 Loss 1.915 Prec@(1,5) (61.5%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:29:23] \u001b[32mTrain: [ 34/50] Step 400/520 Loss 1.918 Prec@(1,5) (61.4%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:29:24] \u001b[32mTrain: [ 34/50] Step 420/520 Loss 1.918 Prec@(1,5) (61.4%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:29:24] \u001b[32mTrain: [ 34/50] Step 440/520 Loss 1.919 Prec@(1,5) (61.3%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:29:25] \u001b[32mTrain: [ 34/50] Step 460/520 Loss 1.922 Prec@(1,5) (61.3%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:29:25] \u001b[32mTrain: [ 34/50] Step 480/520 Loss 1.926 Prec@(1,5) (61.2%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:29:26] \u001b[32mTrain: [ 34/50] Step 500/520 Loss 1.924 Prec@(1,5) (61.2%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:29:26] \u001b[32mTrain: [ 34/50] Step 520/520 Loss 1.929 Prec@(1,5) (61.2%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:29:26] \u001b[32mTrain: [ 34/50] Final Prec@1 61.1520%\u001b[0m\n",
            "[2024-04-02 19:29:30] \u001b[32mValid: [ 34/50] Step 000/104 Loss 1.893 Prec@(1,5) (65.6%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:29:30] \u001b[32mValid: [ 34/50] Step 020/104 Loss 2.073 Prec@(1,5) (56.6%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:29:30] \u001b[32mValid: [ 34/50] Step 040/104 Loss 2.038 Prec@(1,5) (56.9%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:29:31] \u001b[32mValid: [ 34/50] Step 060/104 Loss 1.992 Prec@(1,5) (57.2%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:29:31] \u001b[32mValid: [ 34/50] Step 080/104 Loss 2.002 Prec@(1,5) (56.8%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:29:31] \u001b[32mValid: [ 34/50] Step 100/104 Loss 1.989 Prec@(1,5) (57.0%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:29:31] \u001b[32mValid: [ 34/50] Step 104/104 Loss 1.989 Prec@(1,5) (56.9%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:29:31] \u001b[32mValid: [ 34/50] Final Prec@1 56.9300%\u001b[0m\n",
            "[2024-04-02 19:29:31] \u001b[32mEpoch 34 LR 0.005803\u001b[0m\n",
            "[2024-04-02 19:29:36] \u001b[32mTrain: [ 35/50] Step 000/520 Loss 1.657 Prec@(1,5) (66.7%, 90.6%)\u001b[0m\n",
            "[2024-04-02 19:29:36] \u001b[32mTrain: [ 35/50] Step 020/520 Loss 1.900 Prec@(1,5) (62.6%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:29:37] \u001b[32mTrain: [ 35/50] Step 040/520 Loss 1.872 Prec@(1,5) (62.7%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:29:37] \u001b[32mTrain: [ 35/50] Step 060/520 Loss 1.892 Prec@(1,5) (62.2%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:29:38] \u001b[32mTrain: [ 35/50] Step 080/520 Loss 1.907 Prec@(1,5) (61.9%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:29:38] \u001b[32mTrain: [ 35/50] Step 100/520 Loss 1.888 Prec@(1,5) (62.3%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:29:39] \u001b[32mTrain: [ 35/50] Step 120/520 Loss 1.883 Prec@(1,5) (62.2%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:29:39] \u001b[32mTrain: [ 35/50] Step 140/520 Loss 1.882 Prec@(1,5) (62.2%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:29:40] \u001b[32mTrain: [ 35/50] Step 160/520 Loss 1.883 Prec@(1,5) (62.3%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:29:40] \u001b[32mTrain: [ 35/50] Step 180/520 Loss 1.885 Prec@(1,5) (62.2%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:29:41] \u001b[32mTrain: [ 35/50] Step 200/520 Loss 1.892 Prec@(1,5) (62.1%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:29:41] \u001b[32mTrain: [ 35/50] Step 220/520 Loss 1.889 Prec@(1,5) (62.2%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:29:42] \u001b[32mTrain: [ 35/50] Step 240/520 Loss 1.890 Prec@(1,5) (62.2%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:29:42] \u001b[32mTrain: [ 35/50] Step 260/520 Loss 1.892 Prec@(1,5) (62.1%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:29:43] \u001b[32mTrain: [ 35/50] Step 280/520 Loss 1.898 Prec@(1,5) (62.0%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:29:43] \u001b[32mTrain: [ 35/50] Step 300/520 Loss 1.897 Prec@(1,5) (62.0%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:29:44] \u001b[32mTrain: [ 35/50] Step 320/520 Loss 1.896 Prec@(1,5) (62.0%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:29:44] \u001b[32mTrain: [ 35/50] Step 340/520 Loss 1.895 Prec@(1,5) (62.0%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:29:45] \u001b[32mTrain: [ 35/50] Step 360/520 Loss 1.896 Prec@(1,5) (61.9%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:29:45] \u001b[32mTrain: [ 35/50] Step 380/520 Loss 1.895 Prec@(1,5) (61.9%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:29:46] \u001b[32mTrain: [ 35/50] Step 400/520 Loss 1.896 Prec@(1,5) (61.9%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:29:46] \u001b[32mTrain: [ 35/50] Step 420/520 Loss 1.895 Prec@(1,5) (61.9%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:29:47] \u001b[32mTrain: [ 35/50] Step 440/520 Loss 1.894 Prec@(1,5) (61.9%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:29:47] \u001b[32mTrain: [ 35/50] Step 460/520 Loss 1.893 Prec@(1,5) (61.9%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:29:48] \u001b[32mTrain: [ 35/50] Step 480/520 Loss 1.894 Prec@(1,5) (61.9%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:29:48] \u001b[32mTrain: [ 35/50] Step 500/520 Loss 1.897 Prec@(1,5) (61.8%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:29:49] \u001b[32mTrain: [ 35/50] Step 520/520 Loss 1.898 Prec@(1,5) (61.7%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:29:49] \u001b[32mTrain: [ 35/50] Final Prec@1 61.7380%\u001b[0m\n",
            "[2024-04-02 19:29:52] \u001b[32mValid: [ 35/50] Step 000/104 Loss 1.898 Prec@(1,5) (62.5%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:29:52] \u001b[32mValid: [ 35/50] Step 020/104 Loss 2.045 Prec@(1,5) (57.8%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:29:53] \u001b[32mValid: [ 35/50] Step 040/104 Loss 2.032 Prec@(1,5) (57.4%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:29:53] \u001b[32mValid: [ 35/50] Step 060/104 Loss 1.995 Prec@(1,5) (57.7%, 85.0%)\u001b[0m\n",
            "[2024-04-02 19:29:53] \u001b[32mValid: [ 35/50] Step 080/104 Loss 1.996 Prec@(1,5) (57.5%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:29:53] \u001b[32mValid: [ 35/50] Step 100/104 Loss 1.976 Prec@(1,5) (57.9%, 85.2%)\u001b[0m\n",
            "[2024-04-02 19:29:53] \u001b[32mValid: [ 35/50] Step 104/104 Loss 1.979 Prec@(1,5) (57.9%, 85.2%)\u001b[0m\n",
            "[2024-04-02 19:29:53] \u001b[32mValid: [ 35/50] Final Prec@1 57.8800%\u001b[0m\n",
            "[2024-04-02 19:29:53] \u001b[32mEpoch 35 LR 0.005153\u001b[0m\n",
            "[2024-04-02 19:29:58] \u001b[32mTrain: [ 36/50] Step 000/520 Loss 1.869 Prec@(1,5) (58.3%, 91.7%)\u001b[0m\n",
            "[2024-04-02 19:29:58] \u001b[32mTrain: [ 36/50] Step 020/520 Loss 1.767 Prec@(1,5) (64.6%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:29:59] \u001b[32mTrain: [ 36/50] Step 040/520 Loss 1.769 Prec@(1,5) (64.5%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:29:59] \u001b[32mTrain: [ 36/50] Step 060/520 Loss 1.790 Prec@(1,5) (64.0%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:30:00] \u001b[32mTrain: [ 36/50] Step 080/520 Loss 1.807 Prec@(1,5) (63.6%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:30:00] \u001b[32mTrain: [ 36/50] Step 100/520 Loss 1.812 Prec@(1,5) (63.5%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:30:01] \u001b[32mTrain: [ 36/50] Step 120/520 Loss 1.822 Prec@(1,5) (63.3%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:30:01] \u001b[32mTrain: [ 36/50] Step 140/520 Loss 1.838 Prec@(1,5) (62.9%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:30:02] \u001b[32mTrain: [ 36/50] Step 160/520 Loss 1.857 Prec@(1,5) (62.8%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:30:02] \u001b[32mTrain: [ 36/50] Step 180/520 Loss 1.853 Prec@(1,5) (62.9%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:30:03] \u001b[32mTrain: [ 36/50] Step 200/520 Loss 1.854 Prec@(1,5) (62.9%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:30:03] \u001b[32mTrain: [ 36/50] Step 220/520 Loss 1.856 Prec@(1,5) (62.9%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:30:04] \u001b[32mTrain: [ 36/50] Step 240/520 Loss 1.855 Prec@(1,5) (62.9%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:30:04] \u001b[32mTrain: [ 36/50] Step 260/520 Loss 1.857 Prec@(1,5) (62.8%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:30:05] \u001b[32mTrain: [ 36/50] Step 280/520 Loss 1.856 Prec@(1,5) (62.9%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:30:05] \u001b[32mTrain: [ 36/50] Step 300/520 Loss 1.856 Prec@(1,5) (62.8%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:30:06] \u001b[32mTrain: [ 36/50] Step 320/520 Loss 1.862 Prec@(1,5) (62.7%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:30:06] \u001b[32mTrain: [ 36/50] Step 340/520 Loss 1.862 Prec@(1,5) (62.8%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:30:07] \u001b[32mTrain: [ 36/50] Step 360/520 Loss 1.865 Prec@(1,5) (62.7%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:30:07] \u001b[32mTrain: [ 36/50] Step 380/520 Loss 1.867 Prec@(1,5) (62.7%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:30:08] \u001b[32mTrain: [ 36/50] Step 400/520 Loss 1.870 Prec@(1,5) (62.5%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:30:08] \u001b[32mTrain: [ 36/50] Step 420/520 Loss 1.872 Prec@(1,5) (62.4%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:30:09] \u001b[32mTrain: [ 36/50] Step 440/520 Loss 1.872 Prec@(1,5) (62.5%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:30:09] \u001b[32mTrain: [ 36/50] Step 460/520 Loss 1.871 Prec@(1,5) (62.5%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:30:10] \u001b[32mTrain: [ 36/50] Step 480/520 Loss 1.871 Prec@(1,5) (62.5%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:30:10] \u001b[32mTrain: [ 36/50] Step 500/520 Loss 1.872 Prec@(1,5) (62.5%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:30:11] \u001b[32mTrain: [ 36/50] Step 520/520 Loss 1.876 Prec@(1,5) (62.4%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:30:11] \u001b[32mTrain: [ 36/50] Final Prec@1 62.3800%\u001b[0m\n",
            "[2024-04-02 19:30:14] \u001b[32mValid: [ 36/50] Step 000/104 Loss 1.948 Prec@(1,5) (63.5%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:30:15] \u001b[32mValid: [ 36/50] Step 020/104 Loss 2.018 Prec@(1,5) (58.1%, 85.0%)\u001b[0m\n",
            "[2024-04-02 19:30:15] \u001b[32mValid: [ 36/50] Step 040/104 Loss 1.959 Prec@(1,5) (58.1%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:30:15] \u001b[32mValid: [ 36/50] Step 060/104 Loss 1.924 Prec@(1,5) (58.4%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:30:15] \u001b[32mValid: [ 36/50] Step 080/104 Loss 1.925 Prec@(1,5) (58.3%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:30:15] \u001b[32mValid: [ 36/50] Step 100/104 Loss 1.912 Prec@(1,5) (58.4%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:30:15] \u001b[32mValid: [ 36/50] Step 104/104 Loss 1.918 Prec@(1,5) (58.3%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:30:16] \u001b[32mValid: [ 36/50] Final Prec@1 58.3400%\u001b[0m\n",
            "[2024-04-02 19:30:16] \u001b[32mEpoch 36 LR 0.004533\u001b[0m\n",
            "[2024-04-02 19:30:20] \u001b[32mTrain: [ 37/50] Step 000/520 Loss 1.995 Prec@(1,5) (55.2%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:30:21] \u001b[32mTrain: [ 37/50] Step 020/520 Loss 1.936 Prec@(1,5) (61.1%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:30:21] \u001b[32mTrain: [ 37/50] Step 040/520 Loss 1.892 Prec@(1,5) (61.8%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:30:22] \u001b[32mTrain: [ 37/50] Step 060/520 Loss 1.875 Prec@(1,5) (62.0%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:30:22] \u001b[32mTrain: [ 37/50] Step 080/520 Loss 1.855 Prec@(1,5) (62.6%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:30:23] \u001b[32mTrain: [ 37/50] Step 100/520 Loss 1.858 Prec@(1,5) (62.4%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:30:23] \u001b[32mTrain: [ 37/50] Step 120/520 Loss 1.845 Prec@(1,5) (62.6%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:30:24] \u001b[32mTrain: [ 37/50] Step 140/520 Loss 1.840 Prec@(1,5) (62.7%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:30:24] \u001b[32mTrain: [ 37/50] Step 160/520 Loss 1.831 Prec@(1,5) (63.0%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:30:25] \u001b[32mTrain: [ 37/50] Step 180/520 Loss 1.835 Prec@(1,5) (62.9%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:30:25] \u001b[32mTrain: [ 37/50] Step 200/520 Loss 1.846 Prec@(1,5) (62.7%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:30:26] \u001b[32mTrain: [ 37/50] Step 220/520 Loss 1.842 Prec@(1,5) (62.8%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:30:26] \u001b[32mTrain: [ 37/50] Step 240/520 Loss 1.840 Prec@(1,5) (62.9%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:30:27] \u001b[32mTrain: [ 37/50] Step 260/520 Loss 1.840 Prec@(1,5) (62.9%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:30:27] \u001b[32mTrain: [ 37/50] Step 280/520 Loss 1.844 Prec@(1,5) (62.8%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:30:28] \u001b[32mTrain: [ 37/50] Step 300/520 Loss 1.845 Prec@(1,5) (62.8%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:30:28] \u001b[32mTrain: [ 37/50] Step 320/520 Loss 1.843 Prec@(1,5) (62.9%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:30:29] \u001b[32mTrain: [ 37/50] Step 340/520 Loss 1.843 Prec@(1,5) (62.9%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:30:29] \u001b[32mTrain: [ 37/50] Step 360/520 Loss 1.846 Prec@(1,5) (62.8%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:30:30] \u001b[32mTrain: [ 37/50] Step 380/520 Loss 1.844 Prec@(1,5) (62.8%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:30:30] \u001b[32mTrain: [ 37/50] Step 400/520 Loss 1.846 Prec@(1,5) (62.8%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:30:31] \u001b[32mTrain: [ 37/50] Step 420/520 Loss 1.848 Prec@(1,5) (62.7%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:30:31] \u001b[32mTrain: [ 37/50] Step 440/520 Loss 1.850 Prec@(1,5) (62.7%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:30:32] \u001b[32mTrain: [ 37/50] Step 460/520 Loss 1.853 Prec@(1,5) (62.6%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:30:32] \u001b[32mTrain: [ 37/50] Step 480/520 Loss 1.855 Prec@(1,5) (62.6%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:30:33] \u001b[32mTrain: [ 37/50] Step 500/520 Loss 1.855 Prec@(1,5) (62.7%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:30:33] \u001b[32mTrain: [ 37/50] Step 520/520 Loss 1.857 Prec@(1,5) (62.6%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:30:33] \u001b[32mTrain: [ 37/50] Final Prec@1 62.6080%\u001b[0m\n",
            "[2024-04-02 19:30:37] \u001b[32mValid: [ 37/50] Step 000/104 Loss 1.883 Prec@(1,5) (63.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:30:37] \u001b[32mValid: [ 37/50] Step 020/104 Loss 2.021 Prec@(1,5) (59.5%, 85.0%)\u001b[0m\n",
            "[2024-04-02 19:30:37] \u001b[32mValid: [ 37/50] Step 040/104 Loss 1.998 Prec@(1,5) (58.7%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:30:37] \u001b[32mValid: [ 37/50] Step 060/104 Loss 1.975 Prec@(1,5) (58.6%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:30:37] \u001b[32mValid: [ 37/50] Step 080/104 Loss 1.986 Prec@(1,5) (58.3%, 85.0%)\u001b[0m\n",
            "[2024-04-02 19:30:38] \u001b[32mValid: [ 37/50] Step 100/104 Loss 1.964 Prec@(1,5) (58.7%, 85.3%)\u001b[0m\n",
            "[2024-04-02 19:30:38] \u001b[32mValid: [ 37/50] Step 104/104 Loss 1.965 Prec@(1,5) (58.6%, 85.2%)\u001b[0m\n",
            "[2024-04-02 19:30:38] \u001b[32mValid: [ 37/50] Final Prec@1 58.6300%\u001b[0m\n",
            "[2024-04-02 19:30:38] \u001b[32mEpoch 37 LR 0.003944\u001b[0m\n",
            "[2024-04-02 19:30:42] \u001b[32mTrain: [ 38/50] Step 000/520 Loss 1.360 Prec@(1,5) (69.8%, 95.8%)\u001b[0m\n",
            "[2024-04-02 19:30:43] \u001b[32mTrain: [ 38/50] Step 020/520 Loss 1.843 Prec@(1,5) (61.9%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:30:43] \u001b[32mTrain: [ 38/50] Step 040/520 Loss 1.836 Prec@(1,5) (62.9%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:30:44] \u001b[32mTrain: [ 38/50] Step 060/520 Loss 1.830 Prec@(1,5) (62.6%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:30:44] \u001b[32mTrain: [ 38/50] Step 080/520 Loss 1.838 Prec@(1,5) (62.4%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:30:45] \u001b[32mTrain: [ 38/50] Step 100/520 Loss 1.835 Prec@(1,5) (62.4%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:30:45] \u001b[32mTrain: [ 38/50] Step 120/520 Loss 1.826 Prec@(1,5) (62.7%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:30:46] \u001b[32mTrain: [ 38/50] Step 140/520 Loss 1.830 Prec@(1,5) (62.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:30:46] \u001b[32mTrain: [ 38/50] Step 160/520 Loss 1.838 Prec@(1,5) (62.5%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:30:47] \u001b[32mTrain: [ 38/50] Step 180/520 Loss 1.835 Prec@(1,5) (62.8%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:30:47] \u001b[32mTrain: [ 38/50] Step 200/520 Loss 1.838 Prec@(1,5) (62.7%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:30:48] \u001b[32mTrain: [ 38/50] Step 220/520 Loss 1.839 Prec@(1,5) (62.7%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:30:48] \u001b[32mTrain: [ 38/50] Step 240/520 Loss 1.837 Prec@(1,5) (62.7%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:30:49] \u001b[32mTrain: [ 38/50] Step 260/520 Loss 1.840 Prec@(1,5) (62.6%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:30:49] \u001b[32mTrain: [ 38/50] Step 280/520 Loss 1.835 Prec@(1,5) (62.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:30:50] \u001b[32mTrain: [ 38/50] Step 300/520 Loss 1.834 Prec@(1,5) (62.8%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:30:50] \u001b[32mTrain: [ 38/50] Step 320/520 Loss 1.838 Prec@(1,5) (62.7%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:30:51] \u001b[32mTrain: [ 38/50] Step 340/520 Loss 1.835 Prec@(1,5) (62.8%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:30:51] \u001b[32mTrain: [ 38/50] Step 360/520 Loss 1.835 Prec@(1,5) (62.8%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:30:52] \u001b[32mTrain: [ 38/50] Step 380/520 Loss 1.833 Prec@(1,5) (62.8%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:30:52] \u001b[32mTrain: [ 38/50] Step 400/520 Loss 1.836 Prec@(1,5) (62.8%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:30:53] \u001b[32mTrain: [ 38/50] Step 420/520 Loss 1.837 Prec@(1,5) (62.8%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:30:53] \u001b[32mTrain: [ 38/50] Step 440/520 Loss 1.839 Prec@(1,5) (62.8%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:30:54] \u001b[32mTrain: [ 38/50] Step 460/520 Loss 1.840 Prec@(1,5) (62.7%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:30:54] \u001b[32mTrain: [ 38/50] Step 480/520 Loss 1.843 Prec@(1,5) (62.6%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:30:55] \u001b[32mTrain: [ 38/50] Step 500/520 Loss 1.841 Prec@(1,5) (62.7%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:30:55] \u001b[32mTrain: [ 38/50] Step 520/520 Loss 1.841 Prec@(1,5) (62.7%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:30:56] \u001b[32mTrain: [ 38/50] Final Prec@1 62.6640%\u001b[0m\n",
            "[2024-04-02 19:30:59] \u001b[32mValid: [ 38/50] Step 000/104 Loss 1.800 Prec@(1,5) (63.5%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:30:59] \u001b[32mValid: [ 38/50] Step 020/104 Loss 1.957 Prec@(1,5) (58.8%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:30:59] \u001b[32mValid: [ 38/50] Step 040/104 Loss 1.946 Prec@(1,5) (58.6%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:31:00] \u001b[32mValid: [ 38/50] Step 060/104 Loss 1.920 Prec@(1,5) (58.8%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:31:00] \u001b[32mValid: [ 38/50] Step 080/104 Loss 1.921 Prec@(1,5) (58.7%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:31:00] \u001b[32mValid: [ 38/50] Step 100/104 Loss 1.903 Prec@(1,5) (58.8%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:31:00] \u001b[32mValid: [ 38/50] Step 104/104 Loss 1.902 Prec@(1,5) (58.8%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:31:00] \u001b[32mValid: [ 38/50] Final Prec@1 58.7700%\u001b[0m\n",
            "[2024-04-02 19:31:00] \u001b[32mEpoch 38 LR 0.003389\u001b[0m\n",
            "[2024-04-02 19:31:05] \u001b[32mTrain: [ 39/50] Step 000/520 Loss 1.835 Prec@(1,5) (62.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:31:05] \u001b[32mTrain: [ 39/50] Step 020/520 Loss 1.823 Prec@(1,5) (64.0%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:31:06] \u001b[32mTrain: [ 39/50] Step 040/520 Loss 1.812 Prec@(1,5) (63.5%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:31:06] \u001b[32mTrain: [ 39/50] Step 060/520 Loss 1.813 Prec@(1,5) (63.4%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:31:07] \u001b[32mTrain: [ 39/50] Step 080/520 Loss 1.789 Prec@(1,5) (63.8%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:31:07] \u001b[32mTrain: [ 39/50] Step 100/520 Loss 1.792 Prec@(1,5) (63.7%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:31:08] \u001b[32mTrain: [ 39/50] Step 120/520 Loss 1.797 Prec@(1,5) (63.6%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:31:08] \u001b[32mTrain: [ 39/50] Step 140/520 Loss 1.802 Prec@(1,5) (63.6%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:31:09] \u001b[32mTrain: [ 39/50] Step 160/520 Loss 1.801 Prec@(1,5) (63.7%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:31:09] \u001b[32mTrain: [ 39/50] Step 180/520 Loss 1.796 Prec@(1,5) (63.7%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:31:10] \u001b[32mTrain: [ 39/50] Step 200/520 Loss 1.792 Prec@(1,5) (63.8%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:31:10] \u001b[32mTrain: [ 39/50] Step 220/520 Loss 1.794 Prec@(1,5) (63.7%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:31:11] \u001b[32mTrain: [ 39/50] Step 240/520 Loss 1.795 Prec@(1,5) (63.7%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:31:11] \u001b[32mTrain: [ 39/50] Step 260/520 Loss 1.800 Prec@(1,5) (63.5%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:31:12] \u001b[32mTrain: [ 39/50] Step 280/520 Loss 1.795 Prec@(1,5) (63.7%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:31:12] \u001b[32mTrain: [ 39/50] Step 300/520 Loss 1.794 Prec@(1,5) (63.7%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:31:13] \u001b[32mTrain: [ 39/50] Step 320/520 Loss 1.796 Prec@(1,5) (63.7%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:31:13] \u001b[32mTrain: [ 39/50] Step 340/520 Loss 1.798 Prec@(1,5) (63.6%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:31:14] \u001b[32mTrain: [ 39/50] Step 360/520 Loss 1.799 Prec@(1,5) (63.7%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:31:14] \u001b[32mTrain: [ 39/50] Step 380/520 Loss 1.800 Prec@(1,5) (63.7%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:31:15] \u001b[32mTrain: [ 39/50] Step 400/520 Loss 1.802 Prec@(1,5) (63.6%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:31:15] \u001b[32mTrain: [ 39/50] Step 420/520 Loss 1.805 Prec@(1,5) (63.5%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:31:16] \u001b[32mTrain: [ 39/50] Step 440/520 Loss 1.809 Prec@(1,5) (63.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:31:16] \u001b[32mTrain: [ 39/50] Step 460/520 Loss 1.810 Prec@(1,5) (63.5%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:31:17] \u001b[32mTrain: [ 39/50] Step 480/520 Loss 1.808 Prec@(1,5) (63.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:31:17] \u001b[32mTrain: [ 39/50] Step 500/520 Loss 1.808 Prec@(1,5) (63.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:31:18] \u001b[32mTrain: [ 39/50] Step 520/520 Loss 1.811 Prec@(1,5) (63.5%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:31:18] \u001b[32mTrain: [ 39/50] Final Prec@1 63.4700%\u001b[0m\n",
            "[2024-04-02 19:31:21] \u001b[32mValid: [ 39/50] Step 000/104 Loss 2.020 Prec@(1,5) (61.5%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:31:21] \u001b[32mValid: [ 39/50] Step 020/104 Loss 2.028 Prec@(1,5) (58.4%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:31:22] \u001b[32mValid: [ 39/50] Step 040/104 Loss 1.990 Prec@(1,5) (58.3%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:31:22] \u001b[32mValid: [ 39/50] Step 060/104 Loss 1.951 Prec@(1,5) (58.5%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:31:22] \u001b[32mValid: [ 39/50] Step 080/104 Loss 1.948 Prec@(1,5) (58.5%, 86.1%)\u001b[0m\n",
            "[2024-04-02 19:31:22] \u001b[32mValid: [ 39/50] Step 100/104 Loss 1.932 Prec@(1,5) (58.6%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:31:22] \u001b[32mValid: [ 39/50] Step 104/104 Loss 1.934 Prec@(1,5) (58.6%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:31:22] \u001b[32mValid: [ 39/50] Final Prec@1 58.6100%\u001b[0m\n",
            "[2024-04-02 19:31:22] \u001b[32mEpoch 39 LR 0.002869\u001b[0m\n",
            "[2024-04-02 19:31:27] \u001b[32mTrain: [ 40/50] Step 000/520 Loss 2.165 Prec@(1,5) (59.4%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:31:27] \u001b[32mTrain: [ 40/50] Step 020/520 Loss 1.834 Prec@(1,5) (64.1%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:31:28] \u001b[32mTrain: [ 40/50] Step 040/520 Loss 1.776 Prec@(1,5) (64.4%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:31:28] \u001b[32mTrain: [ 40/50] Step 060/520 Loss 1.788 Prec@(1,5) (64.1%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:31:29] \u001b[32mTrain: [ 40/50] Step 080/520 Loss 1.788 Prec@(1,5) (63.8%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:31:29] \u001b[32mTrain: [ 40/50] Step 100/520 Loss 1.782 Prec@(1,5) (63.9%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:31:30] \u001b[32mTrain: [ 40/50] Step 120/520 Loss 1.785 Prec@(1,5) (63.9%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:31:30] \u001b[32mTrain: [ 40/50] Step 140/520 Loss 1.779 Prec@(1,5) (64.1%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:31:31] \u001b[32mTrain: [ 40/50] Step 160/520 Loss 1.784 Prec@(1,5) (63.9%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:31:31] \u001b[32mTrain: [ 40/50] Step 180/520 Loss 1.789 Prec@(1,5) (63.7%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:31:32] \u001b[32mTrain: [ 40/50] Step 200/520 Loss 1.792 Prec@(1,5) (63.7%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:31:32] \u001b[32mTrain: [ 40/50] Step 220/520 Loss 1.793 Prec@(1,5) (63.6%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:31:33] \u001b[32mTrain: [ 40/50] Step 240/520 Loss 1.793 Prec@(1,5) (63.6%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:31:33] \u001b[32mTrain: [ 40/50] Step 260/520 Loss 1.798 Prec@(1,5) (63.6%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:31:34] \u001b[32mTrain: [ 40/50] Step 280/520 Loss 1.796 Prec@(1,5) (63.7%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:31:34] \u001b[32mTrain: [ 40/50] Step 300/520 Loss 1.793 Prec@(1,5) (63.7%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:31:35] \u001b[32mTrain: [ 40/50] Step 320/520 Loss 1.791 Prec@(1,5) (63.7%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:31:35] \u001b[32mTrain: [ 40/50] Step 340/520 Loss 1.787 Prec@(1,5) (63.7%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:31:36] \u001b[32mTrain: [ 40/50] Step 360/520 Loss 1.786 Prec@(1,5) (63.7%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:31:36] \u001b[32mTrain: [ 40/50] Step 380/520 Loss 1.788 Prec@(1,5) (63.7%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:31:37] \u001b[32mTrain: [ 40/50] Step 400/520 Loss 1.787 Prec@(1,5) (63.8%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:31:37] \u001b[32mTrain: [ 40/50] Step 420/520 Loss 1.785 Prec@(1,5) (63.9%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:31:38] \u001b[32mTrain: [ 40/50] Step 440/520 Loss 1.787 Prec@(1,5) (63.8%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:31:38] \u001b[32mTrain: [ 40/50] Step 460/520 Loss 1.790 Prec@(1,5) (63.8%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:31:39] \u001b[32mTrain: [ 40/50] Step 480/520 Loss 1.789 Prec@(1,5) (63.8%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:31:39] \u001b[32mTrain: [ 40/50] Step 500/520 Loss 1.790 Prec@(1,5) (63.7%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:31:40] \u001b[32mTrain: [ 40/50] Step 520/520 Loss 1.793 Prec@(1,5) (63.7%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:31:40] \u001b[32mTrain: [ 40/50] Final Prec@1 63.6860%\u001b[0m\n",
            "[2024-04-02 19:31:43] \u001b[32mValid: [ 40/50] Step 000/104 Loss 1.864 Prec@(1,5) (64.6%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:31:44] \u001b[32mValid: [ 40/50] Step 020/104 Loss 1.926 Prec@(1,5) (59.4%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:31:44] \u001b[32mValid: [ 40/50] Step 040/104 Loss 1.904 Prec@(1,5) (58.9%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:31:44] \u001b[32mValid: [ 40/50] Step 060/104 Loss 1.873 Prec@(1,5) (59.2%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:31:44] \u001b[32mValid: [ 40/50] Step 080/104 Loss 1.872 Prec@(1,5) (59.1%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:31:44] \u001b[32mValid: [ 40/50] Step 100/104 Loss 1.855 Prec@(1,5) (59.6%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:31:44] \u001b[32mValid: [ 40/50] Step 104/104 Loss 1.856 Prec@(1,5) (59.5%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:31:45] \u001b[32mValid: [ 40/50] Final Prec@1 59.5000%\u001b[0m\n",
            "[2024-04-02 19:31:45] \u001b[32mEpoch 40 LR 0.002388\u001b[0m\n",
            "[2024-04-02 19:31:49] \u001b[32mTrain: [ 41/50] Step 000/520 Loss 1.972 Prec@(1,5) (63.5%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:31:50] \u001b[32mTrain: [ 41/50] Step 020/520 Loss 1.820 Prec@(1,5) (62.5%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:31:50] \u001b[32mTrain: [ 41/50] Step 040/520 Loss 1.768 Prec@(1,5) (64.0%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:31:51] \u001b[32mTrain: [ 41/50] Step 060/520 Loss 1.783 Prec@(1,5) (63.7%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:31:51] \u001b[32mTrain: [ 41/50] Step 080/520 Loss 1.767 Prec@(1,5) (64.0%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:31:52] \u001b[32mTrain: [ 41/50] Step 100/520 Loss 1.763 Prec@(1,5) (64.0%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:31:52] \u001b[32mTrain: [ 41/50] Step 120/520 Loss 1.768 Prec@(1,5) (64.0%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:31:53] \u001b[32mTrain: [ 41/50] Step 140/520 Loss 1.758 Prec@(1,5) (64.2%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:31:53] \u001b[32mTrain: [ 41/50] Step 160/520 Loss 1.754 Prec@(1,5) (64.3%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:31:54] \u001b[32mTrain: [ 41/50] Step 180/520 Loss 1.752 Prec@(1,5) (64.4%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:31:54] \u001b[32mTrain: [ 41/50] Step 200/520 Loss 1.751 Prec@(1,5) (64.4%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:31:55] \u001b[32mTrain: [ 41/50] Step 220/520 Loss 1.755 Prec@(1,5) (64.4%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:31:55] \u001b[32mTrain: [ 41/50] Step 240/520 Loss 1.759 Prec@(1,5) (64.2%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:31:56] \u001b[32mTrain: [ 41/50] Step 260/520 Loss 1.761 Prec@(1,5) (64.1%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:31:56] \u001b[32mTrain: [ 41/50] Step 280/520 Loss 1.764 Prec@(1,5) (63.9%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:31:57] \u001b[32mTrain: [ 41/50] Step 300/520 Loss 1.762 Prec@(1,5) (64.0%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:31:57] \u001b[32mTrain: [ 41/50] Step 320/520 Loss 1.768 Prec@(1,5) (63.9%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:31:58] \u001b[32mTrain: [ 41/50] Step 340/520 Loss 1.768 Prec@(1,5) (63.9%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:31:58] \u001b[32mTrain: [ 41/50] Step 360/520 Loss 1.771 Prec@(1,5) (63.9%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:31:58] \u001b[32mTrain: [ 41/50] Step 380/520 Loss 1.774 Prec@(1,5) (63.9%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:31:59] \u001b[32mTrain: [ 41/50] Step 400/520 Loss 1.776 Prec@(1,5) (63.9%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:31:59] \u001b[32mTrain: [ 41/50] Step 420/520 Loss 1.778 Prec@(1,5) (63.8%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:32:00] \u001b[32mTrain: [ 41/50] Step 440/520 Loss 1.780 Prec@(1,5) (63.8%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:32:00] \u001b[32mTrain: [ 41/50] Step 460/520 Loss 1.778 Prec@(1,5) (63.9%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:32:01] \u001b[32mTrain: [ 41/50] Step 480/520 Loss 1.780 Prec@(1,5) (63.9%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:32:01] \u001b[32mTrain: [ 41/50] Step 500/520 Loss 1.776 Prec@(1,5) (64.0%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:32:02] \u001b[32mTrain: [ 41/50] Step 520/520 Loss 1.776 Prec@(1,5) (64.0%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:32:02] \u001b[32mTrain: [ 41/50] Final Prec@1 64.0320%\u001b[0m\n",
            "[2024-04-02 19:32:06] \u001b[32mValid: [ 41/50] Step 000/104 Loss 1.829 Prec@(1,5) (64.6%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:32:06] \u001b[32mValid: [ 41/50] Step 020/104 Loss 1.925 Prec@(1,5) (60.6%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:32:06] \u001b[32mValid: [ 41/50] Step 040/104 Loss 1.898 Prec@(1,5) (60.1%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:32:06] \u001b[32mValid: [ 41/50] Step 060/104 Loss 1.862 Prec@(1,5) (60.2%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:32:06] \u001b[32mValid: [ 41/50] Step 080/104 Loss 1.863 Prec@(1,5) (60.1%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:32:06] \u001b[32mValid: [ 41/50] Step 100/104 Loss 1.842 Prec@(1,5) (60.2%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:32:07] \u001b[32mValid: [ 41/50] Step 104/104 Loss 1.845 Prec@(1,5) (60.2%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:32:07] \u001b[32mValid: [ 41/50] Final Prec@1 60.1800%\u001b[0m\n",
            "[2024-04-02 19:32:07] \u001b[32mEpoch 41 LR 0.001947\u001b[0m\n",
            "[2024-04-02 19:32:11] \u001b[32mTrain: [ 42/50] Step 000/520 Loss 1.227 Prec@(1,5) (75.0%, 93.8%)\u001b[0m\n",
            "[2024-04-02 19:32:12] \u001b[32mTrain: [ 42/50] Step 020/520 Loss 1.759 Prec@(1,5) (65.0%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:32:12] \u001b[32mTrain: [ 42/50] Step 040/520 Loss 1.777 Prec@(1,5) (63.6%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:32:13] \u001b[32mTrain: [ 42/50] Step 060/520 Loss 1.733 Prec@(1,5) (64.3%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:32:13] \u001b[32mTrain: [ 42/50] Step 080/520 Loss 1.743 Prec@(1,5) (64.2%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:32:14] \u001b[32mTrain: [ 42/50] Step 100/520 Loss 1.748 Prec@(1,5) (64.1%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:32:14] \u001b[32mTrain: [ 42/50] Step 120/520 Loss 1.741 Prec@(1,5) (64.4%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:32:15] \u001b[32mTrain: [ 42/50] Step 140/520 Loss 1.749 Prec@(1,5) (64.4%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:32:15] \u001b[32mTrain: [ 42/50] Step 160/520 Loss 1.758 Prec@(1,5) (64.3%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:32:16] \u001b[32mTrain: [ 42/50] Step 180/520 Loss 1.756 Prec@(1,5) (64.3%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:32:16] \u001b[32mTrain: [ 42/50] Step 200/520 Loss 1.759 Prec@(1,5) (64.5%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:32:17] \u001b[32mTrain: [ 42/50] Step 220/520 Loss 1.764 Prec@(1,5) (64.4%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:32:17] \u001b[32mTrain: [ 42/50] Step 240/520 Loss 1.764 Prec@(1,5) (64.4%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:32:18] \u001b[32mTrain: [ 42/50] Step 260/520 Loss 1.768 Prec@(1,5) (64.3%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:32:18] \u001b[32mTrain: [ 42/50] Step 280/520 Loss 1.766 Prec@(1,5) (64.3%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:32:19] \u001b[32mTrain: [ 42/50] Step 300/520 Loss 1.767 Prec@(1,5) (64.3%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:32:19] \u001b[32mTrain: [ 42/50] Step 320/520 Loss 1.768 Prec@(1,5) (64.3%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:32:20] \u001b[32mTrain: [ 42/50] Step 340/520 Loss 1.769 Prec@(1,5) (64.2%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:32:20] \u001b[32mTrain: [ 42/50] Step 360/520 Loss 1.762 Prec@(1,5) (64.3%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:32:21] \u001b[32mTrain: [ 42/50] Step 380/520 Loss 1.764 Prec@(1,5) (64.3%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:32:21] \u001b[32mTrain: [ 42/50] Step 400/520 Loss 1.760 Prec@(1,5) (64.3%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:32:22] \u001b[32mTrain: [ 42/50] Step 420/520 Loss 1.761 Prec@(1,5) (64.3%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:32:22] \u001b[32mTrain: [ 42/50] Step 440/520 Loss 1.762 Prec@(1,5) (64.2%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:32:23] \u001b[32mTrain: [ 42/50] Step 460/520 Loss 1.759 Prec@(1,5) (64.2%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:32:23] \u001b[32mTrain: [ 42/50] Step 480/520 Loss 1.758 Prec@(1,5) (64.2%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:32:24] \u001b[32mTrain: [ 42/50] Step 500/520 Loss 1.757 Prec@(1,5) (64.3%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:32:24] \u001b[32mTrain: [ 42/50] Step 520/520 Loss 1.753 Prec@(1,5) (64.3%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:32:24] \u001b[32mTrain: [ 42/50] Final Prec@1 64.3360%\u001b[0m\n",
            "[2024-04-02 19:32:28] \u001b[32mValid: [ 42/50] Step 000/104 Loss 1.835 Prec@(1,5) (65.6%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:32:28] \u001b[32mValid: [ 42/50] Step 020/104 Loss 1.943 Prec@(1,5) (59.4%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:32:28] \u001b[32mValid: [ 42/50] Step 040/104 Loss 1.926 Prec@(1,5) (59.3%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:32:28] \u001b[32mValid: [ 42/50] Step 060/104 Loss 1.890 Prec@(1,5) (59.7%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:32:29] \u001b[32mValid: [ 42/50] Step 080/104 Loss 1.888 Prec@(1,5) (59.5%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:32:29] \u001b[32mValid: [ 42/50] Step 100/104 Loss 1.872 Prec@(1,5) (59.9%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:32:29] \u001b[32mValid: [ 42/50] Step 104/104 Loss 1.874 Prec@(1,5) (59.9%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:32:29] \u001b[32mValid: [ 42/50] Final Prec@1 59.9000%\u001b[0m\n",
            "[2024-04-02 19:32:29] \u001b[32mEpoch 42 LR 0.001547\u001b[0m\n",
            "[2024-04-02 19:32:34] \u001b[32mTrain: [ 43/50] Step 000/520 Loss 1.821 Prec@(1,5) (61.5%, 91.7%)\u001b[0m\n",
            "[2024-04-02 19:32:34] \u001b[32mTrain: [ 43/50] Step 020/520 Loss 1.717 Prec@(1,5) (66.2%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:32:35] \u001b[32mTrain: [ 43/50] Step 040/520 Loss 1.784 Prec@(1,5) (64.3%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:32:35] \u001b[32mTrain: [ 43/50] Step 060/520 Loss 1.778 Prec@(1,5) (64.2%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:32:36] \u001b[32mTrain: [ 43/50] Step 080/520 Loss 1.764 Prec@(1,5) (64.4%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:32:36] \u001b[32mTrain: [ 43/50] Step 100/520 Loss 1.764 Prec@(1,5) (64.5%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:32:37] \u001b[32mTrain: [ 43/50] Step 120/520 Loss 1.755 Prec@(1,5) (64.5%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:32:37] \u001b[32mTrain: [ 43/50] Step 140/520 Loss 1.756 Prec@(1,5) (64.6%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:32:38] \u001b[32mTrain: [ 43/50] Step 160/520 Loss 1.759 Prec@(1,5) (64.4%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:32:38] \u001b[32mTrain: [ 43/50] Step 180/520 Loss 1.757 Prec@(1,5) (64.4%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:32:39] \u001b[32mTrain: [ 43/50] Step 200/520 Loss 1.752 Prec@(1,5) (64.6%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:32:39] \u001b[32mTrain: [ 43/50] Step 220/520 Loss 1.751 Prec@(1,5) (64.6%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:32:40] \u001b[32mTrain: [ 43/50] Step 240/520 Loss 1.747 Prec@(1,5) (64.7%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:32:40] \u001b[32mTrain: [ 43/50] Step 260/520 Loss 1.750 Prec@(1,5) (64.6%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:32:41] \u001b[32mTrain: [ 43/50] Step 280/520 Loss 1.751 Prec@(1,5) (64.6%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:32:41] \u001b[32mTrain: [ 43/50] Step 300/520 Loss 1.754 Prec@(1,5) (64.5%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:32:42] \u001b[32mTrain: [ 43/50] Step 320/520 Loss 1.752 Prec@(1,5) (64.5%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:32:42] \u001b[32mTrain: [ 43/50] Step 340/520 Loss 1.754 Prec@(1,5) (64.5%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:32:43] \u001b[32mTrain: [ 43/50] Step 360/520 Loss 1.748 Prec@(1,5) (64.7%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:32:43] \u001b[32mTrain: [ 43/50] Step 380/520 Loss 1.749 Prec@(1,5) (64.7%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:32:44] \u001b[32mTrain: [ 43/50] Step 400/520 Loss 1.753 Prec@(1,5) (64.7%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:32:44] \u001b[32mTrain: [ 43/50] Step 420/520 Loss 1.751 Prec@(1,5) (64.7%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:32:45] \u001b[32mTrain: [ 43/50] Step 440/520 Loss 1.749 Prec@(1,5) (64.8%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:32:45] \u001b[32mTrain: [ 43/50] Step 460/520 Loss 1.750 Prec@(1,5) (64.7%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:32:46] \u001b[32mTrain: [ 43/50] Step 480/520 Loss 1.751 Prec@(1,5) (64.7%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:32:46] \u001b[32mTrain: [ 43/50] Step 500/520 Loss 1.750 Prec@(1,5) (64.7%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:32:47] \u001b[32mTrain: [ 43/50] Step 520/520 Loss 1.748 Prec@(1,5) (64.7%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:32:47] \u001b[32mTrain: [ 43/50] Final Prec@1 64.7120%\u001b[0m\n",
            "[2024-04-02 19:32:51] \u001b[32mValid: [ 43/50] Step 000/104 Loss 1.743 Prec@(1,5) (61.5%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:32:51] \u001b[32mValid: [ 43/50] Step 020/104 Loss 1.909 Prec@(1,5) (60.1%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:32:51] \u001b[32mValid: [ 43/50] Step 040/104 Loss 1.883 Prec@(1,5) (59.8%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:32:51] \u001b[32mValid: [ 43/50] Step 060/104 Loss 1.853 Prec@(1,5) (60.1%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:32:51] \u001b[32mValid: [ 43/50] Step 080/104 Loss 1.853 Prec@(1,5) (60.0%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:32:52] \u001b[32mValid: [ 43/50] Step 100/104 Loss 1.834 Prec@(1,5) (60.5%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:32:52] \u001b[32mValid: [ 43/50] Step 104/104 Loss 1.836 Prec@(1,5) (60.4%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:32:52] \u001b[32mValid: [ 43/50] Final Prec@1 60.4300%\u001b[0m\n",
            "[2024-04-02 19:32:52] \u001b[32mEpoch 43 LR 0.001191\u001b[0m\n",
            "[2024-04-02 19:32:56] \u001b[32mTrain: [ 44/50] Step 000/520 Loss 1.820 Prec@(1,5) (66.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:32:57] \u001b[32mTrain: [ 44/50] Step 020/520 Loss 1.743 Prec@(1,5) (64.9%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:32:57] \u001b[32mTrain: [ 44/50] Step 040/520 Loss 1.746 Prec@(1,5) (64.7%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:32:58] \u001b[32mTrain: [ 44/50] Step 060/520 Loss 1.734 Prec@(1,5) (64.6%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:32:58] \u001b[32mTrain: [ 44/50] Step 080/520 Loss 1.732 Prec@(1,5) (65.0%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:32:59] \u001b[32mTrain: [ 44/50] Step 100/520 Loss 1.729 Prec@(1,5) (65.1%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:32:59] \u001b[32mTrain: [ 44/50] Step 120/520 Loss 1.733 Prec@(1,5) (64.8%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:33:00] \u001b[32mTrain: [ 44/50] Step 140/520 Loss 1.740 Prec@(1,5) (64.6%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:33:01] \u001b[32mTrain: [ 44/50] Step 160/520 Loss 1.742 Prec@(1,5) (64.6%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:33:01] \u001b[32mTrain: [ 44/50] Step 180/520 Loss 1.742 Prec@(1,5) (64.6%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:33:02] \u001b[32mTrain: [ 44/50] Step 200/520 Loss 1.735 Prec@(1,5) (64.8%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:33:02] \u001b[32mTrain: [ 44/50] Step 220/520 Loss 1.731 Prec@(1,5) (64.9%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:33:03] \u001b[32mTrain: [ 44/50] Step 240/520 Loss 1.730 Prec@(1,5) (64.9%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:33:03] \u001b[32mTrain: [ 44/50] Step 260/520 Loss 1.735 Prec@(1,5) (64.9%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:33:04] \u001b[32mTrain: [ 44/50] Step 280/520 Loss 1.734 Prec@(1,5) (64.9%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:33:04] \u001b[32mTrain: [ 44/50] Step 300/520 Loss 1.736 Prec@(1,5) (64.9%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:33:05] \u001b[32mTrain: [ 44/50] Step 320/520 Loss 1.737 Prec@(1,5) (64.8%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:33:05] \u001b[32mTrain: [ 44/50] Step 340/520 Loss 1.735 Prec@(1,5) (64.8%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:33:06] \u001b[32mTrain: [ 44/50] Step 360/520 Loss 1.736 Prec@(1,5) (64.8%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:33:06] \u001b[32mTrain: [ 44/50] Step 380/520 Loss 1.734 Prec@(1,5) (64.9%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:33:07] \u001b[32mTrain: [ 44/50] Step 400/520 Loss 1.734 Prec@(1,5) (64.8%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:33:07] \u001b[32mTrain: [ 44/50] Step 420/520 Loss 1.732 Prec@(1,5) (64.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:33:08] \u001b[32mTrain: [ 44/50] Step 440/520 Loss 1.732 Prec@(1,5) (64.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:33:08] \u001b[32mTrain: [ 44/50] Step 460/520 Loss 1.733 Prec@(1,5) (64.9%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:33:09] \u001b[32mTrain: [ 44/50] Step 480/520 Loss 1.736 Prec@(1,5) (64.9%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:33:09] \u001b[32mTrain: [ 44/50] Step 500/520 Loss 1.737 Prec@(1,5) (64.9%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:33:10] \u001b[32mTrain: [ 44/50] Step 520/520 Loss 1.736 Prec@(1,5) (64.9%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:33:10] \u001b[32mTrain: [ 44/50] Final Prec@1 64.9360%\u001b[0m\n",
            "[2024-04-02 19:33:13] \u001b[32mValid: [ 44/50] Step 000/104 Loss 1.797 Prec@(1,5) (62.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:33:13] \u001b[32mValid: [ 44/50] Step 020/104 Loss 1.838 Prec@(1,5) (60.1%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:33:14] \u001b[32mValid: [ 44/50] Step 040/104 Loss 1.812 Prec@(1,5) (59.9%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:33:14] \u001b[32mValid: [ 44/50] Step 060/104 Loss 1.787 Prec@(1,5) (60.3%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:33:14] \u001b[32mValid: [ 44/50] Step 080/104 Loss 1.788 Prec@(1,5) (60.4%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:33:14] \u001b[32mValid: [ 44/50] Step 100/104 Loss 1.773 Prec@(1,5) (60.7%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:33:14] \u001b[32mValid: [ 44/50] Step 104/104 Loss 1.775 Prec@(1,5) (60.7%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:33:14] \u001b[32mValid: [ 44/50] Final Prec@1 60.7100%\u001b[0m\n",
            "[2024-04-02 19:33:14] \u001b[32mEpoch 44 LR 0.000879\u001b[0m\n",
            "[2024-04-02 19:33:19] \u001b[32mTrain: [ 45/50] Step 000/520 Loss 1.531 Prec@(1,5) (69.8%, 90.6%)\u001b[0m\n",
            "[2024-04-02 19:33:19] \u001b[32mTrain: [ 45/50] Step 020/520 Loss 1.737 Prec@(1,5) (64.8%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:33:20] \u001b[32mTrain: [ 45/50] Step 040/520 Loss 1.747 Prec@(1,5) (64.2%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:33:20] \u001b[32mTrain: [ 45/50] Step 060/520 Loss 1.746 Prec@(1,5) (64.3%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:33:21] \u001b[32mTrain: [ 45/50] Step 080/520 Loss 1.742 Prec@(1,5) (64.2%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:33:21] \u001b[32mTrain: [ 45/50] Step 100/520 Loss 1.744 Prec@(1,5) (64.2%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:33:22] \u001b[32mTrain: [ 45/50] Step 120/520 Loss 1.724 Prec@(1,5) (64.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:33:22] \u001b[32mTrain: [ 45/50] Step 140/520 Loss 1.732 Prec@(1,5) (64.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:33:23] \u001b[32mTrain: [ 45/50] Step 160/520 Loss 1.738 Prec@(1,5) (64.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:33:23] \u001b[32mTrain: [ 45/50] Step 180/520 Loss 1.732 Prec@(1,5) (64.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:33:24] \u001b[32mTrain: [ 45/50] Step 200/520 Loss 1.730 Prec@(1,5) (64.6%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:33:24] \u001b[32mTrain: [ 45/50] Step 220/520 Loss 1.726 Prec@(1,5) (64.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:33:25] \u001b[32mTrain: [ 45/50] Step 240/520 Loss 1.728 Prec@(1,5) (64.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:33:25] \u001b[32mTrain: [ 45/50] Step 260/520 Loss 1.727 Prec@(1,5) (64.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:33:26] \u001b[32mTrain: [ 45/50] Step 280/520 Loss 1.732 Prec@(1,5) (64.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:33:26] \u001b[32mTrain: [ 45/50] Step 300/520 Loss 1.728 Prec@(1,5) (64.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:33:27] \u001b[32mTrain: [ 45/50] Step 320/520 Loss 1.729 Prec@(1,5) (64.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:33:27] \u001b[32mTrain: [ 45/50] Step 340/520 Loss 1.723 Prec@(1,5) (64.8%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:33:28] \u001b[32mTrain: [ 45/50] Step 360/520 Loss 1.726 Prec@(1,5) (64.8%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:33:28] \u001b[32mTrain: [ 45/50] Step 380/520 Loss 1.727 Prec@(1,5) (64.8%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:33:29] \u001b[32mTrain: [ 45/50] Step 400/520 Loss 1.728 Prec@(1,5) (64.8%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:33:29] \u001b[32mTrain: [ 45/50] Step 420/520 Loss 1.726 Prec@(1,5) (64.8%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:33:30] \u001b[32mTrain: [ 45/50] Step 440/520 Loss 1.727 Prec@(1,5) (64.7%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:33:30] \u001b[32mTrain: [ 45/50] Step 460/520 Loss 1.729 Prec@(1,5) (64.7%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:33:31] \u001b[32mTrain: [ 45/50] Step 480/520 Loss 1.727 Prec@(1,5) (64.8%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:33:31] \u001b[32mTrain: [ 45/50] Step 500/520 Loss 1.726 Prec@(1,5) (64.8%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:33:32] \u001b[32mTrain: [ 45/50] Step 520/520 Loss 1.728 Prec@(1,5) (64.8%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:33:32] \u001b[32mTrain: [ 45/50] Final Prec@1 64.7880%\u001b[0m\n",
            "[2024-04-02 19:33:35] \u001b[32mValid: [ 45/50] Step 000/104 Loss 1.787 Prec@(1,5) (62.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:33:36] \u001b[32mValid: [ 45/50] Step 020/104 Loss 1.846 Prec@(1,5) (60.5%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:33:36] \u001b[32mValid: [ 45/50] Step 040/104 Loss 1.834 Prec@(1,5) (60.0%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:33:36] \u001b[32mValid: [ 45/50] Step 060/104 Loss 1.805 Prec@(1,5) (60.4%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:33:36] \u001b[32mValid: [ 45/50] Step 080/104 Loss 1.805 Prec@(1,5) (60.5%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:33:36] \u001b[32mValid: [ 45/50] Step 100/104 Loss 1.790 Prec@(1,5) (60.8%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:33:36] \u001b[32mValid: [ 45/50] Step 104/104 Loss 1.792 Prec@(1,5) (60.8%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:33:36] \u001b[32mValid: [ 45/50] Final Prec@1 60.8400%\u001b[0m\n",
            "[2024-04-02 19:33:36] \u001b[32mEpoch 45 LR 0.000613\u001b[0m\n",
            "[2024-04-02 19:33:41] \u001b[32mTrain: [ 46/50] Step 000/520 Loss 1.786 Prec@(1,5) (66.7%, 91.7%)\u001b[0m\n",
            "[2024-04-02 19:33:42] \u001b[32mTrain: [ 46/50] Step 020/520 Loss 1.744 Prec@(1,5) (65.6%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:33:42] \u001b[32mTrain: [ 46/50] Step 040/520 Loss 1.743 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:33:43] \u001b[32mTrain: [ 46/50] Step 060/520 Loss 1.748 Prec@(1,5) (65.0%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:33:43] \u001b[32mTrain: [ 46/50] Step 080/520 Loss 1.747 Prec@(1,5) (65.0%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:33:44] \u001b[32mTrain: [ 46/50] Step 100/520 Loss 1.730 Prec@(1,5) (65.2%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:33:44] \u001b[32mTrain: [ 46/50] Step 120/520 Loss 1.721 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:33:45] \u001b[32mTrain: [ 46/50] Step 140/520 Loss 1.717 Prec@(1,5) (65.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:33:45] \u001b[32mTrain: [ 46/50] Step 160/520 Loss 1.722 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:33:46] \u001b[32mTrain: [ 46/50] Step 180/520 Loss 1.723 Prec@(1,5) (65.1%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:33:46] \u001b[32mTrain: [ 46/50] Step 200/520 Loss 1.717 Prec@(1,5) (65.3%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:33:47] \u001b[32mTrain: [ 46/50] Step 220/520 Loss 1.720 Prec@(1,5) (65.2%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:33:47] \u001b[32mTrain: [ 46/50] Step 240/520 Loss 1.720 Prec@(1,5) (65.3%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:33:48] \u001b[32mTrain: [ 46/50] Step 260/520 Loss 1.719 Prec@(1,5) (65.3%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:33:48] \u001b[32mTrain: [ 46/50] Step 280/520 Loss 1.724 Prec@(1,5) (65.1%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:33:49] \u001b[32mTrain: [ 46/50] Step 300/520 Loss 1.722 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:33:49] \u001b[32mTrain: [ 46/50] Step 320/520 Loss 1.722 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:33:50] \u001b[32mTrain: [ 46/50] Step 340/520 Loss 1.721 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:33:50] \u001b[32mTrain: [ 46/50] Step 360/520 Loss 1.723 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:33:51] \u001b[32mTrain: [ 46/50] Step 380/520 Loss 1.721 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:33:51] \u001b[32mTrain: [ 46/50] Step 400/520 Loss 1.721 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:33:52] \u001b[32mTrain: [ 46/50] Step 420/520 Loss 1.720 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:33:52] \u001b[32mTrain: [ 46/50] Step 440/520 Loss 1.719 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:33:53] \u001b[32mTrain: [ 46/50] Step 460/520 Loss 1.716 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:33:53] \u001b[32mTrain: [ 46/50] Step 480/520 Loss 1.720 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:33:54] \u001b[32mTrain: [ 46/50] Step 500/520 Loss 1.723 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:33:54] \u001b[32mTrain: [ 46/50] Step 520/520 Loss 1.723 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:33:55] \u001b[32mTrain: [ 46/50] Final Prec@1 65.1580%\u001b[0m\n",
            "[2024-04-02 19:33:58] \u001b[32mValid: [ 46/50] Step 000/104 Loss 1.781 Prec@(1,5) (62.5%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:33:58] \u001b[32mValid: [ 46/50] Step 020/104 Loss 1.853 Prec@(1,5) (60.4%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:33:58] \u001b[32mValid: [ 46/50] Step 040/104 Loss 1.825 Prec@(1,5) (60.6%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:33:59] \u001b[32mValid: [ 46/50] Step 060/104 Loss 1.792 Prec@(1,5) (60.9%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:33:59] \u001b[32mValid: [ 46/50] Step 080/104 Loss 1.794 Prec@(1,5) (60.9%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:33:59] \u001b[32mValid: [ 46/50] Step 100/104 Loss 1.776 Prec@(1,5) (61.3%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:33:59] \u001b[32mValid: [ 46/50] Step 104/104 Loss 1.779 Prec@(1,5) (61.3%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:33:59] \u001b[32mValid: [ 46/50] Final Prec@1 61.2600%\u001b[0m\n",
            "[2024-04-02 19:33:59] \u001b[32mEpoch 46 LR 0.000394\u001b[0m\n",
            "[2024-04-02 19:34:04] \u001b[32mTrain: [ 47/50] Step 000/520 Loss 1.902 Prec@(1,5) (58.3%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:34:04] \u001b[32mTrain: [ 47/50] Step 020/520 Loss 1.737 Prec@(1,5) (65.1%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:34:05] \u001b[32mTrain: [ 47/50] Step 040/520 Loss 1.711 Prec@(1,5) (65.1%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:34:05] \u001b[32mTrain: [ 47/50] Step 060/520 Loss 1.696 Prec@(1,5) (65.5%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:34:06] \u001b[32mTrain: [ 47/50] Step 080/520 Loss 1.692 Prec@(1,5) (65.5%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:34:06] \u001b[32mTrain: [ 47/50] Step 100/520 Loss 1.683 Prec@(1,5) (65.5%, 89.9%)\u001b[0m\n",
            "[2024-04-02 19:34:07] \u001b[32mTrain: [ 47/50] Step 120/520 Loss 1.684 Prec@(1,5) (65.6%, 90.0%)\u001b[0m\n",
            "[2024-04-02 19:34:07] \u001b[32mTrain: [ 47/50] Step 140/520 Loss 1.682 Prec@(1,5) (65.7%, 90.1%)\u001b[0m\n",
            "[2024-04-02 19:34:08] \u001b[32mTrain: [ 47/50] Step 160/520 Loss 1.692 Prec@(1,5) (65.6%, 89.9%)\u001b[0m\n",
            "[2024-04-02 19:34:08] \u001b[32mTrain: [ 47/50] Step 180/520 Loss 1.701 Prec@(1,5) (65.4%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:34:09] \u001b[32mTrain: [ 47/50] Step 200/520 Loss 1.697 Prec@(1,5) (65.5%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:34:10] \u001b[32mTrain: [ 47/50] Step 220/520 Loss 1.705 Prec@(1,5) (65.4%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:34:10] \u001b[32mTrain: [ 47/50] Step 240/520 Loss 1.703 Prec@(1,5) (65.4%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:34:11] \u001b[32mTrain: [ 47/50] Step 260/520 Loss 1.702 Prec@(1,5) (65.6%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:34:11] \u001b[32mTrain: [ 47/50] Step 280/520 Loss 1.701 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:34:12] \u001b[32mTrain: [ 47/50] Step 300/520 Loss 1.703 Prec@(1,5) (65.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:34:12] \u001b[32mTrain: [ 47/50] Step 320/520 Loss 1.706 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:34:13] \u001b[32mTrain: [ 47/50] Step 340/520 Loss 1.710 Prec@(1,5) (65.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:34:13] \u001b[32mTrain: [ 47/50] Step 360/520 Loss 1.708 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:34:14] \u001b[32mTrain: [ 47/50] Step 380/520 Loss 1.709 Prec@(1,5) (65.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:34:14] \u001b[32mTrain: [ 47/50] Step 400/520 Loss 1.709 Prec@(1,5) (65.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:34:15] \u001b[32mTrain: [ 47/50] Step 420/520 Loss 1.708 Prec@(1,5) (65.5%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:34:15] \u001b[32mTrain: [ 47/50] Step 440/520 Loss 1.709 Prec@(1,5) (65.5%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:34:16] \u001b[32mTrain: [ 47/50] Step 460/520 Loss 1.709 Prec@(1,5) (65.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:34:16] \u001b[32mTrain: [ 47/50] Step 480/520 Loss 1.711 Prec@(1,5) (65.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:34:17] \u001b[32mTrain: [ 47/50] Step 500/520 Loss 1.711 Prec@(1,5) (65.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:34:17] \u001b[32mTrain: [ 47/50] Step 520/520 Loss 1.711 Prec@(1,5) (65.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:34:17] \u001b[32mTrain: [ 47/50] Final Prec@1 65.5420%\u001b[0m\n",
            "[2024-04-02 19:34:21] \u001b[32mValid: [ 47/50] Step 000/104 Loss 1.727 Prec@(1,5) (63.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:34:21] \u001b[32mValid: [ 47/50] Step 020/104 Loss 1.829 Prec@(1,5) (60.8%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:34:21] \u001b[32mValid: [ 47/50] Step 040/104 Loss 1.808 Prec@(1,5) (60.6%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:34:21] \u001b[32mValid: [ 47/50] Step 060/104 Loss 1.778 Prec@(1,5) (60.9%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:34:21] \u001b[32mValid: [ 47/50] Step 080/104 Loss 1.778 Prec@(1,5) (60.9%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:34:22] \u001b[32mValid: [ 47/50] Step 100/104 Loss 1.761 Prec@(1,5) (61.4%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:34:22] \u001b[32mValid: [ 47/50] Step 104/104 Loss 1.762 Prec@(1,5) (61.3%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:34:22] \u001b[32mValid: [ 47/50] Final Prec@1 61.3400%\u001b[0m\n",
            "[2024-04-02 19:34:22] \u001b[32mEpoch 47 LR 0.000222\u001b[0m\n",
            "[2024-04-02 19:34:26] \u001b[32mTrain: [ 48/50] Step 000/520 Loss 1.653 Prec@(1,5) (63.5%, 92.7%)\u001b[0m\n",
            "[2024-04-02 19:34:27] \u001b[32mTrain: [ 48/50] Step 020/520 Loss 1.752 Prec@(1,5) (65.5%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:34:27] \u001b[32mTrain: [ 48/50] Step 040/520 Loss 1.713 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:34:28] \u001b[32mTrain: [ 48/50] Step 060/520 Loss 1.709 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:34:28] \u001b[32mTrain: [ 48/50] Step 080/520 Loss 1.710 Prec@(1,5) (65.3%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:34:29] \u001b[32mTrain: [ 48/50] Step 100/520 Loss 1.713 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:34:29] \u001b[32mTrain: [ 48/50] Step 120/520 Loss 1.721 Prec@(1,5) (65.3%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:34:30] \u001b[32mTrain: [ 48/50] Step 140/520 Loss 1.718 Prec@(1,5) (65.4%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:34:30] \u001b[32mTrain: [ 48/50] Step 160/520 Loss 1.713 Prec@(1,5) (65.6%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:34:31] \u001b[32mTrain: [ 48/50] Step 180/520 Loss 1.711 Prec@(1,5) (65.7%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:34:31] \u001b[32mTrain: [ 48/50] Step 200/520 Loss 1.713 Prec@(1,5) (65.7%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:34:32] \u001b[32mTrain: [ 48/50] Step 220/520 Loss 1.710 Prec@(1,5) (65.7%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:34:32] \u001b[32mTrain: [ 48/50] Step 240/520 Loss 1.717 Prec@(1,5) (65.6%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:34:33] \u001b[32mTrain: [ 48/50] Step 260/520 Loss 1.717 Prec@(1,5) (65.5%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:34:33] \u001b[32mTrain: [ 48/50] Step 280/520 Loss 1.718 Prec@(1,5) (65.5%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:34:34] \u001b[32mTrain: [ 48/50] Step 300/520 Loss 1.722 Prec@(1,5) (65.3%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:34:34] \u001b[32mTrain: [ 48/50] Step 320/520 Loss 1.720 Prec@(1,5) (65.4%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:34:35] \u001b[32mTrain: [ 48/50] Step 340/520 Loss 1.724 Prec@(1,5) (65.3%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:34:35] \u001b[32mTrain: [ 48/50] Step 360/520 Loss 1.727 Prec@(1,5) (65.2%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:34:36] \u001b[32mTrain: [ 48/50] Step 380/520 Loss 1.724 Prec@(1,5) (65.3%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:34:36] \u001b[32mTrain: [ 48/50] Step 400/520 Loss 1.725 Prec@(1,5) (65.3%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:34:37] \u001b[32mTrain: [ 48/50] Step 420/520 Loss 1.729 Prec@(1,5) (65.2%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:34:37] \u001b[32mTrain: [ 48/50] Step 440/520 Loss 1.725 Prec@(1,5) (65.3%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:34:38] \u001b[32mTrain: [ 48/50] Step 460/520 Loss 1.723 Prec@(1,5) (65.3%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:34:38] \u001b[32mTrain: [ 48/50] Step 480/520 Loss 1.720 Prec@(1,5) (65.3%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:34:39] \u001b[32mTrain: [ 48/50] Step 500/520 Loss 1.717 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:34:39] \u001b[32mTrain: [ 48/50] Step 520/520 Loss 1.716 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:34:40] \u001b[32mTrain: [ 48/50] Final Prec@1 65.4020%\u001b[0m\n",
            "[2024-04-02 19:34:43] \u001b[32mValid: [ 48/50] Step 000/104 Loss 1.730 Prec@(1,5) (61.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:34:43] \u001b[32mValid: [ 48/50] Step 020/104 Loss 1.840 Prec@(1,5) (60.7%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:34:43] \u001b[32mValid: [ 48/50] Step 040/104 Loss 1.814 Prec@(1,5) (60.6%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:34:44] \u001b[32mValid: [ 48/50] Step 060/104 Loss 1.783 Prec@(1,5) (60.9%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:34:44] \u001b[32mValid: [ 48/50] Step 080/104 Loss 1.783 Prec@(1,5) (60.8%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:34:44] \u001b[32mValid: [ 48/50] Step 100/104 Loss 1.765 Prec@(1,5) (61.1%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:34:44] \u001b[32mValid: [ 48/50] Step 104/104 Loss 1.768 Prec@(1,5) (61.1%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:34:44] \u001b[32mValid: [ 48/50] Final Prec@1 61.1400%\u001b[0m\n",
            "[2024-04-02 19:34:44] \u001b[32mEpoch 48 LR 0.000100\u001b[0m\n",
            "[2024-04-02 19:34:49] \u001b[32mTrain: [ 49/50] Step 000/520 Loss 1.522 Prec@(1,5) (67.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:34:49] \u001b[32mTrain: [ 49/50] Step 020/520 Loss 1.719 Prec@(1,5) (66.4%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:34:50] \u001b[32mTrain: [ 49/50] Step 040/520 Loss 1.712 Prec@(1,5) (65.0%, 90.0%)\u001b[0m\n",
            "[2024-04-02 19:34:50] \u001b[32mTrain: [ 49/50] Step 060/520 Loss 1.724 Prec@(1,5) (65.1%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:34:51] \u001b[32mTrain: [ 49/50] Step 080/520 Loss 1.709 Prec@(1,5) (65.4%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:34:51] \u001b[32mTrain: [ 49/50] Step 100/520 Loss 1.704 Prec@(1,5) (65.7%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:34:52] \u001b[32mTrain: [ 49/50] Step 120/520 Loss 1.697 Prec@(1,5) (65.8%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:34:52] \u001b[32mTrain: [ 49/50] Step 140/520 Loss 1.688 Prec@(1,5) (65.9%, 90.0%)\u001b[0m\n",
            "[2024-04-02 19:34:53] \u001b[32mTrain: [ 49/50] Step 160/520 Loss 1.691 Prec@(1,5) (65.8%, 89.9%)\u001b[0m\n",
            "[2024-04-02 19:34:53] \u001b[32mTrain: [ 49/50] Step 180/520 Loss 1.686 Prec@(1,5) (65.9%, 89.9%)\u001b[0m\n",
            "[2024-04-02 19:34:54] \u001b[32mTrain: [ 49/50] Step 200/520 Loss 1.687 Prec@(1,5) (65.9%, 89.9%)\u001b[0m\n",
            "[2024-04-02 19:34:54] \u001b[32mTrain: [ 49/50] Step 220/520 Loss 1.684 Prec@(1,5) (66.0%, 90.0%)\u001b[0m\n",
            "[2024-04-02 19:34:55] \u001b[32mTrain: [ 49/50] Step 240/520 Loss 1.687 Prec@(1,5) (65.9%, 89.9%)\u001b[0m\n",
            "[2024-04-02 19:34:55] \u001b[32mTrain: [ 49/50] Step 260/520 Loss 1.691 Prec@(1,5) (65.7%, 89.9%)\u001b[0m\n",
            "[2024-04-02 19:34:56] \u001b[32mTrain: [ 49/50] Step 280/520 Loss 1.697 Prec@(1,5) (65.7%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:34:56] \u001b[32mTrain: [ 49/50] Step 300/520 Loss 1.698 Prec@(1,5) (65.6%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:34:57] \u001b[32mTrain: [ 49/50] Step 320/520 Loss 1.697 Prec@(1,5) (65.6%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:34:57] \u001b[32mTrain: [ 49/50] Step 340/520 Loss 1.697 Prec@(1,5) (65.6%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:34:58] \u001b[32mTrain: [ 49/50] Step 360/520 Loss 1.697 Prec@(1,5) (65.6%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:34:58] \u001b[32mTrain: [ 49/50] Step 380/520 Loss 1.694 Prec@(1,5) (65.7%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:34:59] \u001b[32mTrain: [ 49/50] Step 400/520 Loss 1.698 Prec@(1,5) (65.7%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:34:59] \u001b[32mTrain: [ 49/50] Step 420/520 Loss 1.702 Prec@(1,5) (65.6%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:35:00] \u001b[32mTrain: [ 49/50] Step 440/520 Loss 1.705 Prec@(1,5) (65.5%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:35:01] \u001b[32mTrain: [ 49/50] Step 460/520 Loss 1.705 Prec@(1,5) (65.5%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:35:01] \u001b[32mTrain: [ 49/50] Step 480/520 Loss 1.708 Prec@(1,5) (65.4%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:35:02] \u001b[32mTrain: [ 49/50] Step 500/520 Loss 1.707 Prec@(1,5) (65.4%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:35:02] \u001b[32mTrain: [ 49/50] Step 520/520 Loss 1.708 Prec@(1,5) (65.4%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:35:02] \u001b[32mTrain: [ 49/50] Final Prec@1 65.4180%\u001b[0m\n",
            "[2024-04-02 19:35:06] \u001b[32mValid: [ 49/50] Step 000/104 Loss 1.765 Prec@(1,5) (63.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:35:06] \u001b[32mValid: [ 49/50] Step 020/104 Loss 1.844 Prec@(1,5) (60.4%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:35:06] \u001b[32mValid: [ 49/50] Step 040/104 Loss 1.823 Prec@(1,5) (60.5%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:35:06] \u001b[32mValid: [ 49/50] Step 060/104 Loss 1.792 Prec@(1,5) (60.8%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:35:06] \u001b[32mValid: [ 49/50] Step 080/104 Loss 1.793 Prec@(1,5) (60.8%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:35:07] \u001b[32mValid: [ 49/50] Step 100/104 Loss 1.775 Prec@(1,5) (61.2%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:35:07] \u001b[32mValid: [ 49/50] Step 104/104 Loss 1.778 Prec@(1,5) (61.3%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:35:07] \u001b[32mValid: [ 49/50] Final Prec@1 61.2600%\u001b[0m\n",
            "[2024-04-02 19:35:07] \u001b[32mEpoch 49 LR 0.000026\u001b[0m\n",
            "[2024-04-02 19:35:11] \u001b[32mTrain: [ 50/50] Step 000/520 Loss 1.785 Prec@(1,5) (63.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:35:12] \u001b[32mTrain: [ 50/50] Step 020/520 Loss 1.685 Prec@(1,5) (65.5%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:35:13] \u001b[32mTrain: [ 50/50] Step 040/520 Loss 1.723 Prec@(1,5) (65.4%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:35:13] \u001b[32mTrain: [ 50/50] Step 060/520 Loss 1.719 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:35:14] \u001b[32mTrain: [ 50/50] Step 080/520 Loss 1.722 Prec@(1,5) (65.0%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:35:14] \u001b[32mTrain: [ 50/50] Step 100/520 Loss 1.730 Prec@(1,5) (64.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:35:15] \u001b[32mTrain: [ 50/50] Step 120/520 Loss 1.723 Prec@(1,5) (65.0%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:35:15] \u001b[32mTrain: [ 50/50] Step 140/520 Loss 1.710 Prec@(1,5) (65.4%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:35:16] \u001b[32mTrain: [ 50/50] Step 160/520 Loss 1.701 Prec@(1,5) (65.7%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:35:16] \u001b[32mTrain: [ 50/50] Step 180/520 Loss 1.712 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:35:17] \u001b[32mTrain: [ 50/50] Step 200/520 Loss 1.712 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:35:17] \u001b[32mTrain: [ 50/50] Step 220/520 Loss 1.718 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:35:18] \u001b[32mTrain: [ 50/50] Step 240/520 Loss 1.716 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:35:18] \u001b[32mTrain: [ 50/50] Step 260/520 Loss 1.720 Prec@(1,5) (65.3%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:35:19] \u001b[32mTrain: [ 50/50] Step 280/520 Loss 1.717 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:35:19] \u001b[32mTrain: [ 50/50] Step 300/520 Loss 1.712 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:35:20] \u001b[32mTrain: [ 50/50] Step 320/520 Loss 1.715 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:35:20] \u001b[32mTrain: [ 50/50] Step 340/520 Loss 1.716 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:35:21] \u001b[32mTrain: [ 50/50] Step 360/520 Loss 1.714 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:35:21] \u001b[32mTrain: [ 50/50] Step 380/520 Loss 1.714 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:35:22] \u001b[32mTrain: [ 50/50] Step 400/520 Loss 1.713 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:35:22] \u001b[32mTrain: [ 50/50] Step 420/520 Loss 1.715 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:35:23] \u001b[32mTrain: [ 50/50] Step 440/520 Loss 1.716 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:35:23] \u001b[32mTrain: [ 50/50] Step 460/520 Loss 1.716 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:35:24] \u001b[32mTrain: [ 50/50] Step 480/520 Loss 1.714 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:35:24] \u001b[32mTrain: [ 50/50] Step 500/520 Loss 1.715 Prec@(1,5) (65.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:35:25] \u001b[32mTrain: [ 50/50] Step 520/520 Loss 1.714 Prec@(1,5) (65.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:35:25] \u001b[32mTrain: [ 50/50] Final Prec@1 65.4680%\u001b[0m\n",
            "[2024-04-02 19:35:28] \u001b[32mValid: [ 50/50] Step 000/104 Loss 1.740 Prec@(1,5) (63.5%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:35:29] \u001b[32mValid: [ 50/50] Step 020/104 Loss 1.832 Prec@(1,5) (61.0%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:35:29] \u001b[32mValid: [ 50/50] Step 040/104 Loss 1.809 Prec@(1,5) (60.8%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:35:29] \u001b[32mValid: [ 50/50] Step 060/104 Loss 1.777 Prec@(1,5) (61.1%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:35:29] \u001b[32mValid: [ 50/50] Step 080/104 Loss 1.778 Prec@(1,5) (61.0%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:35:29] \u001b[32mValid: [ 50/50] Step 100/104 Loss 1.761 Prec@(1,5) (61.4%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:35:29] \u001b[32mValid: [ 50/50] Step 104/104 Loss 1.764 Prec@(1,5) (61.4%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:35:30] \u001b[32mValid: [ 50/50] Final Prec@1 61.4400%\u001b[0m\n",
            "Final best Prec@1 = 61.4400%\n",
            "{'lambd=1.263157894736842': 0.6138000170707703, 'lambd=1.6842105263157894': 0.6144000166893006}\n",
            "random_edges/lambd=2.1052631578947367/\n",
            "[2024-04-02 19:35:30] \u001b[32mFixed architecture: {'reduce_n2_p0': 'sepconv5x5', 'reduce_n2_p1': 'sepconv5x5', 'reduce_n3_p0': 'dilconv5x5', 'reduce_n3_p1': 'sepconv5x5', 'reduce_n3_p2': 'sepconv5x5', 'reduce_n4_p0': 'sepconv3x3', 'reduce_n4_p1': 'sepconv5x5', 'reduce_n4_p2': 'sepconv5x5', 'reduce_n4_p3': 'sepconv5x5', 'reduce_n5_p0': 'maxpool', 'reduce_n5_p1': 'sepconv3x3', 'reduce_n5_p2': 'sepconv5x5', 'reduce_n5_p3': 'sepconv5x5', 'reduce_n5_p4': 'maxpool', 'reduce_n2_switch': [1], 'reduce_n3_switch': [1], 'reduce_n4_switch': [0], 'reduce_n5_switch': [4]}\u001b[0m\n",
            "[2024-04-02 19:35:30] \u001b[32mEpoch 0 LR 0.025000\u001b[0m\n",
            "[2024-04-02 19:35:34] \u001b[32mTrain: [  1/50] Step 000/520 Loss 6.498 Prec@(1,5) (0.0%, 4.2%)\u001b[0m\n",
            "[2024-04-02 19:35:35] \u001b[32mTrain: [  1/50] Step 020/520 Loss 6.406 Prec@(1,5) (1.6%, 7.9%)\u001b[0m\n",
            "[2024-04-02 19:35:35] \u001b[32mTrain: [  1/50] Step 040/520 Loss 6.320 Prec@(1,5) (2.5%, 10.3%)\u001b[0m\n",
            "[2024-04-02 19:35:36] \u001b[32mTrain: [  1/50] Step 060/520 Loss 6.217 Prec@(1,5) (3.5%, 12.9%)\u001b[0m\n",
            "[2024-04-02 19:35:36] \u001b[32mTrain: [  1/50] Step 080/520 Loss 6.121 Prec@(1,5) (4.2%, 15.2%)\u001b[0m\n",
            "[2024-04-02 19:35:37] \u001b[32mTrain: [  1/50] Step 100/520 Loss 6.048 Prec@(1,5) (4.7%, 16.7%)\u001b[0m\n",
            "[2024-04-02 19:35:37] \u001b[32mTrain: [  1/50] Step 120/520 Loss 5.984 Prec@(1,5) (5.4%, 18.1%)\u001b[0m\n",
            "[2024-04-02 19:35:38] \u001b[32mTrain: [  1/50] Step 140/520 Loss 5.928 Prec@(1,5) (5.9%, 19.2%)\u001b[0m\n",
            "[2024-04-02 19:35:38] \u001b[32mTrain: [  1/50] Step 160/520 Loss 5.875 Prec@(1,5) (6.3%, 20.2%)\u001b[0m\n",
            "[2024-04-02 19:35:39] \u001b[32mTrain: [  1/50] Step 180/520 Loss 5.825 Prec@(1,5) (6.8%, 21.4%)\u001b[0m\n",
            "[2024-04-02 19:35:39] \u001b[32mTrain: [  1/50] Step 200/520 Loss 5.784 Prec@(1,5) (7.0%, 22.2%)\u001b[0m\n",
            "[2024-04-02 19:35:39] \u001b[32mTrain: [  1/50] Step 220/520 Loss 5.746 Prec@(1,5) (7.3%, 23.1%)\u001b[0m\n",
            "[2024-04-02 19:35:40] \u001b[32mTrain: [  1/50] Step 240/520 Loss 5.709 Prec@(1,5) (7.7%, 24.0%)\u001b[0m\n",
            "[2024-04-02 19:35:40] \u001b[32mTrain: [  1/50] Step 260/520 Loss 5.674 Prec@(1,5) (8.0%, 24.7%)\u001b[0m\n",
            "[2024-04-02 19:35:41] \u001b[32mTrain: [  1/50] Step 280/520 Loss 5.647 Prec@(1,5) (8.2%, 25.4%)\u001b[0m\n",
            "[2024-04-02 19:35:41] \u001b[32mTrain: [  1/50] Step 300/520 Loss 5.614 Prec@(1,5) (8.6%, 26.1%)\u001b[0m\n",
            "[2024-04-02 19:35:42] \u001b[32mTrain: [  1/50] Step 320/520 Loss 5.581 Prec@(1,5) (8.9%, 26.9%)\u001b[0m\n",
            "[2024-04-02 19:35:42] \u001b[32mTrain: [  1/50] Step 340/520 Loss 5.550 Prec@(1,5) (9.2%, 27.5%)\u001b[0m\n",
            "[2024-04-02 19:35:43] \u001b[32mTrain: [  1/50] Step 360/520 Loss 5.524 Prec@(1,5) (9.4%, 28.2%)\u001b[0m\n",
            "[2024-04-02 19:35:43] \u001b[32mTrain: [  1/50] Step 380/520 Loss 5.497 Prec@(1,5) (9.7%, 28.7%)\u001b[0m\n",
            "[2024-04-02 19:35:44] \u001b[32mTrain: [  1/50] Step 400/520 Loss 5.474 Prec@(1,5) (9.9%, 29.2%)\u001b[0m\n",
            "[2024-04-02 19:35:44] \u001b[32mTrain: [  1/50] Step 420/520 Loss 5.453 Prec@(1,5) (10.1%, 29.7%)\u001b[0m\n",
            "[2024-04-02 19:35:45] \u001b[32mTrain: [  1/50] Step 440/520 Loss 5.429 Prec@(1,5) (10.4%, 30.2%)\u001b[0m\n",
            "[2024-04-02 19:35:45] \u001b[32mTrain: [  1/50] Step 460/520 Loss 5.406 Prec@(1,5) (10.5%, 30.6%)\u001b[0m\n",
            "[2024-04-02 19:35:46] \u001b[32mTrain: [  1/50] Step 480/520 Loss 5.381 Prec@(1,5) (10.8%, 31.2%)\u001b[0m\n",
            "[2024-04-02 19:35:46] \u001b[32mTrain: [  1/50] Step 500/520 Loss 5.355 Prec@(1,5) (11.1%, 31.7%)\u001b[0m\n",
            "[2024-04-02 19:35:46] \u001b[32mTrain: [  1/50] Step 520/520 Loss 5.333 Prec@(1,5) (11.3%, 32.2%)\u001b[0m\n",
            "[2024-04-02 19:35:47] \u001b[32mTrain: [  1/50] Final Prec@1 11.3120%\u001b[0m\n",
            "[2024-04-02 19:35:50] \u001b[32mValid: [  1/50] Step 000/104 Loss 4.845 Prec@(1,5) (16.7%, 35.4%)\u001b[0m\n",
            "[2024-04-02 19:35:50] \u001b[32mValid: [  1/50] Step 020/104 Loss 4.421 Prec@(1,5) (16.1%, 42.2%)\u001b[0m\n",
            "[2024-04-02 19:35:50] \u001b[32mValid: [  1/50] Step 040/104 Loss 4.391 Prec@(1,5) (15.8%, 42.4%)\u001b[0m\n",
            "[2024-04-02 19:35:51] \u001b[32mValid: [  1/50] Step 060/104 Loss 4.371 Prec@(1,5) (16.2%, 42.6%)\u001b[0m\n",
            "[2024-04-02 19:35:51] \u001b[32mValid: [  1/50] Step 080/104 Loss 4.382 Prec@(1,5) (16.2%, 42.8%)\u001b[0m\n",
            "[2024-04-02 19:35:51] \u001b[32mValid: [  1/50] Step 100/104 Loss 4.389 Prec@(1,5) (16.1%, 43.0%)\u001b[0m\n",
            "[2024-04-02 19:35:51] \u001b[32mValid: [  1/50] Step 104/104 Loss 4.393 Prec@(1,5) (16.1%, 42.9%)\u001b[0m\n",
            "[2024-04-02 19:35:51] \u001b[32mValid: [  1/50] Final Prec@1 16.1100%\u001b[0m\n",
            "[2024-04-02 19:35:51] \u001b[32mEpoch 1 LR 0.024975\u001b[0m\n",
            "[2024-04-02 19:35:56] \u001b[32mTrain: [  2/50] Step 000/520 Loss 4.670 Prec@(1,5) (18.8%, 50.0%)\u001b[0m\n",
            "[2024-04-02 19:35:56] \u001b[32mTrain: [  2/50] Step 020/520 Loss 4.775 Prec@(1,5) (16.0%, 43.9%)\u001b[0m\n",
            "[2024-04-02 19:35:57] \u001b[32mTrain: [  2/50] Step 040/520 Loss 4.733 Prec@(1,5) (15.8%, 44.4%)\u001b[0m\n",
            "[2024-04-02 19:35:57] \u001b[32mTrain: [  2/50] Step 060/520 Loss 4.727 Prec@(1,5) (16.5%, 44.7%)\u001b[0m\n",
            "[2024-04-02 19:35:58] \u001b[32mTrain: [  2/50] Step 080/520 Loss 4.708 Prec@(1,5) (16.8%, 45.1%)\u001b[0m\n",
            "[2024-04-02 19:35:58] \u001b[32mTrain: [  2/50] Step 100/520 Loss 4.716 Prec@(1,5) (16.9%, 44.9%)\u001b[0m\n",
            "[2024-04-02 19:35:59] \u001b[32mTrain: [  2/50] Step 120/520 Loss 4.703 Prec@(1,5) (17.3%, 45.0%)\u001b[0m\n",
            "[2024-04-02 19:35:59] \u001b[32mTrain: [  2/50] Step 140/520 Loss 4.681 Prec@(1,5) (17.7%, 45.4%)\u001b[0m\n",
            "[2024-04-02 19:36:00] \u001b[32mTrain: [  2/50] Step 160/520 Loss 4.669 Prec@(1,5) (17.9%, 45.8%)\u001b[0m\n",
            "[2024-04-02 19:36:00] \u001b[32mTrain: [  2/50] Step 180/520 Loss 4.662 Prec@(1,5) (18.0%, 46.0%)\u001b[0m\n",
            "[2024-04-02 19:36:01] \u001b[32mTrain: [  2/50] Step 200/520 Loss 4.660 Prec@(1,5) (18.1%, 46.0%)\u001b[0m\n",
            "[2024-04-02 19:36:01] \u001b[32mTrain: [  2/50] Step 220/520 Loss 4.650 Prec@(1,5) (18.2%, 46.2%)\u001b[0m\n",
            "[2024-04-02 19:36:02] \u001b[32mTrain: [  2/50] Step 240/520 Loss 4.628 Prec@(1,5) (18.6%, 46.7%)\u001b[0m\n",
            "[2024-04-02 19:36:02] \u001b[32mTrain: [  2/50] Step 260/520 Loss 4.609 Prec@(1,5) (18.9%, 47.1%)\u001b[0m\n",
            "[2024-04-02 19:36:03] \u001b[32mTrain: [  2/50] Step 280/520 Loss 4.599 Prec@(1,5) (19.0%, 47.2%)\u001b[0m\n",
            "[2024-04-02 19:36:03] \u001b[32mTrain: [  2/50] Step 300/520 Loss 4.587 Prec@(1,5) (19.3%, 47.5%)\u001b[0m\n",
            "[2024-04-02 19:36:04] \u001b[32mTrain: [  2/50] Step 320/520 Loss 4.580 Prec@(1,5) (19.3%, 47.5%)\u001b[0m\n",
            "[2024-04-02 19:36:04] \u001b[32mTrain: [  2/50] Step 340/520 Loss 4.567 Prec@(1,5) (19.4%, 47.7%)\u001b[0m\n",
            "[2024-04-02 19:36:05] \u001b[32mTrain: [  2/50] Step 360/520 Loss 4.559 Prec@(1,5) (19.5%, 47.9%)\u001b[0m\n",
            "[2024-04-02 19:36:05] \u001b[32mTrain: [  2/50] Step 380/520 Loss 4.552 Prec@(1,5) (19.6%, 48.0%)\u001b[0m\n",
            "[2024-04-02 19:36:06] \u001b[32mTrain: [  2/50] Step 400/520 Loss 4.542 Prec@(1,5) (19.7%, 48.3%)\u001b[0m\n",
            "[2024-04-02 19:36:06] \u001b[32mTrain: [  2/50] Step 420/520 Loss 4.531 Prec@(1,5) (19.9%, 48.5%)\u001b[0m\n",
            "[2024-04-02 19:36:07] \u001b[32mTrain: [  2/50] Step 440/520 Loss 4.521 Prec@(1,5) (20.1%, 48.7%)\u001b[0m\n",
            "[2024-04-02 19:36:07] \u001b[32mTrain: [  2/50] Step 460/520 Loss 4.512 Prec@(1,5) (20.3%, 48.9%)\u001b[0m\n",
            "[2024-04-02 19:36:08] \u001b[32mTrain: [  2/50] Step 480/520 Loss 4.498 Prec@(1,5) (20.4%, 49.1%)\u001b[0m\n",
            "[2024-04-02 19:36:08] \u001b[32mTrain: [  2/50] Step 500/520 Loss 4.490 Prec@(1,5) (20.5%, 49.3%)\u001b[0m\n",
            "[2024-04-02 19:36:09] \u001b[32mTrain: [  2/50] Step 520/520 Loss 4.482 Prec@(1,5) (20.6%, 49.5%)\u001b[0m\n",
            "[2024-04-02 19:36:09] \u001b[32mTrain: [  2/50] Final Prec@1 20.6060%\u001b[0m\n",
            "[2024-04-02 19:36:12] \u001b[32mValid: [  2/50] Step 000/104 Loss 4.404 Prec@(1,5) (26.0%, 52.1%)\u001b[0m\n",
            "[2024-04-02 19:36:12] \u001b[32mValid: [  2/50] Step 020/104 Loss 4.098 Prec@(1,5) (24.1%, 53.5%)\u001b[0m\n",
            "[2024-04-02 19:36:13] \u001b[32mValid: [  2/50] Step 040/104 Loss 4.053 Prec@(1,5) (23.3%, 54.0%)\u001b[0m\n",
            "[2024-04-02 19:36:13] \u001b[32mValid: [  2/50] Step 060/104 Loss 4.035 Prec@(1,5) (23.7%, 53.9%)\u001b[0m\n",
            "[2024-04-02 19:36:13] \u001b[32mValid: [  2/50] Step 080/104 Loss 4.078 Prec@(1,5) (23.2%, 53.2%)\u001b[0m\n",
            "[2024-04-02 19:36:13] \u001b[32mValid: [  2/50] Step 100/104 Loss 4.082 Prec@(1,5) (23.0%, 53.2%)\u001b[0m\n",
            "[2024-04-02 19:36:13] \u001b[32mValid: [  2/50] Step 104/104 Loss 4.085 Prec@(1,5) (22.9%, 53.1%)\u001b[0m\n",
            "[2024-04-02 19:36:13] \u001b[32mValid: [  2/50] Final Prec@1 22.9200%\u001b[0m\n",
            "[2024-04-02 19:36:13] \u001b[32mEpoch 2 LR 0.024901\u001b[0m\n",
            "[2024-04-02 19:36:18] \u001b[32mTrain: [  3/50] Step 000/520 Loss 3.901 Prec@(1,5) (27.1%, 64.6%)\u001b[0m\n",
            "[2024-04-02 19:36:19] \u001b[32mTrain: [  3/50] Step 020/520 Loss 4.150 Prec@(1,5) (24.4%, 55.4%)\u001b[0m\n",
            "[2024-04-02 19:36:19] \u001b[32mTrain: [  3/50] Step 040/520 Loss 4.140 Prec@(1,5) (25.0%, 55.5%)\u001b[0m\n",
            "[2024-04-02 19:36:19] \u001b[32mTrain: [  3/50] Step 060/520 Loss 4.119 Prec@(1,5) (25.1%, 55.7%)\u001b[0m\n",
            "[2024-04-02 19:36:20] \u001b[32mTrain: [  3/50] Step 080/520 Loss 4.104 Prec@(1,5) (25.4%, 55.9%)\u001b[0m\n",
            "[2024-04-02 19:36:20] \u001b[32mTrain: [  3/50] Step 100/520 Loss 4.113 Prec@(1,5) (25.1%, 55.9%)\u001b[0m\n",
            "[2024-04-02 19:36:21] \u001b[32mTrain: [  3/50] Step 120/520 Loss 4.098 Prec@(1,5) (25.2%, 56.1%)\u001b[0m\n",
            "[2024-04-02 19:36:21] \u001b[32mTrain: [  3/50] Step 140/520 Loss 4.088 Prec@(1,5) (25.5%, 56.4%)\u001b[0m\n",
            "[2024-04-02 19:36:22] \u001b[32mTrain: [  3/50] Step 160/520 Loss 4.084 Prec@(1,5) (25.6%, 56.4%)\u001b[0m\n",
            "[2024-04-02 19:36:22] \u001b[32mTrain: [  3/50] Step 180/520 Loss 4.081 Prec@(1,5) (25.8%, 56.5%)\u001b[0m\n",
            "[2024-04-02 19:36:23] \u001b[32mTrain: [  3/50] Step 200/520 Loss 4.075 Prec@(1,5) (25.9%, 56.6%)\u001b[0m\n",
            "[2024-04-02 19:36:23] \u001b[32mTrain: [  3/50] Step 220/520 Loss 4.067 Prec@(1,5) (26.1%, 56.8%)\u001b[0m\n",
            "[2024-04-02 19:36:24] \u001b[32mTrain: [  3/50] Step 240/520 Loss 4.056 Prec@(1,5) (26.2%, 57.0%)\u001b[0m\n",
            "[2024-04-02 19:36:24] \u001b[32mTrain: [  3/50] Step 260/520 Loss 4.050 Prec@(1,5) (26.4%, 57.1%)\u001b[0m\n",
            "[2024-04-02 19:36:25] \u001b[32mTrain: [  3/50] Step 280/520 Loss 4.048 Prec@(1,5) (26.4%, 57.1%)\u001b[0m\n",
            "[2024-04-02 19:36:25] \u001b[32mTrain: [  3/50] Step 300/520 Loss 4.045 Prec@(1,5) (26.5%, 57.2%)\u001b[0m\n",
            "[2024-04-02 19:36:26] \u001b[32mTrain: [  3/50] Step 320/520 Loss 4.042 Prec@(1,5) (26.6%, 57.3%)\u001b[0m\n",
            "[2024-04-02 19:36:26] \u001b[32mTrain: [  3/50] Step 340/520 Loss 4.037 Prec@(1,5) (26.7%, 57.4%)\u001b[0m\n",
            "[2024-04-02 19:36:27] \u001b[32mTrain: [  3/50] Step 360/520 Loss 4.036 Prec@(1,5) (26.6%, 57.5%)\u001b[0m\n",
            "[2024-04-02 19:36:27] \u001b[32mTrain: [  3/50] Step 380/520 Loss 4.029 Prec@(1,5) (26.8%, 57.6%)\u001b[0m\n",
            "[2024-04-02 19:36:28] \u001b[32mTrain: [  3/50] Step 400/520 Loss 4.025 Prec@(1,5) (26.8%, 57.7%)\u001b[0m\n",
            "[2024-04-02 19:36:28] \u001b[32mTrain: [  3/50] Step 420/520 Loss 4.027 Prec@(1,5) (26.7%, 57.7%)\u001b[0m\n",
            "[2024-04-02 19:36:29] \u001b[32mTrain: [  3/50] Step 440/520 Loss 4.025 Prec@(1,5) (26.7%, 57.8%)\u001b[0m\n",
            "[2024-04-02 19:36:29] \u001b[32mTrain: [  3/50] Step 460/520 Loss 4.018 Prec@(1,5) (26.9%, 57.8%)\u001b[0m\n",
            "[2024-04-02 19:36:30] \u001b[32mTrain: [  3/50] Step 480/520 Loss 4.017 Prec@(1,5) (26.9%, 57.8%)\u001b[0m\n",
            "[2024-04-02 19:36:30] \u001b[32mTrain: [  3/50] Step 500/520 Loss 4.012 Prec@(1,5) (27.0%, 57.9%)\u001b[0m\n",
            "[2024-04-02 19:36:31] \u001b[32mTrain: [  3/50] Step 520/520 Loss 4.011 Prec@(1,5) (27.0%, 57.9%)\u001b[0m\n",
            "[2024-04-02 19:36:31] \u001b[32mTrain: [  3/50] Final Prec@1 27.0240%\u001b[0m\n",
            "[2024-04-02 19:36:35] \u001b[32mValid: [  3/50] Step 000/104 Loss 4.111 Prec@(1,5) (28.1%, 56.2%)\u001b[0m\n",
            "[2024-04-02 19:36:35] \u001b[32mValid: [  3/50] Step 020/104 Loss 4.059 Prec@(1,5) (26.6%, 57.5%)\u001b[0m\n",
            "[2024-04-02 19:36:35] \u001b[32mValid: [  3/50] Step 040/104 Loss 3.970 Prec@(1,5) (26.8%, 58.2%)\u001b[0m\n",
            "[2024-04-02 19:36:35] \u001b[32mValid: [  3/50] Step 060/104 Loss 3.908 Prec@(1,5) (27.1%, 58.6%)\u001b[0m\n",
            "[2024-04-02 19:36:35] \u001b[32mValid: [  3/50] Step 080/104 Loss 3.941 Prec@(1,5) (26.8%, 58.3%)\u001b[0m\n",
            "[2024-04-02 19:36:35] \u001b[32mValid: [  3/50] Step 100/104 Loss 3.948 Prec@(1,5) (26.8%, 58.2%)\u001b[0m\n",
            "[2024-04-02 19:36:35] \u001b[32mValid: [  3/50] Step 104/104 Loss 3.950 Prec@(1,5) (26.7%, 58.2%)\u001b[0m\n",
            "[2024-04-02 19:36:36] \u001b[32mValid: [  3/50] Final Prec@1 26.6900%\u001b[0m\n",
            "[2024-04-02 19:36:36] \u001b[32mEpoch 3 LR 0.024779\u001b[0m\n",
            "[2024-04-02 19:36:40] \u001b[32mTrain: [  4/50] Step 000/520 Loss 4.090 Prec@(1,5) (24.0%, 52.1%)\u001b[0m\n",
            "[2024-04-02 19:36:41] \u001b[32mTrain: [  4/50] Step 020/520 Loss 3.798 Prec@(1,5) (29.2%, 61.6%)\u001b[0m\n",
            "[2024-04-02 19:36:41] \u001b[32mTrain: [  4/50] Step 040/520 Loss 3.791 Prec@(1,5) (30.1%, 61.3%)\u001b[0m\n",
            "[2024-04-02 19:36:42] \u001b[32mTrain: [  4/50] Step 060/520 Loss 3.810 Prec@(1,5) (29.9%, 60.8%)\u001b[0m\n",
            "[2024-04-02 19:36:42] \u001b[32mTrain: [  4/50] Step 080/520 Loss 3.810 Prec@(1,5) (29.9%, 61.2%)\u001b[0m\n",
            "[2024-04-02 19:36:43] \u001b[32mTrain: [  4/50] Step 100/520 Loss 3.823 Prec@(1,5) (29.8%, 61.0%)\u001b[0m\n",
            "[2024-04-02 19:36:43] \u001b[32mTrain: [  4/50] Step 120/520 Loss 3.820 Prec@(1,5) (29.8%, 61.0%)\u001b[0m\n",
            "[2024-04-02 19:36:44] \u001b[32mTrain: [  4/50] Step 140/520 Loss 3.815 Prec@(1,5) (29.8%, 61.1%)\u001b[0m\n",
            "[2024-04-02 19:36:44] \u001b[32mTrain: [  4/50] Step 160/520 Loss 3.802 Prec@(1,5) (30.1%, 61.3%)\u001b[0m\n",
            "[2024-04-02 19:36:45] \u001b[32mTrain: [  4/50] Step 180/520 Loss 3.794 Prec@(1,5) (30.1%, 61.5%)\u001b[0m\n",
            "[2024-04-02 19:36:45] \u001b[32mTrain: [  4/50] Step 200/520 Loss 3.797 Prec@(1,5) (30.0%, 61.4%)\u001b[0m\n",
            "[2024-04-02 19:36:46] \u001b[32mTrain: [  4/50] Step 220/520 Loss 3.783 Prec@(1,5) (30.2%, 61.6%)\u001b[0m\n",
            "[2024-04-02 19:36:46] \u001b[32mTrain: [  4/50] Step 240/520 Loss 3.777 Prec@(1,5) (30.3%, 61.8%)\u001b[0m\n",
            "[2024-04-02 19:36:47] \u001b[32mTrain: [  4/50] Step 260/520 Loss 3.772 Prec@(1,5) (30.3%, 61.8%)\u001b[0m\n",
            "[2024-04-02 19:36:47] \u001b[32mTrain: [  4/50] Step 280/520 Loss 3.769 Prec@(1,5) (30.4%, 61.9%)\u001b[0m\n",
            "[2024-04-02 19:36:48] \u001b[32mTrain: [  4/50] Step 300/520 Loss 3.765 Prec@(1,5) (30.5%, 62.0%)\u001b[0m\n",
            "[2024-04-02 19:36:48] \u001b[32mTrain: [  4/50] Step 320/520 Loss 3.760 Prec@(1,5) (30.5%, 62.1%)\u001b[0m\n",
            "[2024-04-02 19:36:49] \u001b[32mTrain: [  4/50] Step 340/520 Loss 3.757 Prec@(1,5) (30.6%, 62.1%)\u001b[0m\n",
            "[2024-04-02 19:36:49] \u001b[32mTrain: [  4/50] Step 360/520 Loss 3.756 Prec@(1,5) (30.6%, 62.1%)\u001b[0m\n",
            "[2024-04-02 19:36:50] \u001b[32mTrain: [  4/50] Step 380/520 Loss 3.750 Prec@(1,5) (30.7%, 62.2%)\u001b[0m\n",
            "[2024-04-02 19:36:50] \u001b[32mTrain: [  4/50] Step 400/520 Loss 3.748 Prec@(1,5) (30.7%, 62.2%)\u001b[0m\n",
            "[2024-04-02 19:36:51] \u001b[32mTrain: [  4/50] Step 420/520 Loss 3.743 Prec@(1,5) (30.7%, 62.3%)\u001b[0m\n",
            "[2024-04-02 19:36:51] \u001b[32mTrain: [  4/50] Step 440/520 Loss 3.740 Prec@(1,5) (30.8%, 62.4%)\u001b[0m\n",
            "[2024-04-02 19:36:52] \u001b[32mTrain: [  4/50] Step 460/520 Loss 3.740 Prec@(1,5) (30.8%, 62.4%)\u001b[0m\n",
            "[2024-04-02 19:36:52] \u001b[32mTrain: [  4/50] Step 480/520 Loss 3.731 Prec@(1,5) (31.0%, 62.6%)\u001b[0m\n",
            "[2024-04-02 19:36:53] \u001b[32mTrain: [  4/50] Step 500/520 Loss 3.724 Prec@(1,5) (31.1%, 62.7%)\u001b[0m\n",
            "[2024-04-02 19:36:53] \u001b[32mTrain: [  4/50] Step 520/520 Loss 3.719 Prec@(1,5) (31.1%, 62.8%)\u001b[0m\n",
            "[2024-04-02 19:36:53] \u001b[32mTrain: [  4/50] Final Prec@1 31.1360%\u001b[0m\n",
            "[2024-04-02 19:36:57] \u001b[32mValid: [  4/50] Step 000/104 Loss 4.005 Prec@(1,5) (32.3%, 58.3%)\u001b[0m\n",
            "[2024-04-02 19:36:57] \u001b[32mValid: [  4/50] Step 020/104 Loss 3.857 Prec@(1,5) (29.9%, 61.9%)\u001b[0m\n",
            "[2024-04-02 19:36:57] \u001b[32mValid: [  4/50] Step 040/104 Loss 3.814 Prec@(1,5) (30.3%, 62.4%)\u001b[0m\n",
            "[2024-04-02 19:36:57] \u001b[32mValid: [  4/50] Step 060/104 Loss 3.783 Prec@(1,5) (30.7%, 62.7%)\u001b[0m\n",
            "[2024-04-02 19:36:58] \u001b[32mValid: [  4/50] Step 080/104 Loss 3.807 Prec@(1,5) (30.2%, 62.3%)\u001b[0m\n",
            "[2024-04-02 19:36:58] \u001b[32mValid: [  4/50] Step 100/104 Loss 3.812 Prec@(1,5) (30.2%, 62.5%)\u001b[0m\n",
            "[2024-04-02 19:36:58] \u001b[32mValid: [  4/50] Step 104/104 Loss 3.819 Prec@(1,5) (30.1%, 62.5%)\u001b[0m\n",
            "[2024-04-02 19:36:58] \u001b[32mValid: [  4/50] Final Prec@1 30.1200%\u001b[0m\n",
            "[2024-04-02 19:36:58] \u001b[32mEpoch 4 LR 0.024607\u001b[0m\n",
            "[2024-04-02 19:37:03] \u001b[32mTrain: [  5/50] Step 000/520 Loss 3.330 Prec@(1,5) (32.3%, 74.0%)\u001b[0m\n",
            "[2024-04-02 19:37:03] \u001b[32mTrain: [  5/50] Step 020/520 Loss 3.629 Prec@(1,5) (31.6%, 64.8%)\u001b[0m\n",
            "[2024-04-02 19:37:04] \u001b[32mTrain: [  5/50] Step 040/520 Loss 3.610 Prec@(1,5) (31.5%, 65.0%)\u001b[0m\n",
            "[2024-04-02 19:37:04] \u001b[32mTrain: [  5/50] Step 060/520 Loss 3.572 Prec@(1,5) (32.5%, 65.5%)\u001b[0m\n",
            "[2024-04-02 19:37:05] \u001b[32mTrain: [  5/50] Step 080/520 Loss 3.576 Prec@(1,5) (33.0%, 65.4%)\u001b[0m\n",
            "[2024-04-02 19:37:05] \u001b[32mTrain: [  5/50] Step 100/520 Loss 3.568 Prec@(1,5) (33.3%, 65.5%)\u001b[0m\n",
            "[2024-04-02 19:37:06] \u001b[32mTrain: [  5/50] Step 120/520 Loss 3.561 Prec@(1,5) (33.3%, 65.5%)\u001b[0m\n",
            "[2024-04-02 19:37:06] \u001b[32mTrain: [  5/50] Step 140/520 Loss 3.557 Prec@(1,5) (33.2%, 65.4%)\u001b[0m\n",
            "[2024-04-02 19:37:07] \u001b[32mTrain: [  5/50] Step 160/520 Loss 3.539 Prec@(1,5) (33.5%, 65.8%)\u001b[0m\n",
            "[2024-04-02 19:37:07] \u001b[32mTrain: [  5/50] Step 180/520 Loss 3.544 Prec@(1,5) (33.5%, 65.7%)\u001b[0m\n",
            "[2024-04-02 19:37:08] \u001b[32mTrain: [  5/50] Step 200/520 Loss 3.544 Prec@(1,5) (33.4%, 65.8%)\u001b[0m\n",
            "[2024-04-02 19:37:08] \u001b[32mTrain: [  5/50] Step 220/520 Loss 3.538 Prec@(1,5) (33.5%, 65.9%)\u001b[0m\n",
            "[2024-04-02 19:37:09] \u001b[32mTrain: [  5/50] Step 240/520 Loss 3.532 Prec@(1,5) (33.5%, 66.1%)\u001b[0m\n",
            "[2024-04-02 19:37:09] \u001b[32mTrain: [  5/50] Step 260/520 Loss 3.529 Prec@(1,5) (33.5%, 66.0%)\u001b[0m\n",
            "[2024-04-02 19:37:10] \u001b[32mTrain: [  5/50] Step 280/520 Loss 3.528 Prec@(1,5) (33.6%, 66.1%)\u001b[0m\n",
            "[2024-04-02 19:37:10] \u001b[32mTrain: [  5/50] Step 300/520 Loss 3.527 Prec@(1,5) (33.7%, 66.0%)\u001b[0m\n",
            "[2024-04-02 19:37:11] \u001b[32mTrain: [  5/50] Step 320/520 Loss 3.527 Prec@(1,5) (33.7%, 66.0%)\u001b[0m\n",
            "[2024-04-02 19:37:11] \u001b[32mTrain: [  5/50] Step 340/520 Loss 3.528 Prec@(1,5) (33.8%, 66.0%)\u001b[0m\n",
            "[2024-04-02 19:37:12] \u001b[32mTrain: [  5/50] Step 360/520 Loss 3.526 Prec@(1,5) (33.8%, 66.0%)\u001b[0m\n",
            "[2024-04-02 19:37:12] \u001b[32mTrain: [  5/50] Step 380/520 Loss 3.519 Prec@(1,5) (34.0%, 66.2%)\u001b[0m\n",
            "[2024-04-02 19:37:12] \u001b[32mTrain: [  5/50] Step 400/520 Loss 3.512 Prec@(1,5) (34.1%, 66.3%)\u001b[0m\n",
            "[2024-04-02 19:37:13] \u001b[32mTrain: [  5/50] Step 420/520 Loss 3.503 Prec@(1,5) (34.2%, 66.4%)\u001b[0m\n",
            "[2024-04-02 19:37:13] \u001b[32mTrain: [  5/50] Step 440/520 Loss 3.504 Prec@(1,5) (34.2%, 66.3%)\u001b[0m\n",
            "[2024-04-02 19:37:14] \u001b[32mTrain: [  5/50] Step 460/520 Loss 3.502 Prec@(1,5) (34.3%, 66.4%)\u001b[0m\n",
            "[2024-04-02 19:37:14] \u001b[32mTrain: [  5/50] Step 480/520 Loss 3.500 Prec@(1,5) (34.4%, 66.4%)\u001b[0m\n",
            "[2024-04-02 19:37:15] \u001b[32mTrain: [  5/50] Step 500/520 Loss 3.498 Prec@(1,5) (34.4%, 66.4%)\u001b[0m\n",
            "[2024-04-02 19:37:15] \u001b[32mTrain: [  5/50] Step 520/520 Loss 3.492 Prec@(1,5) (34.5%, 66.5%)\u001b[0m\n",
            "[2024-04-02 19:37:16] \u001b[32mTrain: [  5/50] Final Prec@1 34.4980%\u001b[0m\n",
            "[2024-04-02 19:37:19] \u001b[32mValid: [  5/50] Step 000/104 Loss 3.564 Prec@(1,5) (31.2%, 63.5%)\u001b[0m\n",
            "[2024-04-02 19:37:19] \u001b[32mValid: [  5/50] Step 020/104 Loss 3.612 Prec@(1,5) (33.2%, 65.5%)\u001b[0m\n",
            "[2024-04-02 19:37:19] \u001b[32mValid: [  5/50] Step 040/104 Loss 3.566 Prec@(1,5) (33.6%, 65.4%)\u001b[0m\n",
            "[2024-04-02 19:37:20] \u001b[32mValid: [  5/50] Step 060/104 Loss 3.560 Prec@(1,5) (33.8%, 64.9%)\u001b[0m\n",
            "[2024-04-02 19:37:20] \u001b[32mValid: [  5/50] Step 080/104 Loss 3.566 Prec@(1,5) (33.1%, 64.7%)\u001b[0m\n",
            "[2024-04-02 19:37:20] \u001b[32mValid: [  5/50] Step 100/104 Loss 3.567 Prec@(1,5) (33.1%, 64.8%)\u001b[0m\n",
            "[2024-04-02 19:37:20] \u001b[32mValid: [  5/50] Step 104/104 Loss 3.564 Prec@(1,5) (33.1%, 64.8%)\u001b[0m\n",
            "[2024-04-02 19:37:20] \u001b[32mValid: [  5/50] Final Prec@1 33.1400%\u001b[0m\n",
            "[2024-04-02 19:37:20] \u001b[32mEpoch 5 LR 0.024388\u001b[0m\n",
            "[2024-04-02 19:37:25] \u001b[32mTrain: [  6/50] Step 000/520 Loss 3.161 Prec@(1,5) (35.4%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:37:25] \u001b[32mTrain: [  6/50] Step 020/520 Loss 3.269 Prec@(1,5) (37.8%, 70.4%)\u001b[0m\n",
            "[2024-04-02 19:37:26] \u001b[32mTrain: [  6/50] Step 040/520 Loss 3.330 Prec@(1,5) (36.5%, 69.6%)\u001b[0m\n",
            "[2024-04-02 19:37:26] \u001b[32mTrain: [  6/50] Step 060/520 Loss 3.351 Prec@(1,5) (36.2%, 69.3%)\u001b[0m\n",
            "[2024-04-02 19:37:27] \u001b[32mTrain: [  6/50] Step 080/520 Loss 3.344 Prec@(1,5) (35.9%, 69.6%)\u001b[0m\n",
            "[2024-04-02 19:37:27] \u001b[32mTrain: [  6/50] Step 100/520 Loss 3.355 Prec@(1,5) (35.8%, 69.4%)\u001b[0m\n",
            "[2024-04-02 19:37:28] \u001b[32mTrain: [  6/50] Step 120/520 Loss 3.365 Prec@(1,5) (36.0%, 69.2%)\u001b[0m\n",
            "[2024-04-02 19:37:28] \u001b[32mTrain: [  6/50] Step 140/520 Loss 3.342 Prec@(1,5) (36.5%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:37:29] \u001b[32mTrain: [  6/50] Step 160/520 Loss 3.340 Prec@(1,5) (36.6%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:37:29] \u001b[32mTrain: [  6/50] Step 180/520 Loss 3.339 Prec@(1,5) (36.7%, 69.6%)\u001b[0m\n",
            "[2024-04-02 19:37:30] \u001b[32mTrain: [  6/50] Step 200/520 Loss 3.341 Prec@(1,5) (36.6%, 69.5%)\u001b[0m\n",
            "[2024-04-02 19:37:30] \u001b[32mTrain: [  6/50] Step 220/520 Loss 3.342 Prec@(1,5) (36.7%, 69.4%)\u001b[0m\n",
            "[2024-04-02 19:37:31] \u001b[32mTrain: [  6/50] Step 240/520 Loss 3.333 Prec@(1,5) (36.8%, 69.5%)\u001b[0m\n",
            "[2024-04-02 19:37:31] \u001b[32mTrain: [  6/50] Step 260/520 Loss 3.330 Prec@(1,5) (36.9%, 69.6%)\u001b[0m\n",
            "[2024-04-02 19:37:32] \u001b[32mTrain: [  6/50] Step 280/520 Loss 3.334 Prec@(1,5) (36.9%, 69.5%)\u001b[0m\n",
            "[2024-04-02 19:37:32] \u001b[32mTrain: [  6/50] Step 300/520 Loss 3.334 Prec@(1,5) (36.8%, 69.5%)\u001b[0m\n",
            "[2024-04-02 19:37:33] \u001b[32mTrain: [  6/50] Step 320/520 Loss 3.331 Prec@(1,5) (36.8%, 69.5%)\u001b[0m\n",
            "[2024-04-02 19:37:33] \u001b[32mTrain: [  6/50] Step 340/520 Loss 3.326 Prec@(1,5) (36.9%, 69.5%)\u001b[0m\n",
            "[2024-04-02 19:37:34] \u001b[32mTrain: [  6/50] Step 360/520 Loss 3.324 Prec@(1,5) (36.9%, 69.6%)\u001b[0m\n",
            "[2024-04-02 19:37:34] \u001b[32mTrain: [  6/50] Step 380/520 Loss 3.322 Prec@(1,5) (37.0%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:37:35] \u001b[32mTrain: [  6/50] Step 400/520 Loss 3.317 Prec@(1,5) (37.1%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:37:35] \u001b[32mTrain: [  6/50] Step 420/520 Loss 3.317 Prec@(1,5) (37.1%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:37:36] \u001b[32mTrain: [  6/50] Step 440/520 Loss 3.313 Prec@(1,5) (37.2%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:37:36] \u001b[32mTrain: [  6/50] Step 460/520 Loss 3.307 Prec@(1,5) (37.3%, 69.8%)\u001b[0m\n",
            "[2024-04-02 19:37:37] \u001b[32mTrain: [  6/50] Step 480/520 Loss 3.308 Prec@(1,5) (37.3%, 69.7%)\u001b[0m\n",
            "[2024-04-02 19:37:37] \u001b[32mTrain: [  6/50] Step 500/520 Loss 3.304 Prec@(1,5) (37.3%, 69.8%)\u001b[0m\n",
            "[2024-04-02 19:37:38] \u001b[32mTrain: [  6/50] Step 520/520 Loss 3.300 Prec@(1,5) (37.4%, 69.9%)\u001b[0m\n",
            "[2024-04-02 19:37:38] \u001b[32mTrain: [  6/50] Final Prec@1 37.3960%\u001b[0m\n",
            "[2024-04-02 19:37:41] \u001b[32mValid: [  6/50] Step 000/104 Loss 3.793 Prec@(1,5) (35.4%, 65.6%)\u001b[0m\n",
            "[2024-04-02 19:37:42] \u001b[32mValid: [  6/50] Step 020/104 Loss 3.495 Prec@(1,5) (35.6%, 68.8%)\u001b[0m\n",
            "[2024-04-02 19:37:42] \u001b[32mValid: [  6/50] Step 040/104 Loss 3.475 Prec@(1,5) (35.3%, 68.3%)\u001b[0m\n",
            "[2024-04-02 19:37:42] \u001b[32mValid: [  6/50] Step 060/104 Loss 3.446 Prec@(1,5) (35.6%, 68.5%)\u001b[0m\n",
            "[2024-04-02 19:37:42] \u001b[32mValid: [  6/50] Step 080/104 Loss 3.473 Prec@(1,5) (34.9%, 68.4%)\u001b[0m\n",
            "[2024-04-02 19:37:42] \u001b[32mValid: [  6/50] Step 100/104 Loss 3.480 Prec@(1,5) (34.9%, 68.0%)\u001b[0m\n",
            "[2024-04-02 19:37:42] \u001b[32mValid: [  6/50] Step 104/104 Loss 3.474 Prec@(1,5) (34.9%, 68.0%)\u001b[0m\n",
            "[2024-04-02 19:37:42] \u001b[32mValid: [  6/50] Final Prec@1 34.8800%\u001b[0m\n",
            "[2024-04-02 19:37:42] \u001b[32mEpoch 6 LR 0.024122\u001b[0m\n",
            "[2024-04-02 19:37:47] \u001b[32mTrain: [  7/50] Step 000/520 Loss 2.938 Prec@(1,5) (43.8%, 77.1%)\u001b[0m\n",
            "[2024-04-02 19:37:48] \u001b[32mTrain: [  7/50] Step 020/520 Loss 3.211 Prec@(1,5) (38.9%, 71.3%)\u001b[0m\n",
            "[2024-04-02 19:37:48] \u001b[32mTrain: [  7/50] Step 040/520 Loss 3.201 Prec@(1,5) (38.6%, 70.8%)\u001b[0m\n",
            "[2024-04-02 19:37:49] \u001b[32mTrain: [  7/50] Step 060/520 Loss 3.201 Prec@(1,5) (38.5%, 70.8%)\u001b[0m\n",
            "[2024-04-02 19:37:49] \u001b[32mTrain: [  7/50] Step 080/520 Loss 3.208 Prec@(1,5) (38.7%, 71.0%)\u001b[0m\n",
            "[2024-04-02 19:37:50] \u001b[32mTrain: [  7/50] Step 100/520 Loss 3.178 Prec@(1,5) (39.3%, 71.4%)\u001b[0m\n",
            "[2024-04-02 19:37:50] \u001b[32mTrain: [  7/50] Step 120/520 Loss 3.186 Prec@(1,5) (38.8%, 71.3%)\u001b[0m\n",
            "[2024-04-02 19:37:51] \u001b[32mTrain: [  7/50] Step 140/520 Loss 3.180 Prec@(1,5) (39.0%, 71.4%)\u001b[0m\n",
            "[2024-04-02 19:37:51] \u001b[32mTrain: [  7/50] Step 160/520 Loss 3.175 Prec@(1,5) (39.3%, 71.5%)\u001b[0m\n",
            "[2024-04-02 19:37:52] \u001b[32mTrain: [  7/50] Step 180/520 Loss 3.174 Prec@(1,5) (39.3%, 71.7%)\u001b[0m\n",
            "[2024-04-02 19:37:52] \u001b[32mTrain: [  7/50] Step 200/520 Loss 3.174 Prec@(1,5) (39.4%, 71.6%)\u001b[0m\n",
            "[2024-04-02 19:37:53] \u001b[32mTrain: [  7/50] Step 220/520 Loss 3.167 Prec@(1,5) (39.5%, 71.7%)\u001b[0m\n",
            "[2024-04-02 19:37:53] \u001b[32mTrain: [  7/50] Step 240/520 Loss 3.161 Prec@(1,5) (39.6%, 71.8%)\u001b[0m\n",
            "[2024-04-02 19:37:53] \u001b[32mTrain: [  7/50] Step 260/520 Loss 3.163 Prec@(1,5) (39.5%, 71.7%)\u001b[0m\n",
            "[2024-04-02 19:37:54] \u001b[32mTrain: [  7/50] Step 280/520 Loss 3.166 Prec@(1,5) (39.5%, 71.6%)\u001b[0m\n",
            "[2024-04-02 19:37:54] \u001b[32mTrain: [  7/50] Step 300/520 Loss 3.165 Prec@(1,5) (39.5%, 71.6%)\u001b[0m\n",
            "[2024-04-02 19:37:55] \u001b[32mTrain: [  7/50] Step 320/520 Loss 3.162 Prec@(1,5) (39.6%, 71.6%)\u001b[0m\n",
            "[2024-04-02 19:37:55] \u001b[32mTrain: [  7/50] Step 340/520 Loss 3.163 Prec@(1,5) (39.6%, 71.7%)\u001b[0m\n",
            "[2024-04-02 19:37:56] \u001b[32mTrain: [  7/50] Step 360/520 Loss 3.156 Prec@(1,5) (39.7%, 71.8%)\u001b[0m\n",
            "[2024-04-02 19:37:56] \u001b[32mTrain: [  7/50] Step 380/520 Loss 3.156 Prec@(1,5) (39.8%, 71.8%)\u001b[0m\n",
            "[2024-04-02 19:37:57] \u001b[32mTrain: [  7/50] Step 400/520 Loss 3.155 Prec@(1,5) (39.8%, 71.8%)\u001b[0m\n",
            "[2024-04-02 19:37:57] \u001b[32mTrain: [  7/50] Step 420/520 Loss 3.157 Prec@(1,5) (39.8%, 71.8%)\u001b[0m\n",
            "[2024-04-02 19:37:58] \u001b[32mTrain: [  7/50] Step 440/520 Loss 3.160 Prec@(1,5) (39.7%, 71.8%)\u001b[0m\n",
            "[2024-04-02 19:37:58] \u001b[32mTrain: [  7/50] Step 460/520 Loss 3.161 Prec@(1,5) (39.7%, 71.8%)\u001b[0m\n",
            "[2024-04-02 19:37:59] \u001b[32mTrain: [  7/50] Step 480/520 Loss 3.161 Prec@(1,5) (39.7%, 71.8%)\u001b[0m\n",
            "[2024-04-02 19:37:59] \u001b[32mTrain: [  7/50] Step 500/520 Loss 3.162 Prec@(1,5) (39.7%, 71.7%)\u001b[0m\n",
            "[2024-04-02 19:38:00] \u001b[32mTrain: [  7/50] Step 520/520 Loss 3.160 Prec@(1,5) (39.8%, 71.8%)\u001b[0m\n",
            "[2024-04-02 19:38:00] \u001b[32mTrain: [  7/50] Final Prec@1 39.7640%\u001b[0m\n",
            "[2024-04-02 19:38:04] \u001b[32mValid: [  7/50] Step 000/104 Loss 3.106 Prec@(1,5) (37.5%, 69.8%)\u001b[0m\n",
            "[2024-04-02 19:38:04] \u001b[32mValid: [  7/50] Step 020/104 Loss 3.264 Prec@(1,5) (36.6%, 69.6%)\u001b[0m\n",
            "[2024-04-02 19:38:04] \u001b[32mValid: [  7/50] Step 040/104 Loss 3.233 Prec@(1,5) (37.2%, 69.9%)\u001b[0m\n",
            "[2024-04-02 19:38:04] \u001b[32mValid: [  7/50] Step 060/104 Loss 3.205 Prec@(1,5) (37.8%, 69.9%)\u001b[0m\n",
            "[2024-04-02 19:38:04] \u001b[32mValid: [  7/50] Step 080/104 Loss 3.196 Prec@(1,5) (37.6%, 69.9%)\u001b[0m\n",
            "[2024-04-02 19:38:04] \u001b[32mValid: [  7/50] Step 100/104 Loss 3.189 Prec@(1,5) (37.8%, 69.9%)\u001b[0m\n",
            "[2024-04-02 19:38:04] \u001b[32mValid: [  7/50] Step 104/104 Loss 3.187 Prec@(1,5) (37.8%, 69.8%)\u001b[0m\n",
            "[2024-04-02 19:38:05] \u001b[32mValid: [  7/50] Final Prec@1 37.8100%\u001b[0m\n",
            "[2024-04-02 19:38:05] \u001b[32mEpoch 7 LR 0.023810\u001b[0m\n",
            "[2024-04-02 19:38:09] \u001b[32mTrain: [  8/50] Step 000/520 Loss 3.096 Prec@(1,5) (43.8%, 69.8%)\u001b[0m\n",
            "[2024-04-02 19:38:10] \u001b[32mTrain: [  8/50] Step 020/520 Loss 2.948 Prec@(1,5) (43.5%, 74.3%)\u001b[0m\n",
            "[2024-04-02 19:38:10] \u001b[32mTrain: [  8/50] Step 040/520 Loss 2.976 Prec@(1,5) (42.7%, 74.6%)\u001b[0m\n",
            "[2024-04-02 19:38:11] \u001b[32mTrain: [  8/50] Step 060/520 Loss 3.000 Prec@(1,5) (42.0%, 74.4%)\u001b[0m\n",
            "[2024-04-02 19:38:11] \u001b[32mTrain: [  8/50] Step 080/520 Loss 2.992 Prec@(1,5) (41.8%, 74.4%)\u001b[0m\n",
            "[2024-04-02 19:38:12] \u001b[32mTrain: [  8/50] Step 100/520 Loss 2.999 Prec@(1,5) (41.7%, 74.3%)\u001b[0m\n",
            "[2024-04-02 19:38:12] \u001b[32mTrain: [  8/50] Step 120/520 Loss 3.013 Prec@(1,5) (41.5%, 74.0%)\u001b[0m\n",
            "[2024-04-02 19:38:13] \u001b[32mTrain: [  8/50] Step 140/520 Loss 3.022 Prec@(1,5) (41.4%, 73.9%)\u001b[0m\n",
            "[2024-04-02 19:38:13] \u001b[32mTrain: [  8/50] Step 160/520 Loss 3.034 Prec@(1,5) (41.3%, 73.6%)\u001b[0m\n",
            "[2024-04-02 19:38:14] \u001b[32mTrain: [  8/50] Step 180/520 Loss 3.031 Prec@(1,5) (41.5%, 73.8%)\u001b[0m\n",
            "[2024-04-02 19:38:14] \u001b[32mTrain: [  8/50] Step 200/520 Loss 3.028 Prec@(1,5) (41.6%, 73.7%)\u001b[0m\n",
            "[2024-04-02 19:38:15] \u001b[32mTrain: [  8/50] Step 220/520 Loss 3.024 Prec@(1,5) (41.8%, 73.9%)\u001b[0m\n",
            "[2024-04-02 19:38:15] \u001b[32mTrain: [  8/50] Step 240/520 Loss 3.020 Prec@(1,5) (41.8%, 74.0%)\u001b[0m\n",
            "[2024-04-02 19:38:16] \u001b[32mTrain: [  8/50] Step 260/520 Loss 3.029 Prec@(1,5) (41.6%, 73.8%)\u001b[0m\n",
            "[2024-04-02 19:38:16] \u001b[32mTrain: [  8/50] Step 280/520 Loss 3.026 Prec@(1,5) (41.7%, 73.8%)\u001b[0m\n",
            "[2024-04-02 19:38:17] \u001b[32mTrain: [  8/50] Step 300/520 Loss 3.028 Prec@(1,5) (41.7%, 73.7%)\u001b[0m\n",
            "[2024-04-02 19:38:17] \u001b[32mTrain: [  8/50] Step 320/520 Loss 3.030 Prec@(1,5) (41.7%, 73.7%)\u001b[0m\n",
            "[2024-04-02 19:38:18] \u001b[32mTrain: [  8/50] Step 340/520 Loss 3.031 Prec@(1,5) (41.7%, 73.7%)\u001b[0m\n",
            "[2024-04-02 19:38:18] \u001b[32mTrain: [  8/50] Step 360/520 Loss 3.034 Prec@(1,5) (41.7%, 73.6%)\u001b[0m\n",
            "[2024-04-02 19:38:19] \u001b[32mTrain: [  8/50] Step 380/520 Loss 3.035 Prec@(1,5) (41.7%, 73.7%)\u001b[0m\n",
            "[2024-04-02 19:38:19] \u001b[32mTrain: [  8/50] Step 400/520 Loss 3.031 Prec@(1,5) (41.8%, 73.7%)\u001b[0m\n",
            "[2024-04-02 19:38:20] \u001b[32mTrain: [  8/50] Step 420/520 Loss 3.032 Prec@(1,5) (41.8%, 73.7%)\u001b[0m\n",
            "[2024-04-02 19:38:20] \u001b[32mTrain: [  8/50] Step 440/520 Loss 3.029 Prec@(1,5) (42.0%, 73.7%)\u001b[0m\n",
            "[2024-04-02 19:38:21] \u001b[32mTrain: [  8/50] Step 460/520 Loss 3.029 Prec@(1,5) (41.9%, 73.7%)\u001b[0m\n",
            "[2024-04-02 19:38:21] \u001b[32mTrain: [  8/50] Step 480/520 Loss 3.026 Prec@(1,5) (42.0%, 73.8%)\u001b[0m\n",
            "[2024-04-02 19:38:22] \u001b[32mTrain: [  8/50] Step 500/520 Loss 3.025 Prec@(1,5) (42.0%, 73.8%)\u001b[0m\n",
            "[2024-04-02 19:38:22] \u001b[32mTrain: [  8/50] Step 520/520 Loss 3.026 Prec@(1,5) (42.0%, 73.8%)\u001b[0m\n",
            "[2024-04-02 19:38:22] \u001b[32mTrain: [  8/50] Final Prec@1 42.0300%\u001b[0m\n",
            "[2024-04-02 19:38:26] \u001b[32mValid: [  8/50] Step 000/104 Loss 3.067 Prec@(1,5) (41.7%, 74.0%)\u001b[0m\n",
            "[2024-04-02 19:38:26] \u001b[32mValid: [  8/50] Step 020/104 Loss 3.197 Prec@(1,5) (38.1%, 71.2%)\u001b[0m\n",
            "[2024-04-02 19:38:26] \u001b[32mValid: [  8/50] Step 040/104 Loss 3.194 Prec@(1,5) (38.2%, 70.8%)\u001b[0m\n",
            "[2024-04-02 19:38:26] \u001b[32mValid: [  8/50] Step 060/104 Loss 3.150 Prec@(1,5) (38.8%, 70.9%)\u001b[0m\n",
            "[2024-04-02 19:38:26] \u001b[32mValid: [  8/50] Step 080/104 Loss 3.141 Prec@(1,5) (38.8%, 71.0%)\u001b[0m\n",
            "[2024-04-02 19:38:27] \u001b[32mValid: [  8/50] Step 100/104 Loss 3.127 Prec@(1,5) (38.9%, 71.2%)\u001b[0m\n",
            "[2024-04-02 19:38:27] \u001b[32mValid: [  8/50] Step 104/104 Loss 3.125 Prec@(1,5) (38.9%, 71.1%)\u001b[0m\n",
            "[2024-04-02 19:38:27] \u001b[32mValid: [  8/50] Final Prec@1 38.9200%\u001b[0m\n",
            "[2024-04-02 19:38:27] \u001b[32mEpoch 8 LR 0.023454\u001b[0m\n",
            "[2024-04-02 19:38:31] \u001b[32mTrain: [  9/50] Step 000/520 Loss 2.756 Prec@(1,5) (45.8%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:38:32] \u001b[32mTrain: [  9/50] Step 020/520 Loss 2.918 Prec@(1,5) (43.7%, 75.9%)\u001b[0m\n",
            "[2024-04-02 19:38:32] \u001b[32mTrain: [  9/50] Step 040/520 Loss 2.885 Prec@(1,5) (43.6%, 76.6%)\u001b[0m\n",
            "[2024-04-02 19:38:33] \u001b[32mTrain: [  9/50] Step 060/520 Loss 2.883 Prec@(1,5) (44.0%, 76.3%)\u001b[0m\n",
            "[2024-04-02 19:38:33] \u001b[32mTrain: [  9/50] Step 080/520 Loss 2.901 Prec@(1,5) (43.4%, 75.8%)\u001b[0m\n",
            "[2024-04-02 19:38:34] \u001b[32mTrain: [  9/50] Step 100/520 Loss 2.915 Prec@(1,5) (43.3%, 75.7%)\u001b[0m\n",
            "[2024-04-02 19:38:34] \u001b[32mTrain: [  9/50] Step 120/520 Loss 2.922 Prec@(1,5) (43.3%, 75.4%)\u001b[0m\n",
            "[2024-04-02 19:38:35] \u001b[32mTrain: [  9/50] Step 140/520 Loss 2.919 Prec@(1,5) (43.5%, 75.5%)\u001b[0m\n",
            "[2024-04-02 19:38:35] \u001b[32mTrain: [  9/50] Step 160/520 Loss 2.921 Prec@(1,5) (43.4%, 75.4%)\u001b[0m\n",
            "[2024-04-02 19:38:36] \u001b[32mTrain: [  9/50] Step 180/520 Loss 2.926 Prec@(1,5) (43.5%, 75.2%)\u001b[0m\n",
            "[2024-04-02 19:38:36] \u001b[32mTrain: [  9/50] Step 200/520 Loss 2.923 Prec@(1,5) (43.7%, 75.4%)\u001b[0m\n",
            "[2024-04-02 19:38:37] \u001b[32mTrain: [  9/50] Step 220/520 Loss 2.924 Prec@(1,5) (43.5%, 75.4%)\u001b[0m\n",
            "[2024-04-02 19:38:37] \u001b[32mTrain: [  9/50] Step 240/520 Loss 2.925 Prec@(1,5) (43.4%, 75.4%)\u001b[0m\n",
            "[2024-04-02 19:38:38] \u001b[32mTrain: [  9/50] Step 260/520 Loss 2.923 Prec@(1,5) (43.5%, 75.3%)\u001b[0m\n",
            "[2024-04-02 19:38:39] \u001b[32mTrain: [  9/50] Step 280/520 Loss 2.926 Prec@(1,5) (43.4%, 75.3%)\u001b[0m\n",
            "[2024-04-02 19:38:39] \u001b[32mTrain: [  9/50] Step 300/520 Loss 2.930 Prec@(1,5) (43.5%, 75.2%)\u001b[0m\n",
            "[2024-04-02 19:38:40] \u001b[32mTrain: [  9/50] Step 320/520 Loss 2.926 Prec@(1,5) (43.6%, 75.2%)\u001b[0m\n",
            "[2024-04-02 19:38:40] \u001b[32mTrain: [  9/50] Step 340/520 Loss 2.931 Prec@(1,5) (43.5%, 75.1%)\u001b[0m\n",
            "[2024-04-02 19:38:41] \u001b[32mTrain: [  9/50] Step 360/520 Loss 2.936 Prec@(1,5) (43.4%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:38:41] \u001b[32mTrain: [  9/50] Step 380/520 Loss 2.935 Prec@(1,5) (43.4%, 75.1%)\u001b[0m\n",
            "[2024-04-02 19:38:42] \u001b[32mTrain: [  9/50] Step 400/520 Loss 2.929 Prec@(1,5) (43.5%, 75.1%)\u001b[0m\n",
            "[2024-04-02 19:38:42] \u001b[32mTrain: [  9/50] Step 420/520 Loss 2.925 Prec@(1,5) (43.6%, 75.1%)\u001b[0m\n",
            "[2024-04-02 19:38:43] \u001b[32mTrain: [  9/50] Step 440/520 Loss 2.925 Prec@(1,5) (43.6%, 75.2%)\u001b[0m\n",
            "[2024-04-02 19:38:43] \u001b[32mTrain: [  9/50] Step 460/520 Loss 2.922 Prec@(1,5) (43.7%, 75.2%)\u001b[0m\n",
            "[2024-04-02 19:38:44] \u001b[32mTrain: [  9/50] Step 480/520 Loss 2.921 Prec@(1,5) (43.7%, 75.2%)\u001b[0m\n",
            "[2024-04-02 19:38:44] \u001b[32mTrain: [  9/50] Step 500/520 Loss 2.923 Prec@(1,5) (43.6%, 75.2%)\u001b[0m\n",
            "[2024-04-02 19:38:45] \u001b[32mTrain: [  9/50] Step 520/520 Loss 2.920 Prec@(1,5) (43.6%, 75.2%)\u001b[0m\n",
            "[2024-04-02 19:38:45] \u001b[32mTrain: [  9/50] Final Prec@1 43.6260%\u001b[0m\n",
            "[2024-04-02 19:38:48] \u001b[32mValid: [  9/50] Step 000/104 Loss 2.893 Prec@(1,5) (45.8%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:38:49] \u001b[32mValid: [  9/50] Step 020/104 Loss 2.869 Prec@(1,5) (43.4%, 73.9%)\u001b[0m\n",
            "[2024-04-02 19:38:49] \u001b[32mValid: [  9/50] Step 040/104 Loss 2.880 Prec@(1,5) (42.0%, 73.5%)\u001b[0m\n",
            "[2024-04-02 19:38:49] \u001b[32mValid: [  9/50] Step 060/104 Loss 2.841 Prec@(1,5) (42.4%, 73.7%)\u001b[0m\n",
            "[2024-04-02 19:38:49] \u001b[32mValid: [  9/50] Step 080/104 Loss 2.839 Prec@(1,5) (42.0%, 73.8%)\u001b[0m\n",
            "[2024-04-02 19:38:49] \u001b[32mValid: [  9/50] Step 100/104 Loss 2.822 Prec@(1,5) (42.3%, 74.0%)\u001b[0m\n",
            "[2024-04-02 19:38:49] \u001b[32mValid: [  9/50] Step 104/104 Loss 2.819 Prec@(1,5) (42.3%, 74.0%)\u001b[0m\n",
            "[2024-04-02 19:38:49] \u001b[32mValid: [  9/50] Final Prec@1 42.2500%\u001b[0m\n",
            "[2024-04-02 19:38:49] \u001b[32mEpoch 9 LR 0.023054\u001b[0m\n",
            "[2024-04-02 19:38:54] \u001b[32mTrain: [ 10/50] Step 000/520 Loss 3.026 Prec@(1,5) (47.9%, 70.8%)\u001b[0m\n",
            "[2024-04-02 19:38:55] \u001b[32mTrain: [ 10/50] Step 020/520 Loss 2.842 Prec@(1,5) (45.1%, 76.0%)\u001b[0m\n",
            "[2024-04-02 19:38:55] \u001b[32mTrain: [ 10/50] Step 040/520 Loss 2.847 Prec@(1,5) (45.3%, 75.9%)\u001b[0m\n",
            "[2024-04-02 19:38:56] \u001b[32mTrain: [ 10/50] Step 060/520 Loss 2.796 Prec@(1,5) (46.0%, 76.8%)\u001b[0m\n",
            "[2024-04-02 19:38:56] \u001b[32mTrain: [ 10/50] Step 080/520 Loss 2.795 Prec@(1,5) (45.9%, 76.7%)\u001b[0m\n",
            "[2024-04-02 19:38:57] \u001b[32mTrain: [ 10/50] Step 100/520 Loss 2.803 Prec@(1,5) (45.9%, 76.7%)\u001b[0m\n",
            "[2024-04-02 19:38:57] \u001b[32mTrain: [ 10/50] Step 120/520 Loss 2.819 Prec@(1,5) (45.5%, 76.5%)\u001b[0m\n",
            "[2024-04-02 19:38:58] \u001b[32mTrain: [ 10/50] Step 140/520 Loss 2.833 Prec@(1,5) (45.2%, 76.4%)\u001b[0m\n",
            "[2024-04-02 19:38:58] \u001b[32mTrain: [ 10/50] Step 160/520 Loss 2.833 Prec@(1,5) (45.1%, 76.5%)\u001b[0m\n",
            "[2024-04-02 19:38:59] \u001b[32mTrain: [ 10/50] Step 180/520 Loss 2.842 Prec@(1,5) (45.0%, 76.3%)\u001b[0m\n",
            "[2024-04-02 19:38:59] \u001b[32mTrain: [ 10/50] Step 200/520 Loss 2.840 Prec@(1,5) (45.1%, 76.2%)\u001b[0m\n",
            "[2024-04-02 19:39:00] \u001b[32mTrain: [ 10/50] Step 220/520 Loss 2.844 Prec@(1,5) (45.1%, 76.2%)\u001b[0m\n",
            "[2024-04-02 19:39:00] \u001b[32mTrain: [ 10/50] Step 240/520 Loss 2.834 Prec@(1,5) (45.3%, 76.4%)\u001b[0m\n",
            "[2024-04-02 19:39:01] \u001b[32mTrain: [ 10/50] Step 260/520 Loss 2.836 Prec@(1,5) (45.3%, 76.3%)\u001b[0m\n",
            "[2024-04-02 19:39:01] \u001b[32mTrain: [ 10/50] Step 280/520 Loss 2.836 Prec@(1,5) (45.3%, 76.4%)\u001b[0m\n",
            "[2024-04-02 19:39:02] \u001b[32mTrain: [ 10/50] Step 300/520 Loss 2.830 Prec@(1,5) (45.4%, 76.4%)\u001b[0m\n",
            "[2024-04-02 19:39:02] \u001b[32mTrain: [ 10/50] Step 320/520 Loss 2.833 Prec@(1,5) (45.3%, 76.3%)\u001b[0m\n",
            "[2024-04-02 19:39:03] \u001b[32mTrain: [ 10/50] Step 340/520 Loss 2.833 Prec@(1,5) (45.3%, 76.3%)\u001b[0m\n",
            "[2024-04-02 19:39:03] \u001b[32mTrain: [ 10/50] Step 360/520 Loss 2.836 Prec@(1,5) (45.2%, 76.4%)\u001b[0m\n",
            "[2024-04-02 19:39:04] \u001b[32mTrain: [ 10/50] Step 380/520 Loss 2.833 Prec@(1,5) (45.3%, 76.5%)\u001b[0m\n",
            "[2024-04-02 19:39:04] \u001b[32mTrain: [ 10/50] Step 400/520 Loss 2.835 Prec@(1,5) (45.2%, 76.4%)\u001b[0m\n",
            "[2024-04-02 19:39:05] \u001b[32mTrain: [ 10/50] Step 420/520 Loss 2.836 Prec@(1,5) (45.2%, 76.5%)\u001b[0m\n",
            "[2024-04-02 19:39:05] \u001b[32mTrain: [ 10/50] Step 440/520 Loss 2.832 Prec@(1,5) (45.2%, 76.5%)\u001b[0m\n",
            "[2024-04-02 19:39:06] \u001b[32mTrain: [ 10/50] Step 460/520 Loss 2.832 Prec@(1,5) (45.2%, 76.5%)\u001b[0m\n",
            "[2024-04-02 19:39:06] \u001b[32mTrain: [ 10/50] Step 480/520 Loss 2.835 Prec@(1,5) (45.2%, 76.5%)\u001b[0m\n",
            "[2024-04-02 19:39:07] \u001b[32mTrain: [ 10/50] Step 500/520 Loss 2.834 Prec@(1,5) (45.2%, 76.5%)\u001b[0m\n",
            "[2024-04-02 19:39:07] \u001b[32mTrain: [ 10/50] Step 520/520 Loss 2.835 Prec@(1,5) (45.2%, 76.5%)\u001b[0m\n",
            "[2024-04-02 19:39:07] \u001b[32mTrain: [ 10/50] Final Prec@1 45.1960%\u001b[0m\n",
            "[2024-04-02 19:39:11] \u001b[32mValid: [ 10/50] Step 000/104 Loss 3.062 Prec@(1,5) (43.8%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:39:11] \u001b[32mValid: [ 10/50] Step 020/104 Loss 3.075 Prec@(1,5) (40.9%, 74.2%)\u001b[0m\n",
            "[2024-04-02 19:39:11] \u001b[32mValid: [ 10/50] Step 040/104 Loss 3.073 Prec@(1,5) (40.3%, 73.8%)\u001b[0m\n",
            "[2024-04-02 19:39:11] \u001b[32mValid: [ 10/50] Step 060/104 Loss 3.024 Prec@(1,5) (41.3%, 74.1%)\u001b[0m\n",
            "[2024-04-02 19:39:12] \u001b[32mValid: [ 10/50] Step 080/104 Loss 3.041 Prec@(1,5) (40.8%, 73.9%)\u001b[0m\n",
            "[2024-04-02 19:39:12] \u001b[32mValid: [ 10/50] Step 100/104 Loss 3.030 Prec@(1,5) (41.1%, 73.8%)\u001b[0m\n",
            "[2024-04-02 19:39:12] \u001b[32mValid: [ 10/50] Step 104/104 Loss 3.032 Prec@(1,5) (41.0%, 73.7%)\u001b[0m\n",
            "[2024-04-02 19:39:12] \u001b[32mValid: [ 10/50] Final Prec@1 41.0100%\u001b[0m\n",
            "[2024-04-02 19:39:12] \u001b[32mEpoch 10 LR 0.022613\u001b[0m\n",
            "[2024-04-02 19:39:17] \u001b[32mTrain: [ 11/50] Step 000/520 Loss 2.759 Prec@(1,5) (49.0%, 76.0%)\u001b[0m\n",
            "[2024-04-02 19:39:17] \u001b[32mTrain: [ 11/50] Step 020/520 Loss 2.757 Prec@(1,5) (46.1%, 77.9%)\u001b[0m\n",
            "[2024-04-02 19:39:18] \u001b[32mTrain: [ 11/50] Step 040/520 Loss 2.728 Prec@(1,5) (47.3%, 78.0%)\u001b[0m\n",
            "[2024-04-02 19:39:18] \u001b[32mTrain: [ 11/50] Step 060/520 Loss 2.762 Prec@(1,5) (46.2%, 77.3%)\u001b[0m\n",
            "[2024-04-02 19:39:19] \u001b[32mTrain: [ 11/50] Step 080/520 Loss 2.746 Prec@(1,5) (46.8%, 77.5%)\u001b[0m\n",
            "[2024-04-02 19:39:19] \u001b[32mTrain: [ 11/50] Step 100/520 Loss 2.749 Prec@(1,5) (46.4%, 77.7%)\u001b[0m\n",
            "[2024-04-02 19:39:20] \u001b[32mTrain: [ 11/50] Step 120/520 Loss 2.760 Prec@(1,5) (46.2%, 77.6%)\u001b[0m\n",
            "[2024-04-02 19:39:20] \u001b[32mTrain: [ 11/50] Step 140/520 Loss 2.758 Prec@(1,5) (46.4%, 77.4%)\u001b[0m\n",
            "[2024-04-02 19:39:21] \u001b[32mTrain: [ 11/50] Step 160/520 Loss 2.752 Prec@(1,5) (46.5%, 77.5%)\u001b[0m\n",
            "[2024-04-02 19:39:21] \u001b[32mTrain: [ 11/50] Step 180/520 Loss 2.755 Prec@(1,5) (46.5%, 77.4%)\u001b[0m\n",
            "[2024-04-02 19:39:22] \u001b[32mTrain: [ 11/50] Step 200/520 Loss 2.748 Prec@(1,5) (46.5%, 77.6%)\u001b[0m\n",
            "[2024-04-02 19:39:22] \u001b[32mTrain: [ 11/50] Step 220/520 Loss 2.756 Prec@(1,5) (46.4%, 77.4%)\u001b[0m\n",
            "[2024-04-02 19:39:23] \u001b[32mTrain: [ 11/50] Step 240/520 Loss 2.756 Prec@(1,5) (46.4%, 77.4%)\u001b[0m\n",
            "[2024-04-02 19:39:23] \u001b[32mTrain: [ 11/50] Step 260/520 Loss 2.758 Prec@(1,5) (46.3%, 77.4%)\u001b[0m\n",
            "[2024-04-02 19:39:24] \u001b[32mTrain: [ 11/50] Step 280/520 Loss 2.760 Prec@(1,5) (46.4%, 77.4%)\u001b[0m\n",
            "[2024-04-02 19:39:24] \u001b[32mTrain: [ 11/50] Step 300/520 Loss 2.763 Prec@(1,5) (46.3%, 77.3%)\u001b[0m\n",
            "[2024-04-02 19:39:25] \u001b[32mTrain: [ 11/50] Step 320/520 Loss 2.760 Prec@(1,5) (46.4%, 77.4%)\u001b[0m\n",
            "[2024-04-02 19:39:25] \u001b[32mTrain: [ 11/50] Step 340/520 Loss 2.758 Prec@(1,5) (46.5%, 77.5%)\u001b[0m\n",
            "[2024-04-02 19:39:25] \u001b[32mTrain: [ 11/50] Step 360/520 Loss 2.757 Prec@(1,5) (46.4%, 77.5%)\u001b[0m\n",
            "[2024-04-02 19:39:26] \u001b[32mTrain: [ 11/50] Step 380/520 Loss 2.756 Prec@(1,5) (46.4%, 77.5%)\u001b[0m\n",
            "[2024-04-02 19:39:26] \u001b[32mTrain: [ 11/50] Step 400/520 Loss 2.756 Prec@(1,5) (46.4%, 77.5%)\u001b[0m\n",
            "[2024-04-02 19:39:27] \u001b[32mTrain: [ 11/50] Step 420/520 Loss 2.754 Prec@(1,5) (46.5%, 77.6%)\u001b[0m\n",
            "[2024-04-02 19:39:27] \u001b[32mTrain: [ 11/50] Step 440/520 Loss 2.751 Prec@(1,5) (46.5%, 77.6%)\u001b[0m\n",
            "[2024-04-02 19:39:28] \u001b[32mTrain: [ 11/50] Step 460/520 Loss 2.750 Prec@(1,5) (46.6%, 77.6%)\u001b[0m\n",
            "[2024-04-02 19:39:28] \u001b[32mTrain: [ 11/50] Step 480/520 Loss 2.747 Prec@(1,5) (46.6%, 77.6%)\u001b[0m\n",
            "[2024-04-02 19:39:29] \u001b[32mTrain: [ 11/50] Step 500/520 Loss 2.748 Prec@(1,5) (46.5%, 77.6%)\u001b[0m\n",
            "[2024-04-02 19:39:29] \u001b[32mTrain: [ 11/50] Step 520/520 Loss 2.747 Prec@(1,5) (46.5%, 77.6%)\u001b[0m\n",
            "[2024-04-02 19:39:30] \u001b[32mTrain: [ 11/50] Final Prec@1 46.5420%\u001b[0m\n",
            "[2024-04-02 19:39:33] \u001b[32mValid: [ 11/50] Step 000/104 Loss 3.035 Prec@(1,5) (45.8%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:39:33] \u001b[32mValid: [ 11/50] Step 020/104 Loss 3.142 Prec@(1,5) (41.3%, 75.1%)\u001b[0m\n",
            "[2024-04-02 19:39:33] \u001b[32mValid: [ 11/50] Step 040/104 Loss 3.088 Prec@(1,5) (41.0%, 74.6%)\u001b[0m\n",
            "[2024-04-02 19:39:34] \u001b[32mValid: [ 11/50] Step 060/104 Loss 3.051 Prec@(1,5) (41.9%, 74.3%)\u001b[0m\n",
            "[2024-04-02 19:39:34] \u001b[32mValid: [ 11/50] Step 080/104 Loss 3.044 Prec@(1,5) (41.8%, 74.3%)\u001b[0m\n",
            "[2024-04-02 19:39:34] \u001b[32mValid: [ 11/50] Step 100/104 Loss 3.040 Prec@(1,5) (42.1%, 74.4%)\u001b[0m\n",
            "[2024-04-02 19:39:34] \u001b[32mValid: [ 11/50] Step 104/104 Loss 3.042 Prec@(1,5) (42.0%, 74.3%)\u001b[0m\n",
            "[2024-04-02 19:39:34] \u001b[32mValid: [ 11/50] Final Prec@1 41.9900%\u001b[0m\n",
            "[2024-04-02 19:39:34] \u001b[32mEpoch 11 LR 0.022132\u001b[0m\n",
            "[2024-04-02 19:39:39] \u001b[32mTrain: [ 12/50] Step 000/520 Loss 2.875 Prec@(1,5) (44.8%, 77.1%)\u001b[0m\n",
            "[2024-04-02 19:39:39] \u001b[32mTrain: [ 12/50] Step 020/520 Loss 2.644 Prec@(1,5) (47.8%, 78.7%)\u001b[0m\n",
            "[2024-04-02 19:39:40] \u001b[32mTrain: [ 12/50] Step 040/520 Loss 2.702 Prec@(1,5) (47.0%, 77.8%)\u001b[0m\n",
            "[2024-04-02 19:39:40] \u001b[32mTrain: [ 12/50] Step 060/520 Loss 2.693 Prec@(1,5) (47.1%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:39:41] \u001b[32mTrain: [ 12/50] Step 080/520 Loss 2.676 Prec@(1,5) (47.4%, 78.3%)\u001b[0m\n",
            "[2024-04-02 19:39:41] \u001b[32mTrain: [ 12/50] Step 100/520 Loss 2.668 Prec@(1,5) (47.5%, 78.6%)\u001b[0m\n",
            "[2024-04-02 19:39:42] \u001b[32mTrain: [ 12/50] Step 120/520 Loss 2.680 Prec@(1,5) (47.3%, 78.3%)\u001b[0m\n",
            "[2024-04-02 19:39:42] \u001b[32mTrain: [ 12/50] Step 140/520 Loss 2.686 Prec@(1,5) (47.3%, 78.2%)\u001b[0m\n",
            "[2024-04-02 19:39:43] \u001b[32mTrain: [ 12/50] Step 160/520 Loss 2.693 Prec@(1,5) (47.3%, 78.3%)\u001b[0m\n",
            "[2024-04-02 19:39:43] \u001b[32mTrain: [ 12/50] Step 180/520 Loss 2.688 Prec@(1,5) (47.3%, 78.4%)\u001b[0m\n",
            "[2024-04-02 19:39:44] \u001b[32mTrain: [ 12/50] Step 200/520 Loss 2.684 Prec@(1,5) (47.4%, 78.4%)\u001b[0m\n",
            "[2024-04-02 19:39:45] \u001b[32mTrain: [ 12/50] Step 220/520 Loss 2.684 Prec@(1,5) (47.4%, 78.4%)\u001b[0m\n",
            "[2024-04-02 19:39:45] \u001b[32mTrain: [ 12/50] Step 240/520 Loss 2.679 Prec@(1,5) (47.5%, 78.4%)\u001b[0m\n",
            "[2024-04-02 19:39:46] \u001b[32mTrain: [ 12/50] Step 260/520 Loss 2.681 Prec@(1,5) (47.5%, 78.4%)\u001b[0m\n",
            "[2024-04-02 19:39:46] \u001b[32mTrain: [ 12/50] Step 280/520 Loss 2.684 Prec@(1,5) (47.5%, 78.4%)\u001b[0m\n",
            "[2024-04-02 19:39:47] \u001b[32mTrain: [ 12/50] Step 300/520 Loss 2.685 Prec@(1,5) (47.5%, 78.5%)\u001b[0m\n",
            "[2024-04-02 19:39:47] \u001b[32mTrain: [ 12/50] Step 320/520 Loss 2.687 Prec@(1,5) (47.5%, 78.4%)\u001b[0m\n",
            "[2024-04-02 19:39:48] \u001b[32mTrain: [ 12/50] Step 340/520 Loss 2.686 Prec@(1,5) (47.6%, 78.5%)\u001b[0m\n",
            "[2024-04-02 19:39:48] \u001b[32mTrain: [ 12/50] Step 360/520 Loss 2.687 Prec@(1,5) (47.6%, 78.5%)\u001b[0m\n",
            "[2024-04-02 19:39:49] \u001b[32mTrain: [ 12/50] Step 380/520 Loss 2.688 Prec@(1,5) (47.5%, 78.4%)\u001b[0m\n",
            "[2024-04-02 19:39:49] \u001b[32mTrain: [ 12/50] Step 400/520 Loss 2.691 Prec@(1,5) (47.4%, 78.4%)\u001b[0m\n",
            "[2024-04-02 19:39:50] \u001b[32mTrain: [ 12/50] Step 420/520 Loss 2.691 Prec@(1,5) (47.5%, 78.4%)\u001b[0m\n",
            "[2024-04-02 19:39:50] \u001b[32mTrain: [ 12/50] Step 440/520 Loss 2.695 Prec@(1,5) (47.5%, 78.4%)\u001b[0m\n",
            "[2024-04-02 19:39:51] \u001b[32mTrain: [ 12/50] Step 460/520 Loss 2.694 Prec@(1,5) (47.5%, 78.4%)\u001b[0m\n",
            "[2024-04-02 19:39:51] \u001b[32mTrain: [ 12/50] Step 480/520 Loss 2.693 Prec@(1,5) (47.5%, 78.5%)\u001b[0m\n",
            "[2024-04-02 19:39:52] \u001b[32mTrain: [ 12/50] Step 500/520 Loss 2.691 Prec@(1,5) (47.6%, 78.5%)\u001b[0m\n",
            "[2024-04-02 19:39:52] \u001b[32mTrain: [ 12/50] Step 520/520 Loss 2.690 Prec@(1,5) (47.6%, 78.5%)\u001b[0m\n",
            "[2024-04-02 19:39:52] \u001b[32mTrain: [ 12/50] Final Prec@1 47.6340%\u001b[0m\n",
            "[2024-04-02 19:39:56] \u001b[32mValid: [ 12/50] Step 000/104 Loss 2.655 Prec@(1,5) (51.0%, 80.2%)\u001b[0m\n",
            "[2024-04-02 19:39:56] \u001b[32mValid: [ 12/50] Step 020/104 Loss 2.759 Prec@(1,5) (45.7%, 77.3%)\u001b[0m\n",
            "[2024-04-02 19:39:56] \u001b[32mValid: [ 12/50] Step 040/104 Loss 2.775 Prec@(1,5) (44.5%, 76.6%)\u001b[0m\n",
            "[2024-04-02 19:39:56] \u001b[32mValid: [ 12/50] Step 060/104 Loss 2.728 Prec@(1,5) (45.2%, 77.0%)\u001b[0m\n",
            "[2024-04-02 19:39:57] \u001b[32mValid: [ 12/50] Step 080/104 Loss 2.747 Prec@(1,5) (44.6%, 76.8%)\u001b[0m\n",
            "[2024-04-02 19:39:57] \u001b[32mValid: [ 12/50] Step 100/104 Loss 2.738 Prec@(1,5) (44.8%, 76.9%)\u001b[0m\n",
            "[2024-04-02 19:39:57] \u001b[32mValid: [ 12/50] Step 104/104 Loss 2.737 Prec@(1,5) (44.8%, 76.9%)\u001b[0m\n",
            "[2024-04-02 19:39:57] \u001b[32mValid: [ 12/50] Final Prec@1 44.7800%\u001b[0m\n",
            "[2024-04-02 19:39:57] \u001b[32mEpoch 12 LR 0.021612\u001b[0m\n",
            "[2024-04-02 19:40:02] \u001b[32mTrain: [ 13/50] Step 000/520 Loss 2.740 Prec@(1,5) (44.8%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:40:02] \u001b[32mTrain: [ 13/50] Step 020/520 Loss 2.633 Prec@(1,5) (47.7%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:40:03] \u001b[32mTrain: [ 13/50] Step 040/520 Loss 2.627 Prec@(1,5) (48.3%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:40:03] \u001b[32mTrain: [ 13/50] Step 060/520 Loss 2.618 Prec@(1,5) (48.5%, 79.3%)\u001b[0m\n",
            "[2024-04-02 19:40:04] \u001b[32mTrain: [ 13/50] Step 080/520 Loss 2.612 Prec@(1,5) (48.7%, 79.5%)\u001b[0m\n",
            "[2024-04-02 19:40:04] \u001b[32mTrain: [ 13/50] Step 100/520 Loss 2.590 Prec@(1,5) (49.4%, 80.0%)\u001b[0m\n",
            "[2024-04-02 19:40:05] \u001b[32mTrain: [ 13/50] Step 120/520 Loss 2.590 Prec@(1,5) (49.4%, 79.9%)\u001b[0m\n",
            "[2024-04-02 19:40:05] \u001b[32mTrain: [ 13/50] Step 140/520 Loss 2.600 Prec@(1,5) (49.2%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:40:06] \u001b[32mTrain: [ 13/50] Step 160/520 Loss 2.601 Prec@(1,5) (48.8%, 79.7%)\u001b[0m\n",
            "[2024-04-02 19:40:06] \u001b[32mTrain: [ 13/50] Step 180/520 Loss 2.597 Prec@(1,5) (49.0%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:40:07] \u001b[32mTrain: [ 13/50] Step 200/520 Loss 2.608 Prec@(1,5) (48.8%, 79.6%)\u001b[0m\n",
            "[2024-04-02 19:40:07] \u001b[32mTrain: [ 13/50] Step 220/520 Loss 2.609 Prec@(1,5) (48.8%, 79.6%)\u001b[0m\n",
            "[2024-04-02 19:40:08] \u001b[32mTrain: [ 13/50] Step 240/520 Loss 2.610 Prec@(1,5) (48.7%, 79.6%)\u001b[0m\n",
            "[2024-04-02 19:40:08] \u001b[32mTrain: [ 13/50] Step 260/520 Loss 2.612 Prec@(1,5) (48.8%, 79.6%)\u001b[0m\n",
            "[2024-04-02 19:40:09] \u001b[32mTrain: [ 13/50] Step 280/520 Loss 2.616 Prec@(1,5) (48.9%, 79.5%)\u001b[0m\n",
            "[2024-04-02 19:40:09] \u001b[32mTrain: [ 13/50] Step 300/520 Loss 2.615 Prec@(1,5) (48.9%, 79.5%)\u001b[0m\n",
            "[2024-04-02 19:40:10] \u001b[32mTrain: [ 13/50] Step 320/520 Loss 2.621 Prec@(1,5) (48.8%, 79.4%)\u001b[0m\n",
            "[2024-04-02 19:40:10] \u001b[32mTrain: [ 13/50] Step 340/520 Loss 2.624 Prec@(1,5) (48.7%, 79.3%)\u001b[0m\n",
            "[2024-04-02 19:40:11] \u001b[32mTrain: [ 13/50] Step 360/520 Loss 2.624 Prec@(1,5) (48.7%, 79.3%)\u001b[0m\n",
            "[2024-04-02 19:40:11] \u001b[32mTrain: [ 13/50] Step 380/520 Loss 2.626 Prec@(1,5) (48.6%, 79.3%)\u001b[0m\n",
            "[2024-04-02 19:40:12] \u001b[32mTrain: [ 13/50] Step 400/520 Loss 2.625 Prec@(1,5) (48.7%, 79.3%)\u001b[0m\n",
            "[2024-04-02 19:40:12] \u001b[32mTrain: [ 13/50] Step 420/520 Loss 2.630 Prec@(1,5) (48.6%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:40:13] \u001b[32mTrain: [ 13/50] Step 440/520 Loss 2.628 Prec@(1,5) (48.7%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:40:13] \u001b[32mTrain: [ 13/50] Step 460/520 Loss 2.628 Prec@(1,5) (48.7%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:40:14] \u001b[32mTrain: [ 13/50] Step 480/520 Loss 2.626 Prec@(1,5) (48.7%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:40:14] \u001b[32mTrain: [ 13/50] Step 500/520 Loss 2.625 Prec@(1,5) (48.8%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:40:15] \u001b[32mTrain: [ 13/50] Step 520/520 Loss 2.623 Prec@(1,5) (48.8%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:40:15] \u001b[32mTrain: [ 13/50] Final Prec@1 48.8300%\u001b[0m\n",
            "[2024-04-02 19:40:19] \u001b[32mValid: [ 13/50] Step 000/104 Loss 2.696 Prec@(1,5) (49.0%, 80.2%)\u001b[0m\n",
            "[2024-04-02 19:40:19] \u001b[32mValid: [ 13/50] Step 020/104 Loss 2.652 Prec@(1,5) (47.3%, 77.6%)\u001b[0m\n",
            "[2024-04-02 19:40:19] \u001b[32mValid: [ 13/50] Step 040/104 Loss 2.635 Prec@(1,5) (46.8%, 77.8%)\u001b[0m\n",
            "[2024-04-02 19:40:19] \u001b[32mValid: [ 13/50] Step 060/104 Loss 2.585 Prec@(1,5) (47.2%, 78.0%)\u001b[0m\n",
            "[2024-04-02 19:40:19] \u001b[32mValid: [ 13/50] Step 080/104 Loss 2.597 Prec@(1,5) (46.8%, 77.9%)\u001b[0m\n",
            "[2024-04-02 19:40:20] \u001b[32mValid: [ 13/50] Step 100/104 Loss 2.590 Prec@(1,5) (46.8%, 78.0%)\u001b[0m\n",
            "[2024-04-02 19:40:20] \u001b[32mValid: [ 13/50] Step 104/104 Loss 2.594 Prec@(1,5) (46.8%, 78.0%)\u001b[0m\n",
            "[2024-04-02 19:40:20] \u001b[32mValid: [ 13/50] Final Prec@1 46.7800%\u001b[0m\n",
            "[2024-04-02 19:40:20] \u001b[32mEpoch 13 LR 0.021057\u001b[0m\n",
            "[2024-04-02 19:40:24] \u001b[32mTrain: [ 14/50] Step 000/520 Loss 2.563 Prec@(1,5) (50.0%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:40:25] \u001b[32mTrain: [ 14/50] Step 020/520 Loss 2.576 Prec@(1,5) (48.9%, 79.6%)\u001b[0m\n",
            "[2024-04-02 19:40:25] \u001b[32mTrain: [ 14/50] Step 040/520 Loss 2.557 Prec@(1,5) (49.3%, 79.9%)\u001b[0m\n",
            "[2024-04-02 19:40:26] \u001b[32mTrain: [ 14/50] Step 060/520 Loss 2.566 Prec@(1,5) (49.3%, 79.6%)\u001b[0m\n",
            "[2024-04-02 19:40:26] \u001b[32mTrain: [ 14/50] Step 080/520 Loss 2.573 Prec@(1,5) (49.2%, 79.3%)\u001b[0m\n",
            "[2024-04-02 19:40:27] \u001b[32mTrain: [ 14/50] Step 100/520 Loss 2.567 Prec@(1,5) (49.6%, 79.6%)\u001b[0m\n",
            "[2024-04-02 19:40:27] \u001b[32mTrain: [ 14/50] Step 120/520 Loss 2.563 Prec@(1,5) (49.6%, 79.6%)\u001b[0m\n",
            "[2024-04-02 19:40:28] \u001b[32mTrain: [ 14/50] Step 140/520 Loss 2.574 Prec@(1,5) (49.4%, 79.6%)\u001b[0m\n",
            "[2024-04-02 19:40:28] \u001b[32mTrain: [ 14/50] Step 160/520 Loss 2.586 Prec@(1,5) (49.2%, 79.6%)\u001b[0m\n",
            "[2024-04-02 19:40:29] \u001b[32mTrain: [ 14/50] Step 180/520 Loss 2.581 Prec@(1,5) (49.2%, 79.7%)\u001b[0m\n",
            "[2024-04-02 19:40:29] \u001b[32mTrain: [ 14/50] Step 200/520 Loss 2.585 Prec@(1,5) (49.2%, 79.7%)\u001b[0m\n",
            "[2024-04-02 19:40:30] \u001b[32mTrain: [ 14/50] Step 220/520 Loss 2.586 Prec@(1,5) (49.1%, 79.6%)\u001b[0m\n",
            "[2024-04-02 19:40:30] \u001b[32mTrain: [ 14/50] Step 240/520 Loss 2.592 Prec@(1,5) (49.0%, 79.5%)\u001b[0m\n",
            "[2024-04-02 19:40:31] \u001b[32mTrain: [ 14/50] Step 260/520 Loss 2.592 Prec@(1,5) (49.0%, 79.5%)\u001b[0m\n",
            "[2024-04-02 19:40:31] \u001b[32mTrain: [ 14/50] Step 280/520 Loss 2.592 Prec@(1,5) (49.1%, 79.6%)\u001b[0m\n",
            "[2024-04-02 19:40:32] \u001b[32mTrain: [ 14/50] Step 300/520 Loss 2.589 Prec@(1,5) (49.1%, 79.6%)\u001b[0m\n",
            "[2024-04-02 19:40:32] \u001b[32mTrain: [ 14/50] Step 320/520 Loss 2.594 Prec@(1,5) (49.1%, 79.5%)\u001b[0m\n",
            "[2024-04-02 19:40:33] \u001b[32mTrain: [ 14/50] Step 340/520 Loss 2.585 Prec@(1,5) (49.2%, 79.6%)\u001b[0m\n",
            "[2024-04-02 19:40:33] \u001b[32mTrain: [ 14/50] Step 360/520 Loss 2.583 Prec@(1,5) (49.2%, 79.6%)\u001b[0m\n",
            "[2024-04-02 19:40:34] \u001b[32mTrain: [ 14/50] Step 380/520 Loss 2.584 Prec@(1,5) (49.2%, 79.6%)\u001b[0m\n",
            "[2024-04-02 19:40:34] \u001b[32mTrain: [ 14/50] Step 400/520 Loss 2.581 Prec@(1,5) (49.3%, 79.6%)\u001b[0m\n",
            "[2024-04-02 19:40:35] \u001b[32mTrain: [ 14/50] Step 420/520 Loss 2.578 Prec@(1,5) (49.4%, 79.7%)\u001b[0m\n",
            "[2024-04-02 19:40:35] \u001b[32mTrain: [ 14/50] Step 440/520 Loss 2.577 Prec@(1,5) (49.4%, 79.7%)\u001b[0m\n",
            "[2024-04-02 19:40:36] \u001b[32mTrain: [ 14/50] Step 460/520 Loss 2.577 Prec@(1,5) (49.4%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:40:36] \u001b[32mTrain: [ 14/50] Step 480/520 Loss 2.575 Prec@(1,5) (49.4%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:40:37] \u001b[32mTrain: [ 14/50] Step 500/520 Loss 2.575 Prec@(1,5) (49.4%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:40:37] \u001b[32mTrain: [ 14/50] Step 520/520 Loss 2.573 Prec@(1,5) (49.5%, 79.9%)\u001b[0m\n",
            "[2024-04-02 19:40:37] \u001b[32mTrain: [ 14/50] Final Prec@1 49.5160%\u001b[0m\n",
            "[2024-04-02 19:40:41] \u001b[32mValid: [ 14/50] Step 000/104 Loss 3.003 Prec@(1,5) (44.8%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:40:41] \u001b[32mValid: [ 14/50] Step 020/104 Loss 2.969 Prec@(1,5) (45.2%, 75.9%)\u001b[0m\n",
            "[2024-04-02 19:40:41] \u001b[32mValid: [ 14/50] Step 040/104 Loss 2.967 Prec@(1,5) (44.7%, 75.6%)\u001b[0m\n",
            "[2024-04-02 19:40:41] \u001b[32mValid: [ 14/50] Step 060/104 Loss 2.890 Prec@(1,5) (45.6%, 75.9%)\u001b[0m\n",
            "[2024-04-02 19:40:42] \u001b[32mValid: [ 14/50] Step 080/104 Loss 2.878 Prec@(1,5) (45.5%, 75.7%)\u001b[0m\n",
            "[2024-04-02 19:40:42] \u001b[32mValid: [ 14/50] Step 100/104 Loss 2.861 Prec@(1,5) (45.3%, 75.8%)\u001b[0m\n",
            "[2024-04-02 19:40:42] \u001b[32mValid: [ 14/50] Step 104/104 Loss 2.860 Prec@(1,5) (45.2%, 75.8%)\u001b[0m\n",
            "[2024-04-02 19:40:42] \u001b[32mValid: [ 14/50] Final Prec@1 45.2300%\u001b[0m\n",
            "[2024-04-02 19:40:42] \u001b[32mEpoch 14 LR 0.020468\u001b[0m\n",
            "[2024-04-02 19:40:47] \u001b[32mTrain: [ 15/50] Step 000/520 Loss 2.427 Prec@(1,5) (51.0%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:40:47] \u001b[32mTrain: [ 15/50] Step 020/520 Loss 2.445 Prec@(1,5) (51.0%, 81.7%)\u001b[0m\n",
            "[2024-04-02 19:40:48] \u001b[32mTrain: [ 15/50] Step 040/520 Loss 2.488 Prec@(1,5) (50.7%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:40:48] \u001b[32mTrain: [ 15/50] Step 060/520 Loss 2.476 Prec@(1,5) (51.2%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:40:49] \u001b[32mTrain: [ 15/50] Step 080/520 Loss 2.489 Prec@(1,5) (50.9%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:40:49] \u001b[32mTrain: [ 15/50] Step 100/520 Loss 2.503 Prec@(1,5) (50.7%, 80.8%)\u001b[0m\n",
            "[2024-04-02 19:40:50] \u001b[32mTrain: [ 15/50] Step 120/520 Loss 2.507 Prec@(1,5) (50.7%, 80.7%)\u001b[0m\n",
            "[2024-04-02 19:40:50] \u001b[32mTrain: [ 15/50] Step 140/520 Loss 2.510 Prec@(1,5) (50.7%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:40:51] \u001b[32mTrain: [ 15/50] Step 160/520 Loss 2.509 Prec@(1,5) (50.6%, 80.8%)\u001b[0m\n",
            "[2024-04-02 19:40:51] \u001b[32mTrain: [ 15/50] Step 180/520 Loss 2.502 Prec@(1,5) (50.9%, 80.8%)\u001b[0m\n",
            "[2024-04-02 19:40:52] \u001b[32mTrain: [ 15/50] Step 200/520 Loss 2.516 Prec@(1,5) (50.6%, 80.7%)\u001b[0m\n",
            "[2024-04-02 19:40:52] \u001b[32mTrain: [ 15/50] Step 220/520 Loss 2.516 Prec@(1,5) (50.5%, 80.8%)\u001b[0m\n",
            "[2024-04-02 19:40:53] \u001b[32mTrain: [ 15/50] Step 240/520 Loss 2.519 Prec@(1,5) (50.5%, 80.8%)\u001b[0m\n",
            "[2024-04-02 19:40:53] \u001b[32mTrain: [ 15/50] Step 260/520 Loss 2.522 Prec@(1,5) (50.4%, 80.7%)\u001b[0m\n",
            "[2024-04-02 19:40:54] \u001b[32mTrain: [ 15/50] Step 280/520 Loss 2.516 Prec@(1,5) (50.5%, 80.8%)\u001b[0m\n",
            "[2024-04-02 19:40:54] \u001b[32mTrain: [ 15/50] Step 300/520 Loss 2.515 Prec@(1,5) (50.5%, 80.8%)\u001b[0m\n",
            "[2024-04-02 19:40:55] \u001b[32mTrain: [ 15/50] Step 320/520 Loss 2.516 Prec@(1,5) (50.5%, 80.8%)\u001b[0m\n",
            "[2024-04-02 19:40:55] \u001b[32mTrain: [ 15/50] Step 340/520 Loss 2.522 Prec@(1,5) (50.4%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:40:56] \u001b[32mTrain: [ 15/50] Step 360/520 Loss 2.522 Prec@(1,5) (50.4%, 80.7%)\u001b[0m\n",
            "[2024-04-02 19:40:56] \u001b[32mTrain: [ 15/50] Step 380/520 Loss 2.522 Prec@(1,5) (50.3%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:40:57] \u001b[32mTrain: [ 15/50] Step 400/520 Loss 2.518 Prec@(1,5) (50.4%, 80.7%)\u001b[0m\n",
            "[2024-04-02 19:40:57] \u001b[32mTrain: [ 15/50] Step 420/520 Loss 2.519 Prec@(1,5) (50.4%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:40:58] \u001b[32mTrain: [ 15/50] Step 440/520 Loss 2.523 Prec@(1,5) (50.4%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:40:58] \u001b[32mTrain: [ 15/50] Step 460/520 Loss 2.527 Prec@(1,5) (50.3%, 80.5%)\u001b[0m\n",
            "[2024-04-02 19:40:59] \u001b[32mTrain: [ 15/50] Step 480/520 Loss 2.527 Prec@(1,5) (50.3%, 80.5%)\u001b[0m\n",
            "[2024-04-02 19:40:59] \u001b[32mTrain: [ 15/50] Step 500/520 Loss 2.528 Prec@(1,5) (50.3%, 80.5%)\u001b[0m\n",
            "[2024-04-02 19:41:00] \u001b[32mTrain: [ 15/50] Step 520/520 Loss 2.526 Prec@(1,5) (50.4%, 80.5%)\u001b[0m\n",
            "[2024-04-02 19:41:00] \u001b[32mTrain: [ 15/50] Final Prec@1 50.3920%\u001b[0m\n",
            "[2024-04-02 19:41:04] \u001b[32mValid: [ 15/50] Step 000/104 Loss 2.326 Prec@(1,5) (54.2%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:41:04] \u001b[32mValid: [ 15/50] Step 020/104 Loss 2.583 Prec@(1,5) (48.9%, 78.8%)\u001b[0m\n",
            "[2024-04-02 19:41:04] \u001b[32mValid: [ 15/50] Step 040/104 Loss 2.575 Prec@(1,5) (48.4%, 78.5%)\u001b[0m\n",
            "[2024-04-02 19:41:04] \u001b[32mValid: [ 15/50] Step 060/104 Loss 2.523 Prec@(1,5) (48.8%, 78.7%)\u001b[0m\n",
            "[2024-04-02 19:41:04] \u001b[32mValid: [ 15/50] Step 080/104 Loss 2.528 Prec@(1,5) (48.3%, 78.7%)\u001b[0m\n",
            "[2024-04-02 19:41:05] \u001b[32mValid: [ 15/50] Step 100/104 Loss 2.512 Prec@(1,5) (48.5%, 78.7%)\u001b[0m\n",
            "[2024-04-02 19:41:05] \u001b[32mValid: [ 15/50] Step 104/104 Loss 2.513 Prec@(1,5) (48.4%, 78.7%)\u001b[0m\n",
            "[2024-04-02 19:41:05] \u001b[32mValid: [ 15/50] Final Prec@1 48.4400%\u001b[0m\n",
            "[2024-04-02 19:41:05] \u001b[32mEpoch 15 LR 0.019848\u001b[0m\n",
            "[2024-04-02 19:41:09] \u001b[32mTrain: [ 16/50] Step 000/520 Loss 2.600 Prec@(1,5) (52.1%, 80.2%)\u001b[0m\n",
            "[2024-04-02 19:41:10] \u001b[32mTrain: [ 16/50] Step 020/520 Loss 2.474 Prec@(1,5) (52.2%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:41:10] \u001b[32mTrain: [ 16/50] Step 040/520 Loss 2.439 Prec@(1,5) (51.7%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:41:11] \u001b[32mTrain: [ 16/50] Step 060/520 Loss 2.444 Prec@(1,5) (51.7%, 81.6%)\u001b[0m\n",
            "[2024-04-02 19:41:11] \u001b[32mTrain: [ 16/50] Step 080/520 Loss 2.465 Prec@(1,5) (51.5%, 81.4%)\u001b[0m\n",
            "[2024-04-02 19:41:12] \u001b[32mTrain: [ 16/50] Step 100/520 Loss 2.471 Prec@(1,5) (51.4%, 81.3%)\u001b[0m\n",
            "[2024-04-02 19:41:12] \u001b[32mTrain: [ 16/50] Step 120/520 Loss 2.469 Prec@(1,5) (51.5%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:41:13] \u001b[32mTrain: [ 16/50] Step 140/520 Loss 2.479 Prec@(1,5) (51.2%, 81.3%)\u001b[0m\n",
            "[2024-04-02 19:41:13] \u001b[32mTrain: [ 16/50] Step 160/520 Loss 2.464 Prec@(1,5) (51.3%, 81.6%)\u001b[0m\n",
            "[2024-04-02 19:41:14] \u001b[32mTrain: [ 16/50] Step 180/520 Loss 2.472 Prec@(1,5) (51.1%, 81.4%)\u001b[0m\n",
            "[2024-04-02 19:41:14] \u001b[32mTrain: [ 16/50] Step 200/520 Loss 2.466 Prec@(1,5) (51.2%, 81.5%)\u001b[0m\n",
            "[2024-04-02 19:41:15] \u001b[32mTrain: [ 16/50] Step 220/520 Loss 2.470 Prec@(1,5) (51.0%, 81.5%)\u001b[0m\n",
            "[2024-04-02 19:41:15] \u001b[32mTrain: [ 16/50] Step 240/520 Loss 2.469 Prec@(1,5) (51.0%, 81.5%)\u001b[0m\n",
            "[2024-04-02 19:41:16] \u001b[32mTrain: [ 16/50] Step 260/520 Loss 2.473 Prec@(1,5) (51.0%, 81.6%)\u001b[0m\n",
            "[2024-04-02 19:41:17] \u001b[32mTrain: [ 16/50] Step 280/520 Loss 2.467 Prec@(1,5) (51.1%, 81.6%)\u001b[0m\n",
            "[2024-04-02 19:41:17] \u001b[32mTrain: [ 16/50] Step 300/520 Loss 2.468 Prec@(1,5) (51.1%, 81.5%)\u001b[0m\n",
            "[2024-04-02 19:41:18] \u001b[32mTrain: [ 16/50] Step 320/520 Loss 2.470 Prec@(1,5) (51.0%, 81.4%)\u001b[0m\n",
            "[2024-04-02 19:41:18] \u001b[32mTrain: [ 16/50] Step 340/520 Loss 2.472 Prec@(1,5) (51.0%, 81.4%)\u001b[0m\n",
            "[2024-04-02 19:41:19] \u001b[32mTrain: [ 16/50] Step 360/520 Loss 2.478 Prec@(1,5) (50.9%, 81.3%)\u001b[0m\n",
            "[2024-04-02 19:41:19] \u001b[32mTrain: [ 16/50] Step 380/520 Loss 2.479 Prec@(1,5) (50.9%, 81.3%)\u001b[0m\n",
            "[2024-04-02 19:41:20] \u001b[32mTrain: [ 16/50] Step 400/520 Loss 2.484 Prec@(1,5) (50.9%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:41:20] \u001b[32mTrain: [ 16/50] Step 420/520 Loss 2.482 Prec@(1,5) (51.0%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:41:21] \u001b[32mTrain: [ 16/50] Step 440/520 Loss 2.480 Prec@(1,5) (51.0%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:41:21] \u001b[32mTrain: [ 16/50] Step 460/520 Loss 2.480 Prec@(1,5) (51.0%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:41:22] \u001b[32mTrain: [ 16/50] Step 480/520 Loss 2.477 Prec@(1,5) (51.0%, 81.3%)\u001b[0m\n",
            "[2024-04-02 19:41:22] \u001b[32mTrain: [ 16/50] Step 500/520 Loss 2.476 Prec@(1,5) (51.0%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:41:23] \u001b[32mTrain: [ 16/50] Step 520/520 Loss 2.476 Prec@(1,5) (51.0%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:41:23] \u001b[32mTrain: [ 16/50] Final Prec@1 51.0180%\u001b[0m\n",
            "[2024-04-02 19:41:26] \u001b[32mValid: [ 16/50] Step 000/104 Loss 2.745 Prec@(1,5) (50.0%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:41:26] \u001b[32mValid: [ 16/50] Step 020/104 Loss 2.656 Prec@(1,5) (47.3%, 78.7%)\u001b[0m\n",
            "[2024-04-02 19:41:27] \u001b[32mValid: [ 16/50] Step 040/104 Loss 2.676 Prec@(1,5) (46.7%, 78.3%)\u001b[0m\n",
            "[2024-04-02 19:41:27] \u001b[32mValid: [ 16/50] Step 060/104 Loss 2.624 Prec@(1,5) (47.4%, 78.7%)\u001b[0m\n",
            "[2024-04-02 19:41:27] \u001b[32mValid: [ 16/50] Step 080/104 Loss 2.633 Prec@(1,5) (47.1%, 78.5%)\u001b[0m\n",
            "[2024-04-02 19:41:27] \u001b[32mValid: [ 16/50] Step 100/104 Loss 2.628 Prec@(1,5) (47.2%, 78.6%)\u001b[0m\n",
            "[2024-04-02 19:41:27] \u001b[32mValid: [ 16/50] Step 104/104 Loss 2.628 Prec@(1,5) (47.2%, 78.6%)\u001b[0m\n",
            "[2024-04-02 19:41:27] \u001b[32mValid: [ 16/50] Final Prec@1 47.1500%\u001b[0m\n",
            "[2024-04-02 19:41:27] \u001b[32mEpoch 16 LR 0.019198\u001b[0m\n",
            "[2024-04-02 19:41:32] \u001b[32mTrain: [ 17/50] Step 000/520 Loss 2.284 Prec@(1,5) (55.2%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:41:33] \u001b[32mTrain: [ 17/50] Step 020/520 Loss 2.405 Prec@(1,5) (52.4%, 82.1%)\u001b[0m\n",
            "[2024-04-02 19:41:33] \u001b[32mTrain: [ 17/50] Step 040/520 Loss 2.405 Prec@(1,5) (52.5%, 81.9%)\u001b[0m\n",
            "[2024-04-02 19:41:34] \u001b[32mTrain: [ 17/50] Step 060/520 Loss 2.401 Prec@(1,5) (52.6%, 81.9%)\u001b[0m\n",
            "[2024-04-02 19:41:34] \u001b[32mTrain: [ 17/50] Step 080/520 Loss 2.423 Prec@(1,5) (52.2%, 81.7%)\u001b[0m\n",
            "[2024-04-02 19:41:35] \u001b[32mTrain: [ 17/50] Step 100/520 Loss 2.439 Prec@(1,5) (51.8%, 81.7%)\u001b[0m\n",
            "[2024-04-02 19:41:35] \u001b[32mTrain: [ 17/50] Step 120/520 Loss 2.433 Prec@(1,5) (52.1%, 81.9%)\u001b[0m\n",
            "[2024-04-02 19:41:36] \u001b[32mTrain: [ 17/50] Step 140/520 Loss 2.432 Prec@(1,5) (52.2%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:41:36] \u001b[32mTrain: [ 17/50] Step 160/520 Loss 2.436 Prec@(1,5) (52.0%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:41:37] \u001b[32mTrain: [ 17/50] Step 180/520 Loss 2.434 Prec@(1,5) (52.1%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:41:37] \u001b[32mTrain: [ 17/50] Step 200/520 Loss 2.444 Prec@(1,5) (52.0%, 81.9%)\u001b[0m\n",
            "[2024-04-02 19:41:38] \u001b[32mTrain: [ 17/50] Step 220/520 Loss 2.441 Prec@(1,5) (51.9%, 81.9%)\u001b[0m\n",
            "[2024-04-02 19:41:38] \u001b[32mTrain: [ 17/50] Step 240/520 Loss 2.443 Prec@(1,5) (51.9%, 81.8%)\u001b[0m\n",
            "[2024-04-02 19:41:39] \u001b[32mTrain: [ 17/50] Step 260/520 Loss 2.436 Prec@(1,5) (52.0%, 81.9%)\u001b[0m\n",
            "[2024-04-02 19:41:39] \u001b[32mTrain: [ 17/50] Step 280/520 Loss 2.430 Prec@(1,5) (52.1%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:41:39] \u001b[32mTrain: [ 17/50] Step 300/520 Loss 2.427 Prec@(1,5) (52.2%, 82.1%)\u001b[0m\n",
            "[2024-04-02 19:41:40] \u001b[32mTrain: [ 17/50] Step 320/520 Loss 2.426 Prec@(1,5) (52.2%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:41:40] \u001b[32mTrain: [ 17/50] Step 340/520 Loss 2.426 Prec@(1,5) (52.1%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:41:41] \u001b[32mTrain: [ 17/50] Step 360/520 Loss 2.424 Prec@(1,5) (52.1%, 82.1%)\u001b[0m\n",
            "[2024-04-02 19:41:41] \u001b[32mTrain: [ 17/50] Step 380/520 Loss 2.423 Prec@(1,5) (52.1%, 82.1%)\u001b[0m\n",
            "[2024-04-02 19:41:42] \u001b[32mTrain: [ 17/50] Step 400/520 Loss 2.425 Prec@(1,5) (52.1%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:41:42] \u001b[32mTrain: [ 17/50] Step 420/520 Loss 2.426 Prec@(1,5) (52.1%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:41:43] \u001b[32mTrain: [ 17/50] Step 440/520 Loss 2.421 Prec@(1,5) (52.2%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:41:43] \u001b[32mTrain: [ 17/50] Step 460/520 Loss 2.422 Prec@(1,5) (52.2%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:41:44] \u001b[32mTrain: [ 17/50] Step 480/520 Loss 2.423 Prec@(1,5) (52.1%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:41:44] \u001b[32mTrain: [ 17/50] Step 500/520 Loss 2.424 Prec@(1,5) (52.1%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:41:45] \u001b[32mTrain: [ 17/50] Step 520/520 Loss 2.423 Prec@(1,5) (52.1%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:41:45] \u001b[32mTrain: [ 17/50] Final Prec@1 52.0980%\u001b[0m\n",
            "[2024-04-02 19:41:49] \u001b[32mValid: [ 17/50] Step 000/104 Loss 2.659 Prec@(1,5) (54.2%, 77.1%)\u001b[0m\n",
            "[2024-04-02 19:41:49] \u001b[32mValid: [ 17/50] Step 020/104 Loss 2.545 Prec@(1,5) (50.8%, 79.7%)\u001b[0m\n",
            "[2024-04-02 19:41:49] \u001b[32mValid: [ 17/50] Step 040/104 Loss 2.569 Prec@(1,5) (49.2%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:41:49] \u001b[32mValid: [ 17/50] Step 060/104 Loss 2.554 Prec@(1,5) (49.3%, 79.0%)\u001b[0m\n",
            "[2024-04-02 19:41:49] \u001b[32mValid: [ 17/50] Step 080/104 Loss 2.568 Prec@(1,5) (48.7%, 78.9%)\u001b[0m\n",
            "[2024-04-02 19:41:49] \u001b[32mValid: [ 17/50] Step 100/104 Loss 2.553 Prec@(1,5) (48.9%, 78.8%)\u001b[0m\n",
            "[2024-04-02 19:41:49] \u001b[32mValid: [ 17/50] Step 104/104 Loss 2.554 Prec@(1,5) (48.8%, 78.7%)\u001b[0m\n",
            "[2024-04-02 19:41:50] \u001b[32mValid: [ 17/50] Final Prec@1 48.7900%\u001b[0m\n",
            "[2024-04-02 19:41:50] \u001b[32mEpoch 17 LR 0.018522\u001b[0m\n",
            "[2024-04-02 19:41:54] \u001b[32mTrain: [ 18/50] Step 000/520 Loss 2.524 Prec@(1,5) (50.0%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:41:55] \u001b[32mTrain: [ 18/50] Step 020/520 Loss 2.375 Prec@(1,5) (53.5%, 82.9%)\u001b[0m\n",
            "[2024-04-02 19:41:55] \u001b[32mTrain: [ 18/50] Step 040/520 Loss 2.362 Prec@(1,5) (52.7%, 82.9%)\u001b[0m\n",
            "[2024-04-02 19:41:56] \u001b[32mTrain: [ 18/50] Step 060/520 Loss 2.378 Prec@(1,5) (52.6%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:41:56] \u001b[32mTrain: [ 18/50] Step 080/520 Loss 2.398 Prec@(1,5) (52.3%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:41:57] \u001b[32mTrain: [ 18/50] Step 100/520 Loss 2.380 Prec@(1,5) (52.6%, 82.1%)\u001b[0m\n",
            "[2024-04-02 19:41:57] \u001b[32mTrain: [ 18/50] Step 120/520 Loss 2.379 Prec@(1,5) (52.6%, 82.0%)\u001b[0m\n",
            "[2024-04-02 19:41:58] \u001b[32mTrain: [ 18/50] Step 140/520 Loss 2.376 Prec@(1,5) (52.8%, 82.1%)\u001b[0m\n",
            "[2024-04-02 19:41:58] \u001b[32mTrain: [ 18/50] Step 160/520 Loss 2.382 Prec@(1,5) (52.6%, 82.1%)\u001b[0m\n",
            "[2024-04-02 19:41:59] \u001b[32mTrain: [ 18/50] Step 180/520 Loss 2.376 Prec@(1,5) (52.7%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:41:59] \u001b[32mTrain: [ 18/50] Step 200/520 Loss 2.377 Prec@(1,5) (52.7%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:42:00] \u001b[32mTrain: [ 18/50] Step 220/520 Loss 2.388 Prec@(1,5) (52.4%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:42:00] \u001b[32mTrain: [ 18/50] Step 240/520 Loss 2.388 Prec@(1,5) (52.4%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:42:01] \u001b[32mTrain: [ 18/50] Step 260/520 Loss 2.381 Prec@(1,5) (52.5%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:42:01] \u001b[32mTrain: [ 18/50] Step 280/520 Loss 2.382 Prec@(1,5) (52.5%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:42:02] \u001b[32mTrain: [ 18/50] Step 300/520 Loss 2.392 Prec@(1,5) (52.4%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:42:02] \u001b[32mTrain: [ 18/50] Step 320/520 Loss 2.392 Prec@(1,5) (52.4%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:42:03] \u001b[32mTrain: [ 18/50] Step 340/520 Loss 2.393 Prec@(1,5) (52.4%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:42:03] \u001b[32mTrain: [ 18/50] Step 360/520 Loss 2.389 Prec@(1,5) (52.5%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:42:04] \u001b[32mTrain: [ 18/50] Step 380/520 Loss 2.386 Prec@(1,5) (52.6%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:42:04] \u001b[32mTrain: [ 18/50] Step 400/520 Loss 2.383 Prec@(1,5) (52.6%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:42:05] \u001b[32mTrain: [ 18/50] Step 420/520 Loss 2.384 Prec@(1,5) (52.6%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:42:05] \u001b[32mTrain: [ 18/50] Step 440/520 Loss 2.385 Prec@(1,5) (52.6%, 82.2%)\u001b[0m\n",
            "[2024-04-02 19:42:06] \u001b[32mTrain: [ 18/50] Step 460/520 Loss 2.383 Prec@(1,5) (52.7%, 82.2%)\u001b[0m\n",
            "[2024-04-02 19:42:06] \u001b[32mTrain: [ 18/50] Step 480/520 Loss 2.385 Prec@(1,5) (52.6%, 82.2%)\u001b[0m\n",
            "[2024-04-02 19:42:07] \u001b[32mTrain: [ 18/50] Step 500/520 Loss 2.385 Prec@(1,5) (52.6%, 82.2%)\u001b[0m\n",
            "[2024-04-02 19:42:07] \u001b[32mTrain: [ 18/50] Step 520/520 Loss 2.386 Prec@(1,5) (52.6%, 82.2%)\u001b[0m\n",
            "[2024-04-02 19:42:07] \u001b[32mTrain: [ 18/50] Final Prec@1 52.6080%\u001b[0m\n",
            "[2024-04-02 19:42:11] \u001b[32mValid: [ 18/50] Step 000/104 Loss 2.443 Prec@(1,5) (54.2%, 80.2%)\u001b[0m\n",
            "[2024-04-02 19:42:11] \u001b[32mValid: [ 18/50] Step 020/104 Loss 2.648 Prec@(1,5) (49.5%, 78.9%)\u001b[0m\n",
            "[2024-04-02 19:42:11] \u001b[32mValid: [ 18/50] Step 040/104 Loss 2.625 Prec@(1,5) (49.0%, 78.9%)\u001b[0m\n",
            "[2024-04-02 19:42:11] \u001b[32mValid: [ 18/50] Step 060/104 Loss 2.591 Prec@(1,5) (48.6%, 78.9%)\u001b[0m\n",
            "[2024-04-02 19:42:12] \u001b[32mValid: [ 18/50] Step 080/104 Loss 2.600 Prec@(1,5) (48.3%, 78.6%)\u001b[0m\n",
            "[2024-04-02 19:42:12] \u001b[32mValid: [ 18/50] Step 100/104 Loss 2.595 Prec@(1,5) (48.3%, 78.5%)\u001b[0m\n",
            "[2024-04-02 19:42:12] \u001b[32mValid: [ 18/50] Step 104/104 Loss 2.599 Prec@(1,5) (48.3%, 78.5%)\u001b[0m\n",
            "[2024-04-02 19:42:12] \u001b[32mValid: [ 18/50] Final Prec@1 48.3400%\u001b[0m\n",
            "[2024-04-02 19:42:12] \u001b[32mEpoch 18 LR 0.017823\u001b[0m\n",
            "[2024-04-02 19:42:17] \u001b[32mTrain: [ 19/50] Step 000/520 Loss 2.398 Prec@(1,5) (56.2%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:42:17] \u001b[32mTrain: [ 19/50] Step 020/520 Loss 2.245 Prec@(1,5) (55.1%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:42:18] \u001b[32mTrain: [ 19/50] Step 040/520 Loss 2.279 Prec@(1,5) (54.7%, 83.6%)\u001b[0m\n",
            "[2024-04-02 19:42:18] \u001b[32mTrain: [ 19/50] Step 060/520 Loss 2.296 Prec@(1,5) (54.7%, 83.4%)\u001b[0m\n",
            "[2024-04-02 19:42:19] \u001b[32mTrain: [ 19/50] Step 080/520 Loss 2.306 Prec@(1,5) (54.7%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:42:19] \u001b[32mTrain: [ 19/50] Step 100/520 Loss 2.298 Prec@(1,5) (54.6%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:42:20] \u001b[32mTrain: [ 19/50] Step 120/520 Loss 2.311 Prec@(1,5) (54.4%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:42:20] \u001b[32mTrain: [ 19/50] Step 140/520 Loss 2.315 Prec@(1,5) (54.1%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:42:21] \u001b[32mTrain: [ 19/50] Step 160/520 Loss 2.313 Prec@(1,5) (54.2%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:42:21] \u001b[32mTrain: [ 19/50] Step 180/520 Loss 2.324 Prec@(1,5) (54.1%, 82.8%)\u001b[0m\n",
            "[2024-04-02 19:42:21] \u001b[32mTrain: [ 19/50] Step 200/520 Loss 2.326 Prec@(1,5) (54.1%, 82.8%)\u001b[0m\n",
            "[2024-04-02 19:42:22] \u001b[32mTrain: [ 19/50] Step 220/520 Loss 2.327 Prec@(1,5) (54.0%, 82.7%)\u001b[0m\n",
            "[2024-04-02 19:42:22] \u001b[32mTrain: [ 19/50] Step 240/520 Loss 2.327 Prec@(1,5) (54.0%, 82.7%)\u001b[0m\n",
            "[2024-04-02 19:42:23] \u001b[32mTrain: [ 19/50] Step 260/520 Loss 2.332 Prec@(1,5) (53.8%, 82.7%)\u001b[0m\n",
            "[2024-04-02 19:42:23] \u001b[32mTrain: [ 19/50] Step 280/520 Loss 2.336 Prec@(1,5) (53.8%, 82.7%)\u001b[0m\n",
            "[2024-04-02 19:42:24] \u001b[32mTrain: [ 19/50] Step 300/520 Loss 2.336 Prec@(1,5) (53.8%, 82.6%)\u001b[0m\n",
            "[2024-04-02 19:42:24] \u001b[32mTrain: [ 19/50] Step 320/520 Loss 2.338 Prec@(1,5) (53.8%, 82.7%)\u001b[0m\n",
            "[2024-04-02 19:42:25] \u001b[32mTrain: [ 19/50] Step 340/520 Loss 2.334 Prec@(1,5) (53.9%, 82.8%)\u001b[0m\n",
            "[2024-04-02 19:42:25] \u001b[32mTrain: [ 19/50] Step 360/520 Loss 2.336 Prec@(1,5) (53.8%, 82.8%)\u001b[0m\n",
            "[2024-04-02 19:42:26] \u001b[32mTrain: [ 19/50] Step 380/520 Loss 2.337 Prec@(1,5) (53.8%, 82.8%)\u001b[0m\n",
            "[2024-04-02 19:42:26] \u001b[32mTrain: [ 19/50] Step 400/520 Loss 2.337 Prec@(1,5) (53.9%, 82.8%)\u001b[0m\n",
            "[2024-04-02 19:42:27] \u001b[32mTrain: [ 19/50] Step 420/520 Loss 2.335 Prec@(1,5) (53.9%, 82.8%)\u001b[0m\n",
            "[2024-04-02 19:42:27] \u001b[32mTrain: [ 19/50] Step 440/520 Loss 2.340 Prec@(1,5) (53.8%, 82.8%)\u001b[0m\n",
            "[2024-04-02 19:42:28] \u001b[32mTrain: [ 19/50] Step 460/520 Loss 2.340 Prec@(1,5) (53.8%, 82.8%)\u001b[0m\n",
            "[2024-04-02 19:42:28] \u001b[32mTrain: [ 19/50] Step 480/520 Loss 2.338 Prec@(1,5) (53.8%, 82.8%)\u001b[0m\n",
            "[2024-04-02 19:42:29] \u001b[32mTrain: [ 19/50] Step 500/520 Loss 2.341 Prec@(1,5) (53.7%, 82.8%)\u001b[0m\n",
            "[2024-04-02 19:42:29] \u001b[32mTrain: [ 19/50] Step 520/520 Loss 2.343 Prec@(1,5) (53.7%, 82.7%)\u001b[0m\n",
            "[2024-04-02 19:42:30] \u001b[32mTrain: [ 19/50] Final Prec@1 53.6620%\u001b[0m\n",
            "[2024-04-02 19:42:33] \u001b[32mValid: [ 19/50] Step 000/104 Loss 2.529 Prec@(1,5) (56.2%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:42:33] \u001b[32mValid: [ 19/50] Step 020/104 Loss 2.637 Prec@(1,5) (50.5%, 80.0%)\u001b[0m\n",
            "[2024-04-02 19:42:33] \u001b[32mValid: [ 19/50] Step 040/104 Loss 2.615 Prec@(1,5) (49.4%, 79.6%)\u001b[0m\n",
            "[2024-04-02 19:42:34] \u001b[32mValid: [ 19/50] Step 060/104 Loss 2.593 Prec@(1,5) (49.7%, 79.5%)\u001b[0m\n",
            "[2024-04-02 19:42:34] \u001b[32mValid: [ 19/50] Step 080/104 Loss 2.599 Prec@(1,5) (49.6%, 79.5%)\u001b[0m\n",
            "[2024-04-02 19:42:34] \u001b[32mValid: [ 19/50] Step 100/104 Loss 2.584 Prec@(1,5) (49.7%, 79.7%)\u001b[0m\n",
            "[2024-04-02 19:42:34] \u001b[32mValid: [ 19/50] Step 104/104 Loss 2.585 Prec@(1,5) (49.6%, 79.7%)\u001b[0m\n",
            "[2024-04-02 19:42:34] \u001b[32mValid: [ 19/50] Final Prec@1 49.5700%\u001b[0m\n",
            "[2024-04-02 19:42:34] \u001b[32mEpoch 19 LR 0.017102\u001b[0m\n",
            "[2024-04-02 19:42:39] \u001b[32mTrain: [ 20/50] Step 000/520 Loss 2.092 Prec@(1,5) (60.4%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:42:39] \u001b[32mTrain: [ 20/50] Step 020/520 Loss 2.260 Prec@(1,5) (54.3%, 83.7%)\u001b[0m\n",
            "[2024-04-02 19:42:40] \u001b[32mTrain: [ 20/50] Step 040/520 Loss 2.301 Prec@(1,5) (53.8%, 83.6%)\u001b[0m\n",
            "[2024-04-02 19:42:40] \u001b[32mTrain: [ 20/50] Step 060/520 Loss 2.290 Prec@(1,5) (53.6%, 83.9%)\u001b[0m\n",
            "[2024-04-02 19:42:41] \u001b[32mTrain: [ 20/50] Step 080/520 Loss 2.278 Prec@(1,5) (54.2%, 84.0%)\u001b[0m\n",
            "[2024-04-02 19:42:41] \u001b[32mTrain: [ 20/50] Step 100/520 Loss 2.279 Prec@(1,5) (54.4%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:42:42] \u001b[32mTrain: [ 20/50] Step 120/520 Loss 2.275 Prec@(1,5) (54.4%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:42:42] \u001b[32mTrain: [ 20/50] Step 140/520 Loss 2.280 Prec@(1,5) (54.4%, 83.6%)\u001b[0m\n",
            "[2024-04-02 19:42:43] \u001b[32mTrain: [ 20/50] Step 160/520 Loss 2.289 Prec@(1,5) (54.2%, 83.5%)\u001b[0m\n",
            "[2024-04-02 19:42:43] \u001b[32mTrain: [ 20/50] Step 180/520 Loss 2.291 Prec@(1,5) (54.1%, 83.6%)\u001b[0m\n",
            "[2024-04-02 19:42:44] \u001b[32mTrain: [ 20/50] Step 200/520 Loss 2.298 Prec@(1,5) (54.0%, 83.5%)\u001b[0m\n",
            "[2024-04-02 19:42:44] \u001b[32mTrain: [ 20/50] Step 220/520 Loss 2.298 Prec@(1,5) (53.9%, 83.4%)\u001b[0m\n",
            "[2024-04-02 19:42:45] \u001b[32mTrain: [ 20/50] Step 240/520 Loss 2.307 Prec@(1,5) (53.8%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:42:45] \u001b[32mTrain: [ 20/50] Step 260/520 Loss 2.305 Prec@(1,5) (53.9%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:42:46] \u001b[32mTrain: [ 20/50] Step 280/520 Loss 2.308 Prec@(1,5) (53.9%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:42:46] \u001b[32mTrain: [ 20/50] Step 300/520 Loss 2.313 Prec@(1,5) (53.8%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:42:47] \u001b[32mTrain: [ 20/50] Step 320/520 Loss 2.313 Prec@(1,5) (53.9%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:42:47] \u001b[32mTrain: [ 20/50] Step 340/520 Loss 2.315 Prec@(1,5) (53.9%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:42:48] \u001b[32mTrain: [ 20/50] Step 360/520 Loss 2.316 Prec@(1,5) (53.9%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:42:48] \u001b[32mTrain: [ 20/50] Step 380/520 Loss 2.315 Prec@(1,5) (53.9%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:42:49] \u001b[32mTrain: [ 20/50] Step 400/520 Loss 2.316 Prec@(1,5) (53.9%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:42:49] \u001b[32mTrain: [ 20/50] Step 420/520 Loss 2.314 Prec@(1,5) (54.0%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:42:50] \u001b[32mTrain: [ 20/50] Step 440/520 Loss 2.314 Prec@(1,5) (54.0%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:42:50] \u001b[32mTrain: [ 20/50] Step 460/520 Loss 2.315 Prec@(1,5) (54.0%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:42:51] \u001b[32mTrain: [ 20/50] Step 480/520 Loss 2.316 Prec@(1,5) (54.0%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:42:51] \u001b[32mTrain: [ 20/50] Step 500/520 Loss 2.312 Prec@(1,5) (54.1%, 83.1%)\u001b[0m\n",
            "[2024-04-02 19:42:52] \u001b[32mTrain: [ 20/50] Step 520/520 Loss 2.314 Prec@(1,5) (54.1%, 83.0%)\u001b[0m\n",
            "[2024-04-02 19:42:52] \u001b[32mTrain: [ 20/50] Final Prec@1 54.1120%\u001b[0m\n",
            "[2024-04-02 19:42:55] \u001b[32mValid: [ 20/50] Step 000/104 Loss 2.669 Prec@(1,5) (51.0%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:42:56] \u001b[32mValid: [ 20/50] Step 020/104 Loss 2.682 Prec@(1,5) (49.4%, 78.3%)\u001b[0m\n",
            "[2024-04-02 19:42:56] \u001b[32mValid: [ 20/50] Step 040/104 Loss 2.655 Prec@(1,5) (49.0%, 78.3%)\u001b[0m\n",
            "[2024-04-02 19:42:56] \u001b[32mValid: [ 20/50] Step 060/104 Loss 2.622 Prec@(1,5) (49.0%, 78.5%)\u001b[0m\n",
            "[2024-04-02 19:42:56] \u001b[32mValid: [ 20/50] Step 080/104 Loss 2.630 Prec@(1,5) (48.7%, 78.3%)\u001b[0m\n",
            "[2024-04-02 19:42:56] \u001b[32mValid: [ 20/50] Step 100/104 Loss 2.594 Prec@(1,5) (49.0%, 78.5%)\u001b[0m\n",
            "[2024-04-02 19:42:56] \u001b[32mValid: [ 20/50] Step 104/104 Loss 2.594 Prec@(1,5) (48.9%, 78.5%)\u001b[0m\n",
            "[2024-04-02 19:42:57] \u001b[32mValid: [ 20/50] Final Prec@1 48.9300%\u001b[0m\n",
            "[2024-04-02 19:42:57] \u001b[32mEpoch 20 LR 0.016363\u001b[0m\n",
            "[2024-04-02 19:43:01] \u001b[32mTrain: [ 21/50] Step 000/520 Loss 2.086 Prec@(1,5) (57.3%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:43:02] \u001b[32mTrain: [ 21/50] Step 020/520 Loss 2.263 Prec@(1,5) (56.2%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:43:02] \u001b[32mTrain: [ 21/50] Step 040/520 Loss 2.291 Prec@(1,5) (55.0%, 83.5%)\u001b[0m\n",
            "[2024-04-02 19:43:03] \u001b[32mTrain: [ 21/50] Step 060/520 Loss 2.277 Prec@(1,5) (55.0%, 83.5%)\u001b[0m\n",
            "[2024-04-02 19:43:03] \u001b[32mTrain: [ 21/50] Step 080/520 Loss 2.276 Prec@(1,5) (54.9%, 83.4%)\u001b[0m\n",
            "[2024-04-02 19:43:04] \u001b[32mTrain: [ 21/50] Step 100/520 Loss 2.282 Prec@(1,5) (54.6%, 83.4%)\u001b[0m\n",
            "[2024-04-02 19:43:04] \u001b[32mTrain: [ 21/50] Step 120/520 Loss 2.274 Prec@(1,5) (54.9%, 83.5%)\u001b[0m\n",
            "[2024-04-02 19:43:05] \u001b[32mTrain: [ 21/50] Step 140/520 Loss 2.265 Prec@(1,5) (55.1%, 83.6%)\u001b[0m\n",
            "[2024-04-02 19:43:05] \u001b[32mTrain: [ 21/50] Step 160/520 Loss 2.261 Prec@(1,5) (55.1%, 83.7%)\u001b[0m\n",
            "[2024-04-02 19:43:06] \u001b[32mTrain: [ 21/50] Step 180/520 Loss 2.267 Prec@(1,5) (55.0%, 83.6%)\u001b[0m\n",
            "[2024-04-02 19:43:06] \u001b[32mTrain: [ 21/50] Step 200/520 Loss 2.269 Prec@(1,5) (55.0%, 83.5%)\u001b[0m\n",
            "[2024-04-02 19:43:07] \u001b[32mTrain: [ 21/50] Step 220/520 Loss 2.267 Prec@(1,5) (54.9%, 83.5%)\u001b[0m\n",
            "[2024-04-02 19:43:07] \u001b[32mTrain: [ 21/50] Step 240/520 Loss 2.272 Prec@(1,5) (54.9%, 83.4%)\u001b[0m\n",
            "[2024-04-02 19:43:08] \u001b[32mTrain: [ 21/50] Step 260/520 Loss 2.274 Prec@(1,5) (54.9%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:43:08] \u001b[32mTrain: [ 21/50] Step 280/520 Loss 2.274 Prec@(1,5) (54.8%, 83.4%)\u001b[0m\n",
            "[2024-04-02 19:43:09] \u001b[32mTrain: [ 21/50] Step 300/520 Loss 2.276 Prec@(1,5) (54.6%, 83.4%)\u001b[0m\n",
            "[2024-04-02 19:43:09] \u001b[32mTrain: [ 21/50] Step 320/520 Loss 2.281 Prec@(1,5) (54.5%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:43:10] \u001b[32mTrain: [ 21/50] Step 340/520 Loss 2.280 Prec@(1,5) (54.5%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:43:10] \u001b[32mTrain: [ 21/50] Step 360/520 Loss 2.278 Prec@(1,5) (54.5%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:43:11] \u001b[32mTrain: [ 21/50] Step 380/520 Loss 2.280 Prec@(1,5) (54.5%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:43:11] \u001b[32mTrain: [ 21/50] Step 400/520 Loss 2.282 Prec@(1,5) (54.5%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:43:12] \u001b[32mTrain: [ 21/50] Step 420/520 Loss 2.282 Prec@(1,5) (54.5%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:43:12] \u001b[32mTrain: [ 21/50] Step 440/520 Loss 2.285 Prec@(1,5) (54.4%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:43:13] \u001b[32mTrain: [ 21/50] Step 460/520 Loss 2.284 Prec@(1,5) (54.3%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:43:13] \u001b[32mTrain: [ 21/50] Step 480/520 Loss 2.283 Prec@(1,5) (54.3%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:43:14] \u001b[32mTrain: [ 21/50] Step 500/520 Loss 2.283 Prec@(1,5) (54.4%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:43:14] \u001b[32mTrain: [ 21/50] Step 520/520 Loss 2.282 Prec@(1,5) (54.5%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:43:14] \u001b[32mTrain: [ 21/50] Final Prec@1 54.4540%\u001b[0m\n",
            "[2024-04-02 19:43:18] \u001b[32mValid: [ 21/50] Step 000/104 Loss 2.720 Prec@(1,5) (50.0%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:43:18] \u001b[32mValid: [ 21/50] Step 020/104 Loss 2.486 Prec@(1,5) (48.9%, 80.3%)\u001b[0m\n",
            "[2024-04-02 19:43:18] \u001b[32mValid: [ 21/50] Step 040/104 Loss 2.502 Prec@(1,5) (48.6%, 80.0%)\u001b[0m\n",
            "[2024-04-02 19:43:18] \u001b[32mValid: [ 21/50] Step 060/104 Loss 2.465 Prec@(1,5) (49.4%, 79.9%)\u001b[0m\n",
            "[2024-04-02 19:43:18] \u001b[32mValid: [ 21/50] Step 080/104 Loss 2.484 Prec@(1,5) (49.3%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:43:19] \u001b[32mValid: [ 21/50] Step 100/104 Loss 2.473 Prec@(1,5) (49.4%, 79.7%)\u001b[0m\n",
            "[2024-04-02 19:43:19] \u001b[32mValid: [ 21/50] Step 104/104 Loss 2.468 Prec@(1,5) (49.5%, 79.7%)\u001b[0m\n",
            "[2024-04-02 19:43:19] \u001b[32mValid: [ 21/50] Final Prec@1 49.5000%\u001b[0m\n",
            "[2024-04-02 19:43:19] \u001b[32mEpoch 21 LR 0.015609\u001b[0m\n",
            "[2024-04-02 19:43:23] \u001b[32mTrain: [ 22/50] Step 000/520 Loss 2.128 Prec@(1,5) (53.1%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:43:24] \u001b[32mTrain: [ 22/50] Step 020/520 Loss 2.261 Prec@(1,5) (54.9%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:43:24] \u001b[32mTrain: [ 22/50] Step 040/520 Loss 2.222 Prec@(1,5) (55.8%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:43:25] \u001b[32mTrain: [ 22/50] Step 060/520 Loss 2.256 Prec@(1,5) (55.0%, 83.5%)\u001b[0m\n",
            "[2024-04-02 19:43:25] \u001b[32mTrain: [ 22/50] Step 080/520 Loss 2.253 Prec@(1,5) (55.3%, 83.7%)\u001b[0m\n",
            "[2024-04-02 19:43:26] \u001b[32mTrain: [ 22/50] Step 100/520 Loss 2.271 Prec@(1,5) (55.1%, 83.4%)\u001b[0m\n",
            "[2024-04-02 19:43:26] \u001b[32mTrain: [ 22/50] Step 120/520 Loss 2.275 Prec@(1,5) (54.6%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:43:27] \u001b[32mTrain: [ 22/50] Step 140/520 Loss 2.270 Prec@(1,5) (54.6%, 83.4%)\u001b[0m\n",
            "[2024-04-02 19:43:27] \u001b[32mTrain: [ 22/50] Step 160/520 Loss 2.261 Prec@(1,5) (54.8%, 83.5%)\u001b[0m\n",
            "[2024-04-02 19:43:28] \u001b[32mTrain: [ 22/50] Step 180/520 Loss 2.260 Prec@(1,5) (54.7%, 83.5%)\u001b[0m\n",
            "[2024-04-02 19:43:28] \u001b[32mTrain: [ 22/50] Step 200/520 Loss 2.254 Prec@(1,5) (54.8%, 83.6%)\u001b[0m\n",
            "[2024-04-02 19:43:29] \u001b[32mTrain: [ 22/50] Step 220/520 Loss 2.250 Prec@(1,5) (54.9%, 83.7%)\u001b[0m\n",
            "[2024-04-02 19:43:29] \u001b[32mTrain: [ 22/50] Step 240/520 Loss 2.253 Prec@(1,5) (54.9%, 83.6%)\u001b[0m\n",
            "[2024-04-02 19:43:30] \u001b[32mTrain: [ 22/50] Step 260/520 Loss 2.255 Prec@(1,5) (55.0%, 83.6%)\u001b[0m\n",
            "[2024-04-02 19:43:30] \u001b[32mTrain: [ 22/50] Step 280/520 Loss 2.254 Prec@(1,5) (55.0%, 83.7%)\u001b[0m\n",
            "[2024-04-02 19:43:31] \u001b[32mTrain: [ 22/50] Step 300/520 Loss 2.251 Prec@(1,5) (55.1%, 83.7%)\u001b[0m\n",
            "[2024-04-02 19:43:31] \u001b[32mTrain: [ 22/50] Step 320/520 Loss 2.253 Prec@(1,5) (55.0%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:43:32] \u001b[32mTrain: [ 22/50] Step 340/520 Loss 2.253 Prec@(1,5) (55.0%, 83.7%)\u001b[0m\n",
            "[2024-04-02 19:43:32] \u001b[32mTrain: [ 22/50] Step 360/520 Loss 2.254 Prec@(1,5) (55.0%, 83.7%)\u001b[0m\n",
            "[2024-04-02 19:43:33] \u001b[32mTrain: [ 22/50] Step 380/520 Loss 2.254 Prec@(1,5) (55.0%, 83.7%)\u001b[0m\n",
            "[2024-04-02 19:43:33] \u001b[32mTrain: [ 22/50] Step 400/520 Loss 2.252 Prec@(1,5) (55.1%, 83.7%)\u001b[0m\n",
            "[2024-04-02 19:43:34] \u001b[32mTrain: [ 22/50] Step 420/520 Loss 2.251 Prec@(1,5) (55.2%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:43:34] \u001b[32mTrain: [ 22/50] Step 440/520 Loss 2.251 Prec@(1,5) (55.2%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:43:35] \u001b[32mTrain: [ 22/50] Step 460/520 Loss 2.250 Prec@(1,5) (55.2%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:43:35] \u001b[32mTrain: [ 22/50] Step 480/520 Loss 2.247 Prec@(1,5) (55.2%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:43:36] \u001b[32mTrain: [ 22/50] Step 500/520 Loss 2.246 Prec@(1,5) (55.2%, 83.9%)\u001b[0m\n",
            "[2024-04-02 19:43:36] \u001b[32mTrain: [ 22/50] Step 520/520 Loss 2.246 Prec@(1,5) (55.3%, 83.9%)\u001b[0m\n",
            "[2024-04-02 19:43:36] \u001b[32mTrain: [ 22/50] Final Prec@1 55.2560%\u001b[0m\n",
            "[2024-04-02 19:43:40] \u001b[32mValid: [ 22/50] Step 000/104 Loss 2.417 Prec@(1,5) (57.3%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:43:40] \u001b[32mValid: [ 22/50] Step 020/104 Loss 2.314 Prec@(1,5) (53.0%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:43:40] \u001b[32mValid: [ 22/50] Step 040/104 Loss 2.298 Prec@(1,5) (52.4%, 82.5%)\u001b[0m\n",
            "[2024-04-02 19:43:41] \u001b[32mValid: [ 22/50] Step 060/104 Loss 2.261 Prec@(1,5) (52.9%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:43:41] \u001b[32mValid: [ 22/50] Step 080/104 Loss 2.276 Prec@(1,5) (52.6%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:43:41] \u001b[32mValid: [ 22/50] Step 100/104 Loss 2.259 Prec@(1,5) (52.7%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:43:41] \u001b[32mValid: [ 22/50] Step 104/104 Loss 2.257 Prec@(1,5) (52.8%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:43:41] \u001b[32mValid: [ 22/50] Final Prec@1 52.7500%\u001b[0m\n",
            "[2024-04-02 19:43:41] \u001b[32mEpoch 22 LR 0.014843\u001b[0m\n",
            "[2024-04-02 19:43:46] \u001b[32mTrain: [ 23/50] Step 000/520 Loss 2.122 Prec@(1,5) (61.5%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:43:46] \u001b[32mTrain: [ 23/50] Step 020/520 Loss 2.176 Prec@(1,5) (56.4%, 84.3%)\u001b[0m\n",
            "[2024-04-02 19:43:47] \u001b[32mTrain: [ 23/50] Step 040/520 Loss 2.161 Prec@(1,5) (57.0%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:43:47] \u001b[32mTrain: [ 23/50] Step 060/520 Loss 2.164 Prec@(1,5) (57.0%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:43:48] \u001b[32mTrain: [ 23/50] Step 080/520 Loss 2.168 Prec@(1,5) (56.9%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:43:48] \u001b[32mTrain: [ 23/50] Step 100/520 Loss 2.169 Prec@(1,5) (56.7%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:43:49] \u001b[32mTrain: [ 23/50] Step 120/520 Loss 2.179 Prec@(1,5) (56.4%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:43:49] \u001b[32mTrain: [ 23/50] Step 140/520 Loss 2.183 Prec@(1,5) (56.3%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:43:50] \u001b[32mTrain: [ 23/50] Step 160/520 Loss 2.188 Prec@(1,5) (56.2%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:43:50] \u001b[32mTrain: [ 23/50] Step 180/520 Loss 2.195 Prec@(1,5) (56.2%, 84.5%)\u001b[0m\n",
            "[2024-04-02 19:43:51] \u001b[32mTrain: [ 23/50] Step 200/520 Loss 2.197 Prec@(1,5) (56.1%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:43:51] \u001b[32mTrain: [ 23/50] Step 220/520 Loss 2.196 Prec@(1,5) (56.1%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:43:52] \u001b[32mTrain: [ 23/50] Step 240/520 Loss 2.198 Prec@(1,5) (56.0%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:43:52] \u001b[32mTrain: [ 23/50] Step 260/520 Loss 2.206 Prec@(1,5) (55.9%, 84.3%)\u001b[0m\n",
            "[2024-04-02 19:43:53] \u001b[32mTrain: [ 23/50] Step 280/520 Loss 2.211 Prec@(1,5) (56.0%, 84.3%)\u001b[0m\n",
            "[2024-04-02 19:43:53] \u001b[32mTrain: [ 23/50] Step 300/520 Loss 2.205 Prec@(1,5) (56.1%, 84.3%)\u001b[0m\n",
            "[2024-04-02 19:43:54] \u001b[32mTrain: [ 23/50] Step 320/520 Loss 2.207 Prec@(1,5) (56.0%, 84.3%)\u001b[0m\n",
            "[2024-04-02 19:43:54] \u001b[32mTrain: [ 23/50] Step 340/520 Loss 2.204 Prec@(1,5) (56.0%, 84.3%)\u001b[0m\n",
            "[2024-04-02 19:43:55] \u001b[32mTrain: [ 23/50] Step 360/520 Loss 2.212 Prec@(1,5) (55.9%, 84.2%)\u001b[0m\n",
            "[2024-04-02 19:43:55] \u001b[32mTrain: [ 23/50] Step 380/520 Loss 2.214 Prec@(1,5) (55.8%, 84.2%)\u001b[0m\n",
            "[2024-04-02 19:43:56] \u001b[32mTrain: [ 23/50] Step 400/520 Loss 2.215 Prec@(1,5) (55.8%, 84.2%)\u001b[0m\n",
            "[2024-04-02 19:43:56] \u001b[32mTrain: [ 23/50] Step 420/520 Loss 2.220 Prec@(1,5) (55.7%, 84.1%)\u001b[0m\n",
            "[2024-04-02 19:43:57] \u001b[32mTrain: [ 23/50] Step 440/520 Loss 2.220 Prec@(1,5) (55.7%, 84.1%)\u001b[0m\n",
            "[2024-04-02 19:43:57] \u001b[32mTrain: [ 23/50] Step 460/520 Loss 2.216 Prec@(1,5) (55.8%, 84.2%)\u001b[0m\n",
            "[2024-04-02 19:43:58] \u001b[32mTrain: [ 23/50] Step 480/520 Loss 2.220 Prec@(1,5) (55.7%, 84.1%)\u001b[0m\n",
            "[2024-04-02 19:43:58] \u001b[32mTrain: [ 23/50] Step 500/520 Loss 2.222 Prec@(1,5) (55.7%, 84.1%)\u001b[0m\n",
            "[2024-04-02 19:43:59] \u001b[32mTrain: [ 23/50] Step 520/520 Loss 2.223 Prec@(1,5) (55.6%, 84.1%)\u001b[0m\n",
            "[2024-04-02 19:43:59] \u001b[32mTrain: [ 23/50] Final Prec@1 55.6360%\u001b[0m\n",
            "[2024-04-02 19:44:02] \u001b[32mValid: [ 23/50] Step 000/104 Loss 2.174 Prec@(1,5) (60.4%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:44:02] \u001b[32mValid: [ 23/50] Step 020/104 Loss 2.473 Prec@(1,5) (51.7%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:44:03] \u001b[32mValid: [ 23/50] Step 040/104 Loss 2.485 Prec@(1,5) (50.7%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:44:03] \u001b[32mValid: [ 23/50] Step 060/104 Loss 2.445 Prec@(1,5) (51.1%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:44:03] \u001b[32mValid: [ 23/50] Step 080/104 Loss 2.465 Prec@(1,5) (50.7%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:44:03] \u001b[32mValid: [ 23/50] Step 100/104 Loss 2.445 Prec@(1,5) (50.9%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:44:03] \u001b[32mValid: [ 23/50] Step 104/104 Loss 2.449 Prec@(1,5) (50.9%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:44:03] \u001b[32mValid: [ 23/50] Final Prec@1 50.9200%\u001b[0m\n",
            "[2024-04-02 19:44:03] \u001b[32mEpoch 23 LR 0.014067\u001b[0m\n",
            "[2024-04-02 19:44:08] \u001b[32mTrain: [ 24/50] Step 000/520 Loss 1.832 Prec@(1,5) (62.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:44:08] \u001b[32mTrain: [ 24/50] Step 020/520 Loss 2.164 Prec@(1,5) (57.0%, 84.3%)\u001b[0m\n",
            "[2024-04-02 19:44:09] \u001b[32mTrain: [ 24/50] Step 040/520 Loss 2.153 Prec@(1,5) (57.3%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:44:09] \u001b[32mTrain: [ 24/50] Step 060/520 Loss 2.146 Prec@(1,5) (57.2%, 85.2%)\u001b[0m\n",
            "[2024-04-02 19:44:10] \u001b[32mTrain: [ 24/50] Step 080/520 Loss 2.161 Prec@(1,5) (56.7%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:44:10] \u001b[32mTrain: [ 24/50] Step 100/520 Loss 2.157 Prec@(1,5) (56.5%, 85.2%)\u001b[0m\n",
            "[2024-04-02 19:44:11] \u001b[32mTrain: [ 24/50] Step 120/520 Loss 2.177 Prec@(1,5) (56.3%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:44:11] \u001b[32mTrain: [ 24/50] Step 140/520 Loss 2.183 Prec@(1,5) (56.1%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:44:12] \u001b[32mTrain: [ 24/50] Step 160/520 Loss 2.170 Prec@(1,5) (56.5%, 85.0%)\u001b[0m\n",
            "[2024-04-02 19:44:12] \u001b[32mTrain: [ 24/50] Step 180/520 Loss 2.171 Prec@(1,5) (56.4%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:44:13] \u001b[32mTrain: [ 24/50] Step 200/520 Loss 2.170 Prec@(1,5) (56.3%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:44:13] \u001b[32mTrain: [ 24/50] Step 220/520 Loss 2.171 Prec@(1,5) (56.4%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:44:14] \u001b[32mTrain: [ 24/50] Step 240/520 Loss 2.175 Prec@(1,5) (56.3%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:44:14] \u001b[32mTrain: [ 24/50] Step 260/520 Loss 2.177 Prec@(1,5) (56.3%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:44:15] \u001b[32mTrain: [ 24/50] Step 280/520 Loss 2.180 Prec@(1,5) (56.3%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:44:15] \u001b[32mTrain: [ 24/50] Step 300/520 Loss 2.177 Prec@(1,5) (56.4%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:44:16] \u001b[32mTrain: [ 24/50] Step 320/520 Loss 2.181 Prec@(1,5) (56.3%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:44:16] \u001b[32mTrain: [ 24/50] Step 340/520 Loss 2.182 Prec@(1,5) (56.3%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:44:17] \u001b[32mTrain: [ 24/50] Step 360/520 Loss 2.180 Prec@(1,5) (56.3%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:44:17] \u001b[32mTrain: [ 24/50] Step 380/520 Loss 2.181 Prec@(1,5) (56.3%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:44:18] \u001b[32mTrain: [ 24/50] Step 400/520 Loss 2.185 Prec@(1,5) (56.3%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:44:18] \u001b[32mTrain: [ 24/50] Step 420/520 Loss 2.186 Prec@(1,5) (56.3%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:44:19] \u001b[32mTrain: [ 24/50] Step 440/520 Loss 2.190 Prec@(1,5) (56.3%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:44:19] \u001b[32mTrain: [ 24/50] Step 460/520 Loss 2.189 Prec@(1,5) (56.2%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:44:20] \u001b[32mTrain: [ 24/50] Step 480/520 Loss 2.189 Prec@(1,5) (56.2%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:44:20] \u001b[32mTrain: [ 24/50] Step 500/520 Loss 2.187 Prec@(1,5) (56.3%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:44:21] \u001b[32mTrain: [ 24/50] Step 520/520 Loss 2.190 Prec@(1,5) (56.2%, 84.6%)\u001b[0m\n",
            "[2024-04-02 19:44:21] \u001b[32mTrain: [ 24/50] Final Prec@1 56.2080%\u001b[0m\n",
            "[2024-04-02 19:44:24] \u001b[32mValid: [ 24/50] Step 000/104 Loss 2.317 Prec@(1,5) (58.3%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:44:25] \u001b[32mValid: [ 24/50] Step 020/104 Loss 2.635 Prec@(1,5) (50.7%, 79.9%)\u001b[0m\n",
            "[2024-04-02 19:44:25] \u001b[32mValid: [ 24/50] Step 040/104 Loss 2.602 Prec@(1,5) (50.6%, 79.7%)\u001b[0m\n",
            "[2024-04-02 19:44:25] \u001b[32mValid: [ 24/50] Step 060/104 Loss 2.564 Prec@(1,5) (50.7%, 80.1%)\u001b[0m\n",
            "[2024-04-02 19:44:25] \u001b[32mValid: [ 24/50] Step 080/104 Loss 2.566 Prec@(1,5) (50.5%, 80.0%)\u001b[0m\n",
            "[2024-04-02 19:44:25] \u001b[32mValid: [ 24/50] Step 100/104 Loss 2.556 Prec@(1,5) (50.5%, 80.2%)\u001b[0m\n",
            "[2024-04-02 19:44:25] \u001b[32mValid: [ 24/50] Step 104/104 Loss 2.561 Prec@(1,5) (50.5%, 80.2%)\u001b[0m\n",
            "[2024-04-02 19:44:25] \u001b[32mValid: [ 24/50] Final Prec@1 50.4500%\u001b[0m\n",
            "[2024-04-02 19:44:25] \u001b[32mEpoch 24 LR 0.013285\u001b[0m\n",
            "[2024-04-02 19:44:30] \u001b[32mTrain: [ 25/50] Step 000/520 Loss 1.971 Prec@(1,5) (58.3%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:44:31] \u001b[32mTrain: [ 25/50] Step 020/520 Loss 2.186 Prec@(1,5) (56.3%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:44:31] \u001b[32mTrain: [ 25/50] Step 040/520 Loss 2.153 Prec@(1,5) (56.7%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:44:32] \u001b[32mTrain: [ 25/50] Step 060/520 Loss 2.143 Prec@(1,5) (56.9%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:44:32] \u001b[32mTrain: [ 25/50] Step 080/520 Loss 2.136 Prec@(1,5) (56.9%, 85.6%)\u001b[0m\n",
            "[2024-04-02 19:44:33] \u001b[32mTrain: [ 25/50] Step 100/520 Loss 2.154 Prec@(1,5) (57.1%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:44:33] \u001b[32mTrain: [ 25/50] Step 120/520 Loss 2.157 Prec@(1,5) (57.0%, 85.0%)\u001b[0m\n",
            "[2024-04-02 19:44:34] \u001b[32mTrain: [ 25/50] Step 140/520 Loss 2.153 Prec@(1,5) (57.0%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:44:34] \u001b[32mTrain: [ 25/50] Step 160/520 Loss 2.152 Prec@(1,5) (57.1%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:44:35] \u001b[32mTrain: [ 25/50] Step 180/520 Loss 2.156 Prec@(1,5) (56.9%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:44:35] \u001b[32mTrain: [ 25/50] Step 200/520 Loss 2.151 Prec@(1,5) (56.9%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:44:36] \u001b[32mTrain: [ 25/50] Step 220/520 Loss 2.152 Prec@(1,5) (57.1%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:44:36] \u001b[32mTrain: [ 25/50] Step 240/520 Loss 2.152 Prec@(1,5) (57.0%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:44:37] \u001b[32mTrain: [ 25/50] Step 260/520 Loss 2.151 Prec@(1,5) (56.9%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:44:37] \u001b[32mTrain: [ 25/50] Step 280/520 Loss 2.157 Prec@(1,5) (56.8%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:44:38] \u001b[32mTrain: [ 25/50] Step 300/520 Loss 2.153 Prec@(1,5) (56.9%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:44:38] \u001b[32mTrain: [ 25/50] Step 320/520 Loss 2.153 Prec@(1,5) (56.9%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:44:39] \u001b[32mTrain: [ 25/50] Step 340/520 Loss 2.152 Prec@(1,5) (57.0%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:44:39] \u001b[32mTrain: [ 25/50] Step 360/520 Loss 2.147 Prec@(1,5) (57.1%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:44:40] \u001b[32mTrain: [ 25/50] Step 380/520 Loss 2.148 Prec@(1,5) (57.0%, 85.0%)\u001b[0m\n",
            "[2024-04-02 19:44:40] \u001b[32mTrain: [ 25/50] Step 400/520 Loss 2.148 Prec@(1,5) (57.0%, 85.0%)\u001b[0m\n",
            "[2024-04-02 19:44:41] \u001b[32mTrain: [ 25/50] Step 420/520 Loss 2.150 Prec@(1,5) (56.9%, 85.0%)\u001b[0m\n",
            "[2024-04-02 19:44:41] \u001b[32mTrain: [ 25/50] Step 440/520 Loss 2.153 Prec@(1,5) (56.9%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:44:42] \u001b[32mTrain: [ 25/50] Step 460/520 Loss 2.157 Prec@(1,5) (56.9%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:44:42] \u001b[32mTrain: [ 25/50] Step 480/520 Loss 2.158 Prec@(1,5) (56.9%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:44:43] \u001b[32mTrain: [ 25/50] Step 500/520 Loss 2.160 Prec@(1,5) (56.9%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:44:43] \u001b[32mTrain: [ 25/50] Step 520/520 Loss 2.162 Prec@(1,5) (56.9%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:44:43] \u001b[32mTrain: [ 25/50] Final Prec@1 56.8620%\u001b[0m\n",
            "[2024-04-02 19:44:47] \u001b[32mValid: [ 25/50] Step 000/104 Loss 2.275 Prec@(1,5) (57.3%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:44:47] \u001b[32mValid: [ 25/50] Step 020/104 Loss 2.259 Prec@(1,5) (53.8%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:44:47] \u001b[32mValid: [ 25/50] Step 040/104 Loss 2.294 Prec@(1,5) (52.7%, 82.2%)\u001b[0m\n",
            "[2024-04-02 19:44:48] \u001b[32mValid: [ 25/50] Step 060/104 Loss 2.239 Prec@(1,5) (53.0%, 82.2%)\u001b[0m\n",
            "[2024-04-02 19:44:48] \u001b[32mValid: [ 25/50] Step 080/104 Loss 2.244 Prec@(1,5) (52.8%, 82.2%)\u001b[0m\n",
            "[2024-04-02 19:44:48] \u001b[32mValid: [ 25/50] Step 100/104 Loss 2.220 Prec@(1,5) (52.8%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:44:48] \u001b[32mValid: [ 25/50] Step 104/104 Loss 2.222 Prec@(1,5) (52.8%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:44:48] \u001b[32mValid: [ 25/50] Final Prec@1 52.7700%\u001b[0m\n",
            "[2024-04-02 19:44:48] \u001b[32mEpoch 25 LR 0.012500\u001b[0m\n",
            "[2024-04-02 19:44:53] \u001b[32mTrain: [ 26/50] Step 000/520 Loss 1.886 Prec@(1,5) (60.4%, 91.7%)\u001b[0m\n",
            "[2024-04-02 19:44:53] \u001b[32mTrain: [ 26/50] Step 020/520 Loss 2.012 Prec@(1,5) (61.1%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:44:54] \u001b[32mTrain: [ 26/50] Step 040/520 Loss 2.040 Prec@(1,5) (60.2%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:44:54] \u001b[32mTrain: [ 26/50] Step 060/520 Loss 2.064 Prec@(1,5) (59.2%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:44:55] \u001b[32mTrain: [ 26/50] Step 080/520 Loss 2.066 Prec@(1,5) (58.8%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:44:55] \u001b[32mTrain: [ 26/50] Step 100/520 Loss 2.073 Prec@(1,5) (58.8%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:44:56] \u001b[32mTrain: [ 26/50] Step 120/520 Loss 2.092 Prec@(1,5) (58.4%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:44:56] \u001b[32mTrain: [ 26/50] Step 140/520 Loss 2.095 Prec@(1,5) (58.3%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:44:57] \u001b[32mTrain: [ 26/50] Step 160/520 Loss 2.100 Prec@(1,5) (58.2%, 85.6%)\u001b[0m\n",
            "[2024-04-02 19:44:57] \u001b[32mTrain: [ 26/50] Step 180/520 Loss 2.106 Prec@(1,5) (58.0%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:44:58] \u001b[32mTrain: [ 26/50] Step 200/520 Loss 2.109 Prec@(1,5) (57.9%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:44:58] \u001b[32mTrain: [ 26/50] Step 220/520 Loss 2.111 Prec@(1,5) (57.9%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:44:59] \u001b[32mTrain: [ 26/50] Step 240/520 Loss 2.106 Prec@(1,5) (58.0%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:44:59] \u001b[32mTrain: [ 26/50] Step 260/520 Loss 2.110 Prec@(1,5) (57.8%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:45:00] \u001b[32mTrain: [ 26/50] Step 280/520 Loss 2.113 Prec@(1,5) (57.8%, 85.3%)\u001b[0m\n",
            "[2024-04-02 19:45:00] \u001b[32mTrain: [ 26/50] Step 300/520 Loss 2.115 Prec@(1,5) (57.8%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:45:01] \u001b[32mTrain: [ 26/50] Step 320/520 Loss 2.113 Prec@(1,5) (57.8%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:45:01] \u001b[32mTrain: [ 26/50] Step 340/520 Loss 2.112 Prec@(1,5) (57.8%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:45:02] \u001b[32mTrain: [ 26/50] Step 360/520 Loss 2.117 Prec@(1,5) (57.7%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:45:02] \u001b[32mTrain: [ 26/50] Step 380/520 Loss 2.123 Prec@(1,5) (57.5%, 85.3%)\u001b[0m\n",
            "[2024-04-02 19:45:03] \u001b[32mTrain: [ 26/50] Step 400/520 Loss 2.124 Prec@(1,5) (57.4%, 85.3%)\u001b[0m\n",
            "[2024-04-02 19:45:03] \u001b[32mTrain: [ 26/50] Step 420/520 Loss 2.125 Prec@(1,5) (57.5%, 85.3%)\u001b[0m\n",
            "[2024-04-02 19:45:04] \u001b[32mTrain: [ 26/50] Step 440/520 Loss 2.123 Prec@(1,5) (57.5%, 85.3%)\u001b[0m\n",
            "[2024-04-02 19:45:04] \u001b[32mTrain: [ 26/50] Step 460/520 Loss 2.123 Prec@(1,5) (57.5%, 85.3%)\u001b[0m\n",
            "[2024-04-02 19:45:05] \u001b[32mTrain: [ 26/50] Step 480/520 Loss 2.124 Prec@(1,5) (57.5%, 85.3%)\u001b[0m\n",
            "[2024-04-02 19:45:05] \u001b[32mTrain: [ 26/50] Step 500/520 Loss 2.127 Prec@(1,5) (57.5%, 85.2%)\u001b[0m\n",
            "[2024-04-02 19:45:06] \u001b[32mTrain: [ 26/50] Step 520/520 Loss 2.128 Prec@(1,5) (57.4%, 85.2%)\u001b[0m\n",
            "[2024-04-02 19:45:06] \u001b[32mTrain: [ 26/50] Final Prec@1 57.4400%\u001b[0m\n",
            "[2024-04-02 19:45:10] \u001b[32mValid: [ 26/50] Step 000/104 Loss 2.202 Prec@(1,5) (59.4%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:45:10] \u001b[32mValid: [ 26/50] Step 020/104 Loss 2.248 Prec@(1,5) (55.0%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:45:10] \u001b[32mValid: [ 26/50] Step 040/104 Loss 2.242 Prec@(1,5) (54.6%, 82.2%)\u001b[0m\n",
            "[2024-04-02 19:45:10] \u001b[32mValid: [ 26/50] Step 060/104 Loss 2.206 Prec@(1,5) (55.0%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:45:10] \u001b[32mValid: [ 26/50] Step 080/104 Loss 2.208 Prec@(1,5) (54.8%, 82.6%)\u001b[0m\n",
            "[2024-04-02 19:45:10] \u001b[32mValid: [ 26/50] Step 100/104 Loss 2.185 Prec@(1,5) (54.9%, 82.7%)\u001b[0m\n",
            "[2024-04-02 19:45:10] \u001b[32mValid: [ 26/50] Step 104/104 Loss 2.184 Prec@(1,5) (54.9%, 82.7%)\u001b[0m\n",
            "[2024-04-02 19:45:11] \u001b[32mValid: [ 26/50] Final Prec@1 54.9000%\u001b[0m\n",
            "[2024-04-02 19:45:11] \u001b[32mEpoch 26 LR 0.011716\u001b[0m\n",
            "[2024-04-02 19:45:15] \u001b[32mTrain: [ 27/50] Step 000/520 Loss 2.174 Prec@(1,5) (56.2%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:45:16] \u001b[32mTrain: [ 27/50] Step 020/520 Loss 2.098 Prec@(1,5) (58.4%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:45:16] \u001b[32mTrain: [ 27/50] Step 040/520 Loss 2.051 Prec@(1,5) (59.6%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:45:17] \u001b[32mTrain: [ 27/50] Step 060/520 Loss 2.043 Prec@(1,5) (59.4%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:45:17] \u001b[32mTrain: [ 27/50] Step 080/520 Loss 2.053 Prec@(1,5) (59.4%, 85.6%)\u001b[0m\n",
            "[2024-04-02 19:45:18] \u001b[32mTrain: [ 27/50] Step 100/520 Loss 2.069 Prec@(1,5) (58.9%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:45:18] \u001b[32mTrain: [ 27/50] Step 120/520 Loss 2.076 Prec@(1,5) (58.7%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:45:19] \u001b[32mTrain: [ 27/50] Step 140/520 Loss 2.083 Prec@(1,5) (58.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:45:19] \u001b[32mTrain: [ 27/50] Step 160/520 Loss 2.078 Prec@(1,5) (58.5%, 85.3%)\u001b[0m\n",
            "[2024-04-02 19:45:20] \u001b[32mTrain: [ 27/50] Step 180/520 Loss 2.073 Prec@(1,5) (58.6%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:45:20] \u001b[32mTrain: [ 27/50] Step 200/520 Loss 2.076 Prec@(1,5) (58.4%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:45:21] \u001b[32mTrain: [ 27/50] Step 220/520 Loss 2.073 Prec@(1,5) (58.5%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:45:21] \u001b[32mTrain: [ 27/50] Step 240/520 Loss 2.082 Prec@(1,5) (58.4%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:45:22] \u001b[32mTrain: [ 27/50] Step 260/520 Loss 2.085 Prec@(1,5) (58.3%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:45:22] \u001b[32mTrain: [ 27/50] Step 280/520 Loss 2.081 Prec@(1,5) (58.3%, 85.6%)\u001b[0m\n",
            "[2024-04-02 19:45:23] \u001b[32mTrain: [ 27/50] Step 300/520 Loss 2.083 Prec@(1,5) (58.3%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:45:23] \u001b[32mTrain: [ 27/50] Step 320/520 Loss 2.085 Prec@(1,5) (58.2%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:45:24] \u001b[32mTrain: [ 27/50] Step 340/520 Loss 2.084 Prec@(1,5) (58.2%, 85.6%)\u001b[0m\n",
            "[2024-04-02 19:45:24] \u001b[32mTrain: [ 27/50] Step 360/520 Loss 2.085 Prec@(1,5) (58.2%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:45:25] \u001b[32mTrain: [ 27/50] Step 380/520 Loss 2.087 Prec@(1,5) (58.2%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:45:25] \u001b[32mTrain: [ 27/50] Step 400/520 Loss 2.089 Prec@(1,5) (58.2%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:45:26] \u001b[32mTrain: [ 27/50] Step 420/520 Loss 2.091 Prec@(1,5) (58.2%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:45:26] \u001b[32mTrain: [ 27/50] Step 440/520 Loss 2.089 Prec@(1,5) (58.1%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:45:27] \u001b[32mTrain: [ 27/50] Step 460/520 Loss 2.089 Prec@(1,5) (58.2%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:45:27] \u001b[32mTrain: [ 27/50] Step 480/520 Loss 2.092 Prec@(1,5) (58.2%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:45:28] \u001b[32mTrain: [ 27/50] Step 500/520 Loss 2.094 Prec@(1,5) (58.1%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:45:28] \u001b[32mTrain: [ 27/50] Step 520/520 Loss 2.098 Prec@(1,5) (58.1%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:45:28] \u001b[32mTrain: [ 27/50] Final Prec@1 58.0500%\u001b[0m\n",
            "[2024-04-02 19:45:32] \u001b[32mValid: [ 27/50] Step 000/104 Loss 2.078 Prec@(1,5) (64.6%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:45:32] \u001b[32mValid: [ 27/50] Step 020/104 Loss 2.268 Prec@(1,5) (54.6%, 83.2%)\u001b[0m\n",
            "[2024-04-02 19:45:32] \u001b[32mValid: [ 27/50] Step 040/104 Loss 2.261 Prec@(1,5) (53.7%, 82.7%)\u001b[0m\n",
            "[2024-04-02 19:45:32] \u001b[32mValid: [ 27/50] Step 060/104 Loss 2.227 Prec@(1,5) (54.1%, 82.9%)\u001b[0m\n",
            "[2024-04-02 19:45:32] \u001b[32mValid: [ 27/50] Step 080/104 Loss 2.248 Prec@(1,5) (53.5%, 82.8%)\u001b[0m\n",
            "[2024-04-02 19:45:33] \u001b[32mValid: [ 27/50] Step 100/104 Loss 2.236 Prec@(1,5) (53.4%, 82.9%)\u001b[0m\n",
            "[2024-04-02 19:45:33] \u001b[32mValid: [ 27/50] Step 104/104 Loss 2.239 Prec@(1,5) (53.4%, 82.9%)\u001b[0m\n",
            "[2024-04-02 19:45:33] \u001b[32mValid: [ 27/50] Final Prec@1 53.4000%\u001b[0m\n",
            "[2024-04-02 19:45:33] \u001b[32mEpoch 27 LR 0.010934\u001b[0m\n",
            "[2024-04-02 19:45:37] \u001b[32mTrain: [ 28/50] Step 000/520 Loss 1.904 Prec@(1,5) (58.3%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:45:38] \u001b[32mTrain: [ 28/50] Step 020/520 Loss 2.023 Prec@(1,5) (59.5%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:45:39] \u001b[32mTrain: [ 28/50] Step 040/520 Loss 2.030 Prec@(1,5) (59.7%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:45:39] \u001b[32mTrain: [ 28/50] Step 060/520 Loss 2.041 Prec@(1,5) (59.5%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:45:40] \u001b[32mTrain: [ 28/50] Step 080/520 Loss 2.044 Prec@(1,5) (59.3%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:45:40] \u001b[32mTrain: [ 28/50] Step 100/520 Loss 2.050 Prec@(1,5) (59.0%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:45:41] \u001b[32mTrain: [ 28/50] Step 120/520 Loss 2.048 Prec@(1,5) (59.0%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:45:41] \u001b[32mTrain: [ 28/50] Step 140/520 Loss 2.045 Prec@(1,5) (59.0%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:45:42] \u001b[32mTrain: [ 28/50] Step 160/520 Loss 2.040 Prec@(1,5) (59.2%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:45:42] \u001b[32mTrain: [ 28/50] Step 180/520 Loss 2.036 Prec@(1,5) (59.4%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:45:43] \u001b[32mTrain: [ 28/50] Step 200/520 Loss 2.036 Prec@(1,5) (59.5%, 86.1%)\u001b[0m\n",
            "[2024-04-02 19:45:43] \u001b[32mTrain: [ 28/50] Step 220/520 Loss 2.039 Prec@(1,5) (59.3%, 86.1%)\u001b[0m\n",
            "[2024-04-02 19:45:44] \u001b[32mTrain: [ 28/50] Step 240/520 Loss 2.049 Prec@(1,5) (59.1%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:45:44] \u001b[32mTrain: [ 28/50] Step 260/520 Loss 2.051 Prec@(1,5) (59.1%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:45:45] \u001b[32mTrain: [ 28/50] Step 280/520 Loss 2.058 Prec@(1,5) (59.0%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:45:45] \u001b[32mTrain: [ 28/50] Step 300/520 Loss 2.057 Prec@(1,5) (59.0%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:45:46] \u001b[32mTrain: [ 28/50] Step 320/520 Loss 2.060 Prec@(1,5) (58.9%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:45:46] \u001b[32mTrain: [ 28/50] Step 340/520 Loss 2.058 Prec@(1,5) (58.9%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:45:47] \u001b[32mTrain: [ 28/50] Step 360/520 Loss 2.058 Prec@(1,5) (58.9%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:45:47] \u001b[32mTrain: [ 28/50] Step 380/520 Loss 2.055 Prec@(1,5) (59.0%, 85.9%)\u001b[0m\n",
            "[2024-04-02 19:45:48] \u001b[32mTrain: [ 28/50] Step 400/520 Loss 2.061 Prec@(1,5) (58.9%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:45:48] \u001b[32mTrain: [ 28/50] Step 420/520 Loss 2.067 Prec@(1,5) (58.8%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:45:49] \u001b[32mTrain: [ 28/50] Step 440/520 Loss 2.073 Prec@(1,5) (58.6%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:45:49] \u001b[32mTrain: [ 28/50] Step 460/520 Loss 2.074 Prec@(1,5) (58.6%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:45:50] \u001b[32mTrain: [ 28/50] Step 480/520 Loss 2.074 Prec@(1,5) (58.6%, 85.7%)\u001b[0m\n",
            "[2024-04-02 19:45:50] \u001b[32mTrain: [ 28/50] Step 500/520 Loss 2.075 Prec@(1,5) (58.6%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:45:51] \u001b[32mTrain: [ 28/50] Step 520/520 Loss 2.077 Prec@(1,5) (58.5%, 85.8%)\u001b[0m\n",
            "[2024-04-02 19:45:51] \u001b[32mTrain: [ 28/50] Final Prec@1 58.5000%\u001b[0m\n",
            "[2024-04-02 19:45:54] \u001b[32mValid: [ 28/50] Step 000/104 Loss 2.365 Prec@(1,5) (56.2%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:45:55] \u001b[32mValid: [ 28/50] Step 020/104 Loss 2.365 Prec@(1,5) (53.6%, 82.9%)\u001b[0m\n",
            "[2024-04-02 19:45:55] \u001b[32mValid: [ 28/50] Step 040/104 Loss 2.334 Prec@(1,5) (53.0%, 82.7%)\u001b[0m\n",
            "[2024-04-02 19:45:55] \u001b[32mValid: [ 28/50] Step 060/104 Loss 2.305 Prec@(1,5) (53.3%, 82.7%)\u001b[0m\n",
            "[2024-04-02 19:45:55] \u001b[32mValid: [ 28/50] Step 080/104 Loss 2.301 Prec@(1,5) (53.1%, 82.7%)\u001b[0m\n",
            "[2024-04-02 19:45:55] \u001b[32mValid: [ 28/50] Step 100/104 Loss 2.277 Prec@(1,5) (53.5%, 82.6%)\u001b[0m\n",
            "[2024-04-02 19:45:55] \u001b[32mValid: [ 28/50] Step 104/104 Loss 2.282 Prec@(1,5) (53.4%, 82.5%)\u001b[0m\n",
            "[2024-04-02 19:45:55] \u001b[32mValid: [ 28/50] Final Prec@1 53.4200%\u001b[0m\n",
            "[2024-04-02 19:45:55] \u001b[32mEpoch 28 LR 0.010158\u001b[0m\n",
            "[2024-04-02 19:46:00] \u001b[32mTrain: [ 29/50] Step 000/520 Loss 2.115 Prec@(1,5) (56.2%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:46:01] \u001b[32mTrain: [ 29/50] Step 020/520 Loss 1.983 Prec@(1,5) (60.6%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:46:01] \u001b[32mTrain: [ 29/50] Step 040/520 Loss 2.030 Prec@(1,5) (59.1%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:46:02] \u001b[32mTrain: [ 29/50] Step 060/520 Loss 2.014 Prec@(1,5) (59.0%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:46:02] \u001b[32mTrain: [ 29/50] Step 080/520 Loss 2.029 Prec@(1,5) (58.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:46:03] \u001b[32mTrain: [ 29/50] Step 100/520 Loss 2.038 Prec@(1,5) (58.5%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:46:03] \u001b[32mTrain: [ 29/50] Step 120/520 Loss 2.038 Prec@(1,5) (58.5%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:46:04] \u001b[32mTrain: [ 29/50] Step 140/520 Loss 2.035 Prec@(1,5) (58.5%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:46:04] \u001b[32mTrain: [ 29/50] Step 160/520 Loss 2.032 Prec@(1,5) (58.9%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:46:05] \u001b[32mTrain: [ 29/50] Step 180/520 Loss 2.033 Prec@(1,5) (58.9%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:46:05] \u001b[32mTrain: [ 29/50] Step 200/520 Loss 2.029 Prec@(1,5) (59.0%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:46:06] \u001b[32mTrain: [ 29/50] Step 220/520 Loss 2.028 Prec@(1,5) (59.0%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:46:06] \u001b[32mTrain: [ 29/50] Step 240/520 Loss 2.031 Prec@(1,5) (59.0%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:46:07] \u001b[32mTrain: [ 29/50] Step 260/520 Loss 2.036 Prec@(1,5) (58.9%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:46:07] \u001b[32mTrain: [ 29/50] Step 280/520 Loss 2.033 Prec@(1,5) (58.9%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:46:08] \u001b[32mTrain: [ 29/50] Step 300/520 Loss 2.040 Prec@(1,5) (58.9%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:46:08] \u001b[32mTrain: [ 29/50] Step 320/520 Loss 2.042 Prec@(1,5) (58.9%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:46:09] \u001b[32mTrain: [ 29/50] Step 340/520 Loss 2.046 Prec@(1,5) (58.8%, 86.1%)\u001b[0m\n",
            "[2024-04-02 19:46:09] \u001b[32mTrain: [ 29/50] Step 360/520 Loss 2.048 Prec@(1,5) (58.8%, 86.1%)\u001b[0m\n",
            "[2024-04-02 19:46:10] \u001b[32mTrain: [ 29/50] Step 380/520 Loss 2.048 Prec@(1,5) (58.8%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:46:10] \u001b[32mTrain: [ 29/50] Step 400/520 Loss 2.050 Prec@(1,5) (58.8%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:46:11] \u001b[32mTrain: [ 29/50] Step 420/520 Loss 2.050 Prec@(1,5) (58.8%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:46:11] \u001b[32mTrain: [ 29/50] Step 440/520 Loss 2.050 Prec@(1,5) (58.8%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:46:12] \u001b[32mTrain: [ 29/50] Step 460/520 Loss 2.048 Prec@(1,5) (58.8%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:46:12] \u001b[32mTrain: [ 29/50] Step 480/520 Loss 2.051 Prec@(1,5) (58.8%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:46:13] \u001b[32mTrain: [ 29/50] Step 500/520 Loss 2.051 Prec@(1,5) (58.8%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:46:13] \u001b[32mTrain: [ 29/50] Step 520/520 Loss 2.050 Prec@(1,5) (58.8%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:46:13] \u001b[32mTrain: [ 29/50] Final Prec@1 58.8080%\u001b[0m\n",
            "[2024-04-02 19:46:17] \u001b[32mValid: [ 29/50] Step 000/104 Loss 2.264 Prec@(1,5) (56.2%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:46:17] \u001b[32mValid: [ 29/50] Step 020/104 Loss 2.191 Prec@(1,5) (55.1%, 83.9%)\u001b[0m\n",
            "[2024-04-02 19:46:17] \u001b[32mValid: [ 29/50] Step 040/104 Loss 2.197 Prec@(1,5) (54.5%, 84.0%)\u001b[0m\n",
            "[2024-04-02 19:46:17] \u001b[32mValid: [ 29/50] Step 060/104 Loss 2.161 Prec@(1,5) (54.6%, 84.0%)\u001b[0m\n",
            "[2024-04-02 19:46:18] \u001b[32mValid: [ 29/50] Step 080/104 Loss 2.168 Prec@(1,5) (54.5%, 84.0%)\u001b[0m\n",
            "[2024-04-02 19:46:18] \u001b[32mValid: [ 29/50] Step 100/104 Loss 2.157 Prec@(1,5) (54.5%, 83.9%)\u001b[0m\n",
            "[2024-04-02 19:46:18] \u001b[32mValid: [ 29/50] Step 104/104 Loss 2.160 Prec@(1,5) (54.5%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:46:18] \u001b[32mValid: [ 29/50] Final Prec@1 54.4900%\u001b[0m\n",
            "[2024-04-02 19:46:18] \u001b[32mEpoch 29 LR 0.009392\u001b[0m\n",
            "[2024-04-02 19:46:23] \u001b[32mTrain: [ 30/50] Step 000/520 Loss 2.105 Prec@(1,5) (55.2%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:46:23] \u001b[32mTrain: [ 30/50] Step 020/520 Loss 2.001 Prec@(1,5) (59.3%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:46:24] \u001b[32mTrain: [ 30/50] Step 040/520 Loss 2.043 Prec@(1,5) (58.8%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:46:24] \u001b[32mTrain: [ 30/50] Step 060/520 Loss 2.060 Prec@(1,5) (59.0%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:46:25] \u001b[32mTrain: [ 30/50] Step 080/520 Loss 2.049 Prec@(1,5) (59.0%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:46:25] \u001b[32mTrain: [ 30/50] Step 100/520 Loss 2.040 Prec@(1,5) (59.2%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:46:26] \u001b[32mTrain: [ 30/50] Step 120/520 Loss 2.045 Prec@(1,5) (59.1%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:46:26] \u001b[32mTrain: [ 30/50] Step 140/520 Loss 2.043 Prec@(1,5) (58.9%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:46:27] \u001b[32mTrain: [ 30/50] Step 160/520 Loss 2.037 Prec@(1,5) (59.1%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:46:27] \u001b[32mTrain: [ 30/50] Step 180/520 Loss 2.038 Prec@(1,5) (59.1%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:46:28] \u001b[32mTrain: [ 30/50] Step 200/520 Loss 2.028 Prec@(1,5) (59.2%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:46:28] \u001b[32mTrain: [ 30/50] Step 220/520 Loss 2.025 Prec@(1,5) (59.3%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:46:29] \u001b[32mTrain: [ 30/50] Step 240/520 Loss 2.028 Prec@(1,5) (59.2%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:46:29] \u001b[32mTrain: [ 30/50] Step 260/520 Loss 2.035 Prec@(1,5) (59.1%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:46:30] \u001b[32mTrain: [ 30/50] Step 280/520 Loss 2.034 Prec@(1,5) (59.1%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:46:30] \u001b[32mTrain: [ 30/50] Step 300/520 Loss 2.031 Prec@(1,5) (59.1%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:46:31] \u001b[32mTrain: [ 30/50] Step 320/520 Loss 2.028 Prec@(1,5) (59.2%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:46:31] \u001b[32mTrain: [ 30/50] Step 340/520 Loss 2.030 Prec@(1,5) (59.0%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:46:32] \u001b[32mTrain: [ 30/50] Step 360/520 Loss 2.025 Prec@(1,5) (59.2%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:46:32] \u001b[32mTrain: [ 30/50] Step 380/520 Loss 2.024 Prec@(1,5) (59.2%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:46:33] \u001b[32mTrain: [ 30/50] Step 400/520 Loss 2.027 Prec@(1,5) (59.2%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:46:33] \u001b[32mTrain: [ 30/50] Step 420/520 Loss 2.026 Prec@(1,5) (59.2%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:46:34] \u001b[32mTrain: [ 30/50] Step 440/520 Loss 2.024 Prec@(1,5) (59.2%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:46:34] \u001b[32mTrain: [ 30/50] Step 460/520 Loss 2.024 Prec@(1,5) (59.2%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:46:35] \u001b[32mTrain: [ 30/50] Step 480/520 Loss 2.026 Prec@(1,5) (59.3%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:46:35] \u001b[32mTrain: [ 30/50] Step 500/520 Loss 2.029 Prec@(1,5) (59.2%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:46:36] \u001b[32mTrain: [ 30/50] Step 520/520 Loss 2.029 Prec@(1,5) (59.2%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:46:36] \u001b[32mTrain: [ 30/50] Final Prec@1 59.2220%\u001b[0m\n",
            "[2024-04-02 19:46:39] \u001b[32mValid: [ 30/50] Step 000/104 Loss 2.019 Prec@(1,5) (62.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:46:39] \u001b[32mValid: [ 30/50] Step 020/104 Loss 2.222 Prec@(1,5) (54.9%, 83.7%)\u001b[0m\n",
            "[2024-04-02 19:46:40] \u001b[32mValid: [ 30/50] Step 040/104 Loss 2.223 Prec@(1,5) (54.3%, 83.6%)\u001b[0m\n",
            "[2024-04-02 19:46:40] \u001b[32mValid: [ 30/50] Step 060/104 Loss 2.166 Prec@(1,5) (54.8%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:46:40] \u001b[32mValid: [ 30/50] Step 080/104 Loss 2.163 Prec@(1,5) (54.6%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:46:40] \u001b[32mValid: [ 30/50] Step 100/104 Loss 2.149 Prec@(1,5) (54.7%, 84.0%)\u001b[0m\n",
            "[2024-04-02 19:46:40] \u001b[32mValid: [ 30/50] Step 104/104 Loss 2.153 Prec@(1,5) (54.8%, 83.9%)\u001b[0m\n",
            "[2024-04-02 19:46:40] \u001b[32mValid: [ 30/50] Final Prec@1 54.7500%\u001b[0m\n",
            "[2024-04-02 19:46:40] \u001b[32mEpoch 30 LR 0.008638\u001b[0m\n",
            "[2024-04-02 19:46:45] \u001b[32mTrain: [ 31/50] Step 000/520 Loss 1.836 Prec@(1,5) (68.8%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:46:45] \u001b[32mTrain: [ 31/50] Step 020/520 Loss 1.998 Prec@(1,5) (59.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:46:46] \u001b[32mTrain: [ 31/50] Step 040/520 Loss 1.980 Prec@(1,5) (59.8%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:46:46] \u001b[32mTrain: [ 31/50] Step 060/520 Loss 2.001 Prec@(1,5) (59.5%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:46:47] \u001b[32mTrain: [ 31/50] Step 080/520 Loss 2.003 Prec@(1,5) (59.2%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:46:47] \u001b[32mTrain: [ 31/50] Step 100/520 Loss 1.995 Prec@(1,5) (59.1%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:46:48] \u001b[32mTrain: [ 31/50] Step 120/520 Loss 2.004 Prec@(1,5) (59.2%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:46:49] \u001b[32mTrain: [ 31/50] Step 140/520 Loss 2.006 Prec@(1,5) (59.2%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:46:49] \u001b[32mTrain: [ 31/50] Step 160/520 Loss 2.002 Prec@(1,5) (59.4%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:46:50] \u001b[32mTrain: [ 31/50] Step 180/520 Loss 2.010 Prec@(1,5) (59.4%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:46:50] \u001b[32mTrain: [ 31/50] Step 200/520 Loss 2.007 Prec@(1,5) (59.4%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:46:51] \u001b[32mTrain: [ 31/50] Step 220/520 Loss 2.002 Prec@(1,5) (59.5%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:46:51] \u001b[32mTrain: [ 31/50] Step 240/520 Loss 2.002 Prec@(1,5) (59.5%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:46:52] \u001b[32mTrain: [ 31/50] Step 260/520 Loss 2.005 Prec@(1,5) (59.4%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:46:52] \u001b[32mTrain: [ 31/50] Step 280/520 Loss 2.006 Prec@(1,5) (59.5%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:46:53] \u001b[32mTrain: [ 31/50] Step 300/520 Loss 2.004 Prec@(1,5) (59.5%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:46:53] \u001b[32mTrain: [ 31/50] Step 320/520 Loss 2.002 Prec@(1,5) (59.6%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:46:54] \u001b[32mTrain: [ 31/50] Step 340/520 Loss 2.002 Prec@(1,5) (59.7%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:46:54] \u001b[32mTrain: [ 31/50] Step 360/520 Loss 1.998 Prec@(1,5) (59.7%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:46:55] \u001b[32mTrain: [ 31/50] Step 380/520 Loss 1.996 Prec@(1,5) (59.8%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:46:55] \u001b[32mTrain: [ 31/50] Step 400/520 Loss 1.997 Prec@(1,5) (59.8%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:46:56] \u001b[32mTrain: [ 31/50] Step 420/520 Loss 1.996 Prec@(1,5) (59.9%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:46:56] \u001b[32mTrain: [ 31/50] Step 440/520 Loss 1.999 Prec@(1,5) (59.8%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:46:57] \u001b[32mTrain: [ 31/50] Step 460/520 Loss 2.001 Prec@(1,5) (59.8%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:46:57] \u001b[32mTrain: [ 31/50] Step 480/520 Loss 2.004 Prec@(1,5) (59.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:46:58] \u001b[32mTrain: [ 31/50] Step 500/520 Loss 2.007 Prec@(1,5) (59.7%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:46:58] \u001b[32mTrain: [ 31/50] Step 520/520 Loss 2.006 Prec@(1,5) (59.7%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:46:58] \u001b[32mTrain: [ 31/50] Final Prec@1 59.6760%\u001b[0m\n",
            "[2024-04-02 19:47:02] \u001b[32mValid: [ 31/50] Step 000/104 Loss 2.093 Prec@(1,5) (61.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:47:02] \u001b[32mValid: [ 31/50] Step 020/104 Loss 2.070 Prec@(1,5) (56.6%, 85.2%)\u001b[0m\n",
            "[2024-04-02 19:47:02] \u001b[32mValid: [ 31/50] Step 040/104 Loss 2.084 Prec@(1,5) (56.1%, 85.3%)\u001b[0m\n",
            "[2024-04-02 19:47:02] \u001b[32mValid: [ 31/50] Step 060/104 Loss 2.048 Prec@(1,5) (56.7%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:47:02] \u001b[32mValid: [ 31/50] Step 080/104 Loss 2.052 Prec@(1,5) (56.5%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:47:03] \u001b[32mValid: [ 31/50] Step 100/104 Loss 2.039 Prec@(1,5) (56.5%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:47:03] \u001b[32mValid: [ 31/50] Step 104/104 Loss 2.040 Prec@(1,5) (56.4%, 85.0%)\u001b[0m\n",
            "[2024-04-02 19:47:03] \u001b[32mValid: [ 31/50] Final Prec@1 56.3800%\u001b[0m\n",
            "[2024-04-02 19:47:03] \u001b[32mEpoch 31 LR 0.007899\u001b[0m\n",
            "[2024-04-02 19:47:07] \u001b[32mTrain: [ 32/50] Step 000/520 Loss 1.877 Prec@(1,5) (63.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:47:08] \u001b[32mTrain: [ 32/50] Step 020/520 Loss 1.862 Prec@(1,5) (62.2%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:47:09] \u001b[32mTrain: [ 32/50] Step 040/520 Loss 1.923 Prec@(1,5) (61.4%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:47:09] \u001b[32mTrain: [ 32/50] Step 060/520 Loss 1.911 Prec@(1,5) (61.2%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:47:10] \u001b[32mTrain: [ 32/50] Step 080/520 Loss 1.926 Prec@(1,5) (60.6%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:47:10] \u001b[32mTrain: [ 32/50] Step 100/520 Loss 1.940 Prec@(1,5) (60.6%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:47:11] \u001b[32mTrain: [ 32/50] Step 120/520 Loss 1.941 Prec@(1,5) (60.5%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:47:11] \u001b[32mTrain: [ 32/50] Step 140/520 Loss 1.950 Prec@(1,5) (60.4%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:47:12] \u001b[32mTrain: [ 32/50] Step 160/520 Loss 1.954 Prec@(1,5) (60.1%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:47:12] \u001b[32mTrain: [ 32/50] Step 180/520 Loss 1.956 Prec@(1,5) (60.2%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:47:13] \u001b[32mTrain: [ 32/50] Step 200/520 Loss 1.952 Prec@(1,5) (60.3%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:47:13] \u001b[32mTrain: [ 32/50] Step 220/520 Loss 1.954 Prec@(1,5) (60.3%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:47:14] \u001b[32mTrain: [ 32/50] Step 240/520 Loss 1.952 Prec@(1,5) (60.5%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:47:14] \u001b[32mTrain: [ 32/50] Step 260/520 Loss 1.954 Prec@(1,5) (60.5%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:47:15] \u001b[32mTrain: [ 32/50] Step 280/520 Loss 1.953 Prec@(1,5) (60.5%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:47:15] \u001b[32mTrain: [ 32/50] Step 300/520 Loss 1.960 Prec@(1,5) (60.4%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:47:16] \u001b[32mTrain: [ 32/50] Step 320/520 Loss 1.961 Prec@(1,5) (60.4%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:47:16] \u001b[32mTrain: [ 32/50] Step 340/520 Loss 1.965 Prec@(1,5) (60.3%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:47:17] \u001b[32mTrain: [ 32/50] Step 360/520 Loss 1.967 Prec@(1,5) (60.2%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:47:17] \u001b[32mTrain: [ 32/50] Step 380/520 Loss 1.968 Prec@(1,5) (60.2%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:47:18] \u001b[32mTrain: [ 32/50] Step 400/520 Loss 1.968 Prec@(1,5) (60.2%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:47:18] \u001b[32mTrain: [ 32/50] Step 420/520 Loss 1.969 Prec@(1,5) (60.2%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:47:19] \u001b[32mTrain: [ 32/50] Step 440/520 Loss 1.969 Prec@(1,5) (60.3%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:47:19] \u001b[32mTrain: [ 32/50] Step 460/520 Loss 1.970 Prec@(1,5) (60.3%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:47:20] \u001b[32mTrain: [ 32/50] Step 480/520 Loss 1.972 Prec@(1,5) (60.2%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:47:20] \u001b[32mTrain: [ 32/50] Step 500/520 Loss 1.974 Prec@(1,5) (60.2%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:47:21] \u001b[32mTrain: [ 32/50] Step 520/520 Loss 1.975 Prec@(1,5) (60.2%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:47:21] \u001b[32mTrain: [ 32/50] Final Prec@1 60.1940%\u001b[0m\n",
            "[2024-04-02 19:47:24] \u001b[32mValid: [ 32/50] Step 000/104 Loss 2.008 Prec@(1,5) (60.4%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:47:25] \u001b[32mValid: [ 32/50] Step 020/104 Loss 2.051 Prec@(1,5) (58.6%, 85.0%)\u001b[0m\n",
            "[2024-04-02 19:47:25] \u001b[32mValid: [ 32/50] Step 040/104 Loss 2.032 Prec@(1,5) (57.7%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:47:25] \u001b[32mValid: [ 32/50] Step 060/104 Loss 1.997 Prec@(1,5) (58.1%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:47:25] \u001b[32mValid: [ 32/50] Step 080/104 Loss 2.000 Prec@(1,5) (57.4%, 85.3%)\u001b[0m\n",
            "[2024-04-02 19:47:25] \u001b[32mValid: [ 32/50] Step 100/104 Loss 1.990 Prec@(1,5) (57.3%, 85.5%)\u001b[0m\n",
            "[2024-04-02 19:47:25] \u001b[32mValid: [ 32/50] Step 104/104 Loss 1.995 Prec@(1,5) (57.2%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:47:26] \u001b[32mValid: [ 32/50] Final Prec@1 57.1700%\u001b[0m\n",
            "[2024-04-02 19:47:26] \u001b[32mEpoch 32 LR 0.007178\u001b[0m\n",
            "[2024-04-02 19:47:30] \u001b[32mTrain: [ 33/50] Step 000/520 Loss 1.889 Prec@(1,5) (65.6%, 91.7%)\u001b[0m\n",
            "[2024-04-02 19:47:31] \u001b[32mTrain: [ 33/50] Step 020/520 Loss 1.917 Prec@(1,5) (61.6%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:47:31] \u001b[32mTrain: [ 33/50] Step 040/520 Loss 1.949 Prec@(1,5) (60.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:47:32] \u001b[32mTrain: [ 33/50] Step 060/520 Loss 1.937 Prec@(1,5) (60.8%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:47:32] \u001b[32mTrain: [ 33/50] Step 080/520 Loss 1.948 Prec@(1,5) (60.4%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:47:33] \u001b[32mTrain: [ 33/50] Step 100/520 Loss 1.956 Prec@(1,5) (60.0%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:47:33] \u001b[32mTrain: [ 33/50] Step 120/520 Loss 1.942 Prec@(1,5) (60.4%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:47:34] \u001b[32mTrain: [ 33/50] Step 140/520 Loss 1.946 Prec@(1,5) (60.5%, 86.8%)\u001b[0m\n",
            "[2024-04-02 19:47:34] \u001b[32mTrain: [ 33/50] Step 160/520 Loss 1.934 Prec@(1,5) (60.8%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:47:35] \u001b[32mTrain: [ 33/50] Step 180/520 Loss 1.938 Prec@(1,5) (60.9%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:47:35] \u001b[32mTrain: [ 33/50] Step 200/520 Loss 1.941 Prec@(1,5) (61.0%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:47:36] \u001b[32mTrain: [ 33/50] Step 220/520 Loss 1.940 Prec@(1,5) (60.9%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:47:36] \u001b[32mTrain: [ 33/50] Step 240/520 Loss 1.945 Prec@(1,5) (60.9%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:47:37] \u001b[32mTrain: [ 33/50] Step 260/520 Loss 1.947 Prec@(1,5) (61.0%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:47:37] \u001b[32mTrain: [ 33/50] Step 280/520 Loss 1.946 Prec@(1,5) (61.0%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:47:38] \u001b[32mTrain: [ 33/50] Step 300/520 Loss 1.949 Prec@(1,5) (61.0%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:47:38] \u001b[32mTrain: [ 33/50] Step 320/520 Loss 1.948 Prec@(1,5) (61.0%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:47:39] \u001b[32mTrain: [ 33/50] Step 340/520 Loss 1.947 Prec@(1,5) (61.0%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:47:39] \u001b[32mTrain: [ 33/50] Step 360/520 Loss 1.949 Prec@(1,5) (61.0%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:47:40] \u001b[32mTrain: [ 33/50] Step 380/520 Loss 1.949 Prec@(1,5) (61.1%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:47:40] \u001b[32mTrain: [ 33/50] Step 400/520 Loss 1.948 Prec@(1,5) (61.0%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:47:41] \u001b[32mTrain: [ 33/50] Step 420/520 Loss 1.949 Prec@(1,5) (61.1%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:47:41] \u001b[32mTrain: [ 33/50] Step 440/520 Loss 1.949 Prec@(1,5) (61.1%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:47:42] \u001b[32mTrain: [ 33/50] Step 460/520 Loss 1.947 Prec@(1,5) (61.0%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:47:42] \u001b[32mTrain: [ 33/50] Step 480/520 Loss 1.949 Prec@(1,5) (61.0%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:47:43] \u001b[32mTrain: [ 33/50] Step 500/520 Loss 1.951 Prec@(1,5) (60.9%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:47:43] \u001b[32mTrain: [ 33/50] Step 520/520 Loss 1.954 Prec@(1,5) (60.9%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:47:43] \u001b[32mTrain: [ 33/50] Final Prec@1 60.8560%\u001b[0m\n",
            "[2024-04-02 19:47:47] \u001b[32mValid: [ 33/50] Step 000/104 Loss 2.206 Prec@(1,5) (58.3%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:47:47] \u001b[32mValid: [ 33/50] Step 020/104 Loss 2.237 Prec@(1,5) (56.9%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:47:47] \u001b[32mValid: [ 33/50] Step 040/104 Loss 2.211 Prec@(1,5) (56.2%, 84.0%)\u001b[0m\n",
            "[2024-04-02 19:47:47] \u001b[32mValid: [ 33/50] Step 060/104 Loss 2.156 Prec@(1,5) (56.6%, 84.2%)\u001b[0m\n",
            "[2024-04-02 19:47:47] \u001b[32mValid: [ 33/50] Step 080/104 Loss 2.157 Prec@(1,5) (56.2%, 84.1%)\u001b[0m\n",
            "[2024-04-02 19:47:48] \u001b[32mValid: [ 33/50] Step 100/104 Loss 2.137 Prec@(1,5) (56.4%, 84.3%)\u001b[0m\n",
            "[2024-04-02 19:47:48] \u001b[32mValid: [ 33/50] Step 104/104 Loss 2.138 Prec@(1,5) (56.4%, 84.3%)\u001b[0m\n",
            "[2024-04-02 19:47:48] \u001b[32mValid: [ 33/50] Final Prec@1 56.3700%\u001b[0m\n",
            "[2024-04-02 19:47:48] \u001b[32mEpoch 33 LR 0.006479\u001b[0m\n",
            "[2024-04-02 19:47:52] \u001b[32mTrain: [ 34/50] Step 000/520 Loss 1.930 Prec@(1,5) (58.3%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:47:53] \u001b[32mTrain: [ 34/50] Step 020/520 Loss 1.850 Prec@(1,5) (62.4%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:47:53] \u001b[32mTrain: [ 34/50] Step 040/520 Loss 1.854 Prec@(1,5) (62.3%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:47:54] \u001b[32mTrain: [ 34/50] Step 060/520 Loss 1.843 Prec@(1,5) (62.8%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:47:54] \u001b[32mTrain: [ 34/50] Step 080/520 Loss 1.866 Prec@(1,5) (62.3%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:47:55] \u001b[32mTrain: [ 34/50] Step 100/520 Loss 1.877 Prec@(1,5) (61.9%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:47:55] \u001b[32mTrain: [ 34/50] Step 120/520 Loss 1.878 Prec@(1,5) (62.1%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:47:56] \u001b[32mTrain: [ 34/50] Step 140/520 Loss 1.878 Prec@(1,5) (62.3%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:47:56] \u001b[32mTrain: [ 34/50] Step 160/520 Loss 1.879 Prec@(1,5) (62.3%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:47:57] \u001b[32mTrain: [ 34/50] Step 180/520 Loss 1.879 Prec@(1,5) (62.3%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:47:57] \u001b[32mTrain: [ 34/50] Step 200/520 Loss 1.884 Prec@(1,5) (62.1%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:47:58] \u001b[32mTrain: [ 34/50] Step 220/520 Loss 1.889 Prec@(1,5) (62.1%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:47:58] \u001b[32mTrain: [ 34/50] Step 240/520 Loss 1.893 Prec@(1,5) (62.0%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:47:59] \u001b[32mTrain: [ 34/50] Step 260/520 Loss 1.900 Prec@(1,5) (61.9%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:47:59] \u001b[32mTrain: [ 34/50] Step 280/520 Loss 1.900 Prec@(1,5) (61.8%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:48:00] \u001b[32mTrain: [ 34/50] Step 300/520 Loss 1.897 Prec@(1,5) (61.9%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:48:00] \u001b[32mTrain: [ 34/50] Step 320/520 Loss 1.899 Prec@(1,5) (61.9%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:48:01] \u001b[32mTrain: [ 34/50] Step 340/520 Loss 1.899 Prec@(1,5) (61.9%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:48:01] \u001b[32mTrain: [ 34/50] Step 360/520 Loss 1.898 Prec@(1,5) (61.9%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:48:02] \u001b[32mTrain: [ 34/50] Step 380/520 Loss 1.904 Prec@(1,5) (61.8%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:48:02] \u001b[32mTrain: [ 34/50] Step 400/520 Loss 1.906 Prec@(1,5) (61.8%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:48:03] \u001b[32mTrain: [ 34/50] Step 420/520 Loss 1.907 Prec@(1,5) (61.8%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:48:03] \u001b[32mTrain: [ 34/50] Step 440/520 Loss 1.909 Prec@(1,5) (61.7%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:48:04] \u001b[32mTrain: [ 34/50] Step 460/520 Loss 1.911 Prec@(1,5) (61.7%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:48:04] \u001b[32mTrain: [ 34/50] Step 480/520 Loss 1.911 Prec@(1,5) (61.7%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:48:05] \u001b[32mTrain: [ 34/50] Step 500/520 Loss 1.912 Prec@(1,5) (61.7%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:48:05] \u001b[32mTrain: [ 34/50] Step 520/520 Loss 1.911 Prec@(1,5) (61.7%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:48:05] \u001b[32mTrain: [ 34/50] Final Prec@1 61.7260%\u001b[0m\n",
            "[2024-04-02 19:48:09] \u001b[32mValid: [ 34/50] Step 000/104 Loss 2.289 Prec@(1,5) (60.4%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:48:09] \u001b[32mValid: [ 34/50] Step 020/104 Loss 2.221 Prec@(1,5) (56.7%, 84.1%)\u001b[0m\n",
            "[2024-04-02 19:48:09] \u001b[32mValid: [ 34/50] Step 040/104 Loss 2.222 Prec@(1,5) (55.8%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:48:09] \u001b[32mValid: [ 34/50] Step 060/104 Loss 2.190 Prec@(1,5) (55.9%, 83.6%)\u001b[0m\n",
            "[2024-04-02 19:48:10] \u001b[32mValid: [ 34/50] Step 080/104 Loss 2.211 Prec@(1,5) (55.6%, 83.5%)\u001b[0m\n",
            "[2024-04-02 19:48:10] \u001b[32mValid: [ 34/50] Step 100/104 Loss 2.185 Prec@(1,5) (55.6%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:48:10] \u001b[32mValid: [ 34/50] Step 104/104 Loss 2.187 Prec@(1,5) (55.6%, 83.8%)\u001b[0m\n",
            "[2024-04-02 19:48:10] \u001b[32mValid: [ 34/50] Final Prec@1 55.6200%\u001b[0m\n",
            "[2024-04-02 19:48:10] \u001b[32mEpoch 34 LR 0.005803\u001b[0m\n",
            "[2024-04-02 19:48:15] \u001b[32mTrain: [ 35/50] Step 000/520 Loss 2.058 Prec@(1,5) (56.2%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:48:15] \u001b[32mTrain: [ 35/50] Step 020/520 Loss 1.875 Prec@(1,5) (60.4%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:48:16] \u001b[32mTrain: [ 35/50] Step 040/520 Loss 1.882 Prec@(1,5) (60.8%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:48:16] \u001b[32mTrain: [ 35/50] Step 060/520 Loss 1.911 Prec@(1,5) (60.6%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:48:17] \u001b[32mTrain: [ 35/50] Step 080/520 Loss 1.896 Prec@(1,5) (60.8%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:48:17] \u001b[32mTrain: [ 35/50] Step 100/520 Loss 1.887 Prec@(1,5) (61.3%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:48:18] \u001b[32mTrain: [ 35/50] Step 120/520 Loss 1.890 Prec@(1,5) (61.4%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:48:18] \u001b[32mTrain: [ 35/50] Step 140/520 Loss 1.879 Prec@(1,5) (61.6%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:48:19] \u001b[32mTrain: [ 35/50] Step 160/520 Loss 1.881 Prec@(1,5) (61.6%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:48:19] \u001b[32mTrain: [ 35/50] Step 180/520 Loss 1.884 Prec@(1,5) (61.6%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:48:20] \u001b[32mTrain: [ 35/50] Step 200/520 Loss 1.884 Prec@(1,5) (61.5%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:48:20] \u001b[32mTrain: [ 35/50] Step 220/520 Loss 1.882 Prec@(1,5) (61.5%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:48:21] \u001b[32mTrain: [ 35/50] Step 240/520 Loss 1.884 Prec@(1,5) (61.5%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:48:21] \u001b[32mTrain: [ 35/50] Step 260/520 Loss 1.885 Prec@(1,5) (61.6%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:48:22] \u001b[32mTrain: [ 35/50] Step 280/520 Loss 1.884 Prec@(1,5) (61.7%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:48:22] \u001b[32mTrain: [ 35/50] Step 300/520 Loss 1.884 Prec@(1,5) (61.7%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:48:23] \u001b[32mTrain: [ 35/50] Step 320/520 Loss 1.886 Prec@(1,5) (61.7%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:48:23] \u001b[32mTrain: [ 35/50] Step 340/520 Loss 1.890 Prec@(1,5) (61.6%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:48:24] \u001b[32mTrain: [ 35/50] Step 360/520 Loss 1.890 Prec@(1,5) (61.7%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:48:24] \u001b[32mTrain: [ 35/50] Step 380/520 Loss 1.893 Prec@(1,5) (61.6%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:48:24] \u001b[32mTrain: [ 35/50] Step 400/520 Loss 1.892 Prec@(1,5) (61.6%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:48:25] \u001b[32mTrain: [ 35/50] Step 420/520 Loss 1.893 Prec@(1,5) (61.6%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:48:25] \u001b[32mTrain: [ 35/50] Step 440/520 Loss 1.891 Prec@(1,5) (61.6%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:48:26] \u001b[32mTrain: [ 35/50] Step 460/520 Loss 1.892 Prec@(1,5) (61.6%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:48:26] \u001b[32mTrain: [ 35/50] Step 480/520 Loss 1.891 Prec@(1,5) (61.6%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:48:27] \u001b[32mTrain: [ 35/50] Step 500/520 Loss 1.894 Prec@(1,5) (61.6%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:48:27] \u001b[32mTrain: [ 35/50] Step 520/520 Loss 1.896 Prec@(1,5) (61.5%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:48:28] \u001b[32mTrain: [ 35/50] Final Prec@1 61.5420%\u001b[0m\n",
            "[2024-04-02 19:48:31] \u001b[32mValid: [ 35/50] Step 000/104 Loss 2.185 Prec@(1,5) (57.3%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:48:31] \u001b[32mValid: [ 35/50] Step 020/104 Loss 2.131 Prec@(1,5) (57.8%, 84.7%)\u001b[0m\n",
            "[2024-04-02 19:48:31] \u001b[32mValid: [ 35/50] Step 040/104 Loss 2.132 Prec@(1,5) (56.5%, 84.1%)\u001b[0m\n",
            "[2024-04-02 19:48:32] \u001b[32mValid: [ 35/50] Step 060/104 Loss 2.102 Prec@(1,5) (56.7%, 84.2%)\u001b[0m\n",
            "[2024-04-02 19:48:32] \u001b[32mValid: [ 35/50] Step 080/104 Loss 2.111 Prec@(1,5) (56.5%, 84.2%)\u001b[0m\n",
            "[2024-04-02 19:48:32] \u001b[32mValid: [ 35/50] Step 100/104 Loss 2.091 Prec@(1,5) (56.7%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:48:32] \u001b[32mValid: [ 35/50] Step 104/104 Loss 2.091 Prec@(1,5) (56.7%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:48:32] \u001b[32mValid: [ 35/50] Final Prec@1 56.6900%\u001b[0m\n",
            "[2024-04-02 19:48:32] \u001b[32mEpoch 35 LR 0.005153\u001b[0m\n",
            "[2024-04-02 19:48:37] \u001b[32mTrain: [ 36/50] Step 000/520 Loss 1.536 Prec@(1,5) (69.8%, 90.6%)\u001b[0m\n",
            "[2024-04-02 19:48:37] \u001b[32mTrain: [ 36/50] Step 020/520 Loss 1.830 Prec@(1,5) (63.0%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:48:38] \u001b[32mTrain: [ 36/50] Step 040/520 Loss 1.834 Prec@(1,5) (62.8%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:48:38] \u001b[32mTrain: [ 36/50] Step 060/520 Loss 1.866 Prec@(1,5) (62.3%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:48:39] \u001b[32mTrain: [ 36/50] Step 080/520 Loss 1.842 Prec@(1,5) (62.9%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:48:39] \u001b[32mTrain: [ 36/50] Step 100/520 Loss 1.851 Prec@(1,5) (62.9%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:48:40] \u001b[32mTrain: [ 36/50] Step 120/520 Loss 1.856 Prec@(1,5) (62.8%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:48:40] \u001b[32mTrain: [ 36/50] Step 140/520 Loss 1.861 Prec@(1,5) (62.7%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:48:41] \u001b[32mTrain: [ 36/50] Step 160/520 Loss 1.856 Prec@(1,5) (62.7%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:48:41] \u001b[32mTrain: [ 36/50] Step 180/520 Loss 1.848 Prec@(1,5) (62.8%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:48:42] \u001b[32mTrain: [ 36/50] Step 200/520 Loss 1.851 Prec@(1,5) (62.8%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:48:42] \u001b[32mTrain: [ 36/50] Step 220/520 Loss 1.854 Prec@(1,5) (62.6%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:48:43] \u001b[32mTrain: [ 36/50] Step 240/520 Loss 1.855 Prec@(1,5) (62.6%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:48:43] \u001b[32mTrain: [ 36/50] Step 260/520 Loss 1.855 Prec@(1,5) (62.5%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:48:44] \u001b[32mTrain: [ 36/50] Step 280/520 Loss 1.858 Prec@(1,5) (62.4%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:48:44] \u001b[32mTrain: [ 36/50] Step 300/520 Loss 1.863 Prec@(1,5) (62.3%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:48:45] \u001b[32mTrain: [ 36/50] Step 320/520 Loss 1.862 Prec@(1,5) (62.3%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:48:45] \u001b[32mTrain: [ 36/50] Step 340/520 Loss 1.864 Prec@(1,5) (62.2%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:48:46] \u001b[32mTrain: [ 36/50] Step 360/520 Loss 1.865 Prec@(1,5) (62.2%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:48:46] \u001b[32mTrain: [ 36/50] Step 380/520 Loss 1.870 Prec@(1,5) (62.1%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:48:47] \u001b[32mTrain: [ 36/50] Step 400/520 Loss 1.869 Prec@(1,5) (62.2%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:48:47] \u001b[32mTrain: [ 36/50] Step 420/520 Loss 1.872 Prec@(1,5) (62.1%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:48:48] \u001b[32mTrain: [ 36/50] Step 440/520 Loss 1.872 Prec@(1,5) (62.2%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:48:48] \u001b[32mTrain: [ 36/50] Step 460/520 Loss 1.874 Prec@(1,5) (62.2%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:48:49] \u001b[32mTrain: [ 36/50] Step 480/520 Loss 1.872 Prec@(1,5) (62.2%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:48:49] \u001b[32mTrain: [ 36/50] Step 500/520 Loss 1.875 Prec@(1,5) (62.1%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:48:50] \u001b[32mTrain: [ 36/50] Step 520/520 Loss 1.876 Prec@(1,5) (62.1%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:48:50] \u001b[32mTrain: [ 36/50] Final Prec@1 62.0620%\u001b[0m\n",
            "[2024-04-02 19:48:53] \u001b[32mValid: [ 36/50] Step 000/104 Loss 2.128 Prec@(1,5) (58.3%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:48:54] \u001b[32mValid: [ 36/50] Step 020/104 Loss 2.134 Prec@(1,5) (57.8%, 85.0%)\u001b[0m\n",
            "[2024-04-02 19:48:54] \u001b[32mValid: [ 36/50] Step 040/104 Loss 2.119 Prec@(1,5) (57.1%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:48:54] \u001b[32mValid: [ 36/50] Step 060/104 Loss 2.083 Prec@(1,5) (57.5%, 84.8%)\u001b[0m\n",
            "[2024-04-02 19:48:54] \u001b[32mValid: [ 36/50] Step 080/104 Loss 2.092 Prec@(1,5) (57.2%, 84.9%)\u001b[0m\n",
            "[2024-04-02 19:48:54] \u001b[32mValid: [ 36/50] Step 100/104 Loss 2.075 Prec@(1,5) (57.3%, 85.1%)\u001b[0m\n",
            "[2024-04-02 19:48:54] \u001b[32mValid: [ 36/50] Step 104/104 Loss 2.078 Prec@(1,5) (57.3%, 85.0%)\u001b[0m\n",
            "[2024-04-02 19:48:55] \u001b[32mValid: [ 36/50] Final Prec@1 57.2900%\u001b[0m\n",
            "[2024-04-02 19:48:55] \u001b[32mEpoch 36 LR 0.004533\u001b[0m\n",
            "[2024-04-02 19:48:59] \u001b[32mTrain: [ 37/50] Step 000/520 Loss 1.489 Prec@(1,5) (74.0%, 92.7%)\u001b[0m\n",
            "[2024-04-02 19:49:00] \u001b[32mTrain: [ 37/50] Step 020/520 Loss 1.841 Prec@(1,5) (62.9%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:49:00] \u001b[32mTrain: [ 37/50] Step 040/520 Loss 1.837 Prec@(1,5) (63.3%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:49:01] \u001b[32mTrain: [ 37/50] Step 060/520 Loss 1.836 Prec@(1,5) (63.2%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:49:01] \u001b[32mTrain: [ 37/50] Step 080/520 Loss 1.835 Prec@(1,5) (63.2%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:49:02] \u001b[32mTrain: [ 37/50] Step 100/520 Loss 1.829 Prec@(1,5) (63.2%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:49:02] \u001b[32mTrain: [ 37/50] Step 120/520 Loss 1.831 Prec@(1,5) (63.2%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:49:03] \u001b[32mTrain: [ 37/50] Step 140/520 Loss 1.839 Prec@(1,5) (62.9%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:49:03] \u001b[32mTrain: [ 37/50] Step 160/520 Loss 1.847 Prec@(1,5) (62.8%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:49:04] \u001b[32mTrain: [ 37/50] Step 180/520 Loss 1.848 Prec@(1,5) (62.8%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:49:04] \u001b[32mTrain: [ 37/50] Step 200/520 Loss 1.844 Prec@(1,5) (63.0%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:49:05] \u001b[32mTrain: [ 37/50] Step 220/520 Loss 1.843 Prec@(1,5) (63.0%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:49:05] \u001b[32mTrain: [ 37/50] Step 240/520 Loss 1.846 Prec@(1,5) (62.9%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:49:06] \u001b[32mTrain: [ 37/50] Step 260/520 Loss 1.843 Prec@(1,5) (62.9%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:49:06] \u001b[32mTrain: [ 37/50] Step 280/520 Loss 1.849 Prec@(1,5) (62.8%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:49:07] \u001b[32mTrain: [ 37/50] Step 300/520 Loss 1.848 Prec@(1,5) (62.8%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:49:07] \u001b[32mTrain: [ 37/50] Step 320/520 Loss 1.849 Prec@(1,5) (62.7%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:49:08] \u001b[32mTrain: [ 37/50] Step 340/520 Loss 1.853 Prec@(1,5) (62.6%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:49:08] \u001b[32mTrain: [ 37/50] Step 360/520 Loss 1.853 Prec@(1,5) (62.6%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:49:09] \u001b[32mTrain: [ 37/50] Step 380/520 Loss 1.852 Prec@(1,5) (62.6%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:49:09] \u001b[32mTrain: [ 37/50] Step 400/520 Loss 1.852 Prec@(1,5) (62.6%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:49:10] \u001b[32mTrain: [ 37/50] Step 420/520 Loss 1.851 Prec@(1,5) (62.6%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:49:10] \u001b[32mTrain: [ 37/50] Step 440/520 Loss 1.852 Prec@(1,5) (62.6%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:49:11] \u001b[32mTrain: [ 37/50] Step 460/520 Loss 1.853 Prec@(1,5) (62.6%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:49:11] \u001b[32mTrain: [ 37/50] Step 480/520 Loss 1.854 Prec@(1,5) (62.6%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:49:12] \u001b[32mTrain: [ 37/50] Step 500/520 Loss 1.854 Prec@(1,5) (62.6%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:49:12] \u001b[32mTrain: [ 37/50] Step 520/520 Loss 1.853 Prec@(1,5) (62.6%, 88.3%)\u001b[0m\n",
            "[2024-04-02 19:49:12] \u001b[32mTrain: [ 37/50] Final Prec@1 62.6240%\u001b[0m\n",
            "[2024-04-02 19:49:16] \u001b[32mValid: [ 37/50] Step 000/104 Loss 2.043 Prec@(1,5) (63.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:49:16] \u001b[32mValid: [ 37/50] Step 020/104 Loss 1.943 Prec@(1,5) (59.3%, 86.0%)\u001b[0m\n",
            "[2024-04-02 19:49:16] \u001b[32mValid: [ 37/50] Step 040/104 Loss 1.934 Prec@(1,5) (58.6%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:49:16] \u001b[32mValid: [ 37/50] Step 060/104 Loss 1.892 Prec@(1,5) (59.1%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:49:16] \u001b[32mValid: [ 37/50] Step 080/104 Loss 1.903 Prec@(1,5) (58.8%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:49:17] \u001b[32mValid: [ 37/50] Step 100/104 Loss 1.893 Prec@(1,5) (58.8%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:49:17] \u001b[32mValid: [ 37/50] Step 104/104 Loss 1.893 Prec@(1,5) (58.8%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:49:17] \u001b[32mValid: [ 37/50] Final Prec@1 58.8000%\u001b[0m\n",
            "[2024-04-02 19:49:17] \u001b[32mEpoch 37 LR 0.003944\u001b[0m\n",
            "[2024-04-02 19:49:21] \u001b[32mTrain: [ 38/50] Step 000/520 Loss 1.566 Prec@(1,5) (71.9%, 92.7%)\u001b[0m\n",
            "[2024-04-02 19:49:22] \u001b[32mTrain: [ 38/50] Step 020/520 Loss 1.839 Prec@(1,5) (64.1%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:49:22] \u001b[32mTrain: [ 38/50] Step 040/520 Loss 1.817 Prec@(1,5) (63.7%, 88.2%)\u001b[0m\n",
            "[2024-04-02 19:49:23] \u001b[32mTrain: [ 38/50] Step 060/520 Loss 1.815 Prec@(1,5) (63.4%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:49:23] \u001b[32mTrain: [ 38/50] Step 080/520 Loss 1.811 Prec@(1,5) (63.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:49:24] \u001b[32mTrain: [ 38/50] Step 100/520 Loss 1.814 Prec@(1,5) (63.3%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:49:24] \u001b[32mTrain: [ 38/50] Step 120/520 Loss 1.825 Prec@(1,5) (63.3%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:49:25] \u001b[32mTrain: [ 38/50] Step 140/520 Loss 1.822 Prec@(1,5) (63.3%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:49:25] \u001b[32mTrain: [ 38/50] Step 160/520 Loss 1.822 Prec@(1,5) (63.4%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:49:26] \u001b[32mTrain: [ 38/50] Step 180/520 Loss 1.818 Prec@(1,5) (63.4%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:49:26] \u001b[32mTrain: [ 38/50] Step 200/520 Loss 1.818 Prec@(1,5) (63.3%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:49:27] \u001b[32mTrain: [ 38/50] Step 220/520 Loss 1.816 Prec@(1,5) (63.3%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:49:27] \u001b[32mTrain: [ 38/50] Step 240/520 Loss 1.822 Prec@(1,5) (63.1%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:49:28] \u001b[32mTrain: [ 38/50] Step 260/520 Loss 1.825 Prec@(1,5) (63.0%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:49:28] \u001b[32mTrain: [ 38/50] Step 280/520 Loss 1.820 Prec@(1,5) (63.2%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:49:29] \u001b[32mTrain: [ 38/50] Step 300/520 Loss 1.825 Prec@(1,5) (63.0%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:49:29] \u001b[32mTrain: [ 38/50] Step 320/520 Loss 1.823 Prec@(1,5) (63.1%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:49:30] \u001b[32mTrain: [ 38/50] Step 340/520 Loss 1.824 Prec@(1,5) (63.1%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:49:30] \u001b[32mTrain: [ 38/50] Step 360/520 Loss 1.824 Prec@(1,5) (63.1%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:49:31] \u001b[32mTrain: [ 38/50] Step 380/520 Loss 1.824 Prec@(1,5) (63.1%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:49:31] \u001b[32mTrain: [ 38/50] Step 400/520 Loss 1.824 Prec@(1,5) (63.1%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:49:32] \u001b[32mTrain: [ 38/50] Step 420/520 Loss 1.825 Prec@(1,5) (63.1%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:49:32] \u001b[32mTrain: [ 38/50] Step 440/520 Loss 1.823 Prec@(1,5) (63.1%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:49:33] \u001b[32mTrain: [ 38/50] Step 460/520 Loss 1.824 Prec@(1,5) (63.1%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:49:33] \u001b[32mTrain: [ 38/50] Step 480/520 Loss 1.827 Prec@(1,5) (63.1%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:49:34] \u001b[32mTrain: [ 38/50] Step 500/520 Loss 1.828 Prec@(1,5) (63.1%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:49:34] \u001b[32mTrain: [ 38/50] Step 520/520 Loss 1.829 Prec@(1,5) (63.1%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:49:34] \u001b[32mTrain: [ 38/50] Final Prec@1 63.1020%\u001b[0m\n",
            "[2024-04-02 19:49:38] \u001b[32mValid: [ 38/50] Step 000/104 Loss 1.918 Prec@(1,5) (60.4%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:49:38] \u001b[32mValid: [ 38/50] Step 020/104 Loss 2.007 Prec@(1,5) (59.8%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:49:38] \u001b[32mValid: [ 38/50] Step 040/104 Loss 2.002 Prec@(1,5) (58.4%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:49:38] \u001b[32mValid: [ 38/50] Step 060/104 Loss 1.948 Prec@(1,5) (59.3%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:49:39] \u001b[32mValid: [ 38/50] Step 080/104 Loss 1.955 Prec@(1,5) (58.8%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:49:39] \u001b[32mValid: [ 38/50] Step 100/104 Loss 1.940 Prec@(1,5) (58.9%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:49:39] \u001b[32mValid: [ 38/50] Step 104/104 Loss 1.941 Prec@(1,5) (59.0%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:49:39] \u001b[32mValid: [ 38/50] Final Prec@1 58.9600%\u001b[0m\n",
            "[2024-04-02 19:49:39] \u001b[32mEpoch 38 LR 0.003389\u001b[0m\n",
            "[2024-04-02 19:49:44] \u001b[32mTrain: [ 39/50] Step 000/520 Loss 1.963 Prec@(1,5) (58.3%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:49:44] \u001b[32mTrain: [ 39/50] Step 020/520 Loss 1.777 Prec@(1,5) (63.8%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:49:45] \u001b[32mTrain: [ 39/50] Step 040/520 Loss 1.782 Prec@(1,5) (64.0%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:49:45] \u001b[32mTrain: [ 39/50] Step 060/520 Loss 1.800 Prec@(1,5) (63.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:49:46] \u001b[32mTrain: [ 39/50] Step 080/520 Loss 1.789 Prec@(1,5) (63.4%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:49:46] \u001b[32mTrain: [ 39/50] Step 100/520 Loss 1.789 Prec@(1,5) (63.6%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:49:47] \u001b[32mTrain: [ 39/50] Step 120/520 Loss 1.778 Prec@(1,5) (63.7%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:49:47] \u001b[32mTrain: [ 39/50] Step 140/520 Loss 1.780 Prec@(1,5) (63.8%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:49:48] \u001b[32mTrain: [ 39/50] Step 160/520 Loss 1.782 Prec@(1,5) (63.8%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:49:48] \u001b[32mTrain: [ 39/50] Step 180/520 Loss 1.786 Prec@(1,5) (63.6%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:49:49] \u001b[32mTrain: [ 39/50] Step 200/520 Loss 1.791 Prec@(1,5) (63.4%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:49:49] \u001b[32mTrain: [ 39/50] Step 220/520 Loss 1.791 Prec@(1,5) (63.4%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:49:50] \u001b[32mTrain: [ 39/50] Step 240/520 Loss 1.797 Prec@(1,5) (63.3%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:49:50] \u001b[32mTrain: [ 39/50] Step 260/520 Loss 1.792 Prec@(1,5) (63.5%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:49:51] \u001b[32mTrain: [ 39/50] Step 280/520 Loss 1.797 Prec@(1,5) (63.3%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:49:51] \u001b[32mTrain: [ 39/50] Step 300/520 Loss 1.799 Prec@(1,5) (63.3%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:49:52] \u001b[32mTrain: [ 39/50] Step 320/520 Loss 1.797 Prec@(1,5) (63.3%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:49:52] \u001b[32mTrain: [ 39/50] Step 340/520 Loss 1.801 Prec@(1,5) (63.3%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:49:53] \u001b[32mTrain: [ 39/50] Step 360/520 Loss 1.804 Prec@(1,5) (63.3%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:49:53] \u001b[32mTrain: [ 39/50] Step 380/520 Loss 1.802 Prec@(1,5) (63.4%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:49:54] \u001b[32mTrain: [ 39/50] Step 400/520 Loss 1.802 Prec@(1,5) (63.4%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:49:54] \u001b[32mTrain: [ 39/50] Step 420/520 Loss 1.806 Prec@(1,5) (63.3%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:49:55] \u001b[32mTrain: [ 39/50] Step 440/520 Loss 1.806 Prec@(1,5) (63.3%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:49:55] \u001b[32mTrain: [ 39/50] Step 460/520 Loss 1.807 Prec@(1,5) (63.3%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:49:56] \u001b[32mTrain: [ 39/50] Step 480/520 Loss 1.810 Prec@(1,5) (63.2%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:49:56] \u001b[32mTrain: [ 39/50] Step 500/520 Loss 1.810 Prec@(1,5) (63.2%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:49:56] \u001b[32mTrain: [ 39/50] Step 520/520 Loss 1.809 Prec@(1,5) (63.2%, 88.4%)\u001b[0m\n",
            "[2024-04-02 19:49:57] \u001b[32mTrain: [ 39/50] Final Prec@1 63.2020%\u001b[0m\n",
            "[2024-04-02 19:50:00] \u001b[32mValid: [ 39/50] Step 000/104 Loss 1.873 Prec@(1,5) (62.5%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:50:00] \u001b[32mValid: [ 39/50] Step 020/104 Loss 1.947 Prec@(1,5) (59.9%, 86.1%)\u001b[0m\n",
            "[2024-04-02 19:50:01] \u001b[32mValid: [ 39/50] Step 040/104 Loss 1.951 Prec@(1,5) (58.9%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:50:01] \u001b[32mValid: [ 39/50] Step 060/104 Loss 1.904 Prec@(1,5) (59.6%, 86.2%)\u001b[0m\n",
            "[2024-04-02 19:50:01] \u001b[32mValid: [ 39/50] Step 080/104 Loss 1.904 Prec@(1,5) (59.3%, 86.3%)\u001b[0m\n",
            "[2024-04-02 19:50:01] \u001b[32mValid: [ 39/50] Step 100/104 Loss 1.895 Prec@(1,5) (59.4%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:50:01] \u001b[32mValid: [ 39/50] Step 104/104 Loss 1.896 Prec@(1,5) (59.4%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:50:01] \u001b[32mValid: [ 39/50] Final Prec@1 59.3900%\u001b[0m\n",
            "[2024-04-02 19:50:01] \u001b[32mEpoch 39 LR 0.002869\u001b[0m\n",
            "[2024-04-02 19:50:06] \u001b[32mTrain: [ 40/50] Step 000/520 Loss 1.753 Prec@(1,5) (64.6%, 90.6%)\u001b[0m\n",
            "[2024-04-02 19:50:06] \u001b[32mTrain: [ 40/50] Step 020/520 Loss 1.741 Prec@(1,5) (64.2%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:50:07] \u001b[32mTrain: [ 40/50] Step 040/520 Loss 1.773 Prec@(1,5) (64.7%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:50:07] \u001b[32mTrain: [ 40/50] Step 060/520 Loss 1.777 Prec@(1,5) (64.5%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:50:08] \u001b[32mTrain: [ 40/50] Step 080/520 Loss 1.791 Prec@(1,5) (63.9%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:50:08] \u001b[32mTrain: [ 40/50] Step 100/520 Loss 1.791 Prec@(1,5) (63.6%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:50:09] \u001b[32mTrain: [ 40/50] Step 120/520 Loss 1.779 Prec@(1,5) (63.8%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:50:09] \u001b[32mTrain: [ 40/50] Step 140/520 Loss 1.785 Prec@(1,5) (63.6%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:50:10] \u001b[32mTrain: [ 40/50] Step 160/520 Loss 1.778 Prec@(1,5) (63.8%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:50:10] \u001b[32mTrain: [ 40/50] Step 180/520 Loss 1.777 Prec@(1,5) (63.9%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:50:11] \u001b[32mTrain: [ 40/50] Step 200/520 Loss 1.777 Prec@(1,5) (64.0%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:50:11] \u001b[32mTrain: [ 40/50] Step 220/520 Loss 1.779 Prec@(1,5) (64.0%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:50:12] \u001b[32mTrain: [ 40/50] Step 240/520 Loss 1.784 Prec@(1,5) (63.9%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:50:12] \u001b[32mTrain: [ 40/50] Step 260/520 Loss 1.786 Prec@(1,5) (63.9%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:50:13] \u001b[32mTrain: [ 40/50] Step 280/520 Loss 1.783 Prec@(1,5) (63.9%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:50:13] \u001b[32mTrain: [ 40/50] Step 300/520 Loss 1.785 Prec@(1,5) (63.8%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:50:14] \u001b[32mTrain: [ 40/50] Step 320/520 Loss 1.784 Prec@(1,5) (63.9%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:50:14] \u001b[32mTrain: [ 40/50] Step 340/520 Loss 1.781 Prec@(1,5) (63.9%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:50:15] \u001b[32mTrain: [ 40/50] Step 360/520 Loss 1.782 Prec@(1,5) (63.9%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:50:15] \u001b[32mTrain: [ 40/50] Step 380/520 Loss 1.784 Prec@(1,5) (63.9%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:50:16] \u001b[32mTrain: [ 40/50] Step 400/520 Loss 1.781 Prec@(1,5) (64.0%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:50:16] \u001b[32mTrain: [ 40/50] Step 420/520 Loss 1.778 Prec@(1,5) (64.0%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:50:17] \u001b[32mTrain: [ 40/50] Step 440/520 Loss 1.781 Prec@(1,5) (64.0%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:50:17] \u001b[32mTrain: [ 40/50] Step 460/520 Loss 1.780 Prec@(1,5) (63.9%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:50:18] \u001b[32mTrain: [ 40/50] Step 480/520 Loss 1.780 Prec@(1,5) (63.9%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:50:18] \u001b[32mTrain: [ 40/50] Step 500/520 Loss 1.783 Prec@(1,5) (63.8%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:50:19] \u001b[32mTrain: [ 40/50] Step 520/520 Loss 1.785 Prec@(1,5) (63.8%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:50:19] \u001b[32mTrain: [ 40/50] Final Prec@1 63.7540%\u001b[0m\n",
            "[2024-04-02 19:50:22] \u001b[32mValid: [ 40/50] Step 000/104 Loss 1.833 Prec@(1,5) (65.6%, 85.4%)\u001b[0m\n",
            "[2024-04-02 19:50:23] \u001b[32mValid: [ 40/50] Step 020/104 Loss 1.942 Prec@(1,5) (60.1%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:50:23] \u001b[32mValid: [ 40/50] Step 040/104 Loss 1.951 Prec@(1,5) (59.1%, 86.4%)\u001b[0m\n",
            "[2024-04-02 19:50:23] \u001b[32mValid: [ 40/50] Step 060/104 Loss 1.892 Prec@(1,5) (59.6%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:50:23] \u001b[32mValid: [ 40/50] Step 080/104 Loss 1.890 Prec@(1,5) (59.4%, 86.6%)\u001b[0m\n",
            "[2024-04-02 19:50:23] \u001b[32mValid: [ 40/50] Step 100/104 Loss 1.876 Prec@(1,5) (59.6%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:50:23] \u001b[32mValid: [ 40/50] Step 104/104 Loss 1.878 Prec@(1,5) (59.6%, 86.7%)\u001b[0m\n",
            "[2024-04-02 19:50:23] \u001b[32mValid: [ 40/50] Final Prec@1 59.6100%\u001b[0m\n",
            "[2024-04-02 19:50:23] \u001b[32mEpoch 40 LR 0.002388\u001b[0m\n",
            "[2024-04-02 19:50:28] \u001b[32mTrain: [ 41/50] Step 000/520 Loss 1.911 Prec@(1,5) (57.3%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:50:29] \u001b[32mTrain: [ 41/50] Step 020/520 Loss 1.806 Prec@(1,5) (62.1%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:50:29] \u001b[32mTrain: [ 41/50] Step 040/520 Loss 1.786 Prec@(1,5) (63.2%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:50:30] \u001b[32mTrain: [ 41/50] Step 060/520 Loss 1.794 Prec@(1,5) (63.2%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:50:30] \u001b[32mTrain: [ 41/50] Step 080/520 Loss 1.795 Prec@(1,5) (63.5%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:50:31] \u001b[32mTrain: [ 41/50] Step 100/520 Loss 1.781 Prec@(1,5) (63.9%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:50:31] \u001b[32mTrain: [ 41/50] Step 120/520 Loss 1.780 Prec@(1,5) (64.0%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:50:32] \u001b[32mTrain: [ 41/50] Step 140/520 Loss 1.797 Prec@(1,5) (63.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:50:32] \u001b[32mTrain: [ 41/50] Step 160/520 Loss 1.791 Prec@(1,5) (63.9%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:50:33] \u001b[32mTrain: [ 41/50] Step 180/520 Loss 1.790 Prec@(1,5) (63.9%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:50:33] \u001b[32mTrain: [ 41/50] Step 200/520 Loss 1.790 Prec@(1,5) (64.0%, 88.6%)\u001b[0m\n",
            "[2024-04-02 19:50:34] \u001b[32mTrain: [ 41/50] Step 220/520 Loss 1.782 Prec@(1,5) (64.0%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:50:34] \u001b[32mTrain: [ 41/50] Step 240/520 Loss 1.781 Prec@(1,5) (64.0%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:50:35] \u001b[32mTrain: [ 41/50] Step 260/520 Loss 1.785 Prec@(1,5) (63.9%, 88.7%)\u001b[0m\n",
            "[2024-04-02 19:50:35] \u001b[32mTrain: [ 41/50] Step 280/520 Loss 1.781 Prec@(1,5) (64.0%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:50:36] \u001b[32mTrain: [ 41/50] Step 300/520 Loss 1.783 Prec@(1,5) (64.0%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:50:36] \u001b[32mTrain: [ 41/50] Step 320/520 Loss 1.782 Prec@(1,5) (63.9%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:50:37] \u001b[32mTrain: [ 41/50] Step 340/520 Loss 1.786 Prec@(1,5) (63.9%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:50:37] \u001b[32mTrain: [ 41/50] Step 360/520 Loss 1.783 Prec@(1,5) (64.0%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:50:38] \u001b[32mTrain: [ 41/50] Step 380/520 Loss 1.784 Prec@(1,5) (63.9%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:50:38] \u001b[32mTrain: [ 41/50] Step 400/520 Loss 1.785 Prec@(1,5) (63.9%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:50:39] \u001b[32mTrain: [ 41/50] Step 420/520 Loss 1.785 Prec@(1,5) (63.9%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:50:39] \u001b[32mTrain: [ 41/50] Step 440/520 Loss 1.782 Prec@(1,5) (64.0%, 88.8%)\u001b[0m\n",
            "[2024-04-02 19:50:40] \u001b[32mTrain: [ 41/50] Step 460/520 Loss 1.778 Prec@(1,5) (64.0%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:50:40] \u001b[32mTrain: [ 41/50] Step 480/520 Loss 1.778 Prec@(1,5) (64.1%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:50:41] \u001b[32mTrain: [ 41/50] Step 500/520 Loss 1.780 Prec@(1,5) (64.0%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:50:41] \u001b[32mTrain: [ 41/50] Step 520/520 Loss 1.778 Prec@(1,5) (64.1%, 88.9%)\u001b[0m\n",
            "[2024-04-02 19:50:41] \u001b[32mTrain: [ 41/50] Final Prec@1 64.0820%\u001b[0m\n",
            "[2024-04-02 19:50:45] \u001b[32mValid: [ 41/50] Step 000/104 Loss 1.896 Prec@(1,5) (60.4%, 84.4%)\u001b[0m\n",
            "[2024-04-02 19:50:45] \u001b[32mValid: [ 41/50] Step 020/104 Loss 1.956 Prec@(1,5) (60.7%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:50:45] \u001b[32mValid: [ 41/50] Step 040/104 Loss 1.950 Prec@(1,5) (59.7%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:50:46] \u001b[32mValid: [ 41/50] Step 060/104 Loss 1.901 Prec@(1,5) (60.2%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:50:46] \u001b[32mValid: [ 41/50] Step 080/104 Loss 1.900 Prec@(1,5) (59.9%, 86.9%)\u001b[0m\n",
            "[2024-04-02 19:50:46] \u001b[32mValid: [ 41/50] Step 100/104 Loss 1.887 Prec@(1,5) (60.1%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:50:46] \u001b[32mValid: [ 41/50] Step 104/104 Loss 1.887 Prec@(1,5) (60.1%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:50:46] \u001b[32mValid: [ 41/50] Final Prec@1 60.0500%\u001b[0m\n",
            "[2024-04-02 19:50:46] \u001b[32mEpoch 41 LR 0.001947\u001b[0m\n",
            "[2024-04-02 19:50:51] \u001b[32mTrain: [ 42/50] Step 000/520 Loss 1.844 Prec@(1,5) (64.6%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:50:51] \u001b[32mTrain: [ 42/50] Step 020/520 Loss 1.779 Prec@(1,5) (64.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:50:52] \u001b[32mTrain: [ 42/50] Step 040/520 Loss 1.756 Prec@(1,5) (64.5%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:50:52] \u001b[32mTrain: [ 42/50] Step 060/520 Loss 1.763 Prec@(1,5) (64.1%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:50:53] \u001b[32mTrain: [ 42/50] Step 080/520 Loss 1.748 Prec@(1,5) (64.3%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:50:53] \u001b[32mTrain: [ 42/50] Step 100/520 Loss 1.740 Prec@(1,5) (64.4%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:50:54] \u001b[32mTrain: [ 42/50] Step 120/520 Loss 1.740 Prec@(1,5) (64.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:50:54] \u001b[32mTrain: [ 42/50] Step 140/520 Loss 1.744 Prec@(1,5) (64.3%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:50:55] \u001b[32mTrain: [ 42/50] Step 160/520 Loss 1.752 Prec@(1,5) (64.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:50:55] \u001b[32mTrain: [ 42/50] Step 180/520 Loss 1.751 Prec@(1,5) (64.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:50:56] \u001b[32mTrain: [ 42/50] Step 200/520 Loss 1.758 Prec@(1,5) (64.2%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:50:56] \u001b[32mTrain: [ 42/50] Step 220/520 Loss 1.767 Prec@(1,5) (64.0%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:50:57] \u001b[32mTrain: [ 42/50] Step 240/520 Loss 1.761 Prec@(1,5) (64.1%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:50:57] \u001b[32mTrain: [ 42/50] Step 260/520 Loss 1.767 Prec@(1,5) (64.1%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:50:58] \u001b[32mTrain: [ 42/50] Step 280/520 Loss 1.766 Prec@(1,5) (64.1%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:50:58] \u001b[32mTrain: [ 42/50] Step 300/520 Loss 1.766 Prec@(1,5) (64.1%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:50:59] \u001b[32mTrain: [ 42/50] Step 320/520 Loss 1.766 Prec@(1,5) (64.2%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:50:59] \u001b[32mTrain: [ 42/50] Step 340/520 Loss 1.763 Prec@(1,5) (64.2%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:51:00] \u001b[32mTrain: [ 42/50] Step 360/520 Loss 1.766 Prec@(1,5) (64.2%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:51:00] \u001b[32mTrain: [ 42/50] Step 380/520 Loss 1.769 Prec@(1,5) (64.1%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:51:01] \u001b[32mTrain: [ 42/50] Step 400/520 Loss 1.771 Prec@(1,5) (64.1%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:51:01] \u001b[32mTrain: [ 42/50] Step 420/520 Loss 1.771 Prec@(1,5) (64.1%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:51:02] \u001b[32mTrain: [ 42/50] Step 440/520 Loss 1.770 Prec@(1,5) (64.2%, 89.0%)\u001b[0m\n",
            "[2024-04-02 19:51:02] \u001b[32mTrain: [ 42/50] Step 460/520 Loss 1.768 Prec@(1,5) (64.2%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:51:03] \u001b[32mTrain: [ 42/50] Step 480/520 Loss 1.766 Prec@(1,5) (64.3%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:51:04] \u001b[32mTrain: [ 42/50] Step 500/520 Loss 1.766 Prec@(1,5) (64.2%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:51:04] \u001b[32mTrain: [ 42/50] Step 520/520 Loss 1.765 Prec@(1,5) (64.2%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:51:04] \u001b[32mTrain: [ 42/50] Final Prec@1 64.2060%\u001b[0m\n",
            "[2024-04-02 19:51:08] \u001b[32mValid: [ 42/50] Step 000/104 Loss 1.928 Prec@(1,5) (63.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:51:08] \u001b[32mValid: [ 42/50] Step 020/104 Loss 1.899 Prec@(1,5) (60.8%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:51:08] \u001b[32mValid: [ 42/50] Step 040/104 Loss 1.906 Prec@(1,5) (59.8%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:51:08] \u001b[32mValid: [ 42/50] Step 060/104 Loss 1.863 Prec@(1,5) (60.1%, 87.2%)\u001b[0m\n",
            "[2024-04-02 19:51:08] \u001b[32mValid: [ 42/50] Step 080/104 Loss 1.870 Prec@(1,5) (60.0%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:51:09] \u001b[32mValid: [ 42/50] Step 100/104 Loss 1.855 Prec@(1,5) (60.3%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:51:09] \u001b[32mValid: [ 42/50] Step 104/104 Loss 1.856 Prec@(1,5) (60.3%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:51:09] \u001b[32mValid: [ 42/50] Final Prec@1 60.2800%\u001b[0m\n",
            "[2024-04-02 19:51:09] \u001b[32mEpoch 42 LR 0.001547\u001b[0m\n",
            "[2024-04-02 19:51:13] \u001b[32mTrain: [ 43/50] Step 000/520 Loss 1.527 Prec@(1,5) (67.7%, 93.8%)\u001b[0m\n",
            "[2024-04-02 19:51:14] \u001b[32mTrain: [ 43/50] Step 020/520 Loss 1.682 Prec@(1,5) (66.9%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:51:14] \u001b[32mTrain: [ 43/50] Step 040/520 Loss 1.723 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:51:15] \u001b[32mTrain: [ 43/50] Step 060/520 Loss 1.720 Prec@(1,5) (65.8%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:51:15] \u001b[32mTrain: [ 43/50] Step 080/520 Loss 1.722 Prec@(1,5) (65.6%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:51:16] \u001b[32mTrain: [ 43/50] Step 100/520 Loss 1.722 Prec@(1,5) (65.7%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:51:16] \u001b[32mTrain: [ 43/50] Step 120/520 Loss 1.730 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:51:17] \u001b[32mTrain: [ 43/50] Step 140/520 Loss 1.734 Prec@(1,5) (65.1%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:51:17] \u001b[32mTrain: [ 43/50] Step 160/520 Loss 1.750 Prec@(1,5) (64.9%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:51:18] \u001b[32mTrain: [ 43/50] Step 180/520 Loss 1.746 Prec@(1,5) (64.7%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:51:18] \u001b[32mTrain: [ 43/50] Step 200/520 Loss 1.751 Prec@(1,5) (64.6%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:51:19] \u001b[32mTrain: [ 43/50] Step 220/520 Loss 1.747 Prec@(1,5) (64.7%, 89.1%)\u001b[0m\n",
            "[2024-04-02 19:51:19] \u001b[32mTrain: [ 43/50] Step 240/520 Loss 1.743 Prec@(1,5) (64.7%, 89.2%)\u001b[0m\n",
            "[2024-04-02 19:51:20] \u001b[32mTrain: [ 43/50] Step 260/520 Loss 1.736 Prec@(1,5) (64.8%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:51:20] \u001b[32mTrain: [ 43/50] Step 280/520 Loss 1.735 Prec@(1,5) (64.8%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:51:21] \u001b[32mTrain: [ 43/50] Step 300/520 Loss 1.741 Prec@(1,5) (64.7%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:51:21] \u001b[32mTrain: [ 43/50] Step 320/520 Loss 1.743 Prec@(1,5) (64.6%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:51:22] \u001b[32mTrain: [ 43/50] Step 340/520 Loss 1.738 Prec@(1,5) (64.7%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:51:22] \u001b[32mTrain: [ 43/50] Step 360/520 Loss 1.737 Prec@(1,5) (64.8%, 89.3%)\u001b[0m\n",
            "[2024-04-02 19:51:23] \u001b[32mTrain: [ 43/50] Step 380/520 Loss 1.734 Prec@(1,5) (64.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:51:23] \u001b[32mTrain: [ 43/50] Step 400/520 Loss 1.732 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:51:24] \u001b[32mTrain: [ 43/50] Step 420/520 Loss 1.733 Prec@(1,5) (64.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:51:24] \u001b[32mTrain: [ 43/50] Step 440/520 Loss 1.733 Prec@(1,5) (64.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:51:25] \u001b[32mTrain: [ 43/50] Step 460/520 Loss 1.732 Prec@(1,5) (64.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:51:25] \u001b[32mTrain: [ 43/50] Step 480/520 Loss 1.736 Prec@(1,5) (64.8%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:51:26] \u001b[32mTrain: [ 43/50] Step 500/520 Loss 1.734 Prec@(1,5) (64.8%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:51:26] \u001b[32mTrain: [ 43/50] Step 520/520 Loss 1.734 Prec@(1,5) (64.8%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:51:26] \u001b[32mTrain: [ 43/50] Final Prec@1 64.8080%\u001b[0m\n",
            "[2024-04-02 19:51:30] \u001b[32mValid: [ 43/50] Step 000/104 Loss 1.840 Prec@(1,5) (61.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:51:30] \u001b[32mValid: [ 43/50] Step 020/104 Loss 1.898 Prec@(1,5) (61.1%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:51:30] \u001b[32mValid: [ 43/50] Step 040/104 Loss 1.891 Prec@(1,5) (60.1%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:51:30] \u001b[32mValid: [ 43/50] Step 060/104 Loss 1.840 Prec@(1,5) (60.5%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:51:31] \u001b[32mValid: [ 43/50] Step 080/104 Loss 1.843 Prec@(1,5) (60.2%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:51:31] \u001b[32mValid: [ 43/50] Step 100/104 Loss 1.823 Prec@(1,5) (60.4%, 87.1%)\u001b[0m\n",
            "[2024-04-02 19:51:31] \u001b[32mValid: [ 43/50] Step 104/104 Loss 1.825 Prec@(1,5) (60.4%, 87.0%)\u001b[0m\n",
            "[2024-04-02 19:51:31] \u001b[32mValid: [ 43/50] Final Prec@1 60.4300%\u001b[0m\n",
            "[2024-04-02 19:51:31] \u001b[32mEpoch 43 LR 0.001191\u001b[0m\n",
            "[2024-04-02 19:51:36] \u001b[32mTrain: [ 44/50] Step 000/520 Loss 1.632 Prec@(1,5) (64.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:51:36] \u001b[32mTrain: [ 44/50] Step 020/520 Loss 1.682 Prec@(1,5) (65.2%, 90.7%)\u001b[0m\n",
            "[2024-04-02 19:51:37] \u001b[32mTrain: [ 44/50] Step 040/520 Loss 1.706 Prec@(1,5) (65.0%, 90.5%)\u001b[0m\n",
            "[2024-04-02 19:51:37] \u001b[32mTrain: [ 44/50] Step 060/520 Loss 1.733 Prec@(1,5) (64.4%, 90.0%)\u001b[0m\n",
            "[2024-04-02 19:51:38] \u001b[32mTrain: [ 44/50] Step 080/520 Loss 1.719 Prec@(1,5) (65.0%, 90.3%)\u001b[0m\n",
            "[2024-04-02 19:51:38] \u001b[32mTrain: [ 44/50] Step 100/520 Loss 1.717 Prec@(1,5) (65.2%, 90.1%)\u001b[0m\n",
            "[2024-04-02 19:51:39] \u001b[32mTrain: [ 44/50] Step 120/520 Loss 1.725 Prec@(1,5) (65.0%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:51:39] \u001b[32mTrain: [ 44/50] Step 140/520 Loss 1.720 Prec@(1,5) (65.1%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:51:40] \u001b[32mTrain: [ 44/50] Step 160/520 Loss 1.716 Prec@(1,5) (65.3%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:51:40] \u001b[32mTrain: [ 44/50] Step 180/520 Loss 1.721 Prec@(1,5) (65.2%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:51:41] \u001b[32mTrain: [ 44/50] Step 200/520 Loss 1.716 Prec@(1,5) (65.4%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:51:41] \u001b[32mTrain: [ 44/50] Step 220/520 Loss 1.717 Prec@(1,5) (65.2%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:51:42] \u001b[32mTrain: [ 44/50] Step 240/520 Loss 1.717 Prec@(1,5) (65.3%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:51:42] \u001b[32mTrain: [ 44/50] Step 260/520 Loss 1.715 Prec@(1,5) (65.3%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:51:43] \u001b[32mTrain: [ 44/50] Step 280/520 Loss 1.714 Prec@(1,5) (65.3%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:51:43] \u001b[32mTrain: [ 44/50] Step 300/520 Loss 1.717 Prec@(1,5) (65.2%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:51:44] \u001b[32mTrain: [ 44/50] Step 320/520 Loss 1.719 Prec@(1,5) (65.1%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:51:44] \u001b[32mTrain: [ 44/50] Step 340/520 Loss 1.719 Prec@(1,5) (65.0%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:51:45] \u001b[32mTrain: [ 44/50] Step 360/520 Loss 1.717 Prec@(1,5) (65.1%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:51:45] \u001b[32mTrain: [ 44/50] Step 380/520 Loss 1.721 Prec@(1,5) (65.0%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:51:46] \u001b[32mTrain: [ 44/50] Step 400/520 Loss 1.722 Prec@(1,5) (65.0%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:51:46] \u001b[32mTrain: [ 44/50] Step 420/520 Loss 1.722 Prec@(1,5) (65.0%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:51:47] \u001b[32mTrain: [ 44/50] Step 440/520 Loss 1.724 Prec@(1,5) (64.9%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:51:47] \u001b[32mTrain: [ 44/50] Step 460/520 Loss 1.725 Prec@(1,5) (64.9%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:51:48] \u001b[32mTrain: [ 44/50] Step 480/520 Loss 1.726 Prec@(1,5) (64.9%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:51:48] \u001b[32mTrain: [ 44/50] Step 500/520 Loss 1.726 Prec@(1,5) (64.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:51:49] \u001b[32mTrain: [ 44/50] Step 520/520 Loss 1.727 Prec@(1,5) (64.8%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:51:49] \u001b[32mTrain: [ 44/50] Final Prec@1 64.8360%\u001b[0m\n",
            "[2024-04-02 19:51:52] \u001b[32mValid: [ 44/50] Step 000/104 Loss 1.819 Prec@(1,5) (62.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:51:53] \u001b[32mValid: [ 44/50] Step 020/104 Loss 1.843 Prec@(1,5) (61.6%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:51:53] \u001b[32mValid: [ 44/50] Step 040/104 Loss 1.841 Prec@(1,5) (60.8%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:51:53] \u001b[32mValid: [ 44/50] Step 060/104 Loss 1.799 Prec@(1,5) (61.1%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:51:53] \u001b[32mValid: [ 44/50] Step 080/104 Loss 1.806 Prec@(1,5) (60.7%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:51:53] \u001b[32mValid: [ 44/50] Step 100/104 Loss 1.787 Prec@(1,5) (60.9%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:51:53] \u001b[32mValid: [ 44/50] Step 104/104 Loss 1.787 Prec@(1,5) (60.9%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:51:53] \u001b[32mValid: [ 44/50] Final Prec@1 60.9300%\u001b[0m\n",
            "[2024-04-02 19:51:53] \u001b[32mEpoch 44 LR 0.000879\u001b[0m\n",
            "[2024-04-02 19:51:58] \u001b[32mTrain: [ 45/50] Step 000/520 Loss 1.582 Prec@(1,5) (60.4%, 92.7%)\u001b[0m\n",
            "[2024-04-02 19:51:59] \u001b[32mTrain: [ 45/50] Step 020/520 Loss 1.700 Prec@(1,5) (63.9%, 90.4%)\u001b[0m\n",
            "[2024-04-02 19:51:59] \u001b[32mTrain: [ 45/50] Step 040/520 Loss 1.726 Prec@(1,5) (64.4%, 90.1%)\u001b[0m\n",
            "[2024-04-02 19:52:00] \u001b[32mTrain: [ 45/50] Step 060/520 Loss 1.717 Prec@(1,5) (64.8%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:52:00] \u001b[32mTrain: [ 45/50] Step 080/520 Loss 1.705 Prec@(1,5) (64.9%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:52:01] \u001b[32mTrain: [ 45/50] Step 100/520 Loss 1.716 Prec@(1,5) (64.8%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:52:01] \u001b[32mTrain: [ 45/50] Step 120/520 Loss 1.706 Prec@(1,5) (64.9%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:52:02] \u001b[32mTrain: [ 45/50] Step 140/520 Loss 1.694 Prec@(1,5) (65.0%, 89.9%)\u001b[0m\n",
            "[2024-04-02 19:52:02] \u001b[32mTrain: [ 45/50] Step 160/520 Loss 1.714 Prec@(1,5) (64.7%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:03] \u001b[32mTrain: [ 45/50] Step 180/520 Loss 1.715 Prec@(1,5) (64.9%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:03] \u001b[32mTrain: [ 45/50] Step 200/520 Loss 1.713 Prec@(1,5) (64.9%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:04] \u001b[32mTrain: [ 45/50] Step 220/520 Loss 1.713 Prec@(1,5) (64.9%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:04] \u001b[32mTrain: [ 45/50] Step 240/520 Loss 1.714 Prec@(1,5) (64.9%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:05] \u001b[32mTrain: [ 45/50] Step 260/520 Loss 1.707 Prec@(1,5) (65.1%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:05] \u001b[32mTrain: [ 45/50] Step 280/520 Loss 1.710 Prec@(1,5) (65.0%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:06] \u001b[32mTrain: [ 45/50] Step 300/520 Loss 1.711 Prec@(1,5) (65.0%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:06] \u001b[32mTrain: [ 45/50] Step 320/520 Loss 1.709 Prec@(1,5) (65.1%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:07] \u001b[32mTrain: [ 45/50] Step 340/520 Loss 1.712 Prec@(1,5) (65.0%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:52:07] \u001b[32mTrain: [ 45/50] Step 360/520 Loss 1.715 Prec@(1,5) (64.9%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:52:08] \u001b[32mTrain: [ 45/50] Step 380/520 Loss 1.719 Prec@(1,5) (64.9%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:52:08] \u001b[32mTrain: [ 45/50] Step 400/520 Loss 1.717 Prec@(1,5) (65.0%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:52:09] \u001b[32mTrain: [ 45/50] Step 420/520 Loss 1.719 Prec@(1,5) (64.9%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:52:09] \u001b[32mTrain: [ 45/50] Step 440/520 Loss 1.716 Prec@(1,5) (65.0%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:52:10] \u001b[32mTrain: [ 45/50] Step 460/520 Loss 1.714 Prec@(1,5) (65.1%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:52:10] \u001b[32mTrain: [ 45/50] Step 480/520 Loss 1.716 Prec@(1,5) (65.1%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:52:11] \u001b[32mTrain: [ 45/50] Step 500/520 Loss 1.713 Prec@(1,5) (65.1%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:52:11] \u001b[32mTrain: [ 45/50] Step 520/520 Loss 1.715 Prec@(1,5) (65.1%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:12] \u001b[32mTrain: [ 45/50] Final Prec@1 65.0540%\u001b[0m\n",
            "[2024-04-02 19:52:15] \u001b[32mValid: [ 45/50] Step 000/104 Loss 1.802 Prec@(1,5) (63.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:52:15] \u001b[32mValid: [ 45/50] Step 020/104 Loss 1.854 Prec@(1,5) (61.3%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:52:15] \u001b[32mValid: [ 45/50] Step 040/104 Loss 1.849 Prec@(1,5) (60.3%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:52:16] \u001b[32mValid: [ 45/50] Step 060/104 Loss 1.805 Prec@(1,5) (60.8%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:52:16] \u001b[32mValid: [ 45/50] Step 080/104 Loss 1.812 Prec@(1,5) (60.7%, 87.3%)\u001b[0m\n",
            "[2024-04-02 19:52:16] \u001b[32mValid: [ 45/50] Step 100/104 Loss 1.791 Prec@(1,5) (61.1%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:52:16] \u001b[32mValid: [ 45/50] Step 104/104 Loss 1.794 Prec@(1,5) (61.1%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:52:16] \u001b[32mValid: [ 45/50] Final Prec@1 61.0500%\u001b[0m\n",
            "[2024-04-02 19:52:16] \u001b[32mEpoch 45 LR 0.000613\u001b[0m\n",
            "[2024-04-02 19:52:21] \u001b[32mTrain: [ 46/50] Step 000/520 Loss 1.637 Prec@(1,5) (63.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:52:21] \u001b[32mTrain: [ 46/50] Step 020/520 Loss 1.714 Prec@(1,5) (66.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:52:22] \u001b[32mTrain: [ 46/50] Step 040/520 Loss 1.745 Prec@(1,5) (64.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:52:22] \u001b[32mTrain: [ 46/50] Step 060/520 Loss 1.734 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:52:23] \u001b[32mTrain: [ 46/50] Step 080/520 Loss 1.722 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:52:23] \u001b[32mTrain: [ 46/50] Step 100/520 Loss 1.717 Prec@(1,5) (65.4%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:24] \u001b[32mTrain: [ 46/50] Step 120/520 Loss 1.715 Prec@(1,5) (65.6%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:52:24] \u001b[32mTrain: [ 46/50] Step 140/520 Loss 1.714 Prec@(1,5) (65.6%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:25] \u001b[32mTrain: [ 46/50] Step 160/520 Loss 1.715 Prec@(1,5) (65.7%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:25] \u001b[32mTrain: [ 46/50] Step 180/520 Loss 1.712 Prec@(1,5) (65.8%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:26] \u001b[32mTrain: [ 46/50] Step 200/520 Loss 1.713 Prec@(1,5) (65.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:52:26] \u001b[32mTrain: [ 46/50] Step 220/520 Loss 1.710 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:52:27] \u001b[32mTrain: [ 46/50] Step 240/520 Loss 1.711 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:52:27] \u001b[32mTrain: [ 46/50] Step 260/520 Loss 1.710 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:52:28] \u001b[32mTrain: [ 46/50] Step 280/520 Loss 1.711 Prec@(1,5) (65.5%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:28] \u001b[32mTrain: [ 46/50] Step 300/520 Loss 1.712 Prec@(1,5) (65.5%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:29] \u001b[32mTrain: [ 46/50] Step 320/520 Loss 1.709 Prec@(1,5) (65.6%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:29] \u001b[32mTrain: [ 46/50] Step 340/520 Loss 1.712 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:52:30] \u001b[32mTrain: [ 46/50] Step 360/520 Loss 1.711 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:52:30] \u001b[32mTrain: [ 46/50] Step 380/520 Loss 1.709 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:52:31] \u001b[32mTrain: [ 46/50] Step 400/520 Loss 1.713 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:52:31] \u001b[32mTrain: [ 46/50] Step 420/520 Loss 1.714 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:52:32] \u001b[32mTrain: [ 46/50] Step 440/520 Loss 1.714 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:52:32] \u001b[32mTrain: [ 46/50] Step 460/520 Loss 1.714 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:52:33] \u001b[32mTrain: [ 46/50] Step 480/520 Loss 1.709 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:52:33] \u001b[32mTrain: [ 46/50] Step 500/520 Loss 1.710 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:52:34] \u001b[32mTrain: [ 46/50] Step 520/520 Loss 1.711 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:52:34] \u001b[32mTrain: [ 46/50] Final Prec@1 65.5740%\u001b[0m\n",
            "[2024-04-02 19:52:37] \u001b[32mValid: [ 46/50] Step 000/104 Loss 1.815 Prec@(1,5) (63.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:52:37] \u001b[32mValid: [ 46/50] Step 020/104 Loss 1.854 Prec@(1,5) (62.2%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:52:38] \u001b[32mValid: [ 46/50] Step 040/104 Loss 1.845 Prec@(1,5) (61.1%, 88.1%)\u001b[0m\n",
            "[2024-04-02 19:52:38] \u001b[32mValid: [ 46/50] Step 060/104 Loss 1.798 Prec@(1,5) (61.6%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:52:38] \u001b[32mValid: [ 46/50] Step 080/104 Loss 1.805 Prec@(1,5) (61.2%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:52:38] \u001b[32mValid: [ 46/50] Step 100/104 Loss 1.786 Prec@(1,5) (61.4%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:52:38] \u001b[32mValid: [ 46/50] Step 104/104 Loss 1.788 Prec@(1,5) (61.5%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:52:38] \u001b[32mValid: [ 46/50] Final Prec@1 61.4600%\u001b[0m\n",
            "[2024-04-02 19:52:38] \u001b[32mEpoch 46 LR 0.000394\u001b[0m\n",
            "[2024-04-02 19:52:43] \u001b[32mTrain: [ 47/50] Step 000/520 Loss 1.795 Prec@(1,5) (63.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:52:44] \u001b[32mTrain: [ 47/50] Step 020/520 Loss 1.711 Prec@(1,5) (65.3%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:52:44] \u001b[32mTrain: [ 47/50] Step 040/520 Loss 1.720 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:52:45] \u001b[32mTrain: [ 47/50] Step 060/520 Loss 1.714 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:52:45] \u001b[32mTrain: [ 47/50] Step 080/520 Loss 1.717 Prec@(1,5) (65.1%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:52:46] \u001b[32mTrain: [ 47/50] Step 100/520 Loss 1.710 Prec@(1,5) (65.3%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:52:46] \u001b[32mTrain: [ 47/50] Step 120/520 Loss 1.701 Prec@(1,5) (65.4%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:47] \u001b[32mTrain: [ 47/50] Step 140/520 Loss 1.696 Prec@(1,5) (65.5%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:52:47] \u001b[32mTrain: [ 47/50] Step 160/520 Loss 1.692 Prec@(1,5) (65.6%, 89.9%)\u001b[0m\n",
            "[2024-04-02 19:52:48] \u001b[32mTrain: [ 47/50] Step 180/520 Loss 1.694 Prec@(1,5) (65.5%, 89.9%)\u001b[0m\n",
            "[2024-04-02 19:52:48] \u001b[32mTrain: [ 47/50] Step 200/520 Loss 1.702 Prec@(1,5) (65.5%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:49] \u001b[32mTrain: [ 47/50] Step 220/520 Loss 1.703 Prec@(1,5) (65.4%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:52:49] \u001b[32mTrain: [ 47/50] Step 240/520 Loss 1.702 Prec@(1,5) (65.4%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:50] \u001b[32mTrain: [ 47/50] Step 260/520 Loss 1.703 Prec@(1,5) (65.4%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:50] \u001b[32mTrain: [ 47/50] Step 280/520 Loss 1.703 Prec@(1,5) (65.5%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:51] \u001b[32mTrain: [ 47/50] Step 300/520 Loss 1.703 Prec@(1,5) (65.5%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:51] \u001b[32mTrain: [ 47/50] Step 320/520 Loss 1.705 Prec@(1,5) (65.4%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:52:52] \u001b[32mTrain: [ 47/50] Step 340/520 Loss 1.708 Prec@(1,5) (65.4%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:52:52] \u001b[32mTrain: [ 47/50] Step 360/520 Loss 1.704 Prec@(1,5) (65.5%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:53] \u001b[32mTrain: [ 47/50] Step 380/520 Loss 1.702 Prec@(1,5) (65.5%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:53] \u001b[32mTrain: [ 47/50] Step 400/520 Loss 1.701 Prec@(1,5) (65.6%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:54] \u001b[32mTrain: [ 47/50] Step 420/520 Loss 1.700 Prec@(1,5) (65.6%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:54] \u001b[32mTrain: [ 47/50] Step 440/520 Loss 1.698 Prec@(1,5) (65.7%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:55] \u001b[32mTrain: [ 47/50] Step 460/520 Loss 1.699 Prec@(1,5) (65.6%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:55] \u001b[32mTrain: [ 47/50] Step 480/520 Loss 1.699 Prec@(1,5) (65.7%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:56] \u001b[32mTrain: [ 47/50] Step 500/520 Loss 1.699 Prec@(1,5) (65.7%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:52:56] \u001b[32mTrain: [ 47/50] Step 520/520 Loss 1.699 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:52:56] \u001b[32mTrain: [ 47/50] Final Prec@1 65.6040%\u001b[0m\n",
            "[2024-04-02 19:53:00] \u001b[32mValid: [ 47/50] Step 000/104 Loss 1.785 Prec@(1,5) (63.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:53:00] \u001b[32mValid: [ 47/50] Step 020/104 Loss 1.866 Prec@(1,5) (60.7%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:53:00] \u001b[32mValid: [ 47/50] Step 040/104 Loss 1.858 Prec@(1,5) (60.2%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:53:00] \u001b[32mValid: [ 47/50] Step 060/104 Loss 1.811 Prec@(1,5) (60.8%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:53:01] \u001b[32mValid: [ 47/50] Step 080/104 Loss 1.816 Prec@(1,5) (60.6%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:53:01] \u001b[32mValid: [ 47/50] Step 100/104 Loss 1.797 Prec@(1,5) (61.0%, 87.6%)\u001b[0m\n",
            "[2024-04-02 19:53:01] \u001b[32mValid: [ 47/50] Step 104/104 Loss 1.798 Prec@(1,5) (61.1%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:53:01] \u001b[32mValid: [ 47/50] Final Prec@1 61.0500%\u001b[0m\n",
            "[2024-04-02 19:53:01] \u001b[32mEpoch 47 LR 0.000222\u001b[0m\n",
            "[2024-04-02 19:53:06] \u001b[32mTrain: [ 48/50] Step 000/520 Loss 1.725 Prec@(1,5) (66.7%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:53:06] \u001b[32mTrain: [ 48/50] Step 020/520 Loss 1.709 Prec@(1,5) (64.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:53:07] \u001b[32mTrain: [ 48/50] Step 040/520 Loss 1.687 Prec@(1,5) (65.7%, 89.9%)\u001b[0m\n",
            "[2024-04-02 19:53:07] \u001b[32mTrain: [ 48/50] Step 060/520 Loss 1.668 Prec@(1,5) (66.3%, 90.1%)\u001b[0m\n",
            "[2024-04-02 19:53:08] \u001b[32mTrain: [ 48/50] Step 080/520 Loss 1.690 Prec@(1,5) (65.5%, 89.9%)\u001b[0m\n",
            "[2024-04-02 19:53:08] \u001b[32mTrain: [ 48/50] Step 100/520 Loss 1.696 Prec@(1,5) (65.6%, 89.9%)\u001b[0m\n",
            "[2024-04-02 19:53:09] \u001b[32mTrain: [ 48/50] Step 120/520 Loss 1.693 Prec@(1,5) (65.8%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:53:09] \u001b[32mTrain: [ 48/50] Step 140/520 Loss 1.696 Prec@(1,5) (65.7%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:53:10] \u001b[32mTrain: [ 48/50] Step 160/520 Loss 1.704 Prec@(1,5) (65.5%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:53:10] \u001b[32mTrain: [ 48/50] Step 180/520 Loss 1.701 Prec@(1,5) (65.6%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:53:11] \u001b[32mTrain: [ 48/50] Step 200/520 Loss 1.698 Prec@(1,5) (65.6%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:53:11] \u001b[32mTrain: [ 48/50] Step 220/520 Loss 1.705 Prec@(1,5) (65.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:53:12] \u001b[32mTrain: [ 48/50] Step 240/520 Loss 1.706 Prec@(1,5) (65.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:53:12] \u001b[32mTrain: [ 48/50] Step 260/520 Loss 1.699 Prec@(1,5) (65.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:53:13] \u001b[32mTrain: [ 48/50] Step 280/520 Loss 1.702 Prec@(1,5) (65.7%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:53:13] \u001b[32mTrain: [ 48/50] Step 300/520 Loss 1.701 Prec@(1,5) (65.7%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:53:14] \u001b[32mTrain: [ 48/50] Step 320/520 Loss 1.701 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:53:14] \u001b[32mTrain: [ 48/50] Step 340/520 Loss 1.703 Prec@(1,5) (65.7%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:53:15] \u001b[32mTrain: [ 48/50] Step 360/520 Loss 1.700 Prec@(1,5) (65.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:53:15] \u001b[32mTrain: [ 48/50] Step 380/520 Loss 1.699 Prec@(1,5) (65.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:53:16] \u001b[32mTrain: [ 48/50] Step 400/520 Loss 1.702 Prec@(1,5) (65.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:53:16] \u001b[32mTrain: [ 48/50] Step 420/520 Loss 1.700 Prec@(1,5) (65.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:53:17] \u001b[32mTrain: [ 48/50] Step 440/520 Loss 1.703 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:53:17] \u001b[32mTrain: [ 48/50] Step 460/520 Loss 1.703 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:53:18] \u001b[32mTrain: [ 48/50] Step 480/520 Loss 1.703 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:53:18] \u001b[32mTrain: [ 48/50] Step 500/520 Loss 1.706 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:53:19] \u001b[32mTrain: [ 48/50] Step 520/520 Loss 1.705 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:53:19] \u001b[32mTrain: [ 48/50] Final Prec@1 65.4840%\u001b[0m\n",
            "[2024-04-02 19:53:22] \u001b[32mValid: [ 48/50] Step 000/104 Loss 1.805 Prec@(1,5) (63.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:53:23] \u001b[32mValid: [ 48/50] Step 020/104 Loss 1.861 Prec@(1,5) (61.6%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:53:23] \u001b[32mValid: [ 48/50] Step 040/104 Loss 1.856 Prec@(1,5) (60.7%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:53:23] \u001b[32mValid: [ 48/50] Step 060/104 Loss 1.810 Prec@(1,5) (61.2%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:53:23] \u001b[32mValid: [ 48/50] Step 080/104 Loss 1.816 Prec@(1,5) (61.0%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:53:23] \u001b[32mValid: [ 48/50] Step 100/104 Loss 1.798 Prec@(1,5) (61.3%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:53:23] \u001b[32mValid: [ 48/50] Step 104/104 Loss 1.799 Prec@(1,5) (61.3%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:53:24] \u001b[32mValid: [ 48/50] Final Prec@1 61.2800%\u001b[0m\n",
            "[2024-04-02 19:53:24] \u001b[32mEpoch 48 LR 0.000100\u001b[0m\n",
            "[2024-04-02 19:53:28] \u001b[32mTrain: [ 49/50] Step 000/520 Loss 1.865 Prec@(1,5) (60.4%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:53:29] \u001b[32mTrain: [ 49/50] Step 020/520 Loss 1.696 Prec@(1,5) (64.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:53:29] \u001b[32mTrain: [ 49/50] Step 040/520 Loss 1.668 Prec@(1,5) (65.6%, 90.0%)\u001b[0m\n",
            "[2024-04-02 19:53:30] \u001b[32mTrain: [ 49/50] Step 060/520 Loss 1.695 Prec@(1,5) (65.4%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:53:30] \u001b[32mTrain: [ 49/50] Step 080/520 Loss 1.693 Prec@(1,5) (65.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:53:31] \u001b[32mTrain: [ 49/50] Step 100/520 Loss 1.689 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:53:31] \u001b[32mTrain: [ 49/50] Step 120/520 Loss 1.691 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:53:32] \u001b[32mTrain: [ 49/50] Step 140/520 Loss 1.690 Prec@(1,5) (65.4%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:53:32] \u001b[32mTrain: [ 49/50] Step 160/520 Loss 1.694 Prec@(1,5) (65.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:53:33] \u001b[32mTrain: [ 49/50] Step 180/520 Loss 1.697 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:53:33] \u001b[32mTrain: [ 49/50] Step 200/520 Loss 1.700 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:53:34] \u001b[32mTrain: [ 49/50] Step 220/520 Loss 1.697 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:53:34] \u001b[32mTrain: [ 49/50] Step 240/520 Loss 1.698 Prec@(1,5) (65.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:53:35] \u001b[32mTrain: [ 49/50] Step 260/520 Loss 1.694 Prec@(1,5) (65.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:53:35] \u001b[32mTrain: [ 49/50] Step 280/520 Loss 1.697 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:53:36] \u001b[32mTrain: [ 49/50] Step 300/520 Loss 1.700 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:53:36] \u001b[32mTrain: [ 49/50] Step 320/520 Loss 1.700 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:53:37] \u001b[32mTrain: [ 49/50] Step 340/520 Loss 1.698 Prec@(1,5) (65.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:53:37] \u001b[32mTrain: [ 49/50] Step 360/520 Loss 1.696 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:53:38] \u001b[32mTrain: [ 49/50] Step 380/520 Loss 1.697 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:53:38] \u001b[32mTrain: [ 49/50] Step 400/520 Loss 1.699 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:53:39] \u001b[32mTrain: [ 49/50] Step 420/520 Loss 1.704 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:53:39] \u001b[32mTrain: [ 49/50] Step 440/520 Loss 1.705 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:53:40] \u001b[32mTrain: [ 49/50] Step 460/520 Loss 1.708 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:53:40] \u001b[32mTrain: [ 49/50] Step 480/520 Loss 1.709 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:53:41] \u001b[32mTrain: [ 49/50] Step 500/520 Loss 1.708 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:53:41] \u001b[32mTrain: [ 49/50] Step 520/520 Loss 1.708 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 19:53:41] \u001b[32mTrain: [ 49/50] Final Prec@1 65.4660%\u001b[0m\n",
            "[2024-04-02 19:53:45] \u001b[32mValid: [ 49/50] Step 000/104 Loss 1.796 Prec@(1,5) (64.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:53:45] \u001b[32mValid: [ 49/50] Step 020/104 Loss 1.861 Prec@(1,5) (62.1%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:53:45] \u001b[32mValid: [ 49/50] Step 040/104 Loss 1.856 Prec@(1,5) (60.9%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:53:45] \u001b[32mValid: [ 49/50] Step 060/104 Loss 1.810 Prec@(1,5) (61.4%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:53:46] \u001b[32mValid: [ 49/50] Step 080/104 Loss 1.815 Prec@(1,5) (61.1%, 87.4%)\u001b[0m\n",
            "[2024-04-02 19:53:46] \u001b[32mValid: [ 49/50] Step 100/104 Loss 1.796 Prec@(1,5) (61.3%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:53:46] \u001b[32mValid: [ 49/50] Step 104/104 Loss 1.797 Prec@(1,5) (61.3%, 87.5%)\u001b[0m\n",
            "[2024-04-02 19:53:46] \u001b[32mValid: [ 49/50] Final Prec@1 61.2900%\u001b[0m\n",
            "[2024-04-02 19:53:46] \u001b[32mEpoch 49 LR 0.000026\u001b[0m\n",
            "[2024-04-02 19:53:51] \u001b[32mTrain: [ 50/50] Step 000/520 Loss 1.507 Prec@(1,5) (67.7%, 92.7%)\u001b[0m\n",
            "[2024-04-02 19:53:51] \u001b[32mTrain: [ 50/50] Step 020/520 Loss 1.759 Prec@(1,5) (64.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:53:52] \u001b[32mTrain: [ 50/50] Step 040/520 Loss 1.725 Prec@(1,5) (64.8%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:53:52] \u001b[32mTrain: [ 50/50] Step 060/520 Loss 1.723 Prec@(1,5) (65.0%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:53:53] \u001b[32mTrain: [ 50/50] Step 080/520 Loss 1.712 Prec@(1,5) (65.3%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:53:53] \u001b[32mTrain: [ 50/50] Step 100/520 Loss 1.711 Prec@(1,5) (65.4%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:53:54] \u001b[32mTrain: [ 50/50] Step 120/520 Loss 1.705 Prec@(1,5) (65.6%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:53:54] \u001b[32mTrain: [ 50/50] Step 140/520 Loss 1.717 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:53:55] \u001b[32mTrain: [ 50/50] Step 160/520 Loss 1.719 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:53:55] \u001b[32mTrain: [ 50/50] Step 180/520 Loss 1.717 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:53:56] \u001b[32mTrain: [ 50/50] Step 200/520 Loss 1.713 Prec@(1,5) (65.4%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:53:56] \u001b[32mTrain: [ 50/50] Step 220/520 Loss 1.718 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 19:53:57] \u001b[32mTrain: [ 50/50] Step 240/520 Loss 1.714 Prec@(1,5) (65.3%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:53:57] \u001b[32mTrain: [ 50/50] Step 260/520 Loss 1.713 Prec@(1,5) (65.3%, 89.6%)\u001b[0m\n",
            "[2024-04-02 19:53:57] \u001b[32mTrain: [ 50/50] Step 280/520 Loss 1.712 Prec@(1,5) (65.4%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:53:58] \u001b[32mTrain: [ 50/50] Step 300/520 Loss 1.712 Prec@(1,5) (65.4%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:53:58] \u001b[32mTrain: [ 50/50] Step 320/520 Loss 1.708 Prec@(1,5) (65.6%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:53:59] \u001b[32mTrain: [ 50/50] Step 340/520 Loss 1.706 Prec@(1,5) (65.5%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:53:59] \u001b[32mTrain: [ 50/50] Step 360/520 Loss 1.705 Prec@(1,5) (65.6%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:54:00] \u001b[32mTrain: [ 50/50] Step 380/520 Loss 1.703 Prec@(1,5) (65.6%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:54:00] \u001b[32mTrain: [ 50/50] Step 400/520 Loss 1.703 Prec@(1,5) (65.6%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:54:01] \u001b[32mTrain: [ 50/50] Step 420/520 Loss 1.700 Prec@(1,5) (65.6%, 89.8%)\u001b[0m\n",
            "[2024-04-02 19:54:01] \u001b[32mTrain: [ 50/50] Step 440/520 Loss 1.700 Prec@(1,5) (65.6%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:54:02] \u001b[32mTrain: [ 50/50] Step 460/520 Loss 1.701 Prec@(1,5) (65.6%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:54:02] \u001b[32mTrain: [ 50/50] Step 480/520 Loss 1.701 Prec@(1,5) (65.6%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:54:03] \u001b[32mTrain: [ 50/50] Step 500/520 Loss 1.699 Prec@(1,5) (65.7%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:54:03] \u001b[32mTrain: [ 50/50] Step 520/520 Loss 1.698 Prec@(1,5) (65.7%, 89.7%)\u001b[0m\n",
            "[2024-04-02 19:54:04] \u001b[32mTrain: [ 50/50] Final Prec@1 65.6620%\u001b[0m\n",
            "[2024-04-02 19:54:07] \u001b[32mValid: [ 50/50] Step 000/104 Loss 1.785 Prec@(1,5) (64.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 19:54:07] \u001b[32mValid: [ 50/50] Step 020/104 Loss 1.853 Prec@(1,5) (61.8%, 88.0%)\u001b[0m\n",
            "[2024-04-02 19:54:07] \u001b[32mValid: [ 50/50] Step 040/104 Loss 1.850 Prec@(1,5) (60.8%, 87.9%)\u001b[0m\n",
            "[2024-04-02 19:54:08] \u001b[32mValid: [ 50/50] Step 060/104 Loss 1.802 Prec@(1,5) (61.3%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:54:08] \u001b[32mValid: [ 50/50] Step 080/104 Loss 1.807 Prec@(1,5) (61.1%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:54:08] \u001b[32mValid: [ 50/50] Step 100/104 Loss 1.786 Prec@(1,5) (61.4%, 87.8%)\u001b[0m\n",
            "[2024-04-02 19:54:08] \u001b[32mValid: [ 50/50] Step 104/104 Loss 1.787 Prec@(1,5) (61.4%, 87.7%)\u001b[0m\n",
            "[2024-04-02 19:54:08] \u001b[32mValid: [ 50/50] Final Prec@1 61.4200%\u001b[0m\n",
            "Final best Prec@1 = 61.4600%\n",
            "{'lambd=1.263157894736842': 0.6138000170707703, 'lambd=1.6842105263157894': 0.6144000166893006, 'lambd=2.1052631578947367': 0.6146000204086304}\n",
            "random_edges/lambd=2.526315789473684/\n",
            "[2024-04-02 19:54:08] \u001b[32mFixed architecture: {'reduce_n2_p0': 'sepconv5x5', 'reduce_n2_p1': 'sepconv5x5', 'reduce_n3_p0': 'dilconv5x5', 'reduce_n3_p1': 'sepconv5x5', 'reduce_n3_p2': 'sepconv5x5', 'reduce_n4_p0': 'sepconv3x3', 'reduce_n4_p1': 'sepconv5x5', 'reduce_n4_p2': 'sepconv5x5', 'reduce_n4_p3': 'sepconv5x5', 'reduce_n5_p0': 'maxpool', 'reduce_n5_p1': 'sepconv3x3', 'reduce_n5_p2': 'sepconv5x5', 'reduce_n5_p3': 'sepconv5x5', 'reduce_n5_p4': 'maxpool', 'reduce_n2_switch': [1], 'reduce_n3_switch': [1], 'reduce_n4_switch': [0], 'reduce_n5_switch': [4]}\u001b[0m\n",
            "[2024-04-02 19:54:08] \u001b[32mEpoch 0 LR 0.025000\u001b[0m\n",
            "[2024-04-02 19:54:13] \u001b[32mTrain: [  1/50] Step 000/520 Loss 6.524 Prec@(1,5) (1.0%, 5.2%)\u001b[0m\n",
            "[2024-04-02 19:54:13] \u001b[32mTrain: [  1/50] Step 020/520 Loss 6.402 Prec@(1,5) (1.4%, 7.2%)\u001b[0m\n",
            "[2024-04-02 19:54:14] \u001b[32mTrain: [  1/50] Step 040/520 Loss 6.325 Prec@(1,5) (2.2%, 9.6%)\u001b[0m\n",
            "[2024-04-02 19:54:14] \u001b[32mTrain: [  1/50] Step 060/520 Loss 6.214 Prec@(1,5) (3.1%, 12.8%)\u001b[0m\n",
            "[2024-04-02 19:54:15] \u001b[32mTrain: [  1/50] Step 080/520 Loss 6.108 Prec@(1,5) (3.9%, 15.4%)\u001b[0m\n",
            "[2024-04-02 19:54:15] \u001b[32mTrain: [  1/50] Step 100/520 Loss 6.029 Prec@(1,5) (4.6%, 17.0%)\u001b[0m\n",
            "[2024-04-02 19:54:16] \u001b[32mTrain: [  1/50] Step 120/520 Loss 5.959 Prec@(1,5) (5.2%, 18.5%)\u001b[0m\n",
            "[2024-04-02 19:54:16] \u001b[32mTrain: [  1/50] Step 140/520 Loss 5.889 Prec@(1,5) (5.7%, 20.0%)\u001b[0m\n",
            "[2024-04-02 19:54:17] \u001b[32mTrain: [  1/50] Step 160/520 Loss 5.832 Prec@(1,5) (6.1%, 21.3%)\u001b[0m\n",
            "[2024-04-02 19:54:17] \u001b[32mTrain: [  1/50] Step 180/520 Loss 5.790 Prec@(1,5) (6.4%, 22.2%)\u001b[0m\n",
            "[2024-04-02 19:54:18] \u001b[32mTrain: [  1/50] Step 200/520 Loss 5.752 Prec@(1,5) (6.8%, 23.1%)\u001b[0m\n",
            "[2024-04-02 19:54:18] \u001b[32mTrain: [  1/50] Step 220/520 Loss 5.710 Prec@(1,5) (7.2%, 24.1%)\u001b[0m\n",
            "[2024-04-02 19:54:18] \u001b[32mTrain: [  1/50] Step 240/520 Loss 5.669 Prec@(1,5) (7.5%, 25.1%)\u001b[0m\n",
            "[2024-04-02 19:54:19] \u001b[32mTrain: [  1/50] Step 260/520 Loss 5.635 Prec@(1,5) (7.9%, 25.8%)\u001b[0m\n",
            "[2024-04-02 19:54:19] \u001b[32mTrain: [  1/50] Step 280/520 Loss 5.595 Prec@(1,5) (8.2%, 26.6%)\u001b[0m\n",
            "[2024-04-02 19:54:20] \u001b[32mTrain: [  1/50] Step 300/520 Loss 5.568 Prec@(1,5) (8.5%, 27.2%)\u001b[0m\n",
            "[2024-04-02 19:54:20] \u001b[32mTrain: [  1/50] Step 320/520 Loss 5.539 Prec@(1,5) (8.8%, 27.9%)\u001b[0m\n",
            "[2024-04-02 19:54:21] \u001b[32mTrain: [  1/50] Step 340/520 Loss 5.507 Prec@(1,5) (9.1%, 28.5%)\u001b[0m\n",
            "[2024-04-02 19:54:21] \u001b[32mTrain: [  1/50] Step 360/520 Loss 5.479 Prec@(1,5) (9.3%, 29.1%)\u001b[0m\n",
            "[2024-04-02 19:54:22] \u001b[32mTrain: [  1/50] Step 380/520 Loss 5.449 Prec@(1,5) (9.6%, 29.8%)\u001b[0m\n",
            "[2024-04-02 19:54:22] \u001b[32mTrain: [  1/50] Step 400/520 Loss 5.422 Prec@(1,5) (9.9%, 30.3%)\u001b[0m\n",
            "[2024-04-02 19:54:23] \u001b[32mTrain: [  1/50] Step 420/520 Loss 5.395 Prec@(1,5) (10.3%, 30.9%)\u001b[0m\n",
            "[2024-04-02 19:54:23] \u001b[32mTrain: [  1/50] Step 440/520 Loss 5.368 Prec@(1,5) (10.6%, 31.5%)\u001b[0m\n",
            "[2024-04-02 19:54:24] \u001b[32mTrain: [  1/50] Step 460/520 Loss 5.344 Prec@(1,5) (10.8%, 32.0%)\u001b[0m\n",
            "[2024-04-02 19:54:24] \u001b[32mTrain: [  1/50] Step 480/520 Loss 5.322 Prec@(1,5) (11.1%, 32.4%)\u001b[0m\n",
            "[2024-04-02 19:54:25] \u001b[32mTrain: [  1/50] Step 500/520 Loss 5.302 Prec@(1,5) (11.3%, 32.9%)\u001b[0m\n",
            "[2024-04-02 19:54:25] \u001b[32mTrain: [  1/50] Step 520/520 Loss 5.277 Prec@(1,5) (11.6%, 33.4%)\u001b[0m\n",
            "[2024-04-02 19:54:25] \u001b[32mTrain: [  1/50] Final Prec@1 11.5960%\u001b[0m\n",
            "[2024-04-02 19:54:29] \u001b[32mValid: [  1/50] Step 000/104 Loss 4.634 Prec@(1,5) (20.8%, 40.6%)\u001b[0m\n",
            "[2024-04-02 19:54:29] \u001b[32mValid: [  1/50] Step 020/104 Loss 4.410 Prec@(1,5) (17.2%, 43.4%)\u001b[0m\n",
            "[2024-04-02 19:54:29] \u001b[32mValid: [  1/50] Step 040/104 Loss 4.398 Prec@(1,5) (17.2%, 44.2%)\u001b[0m\n",
            "[2024-04-02 19:54:29] \u001b[32mValid: [  1/50] Step 060/104 Loss 4.356 Prec@(1,5) (17.7%, 44.0%)\u001b[0m\n",
            "[2024-04-02 19:54:29] \u001b[32mValid: [  1/50] Step 080/104 Loss 4.382 Prec@(1,5) (17.3%, 43.9%)\u001b[0m\n",
            "[2024-04-02 19:54:30] \u001b[32mValid: [  1/50] Step 100/104 Loss 4.385 Prec@(1,5) (17.1%, 43.9%)\u001b[0m\n",
            "[2024-04-02 19:54:30] \u001b[32mValid: [  1/50] Step 104/104 Loss 4.388 Prec@(1,5) (17.0%, 43.9%)\u001b[0m\n",
            "[2024-04-02 19:54:30] \u001b[32mValid: [  1/50] Final Prec@1 17.0100%\u001b[0m\n",
            "[2024-04-02 19:54:30] \u001b[32mEpoch 1 LR 0.024975\u001b[0m\n",
            "[2024-04-02 19:54:34] \u001b[32mTrain: [  2/50] Step 000/520 Loss 4.232 Prec@(1,5) (28.1%, 47.9%)\u001b[0m\n",
            "[2024-04-02 19:54:35] \u001b[32mTrain: [  2/50] Step 020/520 Loss 4.623 Prec@(1,5) (19.6%, 46.6%)\u001b[0m\n",
            "[2024-04-02 19:54:35] \u001b[32mTrain: [  2/50] Step 040/520 Loss 4.593 Prec@(1,5) (19.3%, 47.6%)\u001b[0m\n",
            "[2024-04-02 19:54:36] \u001b[32mTrain: [  2/50] Step 060/520 Loss 4.574 Prec@(1,5) (19.6%, 48.0%)\u001b[0m\n",
            "[2024-04-02 19:54:36] \u001b[32mTrain: [  2/50] Step 080/520 Loss 4.567 Prec@(1,5) (20.0%, 48.2%)\u001b[0m\n",
            "[2024-04-02 19:54:37] \u001b[32mTrain: [  2/50] Step 100/520 Loss 4.568 Prec@(1,5) (19.8%, 48.0%)\u001b[0m\n",
            "[2024-04-02 19:54:37] \u001b[32mTrain: [  2/50] Step 120/520 Loss 4.557 Prec@(1,5) (19.9%, 48.2%)\u001b[0m\n",
            "[2024-04-02 19:54:38] \u001b[32mTrain: [  2/50] Step 140/520 Loss 4.546 Prec@(1,5) (20.0%, 48.3%)\u001b[0m\n",
            "[2024-04-02 19:54:38] \u001b[32mTrain: [  2/50] Step 160/520 Loss 4.542 Prec@(1,5) (20.1%, 48.2%)\u001b[0m\n",
            "[2024-04-02 19:54:39] \u001b[32mTrain: [  2/50] Step 180/520 Loss 4.538 Prec@(1,5) (20.2%, 48.3%)\u001b[0m\n",
            "[2024-04-02 19:54:39] \u001b[32mTrain: [  2/50] Step 200/520 Loss 4.520 Prec@(1,5) (20.3%, 48.6%)\u001b[0m\n",
            "[2024-04-02 19:54:40] \u001b[32mTrain: [  2/50] Step 220/520 Loss 4.516 Prec@(1,5) (20.5%, 48.7%)\u001b[0m\n",
            "[2024-04-02 19:54:40] \u001b[32mTrain: [  2/50] Step 240/520 Loss 4.502 Prec@(1,5) (20.6%, 49.0%)\u001b[0m\n",
            "[2024-04-02 19:54:41] \u001b[32mTrain: [  2/50] Step 260/520 Loss 4.492 Prec@(1,5) (20.9%, 49.2%)\u001b[0m\n",
            "[2024-04-02 19:54:41] \u001b[32mTrain: [  2/50] Step 280/520 Loss 4.479 Prec@(1,5) (21.0%, 49.4%)\u001b[0m\n",
            "[2024-04-02 19:54:42] \u001b[32mTrain: [  2/50] Step 300/520 Loss 4.470 Prec@(1,5) (21.1%, 49.6%)\u001b[0m\n",
            "[2024-04-02 19:54:42] \u001b[32mTrain: [  2/50] Step 320/520 Loss 4.461 Prec@(1,5) (21.2%, 49.8%)\u001b[0m\n",
            "[2024-04-02 19:54:43] \u001b[32mTrain: [  2/50] Step 340/520 Loss 4.448 Prec@(1,5) (21.4%, 50.1%)\u001b[0m\n",
            "[2024-04-02 19:54:43] \u001b[32mTrain: [  2/50] Step 360/520 Loss 4.436 Prec@(1,5) (21.6%, 50.3%)\u001b[0m\n",
            "[2024-04-02 19:54:44] \u001b[32mTrain: [  2/50] Step 380/520 Loss 4.424 Prec@(1,5) (21.7%, 50.5%)\u001b[0m\n",
            "[2024-04-02 19:54:44] \u001b[32mTrain: [  2/50] Step 400/520 Loss 4.415 Prec@(1,5) (21.8%, 50.7%)\u001b[0m\n",
            "[2024-04-02 19:54:45] \u001b[32mTrain: [  2/50] Step 420/520 Loss 4.407 Prec@(1,5) (21.8%, 50.8%)\u001b[0m\n",
            "[2024-04-02 19:54:45] \u001b[32mTrain: [  2/50] Step 440/520 Loss 4.399 Prec@(1,5) (22.1%, 51.0%)\u001b[0m\n",
            "[2024-04-02 19:54:46] \u001b[32mTrain: [  2/50] Step 460/520 Loss 4.390 Prec@(1,5) (22.2%, 51.2%)\u001b[0m\n",
            "[2024-04-02 19:54:46] \u001b[32mTrain: [  2/50] Step 480/520 Loss 4.378 Prec@(1,5) (22.3%, 51.5%)\u001b[0m\n",
            "[2024-04-02 19:54:47] \u001b[32mTrain: [  2/50] Step 500/520 Loss 4.369 Prec@(1,5) (22.4%, 51.6%)\u001b[0m\n",
            "[2024-04-02 19:54:47] \u001b[32mTrain: [  2/50] Step 520/520 Loss 4.357 Prec@(1,5) (22.6%, 51.8%)\u001b[0m\n",
            "[2024-04-02 19:54:48] \u001b[32mTrain: [  2/50] Final Prec@1 22.5700%\u001b[0m\n",
            "[2024-04-02 19:54:51] \u001b[32mValid: [  2/50] Step 000/104 Loss 4.697 Prec@(1,5) (22.9%, 51.0%)\u001b[0m\n",
            "[2024-04-02 19:54:51] \u001b[32mValid: [  2/50] Step 020/104 Loss 4.374 Prec@(1,5) (22.5%, 52.4%)\u001b[0m\n",
            "[2024-04-02 19:54:51] \u001b[32mValid: [  2/50] Step 040/104 Loss 4.368 Prec@(1,5) (22.0%, 52.1%)\u001b[0m\n",
            "[2024-04-02 19:54:52] \u001b[32mValid: [  2/50] Step 060/104 Loss 4.312 Prec@(1,5) (22.3%, 52.1%)\u001b[0m\n",
            "[2024-04-02 19:54:52] \u001b[32mValid: [  2/50] Step 080/104 Loss 4.331 Prec@(1,5) (22.2%, 52.2%)\u001b[0m\n",
            "[2024-04-02 19:54:52] \u001b[32mValid: [  2/50] Step 100/104 Loss 4.358 Prec@(1,5) (22.0%, 51.8%)\u001b[0m\n",
            "[2024-04-02 19:54:52] \u001b[32mValid: [  2/50] Step 104/104 Loss 4.361 Prec@(1,5) (21.9%, 51.8%)\u001b[0m\n",
            "[2024-04-02 19:54:52] \u001b[32mValid: [  2/50] Final Prec@1 21.9400%\u001b[0m\n",
            "[2024-04-02 19:54:52] \u001b[32mEpoch 2 LR 0.024901\u001b[0m\n",
            "[2024-04-02 19:54:57] \u001b[32mTrain: [  3/50] Step 000/520 Loss 4.257 Prec@(1,5) (20.8%, 53.1%)\u001b[0m\n",
            "[2024-04-02 19:54:57] \u001b[32mTrain: [  3/50] Step 020/520 Loss 4.135 Prec@(1,5) (26.0%, 55.9%)\u001b[0m\n",
            "[2024-04-02 19:54:58] \u001b[32mTrain: [  3/50] Step 040/520 Loss 4.077 Prec@(1,5) (26.0%, 56.9%)\u001b[0m\n",
            "[2024-04-02 19:54:58] \u001b[32mTrain: [  3/50] Step 060/520 Loss 4.053 Prec@(1,5) (26.3%, 57.7%)\u001b[0m\n",
            "[2024-04-02 19:54:59] \u001b[32mTrain: [  3/50] Step 080/520 Loss 4.045 Prec@(1,5) (26.3%, 57.9%)\u001b[0m\n",
            "[2024-04-02 19:54:59] \u001b[32mTrain: [  3/50] Step 100/520 Loss 4.017 Prec@(1,5) (26.7%, 58.3%)\u001b[0m\n",
            "[2024-04-02 19:55:00] \u001b[32mTrain: [  3/50] Step 120/520 Loss 4.022 Prec@(1,5) (26.5%, 58.2%)\u001b[0m\n",
            "[2024-04-02 19:55:00] \u001b[32mTrain: [  3/50] Step 140/520 Loss 4.023 Prec@(1,5) (26.6%, 58.0%)\u001b[0m\n",
            "[2024-04-02 19:55:01] \u001b[32mTrain: [  3/50] Step 160/520 Loss 4.019 Prec@(1,5) (26.8%, 58.1%)\u001b[0m\n",
            "[2024-04-02 19:55:01] \u001b[32mTrain: [  3/50] Step 180/520 Loss 4.012 Prec@(1,5) (26.8%, 58.1%)\u001b[0m\n",
            "[2024-04-02 19:55:02] \u001b[32mTrain: [  3/50] Step 200/520 Loss 4.010 Prec@(1,5) (26.8%, 58.1%)\u001b[0m\n",
            "[2024-04-02 19:55:02] \u001b[32mTrain: [  3/50] Step 220/520 Loss 4.001 Prec@(1,5) (27.0%, 58.3%)\u001b[0m\n",
            "[2024-04-02 19:55:03] \u001b[32mTrain: [  3/50] Step 240/520 Loss 3.995 Prec@(1,5) (27.1%, 58.5%)\u001b[0m\n",
            "[2024-04-02 19:55:03] \u001b[32mTrain: [  3/50] Step 260/520 Loss 3.993 Prec@(1,5) (27.2%, 58.5%)\u001b[0m\n",
            "[2024-04-02 19:55:04] \u001b[32mTrain: [  3/50] Step 280/520 Loss 3.997 Prec@(1,5) (27.2%, 58.5%)\u001b[0m\n",
            "[2024-04-02 19:55:04] \u001b[32mTrain: [  3/50] Step 300/520 Loss 3.985 Prec@(1,5) (27.5%, 58.7%)\u001b[0m\n",
            "[2024-04-02 19:55:05] \u001b[32mTrain: [  3/50] Step 320/520 Loss 3.979 Prec@(1,5) (27.5%, 58.8%)\u001b[0m\n",
            "[2024-04-02 19:55:05] \u001b[32mTrain: [  3/50] Step 340/520 Loss 3.968 Prec@(1,5) (27.6%, 58.9%)\u001b[0m\n",
            "[2024-04-02 19:55:06] \u001b[32mTrain: [  3/50] Step 360/520 Loss 3.968 Prec@(1,5) (27.7%, 58.9%)\u001b[0m\n",
            "[2024-04-02 19:55:06] \u001b[32mTrain: [  3/50] Step 380/520 Loss 3.959 Prec@(1,5) (27.8%, 59.0%)\u001b[0m\n",
            "[2024-04-02 19:55:07] \u001b[32mTrain: [  3/50] Step 400/520 Loss 3.948 Prec@(1,5) (28.0%, 59.2%)\u001b[0m\n",
            "[2024-04-02 19:55:07] \u001b[32mTrain: [  3/50] Step 420/520 Loss 3.943 Prec@(1,5) (28.0%, 59.3%)\u001b[0m\n",
            "[2024-04-02 19:55:08] \u001b[32mTrain: [  3/50] Step 440/520 Loss 3.941 Prec@(1,5) (28.1%, 59.4%)\u001b[0m\n",
            "[2024-04-02 19:55:08] \u001b[32mTrain: [  3/50] Step 460/520 Loss 3.931 Prec@(1,5) (28.2%, 59.5%)\u001b[0m\n",
            "[2024-04-02 19:55:09] \u001b[32mTrain: [  3/50] Step 480/520 Loss 3.924 Prec@(1,5) (28.4%, 59.6%)\u001b[0m\n",
            "[2024-04-02 19:55:09] \u001b[32mTrain: [  3/50] Step 500/520 Loss 3.920 Prec@(1,5) (28.5%, 59.7%)\u001b[0m\n",
            "[2024-04-02 19:55:10] \u001b[32mTrain: [  3/50] Step 520/520 Loss 3.913 Prec@(1,5) (28.5%, 59.8%)\u001b[0m\n",
            "[2024-04-02 19:55:10] \u001b[32mTrain: [  3/50] Final Prec@1 28.5280%\u001b[0m\n",
            "[2024-04-02 19:55:13] \u001b[32mValid: [  3/50] Step 000/104 Loss 4.802 Prec@(1,5) (21.9%, 51.0%)\u001b[0m\n",
            "[2024-04-02 19:55:13] \u001b[32mValid: [  3/50] Step 020/104 Loss 4.645 Prec@(1,5) (22.8%, 52.1%)\u001b[0m\n",
            "[2024-04-02 19:55:14] \u001b[32mValid: [  3/50] Step 040/104 Loss 4.592 Prec@(1,5) (23.6%, 52.3%)\u001b[0m\n",
            "[2024-04-02 19:55:14] \u001b[32mValid: [  3/50] Step 060/104 Loss 4.507 Prec@(1,5) (23.7%, 53.0%)\u001b[0m\n",
            "[2024-04-02 19:55:14] \u001b[32mValid: [  3/50] Step 080/104 Loss 4.519 Prec@(1,5) (23.6%, 53.1%)\u001b[0m\n",
            "[2024-04-02 19:55:14] \u001b[32mValid: [  3/50] Step 100/104 Loss 4.525 Prec@(1,5) (23.5%, 53.2%)\u001b[0m\n",
            "[2024-04-02 19:55:14] \u001b[32mValid: [  3/50] Step 104/104 Loss 4.513 Prec@(1,5) (23.6%, 53.3%)\u001b[0m\n",
            "[2024-04-02 19:55:14] \u001b[32mValid: [  3/50] Final Prec@1 23.5600%\u001b[0m\n",
            "[2024-04-02 19:55:14] \u001b[32mEpoch 3 LR 0.024779\u001b[0m\n",
            "[2024-04-02 19:55:19] \u001b[32mTrain: [  4/50] Step 000/520 Loss 3.862 Prec@(1,5) (30.2%, 57.3%)\u001b[0m\n",
            "[2024-04-02 19:55:20] \u001b[32mTrain: [  4/50] Step 020/520 Loss 3.748 Prec@(1,5) (29.8%, 63.5%)\u001b[0m\n",
            "[2024-04-02 19:55:20] \u001b[32mTrain: [  4/50] Step 040/520 Loss 3.746 Prec@(1,5) (30.0%, 63.0%)\u001b[0m\n",
            "[2024-04-02 19:55:21] \u001b[32mTrain: [  4/50] Step 060/520 Loss 3.723 Prec@(1,5) (30.3%, 63.5%)\u001b[0m\n",
            "[2024-04-02 19:55:21] \u001b[32mTrain: [  4/50] Step 080/520 Loss 3.707 Prec@(1,5) (31.1%, 63.6%)\u001b[0m\n",
            "[2024-04-02 19:55:22] \u001b[32mTrain: [  4/50] Step 100/520 Loss 3.701 Prec@(1,5) (31.4%, 63.7%)\u001b[0m\n",
            "[2024-04-02 19:55:22] \u001b[32mTrain: [  4/50] Step 120/520 Loss 3.688 Prec@(1,5) (31.6%, 63.8%)\u001b[0m\n",
            "[2024-04-02 19:55:23] \u001b[32mTrain: [  4/50] Step 140/520 Loss 3.685 Prec@(1,5) (31.5%, 63.8%)\u001b[0m\n",
            "[2024-04-02 19:55:23] \u001b[32mTrain: [  4/50] Step 160/520 Loss 3.682 Prec@(1,5) (31.7%, 63.9%)\u001b[0m\n",
            "[2024-04-02 19:55:24] \u001b[32mTrain: [  4/50] Step 180/520 Loss 3.686 Prec@(1,5) (31.5%, 63.8%)\u001b[0m\n",
            "[2024-04-02 19:55:24] \u001b[32mTrain: [  4/50] Step 200/520 Loss 3.673 Prec@(1,5) (31.7%, 64.0%)\u001b[0m\n",
            "[2024-04-02 19:55:24] \u001b[32mTrain: [  4/50] Step 220/520 Loss 3.667 Prec@(1,5) (31.9%, 64.2%)\u001b[0m\n",
            "[2024-04-02 19:55:25] \u001b[32mTrain: [  4/50] Step 240/520 Loss 3.668 Prec@(1,5) (31.9%, 64.1%)\u001b[0m\n",
            "[2024-04-02 19:55:25] \u001b[32mTrain: [  4/50] Step 260/520 Loss 3.658 Prec@(1,5) (32.0%, 64.3%)\u001b[0m\n",
            "[2024-04-02 19:55:26] \u001b[32mTrain: [  4/50] Step 280/520 Loss 3.654 Prec@(1,5) (32.1%, 64.3%)\u001b[0m\n",
            "[2024-04-02 19:55:26] \u001b[32mTrain: [  4/50] Step 300/520 Loss 3.651 Prec@(1,5) (32.2%, 64.3%)\u001b[0m\n",
            "[2024-04-02 19:55:27] \u001b[32mTrain: [  4/50] Step 320/520 Loss 3.654 Prec@(1,5) (32.2%, 64.2%)\u001b[0m\n",
            "[2024-04-02 19:55:27] \u001b[32mTrain: [  4/50] Step 340/520 Loss 3.652 Prec@(1,5) (32.3%, 64.3%)\u001b[0m\n",
            "[2024-04-02 19:55:28] \u001b[32mTrain: [  4/50] Step 360/520 Loss 3.648 Prec@(1,5) (32.4%, 64.3%)\u001b[0m\n",
            "[2024-04-02 19:55:28] \u001b[32mTrain: [  4/50] Step 380/520 Loss 3.645 Prec@(1,5) (32.4%, 64.4%)\u001b[0m\n",
            "[2024-04-02 19:55:29] \u001b[32mTrain: [  4/50] Step 400/520 Loss 3.642 Prec@(1,5) (32.4%, 64.4%)\u001b[0m\n",
            "[2024-04-02 19:55:29] \u001b[32mTrain: [  4/50] Step 420/520 Loss 3.641 Prec@(1,5) (32.5%, 64.5%)\u001b[0m\n",
            "[2024-04-02 19:55:30] \u001b[32mTrain: [  4/50] Step 440/520 Loss 3.634 Prec@(1,5) (32.6%, 64.5%)\u001b[0m\n",
            "[2024-04-02 19:55:30] \u001b[32mTrain: [  4/50] Step 460/520 Loss 3.630 Prec@(1,5) (32.7%, 64.6%)\u001b[0m\n",
            "[2024-04-02 19:55:31] \u001b[32mTrain: [  4/50] Step 480/520 Loss 3.626 Prec@(1,5) (32.8%, 64.6%)\u001b[0m\n",
            "[2024-04-02 19:55:31] \u001b[32mTrain: [  4/50] Step 500/520 Loss 3.624 Prec@(1,5) (32.8%, 64.7%)\u001b[0m\n",
            "[2024-04-02 19:55:32] \u001b[32mTrain: [  4/50] Step 520/520 Loss 3.618 Prec@(1,5) (32.9%, 64.8%)\u001b[0m\n",
            "[2024-04-02 19:55:32] \u001b[32mTrain: [  4/50] Final Prec@1 32.8700%\u001b[0m\n",
            "[2024-04-02 19:55:36] \u001b[32mValid: [  4/50] Step 000/104 Loss 3.397 Prec@(1,5) (39.6%, 64.6%)\u001b[0m\n",
            "[2024-04-02 19:55:36] \u001b[32mValid: [  4/50] Step 020/104 Loss 3.460 Prec@(1,5) (33.6%, 64.9%)\u001b[0m\n",
            "[2024-04-02 19:55:36] \u001b[32mValid: [  4/50] Step 040/104 Loss 3.441 Prec@(1,5) (32.6%, 65.2%)\u001b[0m\n",
            "[2024-04-02 19:55:36] \u001b[32mValid: [  4/50] Step 060/104 Loss 3.410 Prec@(1,5) (32.9%, 65.4%)\u001b[0m\n",
            "[2024-04-02 19:55:36] \u001b[32mValid: [  4/50] Step 080/104 Loss 3.417 Prec@(1,5) (32.6%, 65.3%)\u001b[0m\n",
            "[2024-04-02 19:55:36] \u001b[32mValid: [  4/50] Step 100/104 Loss 3.420 Prec@(1,5) (32.7%, 65.2%)\u001b[0m\n",
            "[2024-04-02 19:55:36] \u001b[32mValid: [  4/50] Step 104/104 Loss 3.418 Prec@(1,5) (32.7%, 65.2%)\u001b[0m\n",
            "[2024-04-02 19:55:37] \u001b[32mValid: [  4/50] Final Prec@1 32.7000%\u001b[0m\n",
            "[2024-04-02 19:55:37] \u001b[32mEpoch 4 LR 0.024607\u001b[0m\n",
            "[2024-04-02 19:55:41] \u001b[32mTrain: [  5/50] Step 000/520 Loss 2.978 Prec@(1,5) (41.7%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:55:42] \u001b[32mTrain: [  5/50] Step 020/520 Loss 3.465 Prec@(1,5) (35.0%, 67.0%)\u001b[0m\n",
            "[2024-04-02 19:55:42] \u001b[32mTrain: [  5/50] Step 040/520 Loss 3.452 Prec@(1,5) (35.0%, 67.3%)\u001b[0m\n",
            "[2024-04-02 19:55:43] \u001b[32mTrain: [  5/50] Step 060/520 Loss 3.439 Prec@(1,5) (35.3%, 67.4%)\u001b[0m\n",
            "[2024-04-02 19:55:43] \u001b[32mTrain: [  5/50] Step 080/520 Loss 3.443 Prec@(1,5) (35.3%, 67.2%)\u001b[0m\n",
            "[2024-04-02 19:55:44] \u001b[32mTrain: [  5/50] Step 100/520 Loss 3.426 Prec@(1,5) (35.4%, 67.3%)\u001b[0m\n",
            "[2024-04-02 19:55:44] \u001b[32mTrain: [  5/50] Step 120/520 Loss 3.421 Prec@(1,5) (35.4%, 67.6%)\u001b[0m\n",
            "[2024-04-02 19:55:45] \u001b[32mTrain: [  5/50] Step 140/520 Loss 3.432 Prec@(1,5) (35.4%, 67.3%)\u001b[0m\n",
            "[2024-04-02 19:55:45] \u001b[32mTrain: [  5/50] Step 160/520 Loss 3.438 Prec@(1,5) (35.3%, 67.4%)\u001b[0m\n",
            "[2024-04-02 19:55:46] \u001b[32mTrain: [  5/50] Step 180/520 Loss 3.439 Prec@(1,5) (35.3%, 67.5%)\u001b[0m\n",
            "[2024-04-02 19:55:46] \u001b[32mTrain: [  5/50] Step 200/520 Loss 3.435 Prec@(1,5) (35.3%, 67.6%)\u001b[0m\n",
            "[2024-04-02 19:55:47] \u001b[32mTrain: [  5/50] Step 220/520 Loss 3.430 Prec@(1,5) (35.3%, 67.7%)\u001b[0m\n",
            "[2024-04-02 19:55:47] \u001b[32mTrain: [  5/50] Step 240/520 Loss 3.425 Prec@(1,5) (35.5%, 67.8%)\u001b[0m\n",
            "[2024-04-02 19:55:48] \u001b[32mTrain: [  5/50] Step 260/520 Loss 3.425 Prec@(1,5) (35.6%, 67.8%)\u001b[0m\n",
            "[2024-04-02 19:55:48] \u001b[32mTrain: [  5/50] Step 280/520 Loss 3.426 Prec@(1,5) (35.6%, 67.9%)\u001b[0m\n",
            "[2024-04-02 19:55:49] \u001b[32mTrain: [  5/50] Step 300/520 Loss 3.421 Prec@(1,5) (35.6%, 67.9%)\u001b[0m\n",
            "[2024-04-02 19:55:49] \u001b[32mTrain: [  5/50] Step 320/520 Loss 3.423 Prec@(1,5) (35.6%, 67.9%)\u001b[0m\n",
            "[2024-04-02 19:55:50] \u001b[32mTrain: [  5/50] Step 340/520 Loss 3.412 Prec@(1,5) (35.8%, 67.9%)\u001b[0m\n",
            "[2024-04-02 19:55:50] \u001b[32mTrain: [  5/50] Step 360/520 Loss 3.413 Prec@(1,5) (35.7%, 67.9%)\u001b[0m\n",
            "[2024-04-02 19:55:51] \u001b[32mTrain: [  5/50] Step 380/520 Loss 3.410 Prec@(1,5) (35.8%, 68.0%)\u001b[0m\n",
            "[2024-04-02 19:55:51] \u001b[32mTrain: [  5/50] Step 400/520 Loss 3.409 Prec@(1,5) (35.8%, 68.1%)\u001b[0m\n",
            "[2024-04-02 19:55:52] \u001b[32mTrain: [  5/50] Step 420/520 Loss 3.404 Prec@(1,5) (35.9%, 68.1%)\u001b[0m\n",
            "[2024-04-02 19:55:52] \u001b[32mTrain: [  5/50] Step 440/520 Loss 3.404 Prec@(1,5) (35.9%, 68.1%)\u001b[0m\n",
            "[2024-04-02 19:55:53] \u001b[32mTrain: [  5/50] Step 460/520 Loss 3.398 Prec@(1,5) (36.0%, 68.2%)\u001b[0m\n",
            "[2024-04-02 19:55:53] \u001b[32mTrain: [  5/50] Step 480/520 Loss 3.394 Prec@(1,5) (36.1%, 68.3%)\u001b[0m\n",
            "[2024-04-02 19:55:54] \u001b[32mTrain: [  5/50] Step 500/520 Loss 3.388 Prec@(1,5) (36.2%, 68.4%)\u001b[0m\n",
            "[2024-04-02 19:55:54] \u001b[32mTrain: [  5/50] Step 520/520 Loss 3.388 Prec@(1,5) (36.1%, 68.4%)\u001b[0m\n",
            "[2024-04-02 19:55:54] \u001b[32mTrain: [  5/50] Final Prec@1 36.1460%\u001b[0m\n",
            "[2024-04-02 19:55:58] \u001b[32mValid: [  5/50] Step 000/104 Loss 3.476 Prec@(1,5) (40.6%, 65.6%)\u001b[0m\n",
            "[2024-04-02 19:55:58] \u001b[32mValid: [  5/50] Step 020/104 Loss 3.680 Prec@(1,5) (33.0%, 64.4%)\u001b[0m\n",
            "[2024-04-02 19:55:58] \u001b[32mValid: [  5/50] Step 040/104 Loss 3.611 Prec@(1,5) (33.1%, 64.4%)\u001b[0m\n",
            "[2024-04-02 19:55:58] \u001b[32mValid: [  5/50] Step 060/104 Loss 3.576 Prec@(1,5) (33.6%, 64.7%)\u001b[0m\n",
            "[2024-04-02 19:55:58] \u001b[32mValid: [  5/50] Step 080/104 Loss 3.576 Prec@(1,5) (33.3%, 64.4%)\u001b[0m\n",
            "[2024-04-02 19:55:59] \u001b[32mValid: [  5/50] Step 100/104 Loss 3.579 Prec@(1,5) (33.6%, 64.4%)\u001b[0m\n",
            "[2024-04-02 19:55:59] \u001b[32mValid: [  5/50] Step 104/104 Loss 3.577 Prec@(1,5) (33.5%, 64.3%)\u001b[0m\n",
            "[2024-04-02 19:55:59] \u001b[32mValid: [  5/50] Final Prec@1 33.4700%\u001b[0m\n",
            "[2024-04-02 19:55:59] \u001b[32mEpoch 5 LR 0.024388\u001b[0m\n",
            "[2024-04-02 19:56:03] \u001b[32mTrain: [  6/50] Step 000/520 Loss 3.534 Prec@(1,5) (38.5%, 62.5%)\u001b[0m\n",
            "[2024-04-02 19:56:04] \u001b[32mTrain: [  6/50] Step 020/520 Loss 3.222 Prec@(1,5) (38.3%, 70.3%)\u001b[0m\n",
            "[2024-04-02 19:56:04] \u001b[32mTrain: [  6/50] Step 040/520 Loss 3.239 Prec@(1,5) (37.9%, 70.5%)\u001b[0m\n",
            "[2024-04-02 19:56:05] \u001b[32mTrain: [  6/50] Step 060/520 Loss 3.228 Prec@(1,5) (38.2%, 70.7%)\u001b[0m\n",
            "[2024-04-02 19:56:05] \u001b[32mTrain: [  6/50] Step 080/520 Loss 3.231 Prec@(1,5) (38.3%, 70.9%)\u001b[0m\n",
            "[2024-04-02 19:56:06] \u001b[32mTrain: [  6/50] Step 100/520 Loss 3.237 Prec@(1,5) (38.3%, 70.7%)\u001b[0m\n",
            "[2024-04-02 19:56:06] \u001b[32mTrain: [  6/50] Step 120/520 Loss 3.223 Prec@(1,5) (38.5%, 71.0%)\u001b[0m\n",
            "[2024-04-02 19:56:07] \u001b[32mTrain: [  6/50] Step 140/520 Loss 3.224 Prec@(1,5) (38.6%, 71.1%)\u001b[0m\n",
            "[2024-04-02 19:56:07] \u001b[32mTrain: [  6/50] Step 160/520 Loss 3.234 Prec@(1,5) (38.4%, 70.8%)\u001b[0m\n",
            "[2024-04-02 19:56:08] \u001b[32mTrain: [  6/50] Step 180/520 Loss 3.233 Prec@(1,5) (38.4%, 70.8%)\u001b[0m\n",
            "[2024-04-02 19:56:08] \u001b[32mTrain: [  6/50] Step 200/520 Loss 3.228 Prec@(1,5) (38.6%, 70.9%)\u001b[0m\n",
            "[2024-04-02 19:56:09] \u001b[32mTrain: [  6/50] Step 220/520 Loss 3.236 Prec@(1,5) (38.6%, 70.7%)\u001b[0m\n",
            "[2024-04-02 19:56:09] \u001b[32mTrain: [  6/50] Step 240/520 Loss 3.229 Prec@(1,5) (38.7%, 70.7%)\u001b[0m\n",
            "[2024-04-02 19:56:10] \u001b[32mTrain: [  6/50] Step 260/520 Loss 3.227 Prec@(1,5) (38.7%, 70.7%)\u001b[0m\n",
            "[2024-04-02 19:56:10] \u001b[32mTrain: [  6/50] Step 280/520 Loss 3.227 Prec@(1,5) (38.7%, 70.7%)\u001b[0m\n",
            "[2024-04-02 19:56:11] \u001b[32mTrain: [  6/50] Step 300/520 Loss 3.230 Prec@(1,5) (38.7%, 70.7%)\u001b[0m\n",
            "[2024-04-02 19:56:11] \u001b[32mTrain: [  6/50] Step 320/520 Loss 3.238 Prec@(1,5) (38.6%, 70.5%)\u001b[0m\n",
            "[2024-04-02 19:56:12] \u001b[32mTrain: [  6/50] Step 340/520 Loss 3.238 Prec@(1,5) (38.5%, 70.5%)\u001b[0m\n",
            "[2024-04-02 19:56:12] \u001b[32mTrain: [  6/50] Step 360/520 Loss 3.231 Prec@(1,5) (38.6%, 70.6%)\u001b[0m\n",
            "[2024-04-02 19:56:13] \u001b[32mTrain: [  6/50] Step 380/520 Loss 3.226 Prec@(1,5) (38.6%, 70.8%)\u001b[0m\n",
            "[2024-04-02 19:56:13] \u001b[32mTrain: [  6/50] Step 400/520 Loss 3.223 Prec@(1,5) (38.7%, 70.8%)\u001b[0m\n",
            "[2024-04-02 19:56:14] \u001b[32mTrain: [  6/50] Step 420/520 Loss 3.217 Prec@(1,5) (38.8%, 70.8%)\u001b[0m\n",
            "[2024-04-02 19:56:14] \u001b[32mTrain: [  6/50] Step 440/520 Loss 3.220 Prec@(1,5) (38.8%, 70.8%)\u001b[0m\n",
            "[2024-04-02 19:56:15] \u001b[32mTrain: [  6/50] Step 460/520 Loss 3.220 Prec@(1,5) (38.7%, 70.8%)\u001b[0m\n",
            "[2024-04-02 19:56:15] \u001b[32mTrain: [  6/50] Step 480/520 Loss 3.220 Prec@(1,5) (38.7%, 70.9%)\u001b[0m\n",
            "[2024-04-02 19:56:16] \u001b[32mTrain: [  6/50] Step 500/520 Loss 3.218 Prec@(1,5) (38.7%, 70.9%)\u001b[0m\n",
            "[2024-04-02 19:56:16] \u001b[32mTrain: [  6/50] Step 520/520 Loss 3.218 Prec@(1,5) (38.7%, 70.9%)\u001b[0m\n",
            "[2024-04-02 19:56:17] \u001b[32mTrain: [  6/50] Final Prec@1 38.7400%\u001b[0m\n",
            "[2024-04-02 19:56:20] \u001b[32mValid: [  6/50] Step 000/104 Loss 2.916 Prec@(1,5) (49.0%, 70.8%)\u001b[0m\n",
            "[2024-04-02 19:56:20] \u001b[32mValid: [  6/50] Step 020/104 Loss 3.309 Prec@(1,5) (38.0%, 69.0%)\u001b[0m\n",
            "[2024-04-02 19:56:20] \u001b[32mValid: [  6/50] Step 040/104 Loss 3.300 Prec@(1,5) (37.0%, 68.7%)\u001b[0m\n",
            "[2024-04-02 19:56:21] \u001b[32mValid: [  6/50] Step 060/104 Loss 3.250 Prec@(1,5) (37.6%, 69.4%)\u001b[0m\n",
            "[2024-04-02 19:56:21] \u001b[32mValid: [  6/50] Step 080/104 Loss 3.250 Prec@(1,5) (37.2%, 69.3%)\u001b[0m\n",
            "[2024-04-02 19:56:21] \u001b[32mValid: [  6/50] Step 100/104 Loss 3.242 Prec@(1,5) (37.1%, 69.4%)\u001b[0m\n",
            "[2024-04-02 19:56:21] \u001b[32mValid: [  6/50] Step 104/104 Loss 3.240 Prec@(1,5) (37.1%, 69.5%)\u001b[0m\n",
            "[2024-04-02 19:56:21] \u001b[32mValid: [  6/50] Final Prec@1 37.1400%\u001b[0m\n",
            "[2024-04-02 19:56:21] \u001b[32mEpoch 6 LR 0.024122\u001b[0m\n",
            "[2024-04-02 19:56:26] \u001b[32mTrain: [  7/50] Step 000/520 Loss 3.137 Prec@(1,5) (35.4%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:56:26] \u001b[32mTrain: [  7/50] Step 020/520 Loss 3.087 Prec@(1,5) (40.8%, 73.4%)\u001b[0m\n",
            "[2024-04-02 19:56:27] \u001b[32mTrain: [  7/50] Step 040/520 Loss 3.041 Prec@(1,5) (41.4%, 73.4%)\u001b[0m\n",
            "[2024-04-02 19:56:27] \u001b[32mTrain: [  7/50] Step 060/520 Loss 3.072 Prec@(1,5) (41.3%, 73.0%)\u001b[0m\n",
            "[2024-04-02 19:56:28] \u001b[32mTrain: [  7/50] Step 080/520 Loss 3.050 Prec@(1,5) (41.5%, 73.2%)\u001b[0m\n",
            "[2024-04-02 19:56:28] \u001b[32mTrain: [  7/50] Step 100/520 Loss 3.052 Prec@(1,5) (41.5%, 73.0%)\u001b[0m\n",
            "[2024-04-02 19:56:29] \u001b[32mTrain: [  7/50] Step 120/520 Loss 3.053 Prec@(1,5) (41.4%, 73.1%)\u001b[0m\n",
            "[2024-04-02 19:56:29] \u001b[32mTrain: [  7/50] Step 140/520 Loss 3.054 Prec@(1,5) (41.2%, 73.3%)\u001b[0m\n",
            "[2024-04-02 19:56:30] \u001b[32mTrain: [  7/50] Step 160/520 Loss 3.067 Prec@(1,5) (41.0%, 73.0%)\u001b[0m\n",
            "[2024-04-02 19:56:30] \u001b[32mTrain: [  7/50] Step 180/520 Loss 3.067 Prec@(1,5) (41.0%, 73.1%)\u001b[0m\n",
            "[2024-04-02 19:56:31] \u001b[32mTrain: [  7/50] Step 200/520 Loss 3.067 Prec@(1,5) (41.0%, 73.0%)\u001b[0m\n",
            "[2024-04-02 19:56:31] \u001b[32mTrain: [  7/50] Step 220/520 Loss 3.067 Prec@(1,5) (41.0%, 73.0%)\u001b[0m\n",
            "[2024-04-02 19:56:32] \u001b[32mTrain: [  7/50] Step 240/520 Loss 3.070 Prec@(1,5) (41.0%, 73.0%)\u001b[0m\n",
            "[2024-04-02 19:56:32] \u001b[32mTrain: [  7/50] Step 260/520 Loss 3.067 Prec@(1,5) (41.0%, 73.0%)\u001b[0m\n",
            "[2024-04-02 19:56:33] \u001b[32mTrain: [  7/50] Step 280/520 Loss 3.063 Prec@(1,5) (41.1%, 73.1%)\u001b[0m\n",
            "[2024-04-02 19:56:33] \u001b[32mTrain: [  7/50] Step 300/520 Loss 3.070 Prec@(1,5) (41.0%, 73.0%)\u001b[0m\n",
            "[2024-04-02 19:56:34] \u001b[32mTrain: [  7/50] Step 320/520 Loss 3.069 Prec@(1,5) (41.1%, 73.0%)\u001b[0m\n",
            "[2024-04-02 19:56:34] \u001b[32mTrain: [  7/50] Step 340/520 Loss 3.070 Prec@(1,5) (41.1%, 73.0%)\u001b[0m\n",
            "[2024-04-02 19:56:35] \u001b[32mTrain: [  7/50] Step 360/520 Loss 3.072 Prec@(1,5) (41.1%, 73.0%)\u001b[0m\n",
            "[2024-04-02 19:56:35] \u001b[32mTrain: [  7/50] Step 380/520 Loss 3.071 Prec@(1,5) (41.1%, 73.0%)\u001b[0m\n",
            "[2024-04-02 19:56:36] \u001b[32mTrain: [  7/50] Step 400/520 Loss 3.070 Prec@(1,5) (41.1%, 73.1%)\u001b[0m\n",
            "[2024-04-02 19:56:36] \u001b[32mTrain: [  7/50] Step 420/520 Loss 3.071 Prec@(1,5) (41.1%, 73.0%)\u001b[0m\n",
            "[2024-04-02 19:56:37] \u001b[32mTrain: [  7/50] Step 440/520 Loss 3.072 Prec@(1,5) (41.1%, 73.0%)\u001b[0m\n",
            "[2024-04-02 19:56:37] \u001b[32mTrain: [  7/50] Step 460/520 Loss 3.070 Prec@(1,5) (41.1%, 73.1%)\u001b[0m\n",
            "[2024-04-02 19:56:38] \u001b[32mTrain: [  7/50] Step 480/520 Loss 3.072 Prec@(1,5) (41.2%, 73.0%)\u001b[0m\n",
            "[2024-04-02 19:56:38] \u001b[32mTrain: [  7/50] Step 500/520 Loss 3.071 Prec@(1,5) (41.2%, 73.0%)\u001b[0m\n",
            "[2024-04-02 19:56:39] \u001b[32mTrain: [  7/50] Step 520/520 Loss 3.069 Prec@(1,5) (41.3%, 73.0%)\u001b[0m\n",
            "[2024-04-02 19:56:39] \u001b[32mTrain: [  7/50] Final Prec@1 41.2520%\u001b[0m\n",
            "[2024-04-02 19:56:42] \u001b[32mValid: [  7/50] Step 000/104 Loss 3.062 Prec@(1,5) (42.7%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:56:43] \u001b[32mValid: [  7/50] Step 020/104 Loss 3.115 Prec@(1,5) (39.7%, 71.6%)\u001b[0m\n",
            "[2024-04-02 19:56:43] \u001b[32mValid: [  7/50] Step 040/104 Loss 3.066 Prec@(1,5) (40.2%, 71.3%)\u001b[0m\n",
            "[2024-04-02 19:56:43] \u001b[32mValid: [  7/50] Step 060/104 Loss 3.042 Prec@(1,5) (40.5%, 71.4%)\u001b[0m\n",
            "[2024-04-02 19:56:43] \u001b[32mValid: [  7/50] Step 080/104 Loss 3.028 Prec@(1,5) (40.2%, 71.9%)\u001b[0m\n",
            "[2024-04-02 19:56:43] \u001b[32mValid: [  7/50] Step 100/104 Loss 3.008 Prec@(1,5) (40.4%, 71.9%)\u001b[0m\n",
            "[2024-04-02 19:56:43] \u001b[32mValid: [  7/50] Step 104/104 Loss 3.002 Prec@(1,5) (40.5%, 72.0%)\u001b[0m\n",
            "[2024-04-02 19:56:44] \u001b[32mValid: [  7/50] Final Prec@1 40.4500%\u001b[0m\n",
            "[2024-04-02 19:56:44] \u001b[32mEpoch 7 LR 0.023810\u001b[0m\n",
            "[2024-04-02 19:56:48] \u001b[32mTrain: [  8/50] Step 000/520 Loss 2.989 Prec@(1,5) (47.9%, 76.0%)\u001b[0m\n",
            "[2024-04-02 19:56:49] \u001b[32mTrain: [  8/50] Step 020/520 Loss 2.969 Prec@(1,5) (44.0%, 74.1%)\u001b[0m\n",
            "[2024-04-02 19:56:49] \u001b[32mTrain: [  8/50] Step 040/520 Loss 2.941 Prec@(1,5) (43.9%, 75.4%)\u001b[0m\n",
            "[2024-04-02 19:56:50] \u001b[32mTrain: [  8/50] Step 060/520 Loss 2.921 Prec@(1,5) (44.0%, 75.6%)\u001b[0m\n",
            "[2024-04-02 19:56:50] \u001b[32mTrain: [  8/50] Step 080/520 Loss 2.948 Prec@(1,5) (43.7%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:56:51] \u001b[32mTrain: [  8/50] Step 100/520 Loss 2.936 Prec@(1,5) (43.8%, 75.2%)\u001b[0m\n",
            "[2024-04-02 19:56:51] \u001b[32mTrain: [  8/50] Step 120/520 Loss 2.931 Prec@(1,5) (43.9%, 75.2%)\u001b[0m\n",
            "[2024-04-02 19:56:52] \u001b[32mTrain: [  8/50] Step 140/520 Loss 2.937 Prec@(1,5) (43.5%, 75.1%)\u001b[0m\n",
            "[2024-04-02 19:56:52] \u001b[32mTrain: [  8/50] Step 160/520 Loss 2.937 Prec@(1,5) (43.6%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:56:53] \u001b[32mTrain: [  8/50] Step 180/520 Loss 2.942 Prec@(1,5) (43.5%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:56:53] \u001b[32mTrain: [  8/50] Step 200/520 Loss 2.947 Prec@(1,5) (43.4%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:56:54] \u001b[32mTrain: [  8/50] Step 220/520 Loss 2.951 Prec@(1,5) (43.3%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:56:54] \u001b[32mTrain: [  8/50] Step 240/520 Loss 2.947 Prec@(1,5) (43.3%, 75.2%)\u001b[0m\n",
            "[2024-04-02 19:56:55] \u001b[32mTrain: [  8/50] Step 260/520 Loss 2.951 Prec@(1,5) (43.1%, 75.2%)\u001b[0m\n",
            "[2024-04-02 19:56:55] \u001b[32mTrain: [  8/50] Step 280/520 Loss 2.958 Prec@(1,5) (43.1%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:56:56] \u001b[32mTrain: [  8/50] Step 300/520 Loss 2.958 Prec@(1,5) (43.0%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:56:56] \u001b[32mTrain: [  8/50] Step 320/520 Loss 2.958 Prec@(1,5) (43.1%, 74.9%)\u001b[0m\n",
            "[2024-04-02 19:56:57] \u001b[32mTrain: [  8/50] Step 340/520 Loss 2.956 Prec@(1,5) (43.2%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:56:57] \u001b[32mTrain: [  8/50] Step 360/520 Loss 2.956 Prec@(1,5) (43.2%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:56:58] \u001b[32mTrain: [  8/50] Step 380/520 Loss 2.953 Prec@(1,5) (43.3%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:56:58] \u001b[32mTrain: [  8/50] Step 400/520 Loss 2.952 Prec@(1,5) (43.3%, 75.1%)\u001b[0m\n",
            "[2024-04-02 19:56:59] \u001b[32mTrain: [  8/50] Step 420/520 Loss 2.951 Prec@(1,5) (43.3%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:57:00] \u001b[32mTrain: [  8/50] Step 440/520 Loss 2.950 Prec@(1,5) (43.3%, 75.1%)\u001b[0m\n",
            "[2024-04-02 19:57:00] \u001b[32mTrain: [  8/50] Step 460/520 Loss 2.949 Prec@(1,5) (43.3%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:57:01] \u001b[32mTrain: [  8/50] Step 480/520 Loss 2.951 Prec@(1,5) (43.2%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:57:01] \u001b[32mTrain: [  8/50] Step 500/520 Loss 2.954 Prec@(1,5) (43.2%, 74.9%)\u001b[0m\n",
            "[2024-04-02 19:57:02] \u001b[32mTrain: [  8/50] Step 520/520 Loss 2.954 Prec@(1,5) (43.2%, 74.9%)\u001b[0m\n",
            "[2024-04-02 19:57:02] \u001b[32mTrain: [  8/50] Final Prec@1 43.2460%\u001b[0m\n",
            "[2024-04-02 19:57:05] \u001b[32mValid: [  8/50] Step 000/104 Loss 3.119 Prec@(1,5) (44.8%, 72.9%)\u001b[0m\n",
            "[2024-04-02 19:57:05] \u001b[32mValid: [  8/50] Step 020/104 Loss 3.209 Prec@(1,5) (39.2%, 71.9%)\u001b[0m\n",
            "[2024-04-02 19:57:06] \u001b[32mValid: [  8/50] Step 040/104 Loss 3.164 Prec@(1,5) (39.5%, 72.1%)\u001b[0m\n",
            "[2024-04-02 19:57:06] \u001b[32mValid: [  8/50] Step 060/104 Loss 3.125 Prec@(1,5) (40.0%, 72.1%)\u001b[0m\n",
            "[2024-04-02 19:57:06] \u001b[32mValid: [  8/50] Step 080/104 Loss 3.121 Prec@(1,5) (39.8%, 72.2%)\u001b[0m\n",
            "[2024-04-02 19:57:06] \u001b[32mValid: [  8/50] Step 100/104 Loss 3.117 Prec@(1,5) (40.0%, 72.2%)\u001b[0m\n",
            "[2024-04-02 19:57:06] \u001b[32mValid: [  8/50] Step 104/104 Loss 3.123 Prec@(1,5) (39.9%, 72.1%)\u001b[0m\n",
            "[2024-04-02 19:57:06] \u001b[32mValid: [  8/50] Final Prec@1 39.8800%\u001b[0m\n",
            "[2024-04-02 19:57:06] \u001b[32mEpoch 8 LR 0.023454\u001b[0m\n",
            "[2024-04-02 19:57:11] \u001b[32mTrain: [  9/50] Step 000/520 Loss 3.233 Prec@(1,5) (41.7%, 69.8%)\u001b[0m\n",
            "[2024-04-02 19:57:11] \u001b[32mTrain: [  9/50] Step 020/520 Loss 2.773 Prec@(1,5) (45.0%, 75.8%)\u001b[0m\n",
            "[2024-04-02 19:57:12] \u001b[32mTrain: [  9/50] Step 040/520 Loss 2.836 Prec@(1,5) (44.3%, 75.4%)\u001b[0m\n",
            "[2024-04-02 19:57:12] \u001b[32mTrain: [  9/50] Step 060/520 Loss 2.844 Prec@(1,5) (44.9%, 75.6%)\u001b[0m\n",
            "[2024-04-02 19:57:13] \u001b[32mTrain: [  9/50] Step 080/520 Loss 2.855 Prec@(1,5) (44.4%, 75.4%)\u001b[0m\n",
            "[2024-04-02 19:57:13] \u001b[32mTrain: [  9/50] Step 100/520 Loss 2.861 Prec@(1,5) (44.5%, 75.3%)\u001b[0m\n",
            "[2024-04-02 19:57:14] \u001b[32mTrain: [  9/50] Step 120/520 Loss 2.861 Prec@(1,5) (44.5%, 75.4%)\u001b[0m\n",
            "[2024-04-02 19:57:14] \u001b[32mTrain: [  9/50] Step 140/520 Loss 2.854 Prec@(1,5) (44.7%, 75.7%)\u001b[0m\n",
            "[2024-04-02 19:57:15] \u001b[32mTrain: [  9/50] Step 160/520 Loss 2.852 Prec@(1,5) (44.7%, 75.7%)\u001b[0m\n",
            "[2024-04-02 19:57:15] \u001b[32mTrain: [  9/50] Step 180/520 Loss 2.851 Prec@(1,5) (44.5%, 75.8%)\u001b[0m\n",
            "[2024-04-02 19:57:16] \u001b[32mTrain: [  9/50] Step 200/520 Loss 2.863 Prec@(1,5) (44.3%, 75.6%)\u001b[0m\n",
            "[2024-04-02 19:57:16] \u001b[32mTrain: [  9/50] Step 220/520 Loss 2.860 Prec@(1,5) (44.4%, 75.7%)\u001b[0m\n",
            "[2024-04-02 19:57:17] \u001b[32mTrain: [  9/50] Step 240/520 Loss 2.861 Prec@(1,5) (44.4%, 75.7%)\u001b[0m\n",
            "[2024-04-02 19:57:17] \u001b[32mTrain: [  9/50] Step 260/520 Loss 2.854 Prec@(1,5) (44.5%, 75.8%)\u001b[0m\n",
            "[2024-04-02 19:57:18] \u001b[32mTrain: [  9/50] Step 280/520 Loss 2.856 Prec@(1,5) (44.5%, 75.9%)\u001b[0m\n",
            "[2024-04-02 19:57:18] \u001b[32mTrain: [  9/50] Step 300/520 Loss 2.858 Prec@(1,5) (44.5%, 75.9%)\u001b[0m\n",
            "[2024-04-02 19:57:19] \u001b[32mTrain: [  9/50] Step 320/520 Loss 2.862 Prec@(1,5) (44.4%, 75.8%)\u001b[0m\n",
            "[2024-04-02 19:57:19] \u001b[32mTrain: [  9/50] Step 340/520 Loss 2.861 Prec@(1,5) (44.4%, 75.8%)\u001b[0m\n",
            "[2024-04-02 19:57:20] \u001b[32mTrain: [  9/50] Step 360/520 Loss 2.857 Prec@(1,5) (44.5%, 75.9%)\u001b[0m\n",
            "[2024-04-02 19:57:20] \u001b[32mTrain: [  9/50] Step 380/520 Loss 2.855 Prec@(1,5) (44.6%, 75.9%)\u001b[0m\n",
            "[2024-04-02 19:57:21] \u001b[32mTrain: [  9/50] Step 400/520 Loss 2.853 Prec@(1,5) (44.7%, 75.9%)\u001b[0m\n",
            "[2024-04-02 19:57:21] \u001b[32mTrain: [  9/50] Step 420/520 Loss 2.850 Prec@(1,5) (44.8%, 76.0%)\u001b[0m\n",
            "[2024-04-02 19:57:22] \u001b[32mTrain: [  9/50] Step 440/520 Loss 2.848 Prec@(1,5) (44.9%, 76.0%)\u001b[0m\n",
            "[2024-04-02 19:57:22] \u001b[32mTrain: [  9/50] Step 460/520 Loss 2.847 Prec@(1,5) (44.9%, 76.0%)\u001b[0m\n",
            "[2024-04-02 19:57:23] \u001b[32mTrain: [  9/50] Step 480/520 Loss 2.848 Prec@(1,5) (44.9%, 75.9%)\u001b[0m\n",
            "[2024-04-02 19:57:23] \u001b[32mTrain: [  9/50] Step 500/520 Loss 2.848 Prec@(1,5) (44.9%, 76.0%)\u001b[0m\n",
            "[2024-04-02 19:57:24] \u001b[32mTrain: [  9/50] Step 520/520 Loss 2.845 Prec@(1,5) (44.9%, 76.1%)\u001b[0m\n",
            "[2024-04-02 19:57:24] \u001b[32mTrain: [  9/50] Final Prec@1 44.9140%\u001b[0m\n",
            "[2024-04-02 19:57:27] \u001b[32mValid: [  9/50] Step 000/104 Loss 2.701 Prec@(1,5) (49.0%, 76.0%)\u001b[0m\n",
            "[2024-04-02 19:57:28] \u001b[32mValid: [  9/50] Step 020/104 Loss 2.938 Prec@(1,5) (43.1%, 75.1%)\u001b[0m\n",
            "[2024-04-02 19:57:28] \u001b[32mValid: [  9/50] Step 040/104 Loss 2.918 Prec@(1,5) (42.9%, 75.2%)\u001b[0m\n",
            "[2024-04-02 19:57:28] \u001b[32mValid: [  9/50] Step 060/104 Loss 2.872 Prec@(1,5) (43.2%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:57:28] \u001b[32mValid: [  9/50] Step 080/104 Loss 2.874 Prec@(1,5) (42.5%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:57:28] \u001b[32mValid: [  9/50] Step 100/104 Loss 2.877 Prec@(1,5) (42.6%, 74.9%)\u001b[0m\n",
            "[2024-04-02 19:57:28] \u001b[32mValid: [  9/50] Step 104/104 Loss 2.877 Prec@(1,5) (42.6%, 74.9%)\u001b[0m\n",
            "[2024-04-02 19:57:29] \u001b[32mValid: [  9/50] Final Prec@1 42.6300%\u001b[0m\n",
            "[2024-04-02 19:57:29] \u001b[32mEpoch 9 LR 0.023054\u001b[0m\n",
            "[2024-04-02 19:57:33] \u001b[32mTrain: [ 10/50] Step 000/520 Loss 2.561 Prec@(1,5) (49.0%, 80.2%)\u001b[0m\n",
            "[2024-04-02 19:57:34] \u001b[32mTrain: [ 10/50] Step 020/520 Loss 2.695 Prec@(1,5) (47.0%, 78.2%)\u001b[0m\n",
            "[2024-04-02 19:57:34] \u001b[32mTrain: [ 10/50] Step 040/520 Loss 2.779 Prec@(1,5) (45.4%, 77.0%)\u001b[0m\n",
            "[2024-04-02 19:57:35] \u001b[32mTrain: [ 10/50] Step 060/520 Loss 2.788 Prec@(1,5) (45.4%, 76.6%)\u001b[0m\n",
            "[2024-04-02 19:57:35] \u001b[32mTrain: [ 10/50] Step 080/520 Loss 2.785 Prec@(1,5) (45.5%, 76.7%)\u001b[0m\n",
            "[2024-04-02 19:57:36] \u001b[32mTrain: [ 10/50] Step 100/520 Loss 2.774 Prec@(1,5) (45.4%, 77.0%)\u001b[0m\n",
            "[2024-04-02 19:57:36] \u001b[32mTrain: [ 10/50] Step 120/520 Loss 2.761 Prec@(1,5) (45.5%, 77.2%)\u001b[0m\n",
            "[2024-04-02 19:57:37] \u001b[32mTrain: [ 10/50] Step 140/520 Loss 2.762 Prec@(1,5) (45.7%, 77.3%)\u001b[0m\n",
            "[2024-04-02 19:57:37] \u001b[32mTrain: [ 10/50] Step 160/520 Loss 2.766 Prec@(1,5) (45.8%, 77.2%)\u001b[0m\n",
            "[2024-04-02 19:57:38] \u001b[32mTrain: [ 10/50] Step 180/520 Loss 2.761 Prec@(1,5) (45.9%, 77.3%)\u001b[0m\n",
            "[2024-04-02 19:57:38] \u001b[32mTrain: [ 10/50] Step 200/520 Loss 2.759 Prec@(1,5) (45.8%, 77.4%)\u001b[0m\n",
            "[2024-04-02 19:57:39] \u001b[32mTrain: [ 10/50] Step 220/520 Loss 2.753 Prec@(1,5) (45.9%, 77.5%)\u001b[0m\n",
            "[2024-04-02 19:57:39] \u001b[32mTrain: [ 10/50] Step 240/520 Loss 2.754 Prec@(1,5) (46.0%, 77.4%)\u001b[0m\n",
            "[2024-04-02 19:57:40] \u001b[32mTrain: [ 10/50] Step 260/520 Loss 2.759 Prec@(1,5) (46.0%, 77.3%)\u001b[0m\n",
            "[2024-04-02 19:57:40] \u001b[32mTrain: [ 10/50] Step 280/520 Loss 2.755 Prec@(1,5) (46.0%, 77.4%)\u001b[0m\n",
            "[2024-04-02 19:57:41] \u001b[32mTrain: [ 10/50] Step 300/520 Loss 2.755 Prec@(1,5) (46.0%, 77.5%)\u001b[0m\n",
            "[2024-04-02 19:57:41] \u001b[32mTrain: [ 10/50] Step 320/520 Loss 2.759 Prec@(1,5) (46.0%, 77.5%)\u001b[0m\n",
            "[2024-04-02 19:57:42] \u001b[32mTrain: [ 10/50] Step 340/520 Loss 2.759 Prec@(1,5) (46.0%, 77.5%)\u001b[0m\n",
            "[2024-04-02 19:57:42] \u001b[32mTrain: [ 10/50] Step 360/520 Loss 2.759 Prec@(1,5) (46.0%, 77.4%)\u001b[0m\n",
            "[2024-04-02 19:57:43] \u001b[32mTrain: [ 10/50] Step 380/520 Loss 2.757 Prec@(1,5) (46.1%, 77.4%)\u001b[0m\n",
            "[2024-04-02 19:57:43] \u001b[32mTrain: [ 10/50] Step 400/520 Loss 2.759 Prec@(1,5) (46.0%, 77.4%)\u001b[0m\n",
            "[2024-04-02 19:57:44] \u001b[32mTrain: [ 10/50] Step 420/520 Loss 2.758 Prec@(1,5) (46.2%, 77.4%)\u001b[0m\n",
            "[2024-04-02 19:57:44] \u001b[32mTrain: [ 10/50] Step 440/520 Loss 2.762 Prec@(1,5) (46.2%, 77.3%)\u001b[0m\n",
            "[2024-04-02 19:57:45] \u001b[32mTrain: [ 10/50] Step 460/520 Loss 2.762 Prec@(1,5) (46.1%, 77.3%)\u001b[0m\n",
            "[2024-04-02 19:57:45] \u001b[32mTrain: [ 10/50] Step 480/520 Loss 2.762 Prec@(1,5) (46.2%, 77.3%)\u001b[0m\n",
            "[2024-04-02 19:57:46] \u001b[32mTrain: [ 10/50] Step 500/520 Loss 2.762 Prec@(1,5) (46.2%, 77.3%)\u001b[0m\n",
            "[2024-04-02 19:57:46] \u001b[32mTrain: [ 10/50] Step 520/520 Loss 2.766 Prec@(1,5) (46.2%, 77.2%)\u001b[0m\n",
            "[2024-04-02 19:57:46] \u001b[32mTrain: [ 10/50] Final Prec@1 46.1680%\u001b[0m\n",
            "[2024-04-02 19:57:50] \u001b[32mValid: [ 10/50] Step 000/104 Loss 3.096 Prec@(1,5) (49.0%, 69.8%)\u001b[0m\n",
            "[2024-04-02 19:57:50] \u001b[32mValid: [ 10/50] Step 020/104 Loss 2.980 Prec@(1,5) (43.8%, 73.2%)\u001b[0m\n",
            "[2024-04-02 19:57:50] \u001b[32mValid: [ 10/50] Step 040/104 Loss 2.996 Prec@(1,5) (42.7%, 73.0%)\u001b[0m\n",
            "[2024-04-02 19:57:50] \u001b[32mValid: [ 10/50] Step 060/104 Loss 2.955 Prec@(1,5) (43.2%, 73.3%)\u001b[0m\n",
            "[2024-04-02 19:57:51] \u001b[32mValid: [ 10/50] Step 080/104 Loss 2.967 Prec@(1,5) (42.5%, 73.4%)\u001b[0m\n",
            "[2024-04-02 19:57:51] \u001b[32mValid: [ 10/50] Step 100/104 Loss 2.974 Prec@(1,5) (42.3%, 73.3%)\u001b[0m\n",
            "[2024-04-02 19:57:51] \u001b[32mValid: [ 10/50] Step 104/104 Loss 2.975 Prec@(1,5) (42.3%, 73.3%)\u001b[0m\n",
            "[2024-04-02 19:57:51] \u001b[32mValid: [ 10/50] Final Prec@1 42.3100%\u001b[0m\n",
            "[2024-04-02 19:57:51] \u001b[32mEpoch 10 LR 0.022613\u001b[0m\n",
            "[2024-04-02 19:57:56] \u001b[32mTrain: [ 11/50] Step 000/520 Loss 2.241 Prec@(1,5) (50.0%, 86.5%)\u001b[0m\n",
            "[2024-04-02 19:57:56] \u001b[32mTrain: [ 11/50] Step 020/520 Loss 2.584 Prec@(1,5) (49.2%, 79.7%)\u001b[0m\n",
            "[2024-04-02 19:57:57] \u001b[32mTrain: [ 11/50] Step 040/520 Loss 2.663 Prec@(1,5) (47.6%, 78.7%)\u001b[0m\n",
            "[2024-04-02 19:57:57] \u001b[32mTrain: [ 11/50] Step 060/520 Loss 2.686 Prec@(1,5) (47.4%, 78.2%)\u001b[0m\n",
            "[2024-04-02 19:57:58] \u001b[32mTrain: [ 11/50] Step 080/520 Loss 2.686 Prec@(1,5) (47.1%, 78.4%)\u001b[0m\n",
            "[2024-04-02 19:57:58] \u001b[32mTrain: [ 11/50] Step 100/520 Loss 2.707 Prec@(1,5) (46.7%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:57:59] \u001b[32mTrain: [ 11/50] Step 120/520 Loss 2.698 Prec@(1,5) (46.8%, 78.3%)\u001b[0m\n",
            "[2024-04-02 19:57:59] \u001b[32mTrain: [ 11/50] Step 140/520 Loss 2.704 Prec@(1,5) (46.8%, 78.2%)\u001b[0m\n",
            "[2024-04-02 19:58:00] \u001b[32mTrain: [ 11/50] Step 160/520 Loss 2.707 Prec@(1,5) (46.8%, 78.2%)\u001b[0m\n",
            "[2024-04-02 19:58:00] \u001b[32mTrain: [ 11/50] Step 180/520 Loss 2.707 Prec@(1,5) (46.9%, 78.2%)\u001b[0m\n",
            "[2024-04-02 19:58:01] \u001b[32mTrain: [ 11/50] Step 200/520 Loss 2.708 Prec@(1,5) (46.9%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:58:01] \u001b[32mTrain: [ 11/50] Step 220/520 Loss 2.705 Prec@(1,5) (47.0%, 78.2%)\u001b[0m\n",
            "[2024-04-02 19:58:02] \u001b[32mTrain: [ 11/50] Step 240/520 Loss 2.699 Prec@(1,5) (47.1%, 78.3%)\u001b[0m\n",
            "[2024-04-02 19:58:02] \u001b[32mTrain: [ 11/50] Step 260/520 Loss 2.703 Prec@(1,5) (47.1%, 78.2%)\u001b[0m\n",
            "[2024-04-02 19:58:03] \u001b[32mTrain: [ 11/50] Step 280/520 Loss 2.701 Prec@(1,5) (47.3%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:58:03] \u001b[32mTrain: [ 11/50] Step 300/520 Loss 2.699 Prec@(1,5) (47.4%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:58:04] \u001b[32mTrain: [ 11/50] Step 320/520 Loss 2.693 Prec@(1,5) (47.5%, 78.2%)\u001b[0m\n",
            "[2024-04-02 19:58:04] \u001b[32mTrain: [ 11/50] Step 340/520 Loss 2.695 Prec@(1,5) (47.4%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:58:05] \u001b[32mTrain: [ 11/50] Step 360/520 Loss 2.702 Prec@(1,5) (47.3%, 78.0%)\u001b[0m\n",
            "[2024-04-02 19:58:05] \u001b[32mTrain: [ 11/50] Step 380/520 Loss 2.701 Prec@(1,5) (47.4%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:58:06] \u001b[32mTrain: [ 11/50] Step 400/520 Loss 2.700 Prec@(1,5) (47.4%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:58:06] \u001b[32mTrain: [ 11/50] Step 420/520 Loss 2.701 Prec@(1,5) (47.5%, 78.0%)\u001b[0m\n",
            "[2024-04-02 19:58:07] \u001b[32mTrain: [ 11/50] Step 440/520 Loss 2.701 Prec@(1,5) (47.4%, 78.0%)\u001b[0m\n",
            "[2024-04-02 19:58:07] \u001b[32mTrain: [ 11/50] Step 460/520 Loss 2.698 Prec@(1,5) (47.5%, 78.0%)\u001b[0m\n",
            "[2024-04-02 19:58:08] \u001b[32mTrain: [ 11/50] Step 480/520 Loss 2.697 Prec@(1,5) (47.5%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:58:08] \u001b[32mTrain: [ 11/50] Step 500/520 Loss 2.698 Prec@(1,5) (47.5%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:58:09] \u001b[32mTrain: [ 11/50] Step 520/520 Loss 2.701 Prec@(1,5) (47.4%, 78.0%)\u001b[0m\n",
            "[2024-04-02 19:58:09] \u001b[32mTrain: [ 11/50] Final Prec@1 47.4220%\u001b[0m\n",
            "[2024-04-02 19:58:13] \u001b[32mValid: [ 11/50] Step 000/104 Loss 3.025 Prec@(1,5) (44.8%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:58:13] \u001b[32mValid: [ 11/50] Step 020/104 Loss 2.943 Prec@(1,5) (44.7%, 76.2%)\u001b[0m\n",
            "[2024-04-02 19:58:13] \u001b[32mValid: [ 11/50] Step 040/104 Loss 2.912 Prec@(1,5) (43.8%, 76.0%)\u001b[0m\n",
            "[2024-04-02 19:58:13] \u001b[32mValid: [ 11/50] Step 060/104 Loss 2.873 Prec@(1,5) (44.3%, 76.2%)\u001b[0m\n",
            "[2024-04-02 19:58:13] \u001b[32mValid: [ 11/50] Step 080/104 Loss 2.882 Prec@(1,5) (43.9%, 76.1%)\u001b[0m\n",
            "[2024-04-02 19:58:13] \u001b[32mValid: [ 11/50] Step 100/104 Loss 2.864 Prec@(1,5) (44.0%, 76.2%)\u001b[0m\n",
            "[2024-04-02 19:58:13] \u001b[32mValid: [ 11/50] Step 104/104 Loss 2.860 Prec@(1,5) (44.0%, 76.2%)\u001b[0m\n",
            "[2024-04-02 19:58:14] \u001b[32mValid: [ 11/50] Final Prec@1 43.9800%\u001b[0m\n",
            "[2024-04-02 19:58:14] \u001b[32mEpoch 11 LR 0.022132\u001b[0m\n",
            "[2024-04-02 19:58:18] \u001b[32mTrain: [ 12/50] Step 000/520 Loss 2.721 Prec@(1,5) (51.0%, 74.0%)\u001b[0m\n",
            "[2024-04-02 19:58:19] \u001b[32mTrain: [ 12/50] Step 020/520 Loss 2.672 Prec@(1,5) (46.5%, 78.6%)\u001b[0m\n",
            "[2024-04-02 19:58:19] \u001b[32mTrain: [ 12/50] Step 040/520 Loss 2.652 Prec@(1,5) (47.5%, 79.0%)\u001b[0m\n",
            "[2024-04-02 19:58:20] \u001b[32mTrain: [ 12/50] Step 060/520 Loss 2.663 Prec@(1,5) (47.5%, 78.8%)\u001b[0m\n",
            "[2024-04-02 19:58:20] \u001b[32mTrain: [ 12/50] Step 080/520 Loss 2.648 Prec@(1,5) (47.9%, 78.8%)\u001b[0m\n",
            "[2024-04-02 19:58:21] \u001b[32mTrain: [ 12/50] Step 100/520 Loss 2.636 Prec@(1,5) (48.2%, 79.0%)\u001b[0m\n",
            "[2024-04-02 19:58:21] \u001b[32mTrain: [ 12/50] Step 120/520 Loss 2.641 Prec@(1,5) (48.2%, 78.9%)\u001b[0m\n",
            "[2024-04-02 19:58:22] \u001b[32mTrain: [ 12/50] Step 140/520 Loss 2.637 Prec@(1,5) (48.2%, 79.0%)\u001b[0m\n",
            "[2024-04-02 19:58:22] \u001b[32mTrain: [ 12/50] Step 160/520 Loss 2.644 Prec@(1,5) (48.2%, 79.0%)\u001b[0m\n",
            "[2024-04-02 19:58:23] \u001b[32mTrain: [ 12/50] Step 180/520 Loss 2.639 Prec@(1,5) (48.1%, 79.1%)\u001b[0m\n",
            "[2024-04-02 19:58:23] \u001b[32mTrain: [ 12/50] Step 200/520 Loss 2.631 Prec@(1,5) (48.2%, 79.1%)\u001b[0m\n",
            "[2024-04-02 19:58:24] \u001b[32mTrain: [ 12/50] Step 220/520 Loss 2.629 Prec@(1,5) (48.3%, 79.1%)\u001b[0m\n",
            "[2024-04-02 19:58:24] \u001b[32mTrain: [ 12/50] Step 240/520 Loss 2.638 Prec@(1,5) (48.2%, 79.0%)\u001b[0m\n",
            "[2024-04-02 19:58:25] \u001b[32mTrain: [ 12/50] Step 260/520 Loss 2.637 Prec@(1,5) (48.1%, 79.0%)\u001b[0m\n",
            "[2024-04-02 19:58:25] \u001b[32mTrain: [ 12/50] Step 280/520 Loss 2.636 Prec@(1,5) (48.2%, 78.9%)\u001b[0m\n",
            "[2024-04-02 19:58:26] \u001b[32mTrain: [ 12/50] Step 300/520 Loss 2.639 Prec@(1,5) (48.1%, 78.9%)\u001b[0m\n",
            "[2024-04-02 19:58:26] \u001b[32mTrain: [ 12/50] Step 320/520 Loss 2.638 Prec@(1,5) (48.2%, 79.0%)\u001b[0m\n",
            "[2024-04-02 19:58:27] \u001b[32mTrain: [ 12/50] Step 340/520 Loss 2.640 Prec@(1,5) (48.2%, 78.9%)\u001b[0m\n",
            "[2024-04-02 19:58:27] \u001b[32mTrain: [ 12/50] Step 360/520 Loss 2.642 Prec@(1,5) (48.2%, 78.8%)\u001b[0m\n",
            "[2024-04-02 19:58:28] \u001b[32mTrain: [ 12/50] Step 380/520 Loss 2.641 Prec@(1,5) (48.3%, 78.8%)\u001b[0m\n",
            "[2024-04-02 19:58:28] \u001b[32mTrain: [ 12/50] Step 400/520 Loss 2.647 Prec@(1,5) (48.3%, 78.8%)\u001b[0m\n",
            "[2024-04-02 19:58:29] \u001b[32mTrain: [ 12/50] Step 420/520 Loss 2.647 Prec@(1,5) (48.3%, 78.7%)\u001b[0m\n",
            "[2024-04-02 19:58:29] \u001b[32mTrain: [ 12/50] Step 440/520 Loss 2.641 Prec@(1,5) (48.4%, 78.8%)\u001b[0m\n",
            "[2024-04-02 19:58:30] \u001b[32mTrain: [ 12/50] Step 460/520 Loss 2.644 Prec@(1,5) (48.4%, 78.8%)\u001b[0m\n",
            "[2024-04-02 19:58:30] \u001b[32mTrain: [ 12/50] Step 480/520 Loss 2.645 Prec@(1,5) (48.4%, 78.8%)\u001b[0m\n",
            "[2024-04-02 19:58:31] \u001b[32mTrain: [ 12/50] Step 500/520 Loss 2.644 Prec@(1,5) (48.4%, 78.8%)\u001b[0m\n",
            "[2024-04-02 19:58:31] \u001b[32mTrain: [ 12/50] Step 520/520 Loss 2.649 Prec@(1,5) (48.3%, 78.7%)\u001b[0m\n",
            "[2024-04-02 19:58:31] \u001b[32mTrain: [ 12/50] Final Prec@1 48.2940%\u001b[0m\n",
            "[2024-04-02 19:58:35] \u001b[32mValid: [ 12/50] Step 000/104 Loss 2.752 Prec@(1,5) (43.8%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:58:35] \u001b[32mValid: [ 12/50] Step 020/104 Loss 2.840 Prec@(1,5) (44.0%, 76.3%)\u001b[0m\n",
            "[2024-04-02 19:58:35] \u001b[32mValid: [ 12/50] Step 040/104 Loss 2.821 Prec@(1,5) (43.6%, 76.3%)\u001b[0m\n",
            "[2024-04-02 19:58:35] \u001b[32mValid: [ 12/50] Step 060/104 Loss 2.797 Prec@(1,5) (43.7%, 76.6%)\u001b[0m\n",
            "[2024-04-02 19:58:35] \u001b[32mValid: [ 12/50] Step 080/104 Loss 2.798 Prec@(1,5) (43.8%, 76.7%)\u001b[0m\n",
            "[2024-04-02 19:58:36] \u001b[32mValid: [ 12/50] Step 100/104 Loss 2.786 Prec@(1,5) (43.9%, 76.7%)\u001b[0m\n",
            "[2024-04-02 19:58:36] \u001b[32mValid: [ 12/50] Step 104/104 Loss 2.786 Prec@(1,5) (44.1%, 76.6%)\u001b[0m\n",
            "[2024-04-02 19:58:36] \u001b[32mValid: [ 12/50] Final Prec@1 44.0500%\u001b[0m\n",
            "[2024-04-02 19:58:36] \u001b[32mEpoch 12 LR 0.021612\u001b[0m\n",
            "[2024-04-02 19:58:41] \u001b[32mTrain: [ 13/50] Step 000/520 Loss 2.746 Prec@(1,5) (37.5%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:58:41] \u001b[32mTrain: [ 13/50] Step 020/520 Loss 2.563 Prec@(1,5) (49.5%, 80.3%)\u001b[0m\n",
            "[2024-04-02 19:58:42] \u001b[32mTrain: [ 13/50] Step 040/520 Loss 2.548 Prec@(1,5) (49.5%, 80.2%)\u001b[0m\n",
            "[2024-04-02 19:58:42] \u001b[32mTrain: [ 13/50] Step 060/520 Loss 2.560 Prec@(1,5) (49.5%, 80.2%)\u001b[0m\n",
            "[2024-04-02 19:58:43] \u001b[32mTrain: [ 13/50] Step 080/520 Loss 2.548 Prec@(1,5) (49.9%, 80.3%)\u001b[0m\n",
            "[2024-04-02 19:58:43] \u001b[32mTrain: [ 13/50] Step 100/520 Loss 2.545 Prec@(1,5) (49.8%, 80.3%)\u001b[0m\n",
            "[2024-04-02 19:58:44] \u001b[32mTrain: [ 13/50] Step 120/520 Loss 2.557 Prec@(1,5) (49.8%, 80.1%)\u001b[0m\n",
            "[2024-04-02 19:58:44] \u001b[32mTrain: [ 13/50] Step 140/520 Loss 2.556 Prec@(1,5) (49.7%, 80.1%)\u001b[0m\n",
            "[2024-04-02 19:58:45] \u001b[32mTrain: [ 13/50] Step 160/520 Loss 2.567 Prec@(1,5) (49.6%, 80.0%)\u001b[0m\n",
            "[2024-04-02 19:58:45] \u001b[32mTrain: [ 13/50] Step 180/520 Loss 2.564 Prec@(1,5) (49.8%, 80.0%)\u001b[0m\n",
            "[2024-04-02 19:58:46] \u001b[32mTrain: [ 13/50] Step 200/520 Loss 2.573 Prec@(1,5) (49.7%, 79.9%)\u001b[0m\n",
            "[2024-04-02 19:58:46] \u001b[32mTrain: [ 13/50] Step 220/520 Loss 2.570 Prec@(1,5) (49.7%, 79.9%)\u001b[0m\n",
            "[2024-04-02 19:58:47] \u001b[32mTrain: [ 13/50] Step 240/520 Loss 2.571 Prec@(1,5) (49.7%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:58:47] \u001b[32mTrain: [ 13/50] Step 260/520 Loss 2.573 Prec@(1,5) (49.6%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:58:48] \u001b[32mTrain: [ 13/50] Step 280/520 Loss 2.577 Prec@(1,5) (49.5%, 79.7%)\u001b[0m\n",
            "[2024-04-02 19:58:48] \u001b[32mTrain: [ 13/50] Step 300/520 Loss 2.574 Prec@(1,5) (49.6%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:58:49] \u001b[32mTrain: [ 13/50] Step 320/520 Loss 2.568 Prec@(1,5) (49.8%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:58:49] \u001b[32mTrain: [ 13/50] Step 340/520 Loss 2.566 Prec@(1,5) (49.8%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:58:50] \u001b[32mTrain: [ 13/50] Step 360/520 Loss 2.563 Prec@(1,5) (49.9%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:58:50] \u001b[32mTrain: [ 13/50] Step 380/520 Loss 2.564 Prec@(1,5) (49.9%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:58:51] \u001b[32mTrain: [ 13/50] Step 400/520 Loss 2.564 Prec@(1,5) (49.9%, 79.9%)\u001b[0m\n",
            "[2024-04-02 19:58:51] \u001b[32mTrain: [ 13/50] Step 420/520 Loss 2.569 Prec@(1,5) (49.8%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:58:52] \u001b[32mTrain: [ 13/50] Step 440/520 Loss 2.571 Prec@(1,5) (49.8%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:58:52] \u001b[32mTrain: [ 13/50] Step 460/520 Loss 2.575 Prec@(1,5) (49.8%, 79.8%)\u001b[0m\n",
            "[2024-04-02 19:58:53] \u001b[32mTrain: [ 13/50] Step 480/520 Loss 2.577 Prec@(1,5) (49.7%, 79.7%)\u001b[0m\n",
            "[2024-04-02 19:58:53] \u001b[32mTrain: [ 13/50] Step 500/520 Loss 2.580 Prec@(1,5) (49.7%, 79.6%)\u001b[0m\n",
            "[2024-04-02 19:58:54] \u001b[32mTrain: [ 13/50] Step 520/520 Loss 2.581 Prec@(1,5) (49.7%, 79.6%)\u001b[0m\n",
            "[2024-04-02 19:58:54] \u001b[32mTrain: [ 13/50] Final Prec@1 49.6720%\u001b[0m\n",
            "[2024-04-02 19:58:57] \u001b[32mValid: [ 13/50] Step 000/104 Loss 2.875 Prec@(1,5) (44.8%, 79.2%)\u001b[0m\n",
            "[2024-04-02 19:58:58] \u001b[32mValid: [ 13/50] Step 020/104 Loss 3.014 Prec@(1,5) (42.4%, 75.7%)\u001b[0m\n",
            "[2024-04-02 19:58:58] \u001b[32mValid: [ 13/50] Step 040/104 Loss 3.023 Prec@(1,5) (42.2%, 75.1%)\u001b[0m\n",
            "[2024-04-02 19:58:58] \u001b[32mValid: [ 13/50] Step 060/104 Loss 2.969 Prec@(1,5) (43.0%, 75.1%)\u001b[0m\n",
            "[2024-04-02 19:58:58] \u001b[32mValid: [ 13/50] Step 080/104 Loss 2.972 Prec@(1,5) (43.0%, 74.8%)\u001b[0m\n",
            "[2024-04-02 19:58:58] \u001b[32mValid: [ 13/50] Step 100/104 Loss 2.961 Prec@(1,5) (43.3%, 75.0%)\u001b[0m\n",
            "[2024-04-02 19:58:58] \u001b[32mValid: [ 13/50] Step 104/104 Loss 2.964 Prec@(1,5) (43.3%, 74.9%)\u001b[0m\n",
            "[2024-04-02 19:58:59] \u001b[32mValid: [ 13/50] Final Prec@1 43.3400%\u001b[0m\n",
            "[2024-04-02 19:58:59] \u001b[32mEpoch 13 LR 0.021057\u001b[0m\n",
            "[2024-04-02 19:59:03] \u001b[32mTrain: [ 14/50] Step 000/520 Loss 2.694 Prec@(1,5) (49.0%, 78.1%)\u001b[0m\n",
            "[2024-04-02 19:59:04] \u001b[32mTrain: [ 14/50] Step 020/520 Loss 2.475 Prec@(1,5) (51.7%, 81.7%)\u001b[0m\n",
            "[2024-04-02 19:59:04] \u001b[32mTrain: [ 14/50] Step 040/520 Loss 2.492 Prec@(1,5) (51.3%, 81.4%)\u001b[0m\n",
            "[2024-04-02 19:59:05] \u001b[32mTrain: [ 14/50] Step 060/520 Loss 2.511 Prec@(1,5) (50.6%, 80.8%)\u001b[0m\n",
            "[2024-04-02 19:59:05] \u001b[32mTrain: [ 14/50] Step 080/520 Loss 2.508 Prec@(1,5) (50.6%, 80.7%)\u001b[0m\n",
            "[2024-04-02 19:59:06] \u001b[32mTrain: [ 14/50] Step 100/520 Loss 2.503 Prec@(1,5) (50.8%, 80.8%)\u001b[0m\n",
            "[2024-04-02 19:59:06] \u001b[32mTrain: [ 14/50] Step 120/520 Loss 2.505 Prec@(1,5) (50.7%, 80.8%)\u001b[0m\n",
            "[2024-04-02 19:59:07] \u001b[32mTrain: [ 14/50] Step 140/520 Loss 2.508 Prec@(1,5) (50.6%, 80.8%)\u001b[0m\n",
            "[2024-04-02 19:59:07] \u001b[32mTrain: [ 14/50] Step 160/520 Loss 2.501 Prec@(1,5) (50.7%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:59:08] \u001b[32mTrain: [ 14/50] Step 180/520 Loss 2.506 Prec@(1,5) (50.8%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:59:08] \u001b[32mTrain: [ 14/50] Step 200/520 Loss 2.511 Prec@(1,5) (50.7%, 80.7%)\u001b[0m\n",
            "[2024-04-02 19:59:09] \u001b[32mTrain: [ 14/50] Step 220/520 Loss 2.509 Prec@(1,5) (50.8%, 80.7%)\u001b[0m\n",
            "[2024-04-02 19:59:09] \u001b[32mTrain: [ 14/50] Step 240/520 Loss 2.515 Prec@(1,5) (50.7%, 80.7%)\u001b[0m\n",
            "[2024-04-02 19:59:10] \u001b[32mTrain: [ 14/50] Step 260/520 Loss 2.514 Prec@(1,5) (50.7%, 80.8%)\u001b[0m\n",
            "[2024-04-02 19:59:10] \u001b[32mTrain: [ 14/50] Step 280/520 Loss 2.511 Prec@(1,5) (50.7%, 80.8%)\u001b[0m\n",
            "[2024-04-02 19:59:11] \u001b[32mTrain: [ 14/50] Step 300/520 Loss 2.513 Prec@(1,5) (50.5%, 80.8%)\u001b[0m\n",
            "[2024-04-02 19:59:11] \u001b[32mTrain: [ 14/50] Step 320/520 Loss 2.518 Prec@(1,5) (50.5%, 80.7%)\u001b[0m\n",
            "[2024-04-02 19:59:12] \u001b[32mTrain: [ 14/50] Step 340/520 Loss 2.520 Prec@(1,5) (50.4%, 80.7%)\u001b[0m\n",
            "[2024-04-02 19:59:12] \u001b[32mTrain: [ 14/50] Step 360/520 Loss 2.520 Prec@(1,5) (50.4%, 80.7%)\u001b[0m\n",
            "[2024-04-02 19:59:13] \u001b[32mTrain: [ 14/50] Step 380/520 Loss 2.521 Prec@(1,5) (50.4%, 80.7%)\u001b[0m\n",
            "[2024-04-02 19:59:13] \u001b[32mTrain: [ 14/50] Step 400/520 Loss 2.520 Prec@(1,5) (50.4%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:59:14] \u001b[32mTrain: [ 14/50] Step 420/520 Loss 2.525 Prec@(1,5) (50.3%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:59:14] \u001b[32mTrain: [ 14/50] Step 440/520 Loss 2.527 Prec@(1,5) (50.3%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:59:15] \u001b[32mTrain: [ 14/50] Step 460/520 Loss 2.525 Prec@(1,5) (50.3%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:59:15] \u001b[32mTrain: [ 14/50] Step 480/520 Loss 2.522 Prec@(1,5) (50.4%, 80.6%)\u001b[0m\n",
            "[2024-04-02 19:59:16] \u001b[32mTrain: [ 14/50] Step 500/520 Loss 2.522 Prec@(1,5) (50.4%, 80.5%)\u001b[0m\n",
            "[2024-04-02 19:59:16] \u001b[32mTrain: [ 14/50] Step 520/520 Loss 2.524 Prec@(1,5) (50.4%, 80.5%)\u001b[0m\n",
            "[2024-04-02 19:59:17] \u001b[32mTrain: [ 14/50] Final Prec@1 50.3620%\u001b[0m\n",
            "[2024-04-02 19:59:20] \u001b[32mValid: [ 14/50] Step 000/104 Loss 2.675 Prec@(1,5) (55.2%, 82.3%)\u001b[0m\n",
            "[2024-04-02 19:59:20] \u001b[32mValid: [ 14/50] Step 020/104 Loss 2.850 Prec@(1,5) (45.7%, 76.0%)\u001b[0m\n",
            "[2024-04-02 19:59:20] \u001b[32mValid: [ 14/50] Step 040/104 Loss 2.820 Prec@(1,5) (45.0%, 76.6%)\u001b[0m\n",
            "[2024-04-02 19:59:21] \u001b[32mValid: [ 14/50] Step 060/104 Loss 2.771 Prec@(1,5) (45.8%, 76.8%)\u001b[0m\n",
            "[2024-04-02 19:59:21] \u001b[32mValid: [ 14/50] Step 080/104 Loss 2.771 Prec@(1,5) (45.6%, 76.7%)\u001b[0m\n",
            "[2024-04-02 19:59:21] \u001b[32mValid: [ 14/50] Step 100/104 Loss 2.762 Prec@(1,5) (45.7%, 77.0%)\u001b[0m\n",
            "[2024-04-02 19:59:21] \u001b[32mValid: [ 14/50] Step 104/104 Loss 2.762 Prec@(1,5) (45.8%, 76.9%)\u001b[0m\n",
            "[2024-04-02 19:59:21] \u001b[32mValid: [ 14/50] Final Prec@1 45.7700%\u001b[0m\n",
            "[2024-04-02 19:59:21] \u001b[32mEpoch 14 LR 0.020468\u001b[0m\n",
            "[2024-04-02 19:59:26] \u001b[32mTrain: [ 15/50] Step 000/520 Loss 2.571 Prec@(1,5) (52.1%, 83.3%)\u001b[0m\n",
            "[2024-04-02 19:59:26] \u001b[32mTrain: [ 15/50] Step 020/520 Loss 2.443 Prec@(1,5) (52.4%, 82.4%)\u001b[0m\n",
            "[2024-04-02 19:59:27] \u001b[32mTrain: [ 15/50] Step 040/520 Loss 2.440 Prec@(1,5) (52.1%, 81.8%)\u001b[0m\n",
            "[2024-04-02 19:59:27] \u001b[32mTrain: [ 15/50] Step 060/520 Loss 2.452 Prec@(1,5) (51.4%, 81.4%)\u001b[0m\n",
            "[2024-04-02 19:59:28] \u001b[32mTrain: [ 15/50] Step 080/520 Loss 2.469 Prec@(1,5) (51.3%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:59:28] \u001b[32mTrain: [ 15/50] Step 100/520 Loss 2.480 Prec@(1,5) (51.4%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:59:29] \u001b[32mTrain: [ 15/50] Step 120/520 Loss 2.477 Prec@(1,5) (51.5%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:59:29] \u001b[32mTrain: [ 15/50] Step 140/520 Loss 2.478 Prec@(1,5) (51.4%, 80.8%)\u001b[0m\n",
            "[2024-04-02 19:59:30] \u001b[32mTrain: [ 15/50] Step 160/520 Loss 2.474 Prec@(1,5) (51.5%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:59:30] \u001b[32mTrain: [ 15/50] Step 180/520 Loss 2.468 Prec@(1,5) (51.5%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:59:31] \u001b[32mTrain: [ 15/50] Step 200/520 Loss 2.471 Prec@(1,5) (51.3%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:59:31] \u001b[32mTrain: [ 15/50] Step 220/520 Loss 2.475 Prec@(1,5) (51.2%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:59:32] \u001b[32mTrain: [ 15/50] Step 240/520 Loss 2.469 Prec@(1,5) (51.2%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:59:32] \u001b[32mTrain: [ 15/50] Step 260/520 Loss 2.467 Prec@(1,5) (51.2%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:59:33] \u001b[32mTrain: [ 15/50] Step 280/520 Loss 2.475 Prec@(1,5) (51.1%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:59:33] \u001b[32mTrain: [ 15/50] Step 300/520 Loss 2.472 Prec@(1,5) (51.2%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:59:34] \u001b[32mTrain: [ 15/50] Step 320/520 Loss 2.477 Prec@(1,5) (51.1%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:59:34] \u001b[32mTrain: [ 15/50] Step 340/520 Loss 2.476 Prec@(1,5) (51.2%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:59:35] \u001b[32mTrain: [ 15/50] Step 360/520 Loss 2.480 Prec@(1,5) (51.2%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:59:35] \u001b[32mTrain: [ 15/50] Step 380/520 Loss 2.478 Prec@(1,5) (51.1%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:59:36] \u001b[32mTrain: [ 15/50] Step 400/520 Loss 2.478 Prec@(1,5) (51.1%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:59:36] \u001b[32mTrain: [ 15/50] Step 420/520 Loss 2.477 Prec@(1,5) (51.2%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:59:37] \u001b[32mTrain: [ 15/50] Step 440/520 Loss 2.476 Prec@(1,5) (51.2%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:59:37] \u001b[32mTrain: [ 15/50] Step 460/520 Loss 2.475 Prec@(1,5) (51.2%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:59:38] \u001b[32mTrain: [ 15/50] Step 480/520 Loss 2.475 Prec@(1,5) (51.2%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:59:38] \u001b[32mTrain: [ 15/50] Step 500/520 Loss 2.476 Prec@(1,5) (51.1%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:59:39] \u001b[32mTrain: [ 15/50] Step 520/520 Loss 2.477 Prec@(1,5) (51.1%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:59:39] \u001b[32mTrain: [ 15/50] Final Prec@1 51.1480%\u001b[0m\n",
            "[2024-04-02 19:59:42] \u001b[32mValid: [ 15/50] Step 000/104 Loss 2.406 Prec@(1,5) (55.2%, 77.1%)\u001b[0m\n",
            "[2024-04-02 19:59:43] \u001b[32mValid: [ 15/50] Step 020/104 Loss 2.734 Prec@(1,5) (46.0%, 77.0%)\u001b[0m\n",
            "[2024-04-02 19:59:43] \u001b[32mValid: [ 15/50] Step 040/104 Loss 2.692 Prec@(1,5) (46.0%, 77.0%)\u001b[0m\n",
            "[2024-04-02 19:59:43] \u001b[32mValid: [ 15/50] Step 060/104 Loss 2.658 Prec@(1,5) (46.7%, 77.5%)\u001b[0m\n",
            "[2024-04-02 19:59:43] \u001b[32mValid: [ 15/50] Step 080/104 Loss 2.662 Prec@(1,5) (46.3%, 77.6%)\u001b[0m\n",
            "[2024-04-02 19:59:43] \u001b[32mValid: [ 15/50] Step 100/104 Loss 2.647 Prec@(1,5) (46.5%, 77.6%)\u001b[0m\n",
            "[2024-04-02 19:59:43] \u001b[32mValid: [ 15/50] Step 104/104 Loss 2.642 Prec@(1,5) (46.7%, 77.6%)\u001b[0m\n",
            "[2024-04-02 19:59:44] \u001b[32mValid: [ 15/50] Final Prec@1 46.7300%\u001b[0m\n",
            "[2024-04-02 19:59:44] \u001b[32mEpoch 15 LR 0.019848\u001b[0m\n",
            "[2024-04-02 19:59:48] \u001b[32mTrain: [ 16/50] Step 000/520 Loss 2.319 Prec@(1,5) (53.1%, 80.2%)\u001b[0m\n",
            "[2024-04-02 19:59:49] \u001b[32mTrain: [ 16/50] Step 020/520 Loss 2.361 Prec@(1,5) (53.1%, 81.5%)\u001b[0m\n",
            "[2024-04-02 19:59:49] \u001b[32mTrain: [ 16/50] Step 040/520 Loss 2.377 Prec@(1,5) (53.1%, 81.3%)\u001b[0m\n",
            "[2024-04-02 19:59:50] \u001b[32mTrain: [ 16/50] Step 060/520 Loss 2.423 Prec@(1,5) (52.3%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:59:50] \u001b[32mTrain: [ 16/50] Step 080/520 Loss 2.428 Prec@(1,5) (52.2%, 81.0%)\u001b[0m\n",
            "[2024-04-02 19:59:51] \u001b[32mTrain: [ 16/50] Step 100/520 Loss 2.428 Prec@(1,5) (52.1%, 80.9%)\u001b[0m\n",
            "[2024-04-02 19:59:51] \u001b[32mTrain: [ 16/50] Step 120/520 Loss 2.428 Prec@(1,5) (52.0%, 81.1%)\u001b[0m\n",
            "[2024-04-02 19:59:52] \u001b[32mTrain: [ 16/50] Step 140/520 Loss 2.420 Prec@(1,5) (52.1%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:59:52] \u001b[32mTrain: [ 16/50] Step 160/520 Loss 2.423 Prec@(1,5) (52.2%, 81.2%)\u001b[0m\n",
            "[2024-04-02 19:59:53] \u001b[32mTrain: [ 16/50] Step 180/520 Loss 2.420 Prec@(1,5) (52.3%, 81.3%)\u001b[0m\n",
            "[2024-04-02 19:59:53] \u001b[32mTrain: [ 16/50] Step 200/520 Loss 2.413 Prec@(1,5) (52.4%, 81.4%)\u001b[0m\n",
            "[2024-04-02 19:59:54] \u001b[32mTrain: [ 16/50] Step 220/520 Loss 2.419 Prec@(1,5) (52.3%, 81.4%)\u001b[0m\n",
            "[2024-04-02 19:59:54] \u001b[32mTrain: [ 16/50] Step 240/520 Loss 2.417 Prec@(1,5) (52.3%, 81.5%)\u001b[0m\n",
            "[2024-04-02 19:59:55] \u001b[32mTrain: [ 16/50] Step 260/520 Loss 2.430 Prec@(1,5) (52.1%, 81.4%)\u001b[0m\n",
            "[2024-04-02 19:59:55] \u001b[32mTrain: [ 16/50] Step 280/520 Loss 2.431 Prec@(1,5) (52.0%, 81.4%)\u001b[0m\n",
            "[2024-04-02 19:59:56] \u001b[32mTrain: [ 16/50] Step 300/520 Loss 2.431 Prec@(1,5) (52.0%, 81.4%)\u001b[0m\n",
            "[2024-04-02 19:59:56] \u001b[32mTrain: [ 16/50] Step 320/520 Loss 2.433 Prec@(1,5) (52.0%, 81.4%)\u001b[0m\n",
            "[2024-04-02 19:59:57] \u001b[32mTrain: [ 16/50] Step 340/520 Loss 2.431 Prec@(1,5) (52.0%, 81.5%)\u001b[0m\n",
            "[2024-04-02 19:59:57] \u001b[32mTrain: [ 16/50] Step 360/520 Loss 2.437 Prec@(1,5) (52.0%, 81.4%)\u001b[0m\n",
            "[2024-04-02 19:59:58] \u001b[32mTrain: [ 16/50] Step 380/520 Loss 2.436 Prec@(1,5) (52.0%, 81.4%)\u001b[0m\n",
            "[2024-04-02 19:59:58] \u001b[32mTrain: [ 16/50] Step 400/520 Loss 2.435 Prec@(1,5) (52.0%, 81.4%)\u001b[0m\n",
            "[2024-04-02 19:59:59] \u001b[32mTrain: [ 16/50] Step 420/520 Loss 2.433 Prec@(1,5) (52.0%, 81.5%)\u001b[0m\n",
            "[2024-04-02 19:59:59] \u001b[32mTrain: [ 16/50] Step 440/520 Loss 2.433 Prec@(1,5) (52.0%, 81.5%)\u001b[0m\n",
            "[2024-04-02 20:00:00] \u001b[32mTrain: [ 16/50] Step 460/520 Loss 2.432 Prec@(1,5) (52.0%, 81.5%)\u001b[0m\n",
            "[2024-04-02 20:00:00] \u001b[32mTrain: [ 16/50] Step 480/520 Loss 2.436 Prec@(1,5) (51.9%, 81.5%)\u001b[0m\n",
            "[2024-04-02 20:00:01] \u001b[32mTrain: [ 16/50] Step 500/520 Loss 2.435 Prec@(1,5) (52.0%, 81.5%)\u001b[0m\n",
            "[2024-04-02 20:00:01] \u001b[32mTrain: [ 16/50] Step 520/520 Loss 2.440 Prec@(1,5) (51.8%, 81.5%)\u001b[0m\n",
            "[2024-04-02 20:00:01] \u001b[32mTrain: [ 16/50] Final Prec@1 51.8480%\u001b[0m\n",
            "[2024-04-02 20:00:05] \u001b[32mValid: [ 16/50] Step 000/104 Loss 2.462 Prec@(1,5) (51.0%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:00:05] \u001b[32mValid: [ 16/50] Step 020/104 Loss 2.576 Prec@(1,5) (47.5%, 78.9%)\u001b[0m\n",
            "[2024-04-02 20:00:05] \u001b[32mValid: [ 16/50] Step 040/104 Loss 2.578 Prec@(1,5) (47.7%, 78.5%)\u001b[0m\n",
            "[2024-04-02 20:00:05] \u001b[32mValid: [ 16/50] Step 060/104 Loss 2.516 Prec@(1,5) (48.4%, 78.9%)\u001b[0m\n",
            "[2024-04-02 20:00:05] \u001b[32mValid: [ 16/50] Step 080/104 Loss 2.511 Prec@(1,5) (48.4%, 79.0%)\u001b[0m\n",
            "[2024-04-02 20:00:06] \u001b[32mValid: [ 16/50] Step 100/104 Loss 2.495 Prec@(1,5) (48.4%, 79.3%)\u001b[0m\n",
            "[2024-04-02 20:00:06] \u001b[32mValid: [ 16/50] Step 104/104 Loss 2.490 Prec@(1,5) (48.6%, 79.2%)\u001b[0m\n",
            "[2024-04-02 20:00:06] \u001b[32mValid: [ 16/50] Final Prec@1 48.5900%\u001b[0m\n",
            "[2024-04-02 20:00:06] \u001b[32mEpoch 16 LR 0.019198\u001b[0m\n",
            "[2024-04-02 20:00:10] \u001b[32mTrain: [ 17/50] Step 000/520 Loss 2.654 Prec@(1,5) (50.0%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:00:11] \u001b[32mTrain: [ 17/50] Step 020/520 Loss 2.353 Prec@(1,5) (53.0%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:00:11] \u001b[32mTrain: [ 17/50] Step 040/520 Loss 2.407 Prec@(1,5) (52.2%, 81.9%)\u001b[0m\n",
            "[2024-04-02 20:00:12] \u001b[32mTrain: [ 17/50] Step 060/520 Loss 2.405 Prec@(1,5) (52.1%, 81.6%)\u001b[0m\n",
            "[2024-04-02 20:00:12] \u001b[32mTrain: [ 17/50] Step 080/520 Loss 2.401 Prec@(1,5) (52.0%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:00:13] \u001b[32mTrain: [ 17/50] Step 100/520 Loss 2.411 Prec@(1,5) (51.9%, 81.6%)\u001b[0m\n",
            "[2024-04-02 20:00:13] \u001b[32mTrain: [ 17/50] Step 120/520 Loss 2.409 Prec@(1,5) (52.2%, 81.6%)\u001b[0m\n",
            "[2024-04-02 20:00:14] \u001b[32mTrain: [ 17/50] Step 140/520 Loss 2.413 Prec@(1,5) (52.2%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:00:14] \u001b[32mTrain: [ 17/50] Step 160/520 Loss 2.409 Prec@(1,5) (52.4%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:00:15] \u001b[32mTrain: [ 17/50] Step 180/520 Loss 2.411 Prec@(1,5) (52.4%, 81.6%)\u001b[0m\n",
            "[2024-04-02 20:00:15] \u001b[32mTrain: [ 17/50] Step 200/520 Loss 2.414 Prec@(1,5) (52.3%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:00:16] \u001b[32mTrain: [ 17/50] Step 220/520 Loss 2.404 Prec@(1,5) (52.5%, 81.8%)\u001b[0m\n",
            "[2024-04-02 20:00:16] \u001b[32mTrain: [ 17/50] Step 240/520 Loss 2.403 Prec@(1,5) (52.5%, 81.8%)\u001b[0m\n",
            "[2024-04-02 20:00:17] \u001b[32mTrain: [ 17/50] Step 260/520 Loss 2.400 Prec@(1,5) (52.5%, 81.8%)\u001b[0m\n",
            "[2024-04-02 20:00:17] \u001b[32mTrain: [ 17/50] Step 280/520 Loss 2.396 Prec@(1,5) (52.5%, 81.9%)\u001b[0m\n",
            "[2024-04-02 20:00:18] \u001b[32mTrain: [ 17/50] Step 300/520 Loss 2.398 Prec@(1,5) (52.5%, 81.8%)\u001b[0m\n",
            "[2024-04-02 20:00:18] \u001b[32mTrain: [ 17/50] Step 320/520 Loss 2.398 Prec@(1,5) (52.5%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:00:19] \u001b[32mTrain: [ 17/50] Step 340/520 Loss 2.396 Prec@(1,5) (52.5%, 81.8%)\u001b[0m\n",
            "[2024-04-02 20:00:19] \u001b[32mTrain: [ 17/50] Step 360/520 Loss 2.397 Prec@(1,5) (52.5%, 81.8%)\u001b[0m\n",
            "[2024-04-02 20:00:20] \u001b[32mTrain: [ 17/50] Step 380/520 Loss 2.401 Prec@(1,5) (52.4%, 81.8%)\u001b[0m\n",
            "[2024-04-02 20:00:20] \u001b[32mTrain: [ 17/50] Step 400/520 Loss 2.405 Prec@(1,5) (52.4%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:00:21] \u001b[32mTrain: [ 17/50] Step 420/520 Loss 2.402 Prec@(1,5) (52.4%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:00:21] \u001b[32mTrain: [ 17/50] Step 440/520 Loss 2.402 Prec@(1,5) (52.5%, 81.8%)\u001b[0m\n",
            "[2024-04-02 20:00:22] \u001b[32mTrain: [ 17/50] Step 460/520 Loss 2.399 Prec@(1,5) (52.5%, 81.8%)\u001b[0m\n",
            "[2024-04-02 20:00:22] \u001b[32mTrain: [ 17/50] Step 480/520 Loss 2.398 Prec@(1,5) (52.5%, 81.9%)\u001b[0m\n",
            "[2024-04-02 20:00:23] \u001b[32mTrain: [ 17/50] Step 500/520 Loss 2.399 Prec@(1,5) (52.5%, 81.9%)\u001b[0m\n",
            "[2024-04-02 20:00:23] \u001b[32mTrain: [ 17/50] Step 520/520 Loss 2.397 Prec@(1,5) (52.5%, 81.9%)\u001b[0m\n",
            "[2024-04-02 20:00:23] \u001b[32mTrain: [ 17/50] Final Prec@1 52.5020%\u001b[0m\n",
            "[2024-04-02 20:00:27] \u001b[32mValid: [ 17/50] Step 000/104 Loss 2.528 Prec@(1,5) (55.2%, 76.0%)\u001b[0m\n",
            "[2024-04-02 20:00:27] \u001b[32mValid: [ 17/50] Step 020/104 Loss 2.522 Prec@(1,5) (50.2%, 79.9%)\u001b[0m\n",
            "[2024-04-02 20:00:27] \u001b[32mValid: [ 17/50] Step 040/104 Loss 2.523 Prec@(1,5) (49.1%, 79.1%)\u001b[0m\n",
            "[2024-04-02 20:00:27] \u001b[32mValid: [ 17/50] Step 060/104 Loss 2.525 Prec@(1,5) (49.4%, 78.8%)\u001b[0m\n",
            "[2024-04-02 20:00:28] \u001b[32mValid: [ 17/50] Step 080/104 Loss 2.531 Prec@(1,5) (49.0%, 78.7%)\u001b[0m\n",
            "[2024-04-02 20:00:28] \u001b[32mValid: [ 17/50] Step 100/104 Loss 2.512 Prec@(1,5) (49.2%, 78.8%)\u001b[0m\n",
            "[2024-04-02 20:00:28] \u001b[32mValid: [ 17/50] Step 104/104 Loss 2.510 Prec@(1,5) (49.3%, 78.7%)\u001b[0m\n",
            "[2024-04-02 20:00:28] \u001b[32mValid: [ 17/50] Final Prec@1 49.2700%\u001b[0m\n",
            "[2024-04-02 20:00:28] \u001b[32mEpoch 17 LR 0.018522\u001b[0m\n",
            "[2024-04-02 20:00:33] \u001b[32mTrain: [ 18/50] Step 000/520 Loss 2.361 Prec@(1,5) (58.3%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:00:33] \u001b[32mTrain: [ 18/50] Step 020/520 Loss 2.295 Prec@(1,5) (55.0%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:00:34] \u001b[32mTrain: [ 18/50] Step 040/520 Loss 2.312 Prec@(1,5) (54.8%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:00:34] \u001b[32mTrain: [ 18/50] Step 060/520 Loss 2.324 Prec@(1,5) (54.4%, 82.4%)\u001b[0m\n",
            "[2024-04-02 20:00:35] \u001b[32mTrain: [ 18/50] Step 080/520 Loss 2.322 Prec@(1,5) (54.4%, 82.4%)\u001b[0m\n",
            "[2024-04-02 20:00:35] \u001b[32mTrain: [ 18/50] Step 100/520 Loss 2.338 Prec@(1,5) (53.8%, 82.2%)\u001b[0m\n",
            "[2024-04-02 20:00:36] \u001b[32mTrain: [ 18/50] Step 120/520 Loss 2.330 Prec@(1,5) (54.0%, 82.4%)\u001b[0m\n",
            "[2024-04-02 20:00:36] \u001b[32mTrain: [ 18/50] Step 140/520 Loss 2.335 Prec@(1,5) (53.9%, 82.4%)\u001b[0m\n",
            "[2024-04-02 20:00:37] \u001b[32mTrain: [ 18/50] Step 160/520 Loss 2.337 Prec@(1,5) (53.6%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:00:37] \u001b[32mTrain: [ 18/50] Step 180/520 Loss 2.343 Prec@(1,5) (53.4%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:00:38] \u001b[32mTrain: [ 18/50] Step 200/520 Loss 2.340 Prec@(1,5) (53.5%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:00:38] \u001b[32mTrain: [ 18/50] Step 220/520 Loss 2.337 Prec@(1,5) (53.4%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:00:39] \u001b[32mTrain: [ 18/50] Step 240/520 Loss 2.340 Prec@(1,5) (53.4%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:00:39] \u001b[32mTrain: [ 18/50] Step 260/520 Loss 2.336 Prec@(1,5) (53.5%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:00:40] \u001b[32mTrain: [ 18/50] Step 280/520 Loss 2.337 Prec@(1,5) (53.5%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:00:40] \u001b[32mTrain: [ 18/50] Step 300/520 Loss 2.336 Prec@(1,5) (53.5%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:00:41] \u001b[32mTrain: [ 18/50] Step 320/520 Loss 2.336 Prec@(1,5) (53.6%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:00:41] \u001b[32mTrain: [ 18/50] Step 340/520 Loss 2.336 Prec@(1,5) (53.6%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:00:42] \u001b[32mTrain: [ 18/50] Step 360/520 Loss 2.337 Prec@(1,5) (53.6%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:00:42] \u001b[32mTrain: [ 18/50] Step 380/520 Loss 2.338 Prec@(1,5) (53.6%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:00:43] \u001b[32mTrain: [ 18/50] Step 400/520 Loss 2.342 Prec@(1,5) (53.5%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:00:43] \u001b[32mTrain: [ 18/50] Step 420/520 Loss 2.342 Prec@(1,5) (53.5%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:00:44] \u001b[32mTrain: [ 18/50] Step 440/520 Loss 2.347 Prec@(1,5) (53.4%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:00:44] \u001b[32mTrain: [ 18/50] Step 460/520 Loss 2.350 Prec@(1,5) (53.4%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:00:45] \u001b[32mTrain: [ 18/50] Step 480/520 Loss 2.354 Prec@(1,5) (53.3%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:00:45] \u001b[32mTrain: [ 18/50] Step 500/520 Loss 2.352 Prec@(1,5) (53.3%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:00:46] \u001b[32mTrain: [ 18/50] Step 520/520 Loss 2.350 Prec@(1,5) (53.3%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:00:46] \u001b[32mTrain: [ 18/50] Final Prec@1 53.3140%\u001b[0m\n",
            "[2024-04-02 20:00:49] \u001b[32mValid: [ 18/50] Step 000/104 Loss 2.416 Prec@(1,5) (52.1%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:00:50] \u001b[32mValid: [ 18/50] Step 020/104 Loss 2.383 Prec@(1,5) (51.6%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:00:50] \u001b[32mValid: [ 18/50] Step 040/104 Loss 2.394 Prec@(1,5) (50.9%, 80.4%)\u001b[0m\n",
            "[2024-04-02 20:00:50] \u001b[32mValid: [ 18/50] Step 060/104 Loss 2.354 Prec@(1,5) (51.4%, 80.7%)\u001b[0m\n",
            "[2024-04-02 20:00:50] \u001b[32mValid: [ 18/50] Step 080/104 Loss 2.361 Prec@(1,5) (50.6%, 80.7%)\u001b[0m\n",
            "[2024-04-02 20:00:50] \u001b[32mValid: [ 18/50] Step 100/104 Loss 2.339 Prec@(1,5) (50.6%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:00:50] \u001b[32mValid: [ 18/50] Step 104/104 Loss 2.337 Prec@(1,5) (50.7%, 80.8%)\u001b[0m\n",
            "[2024-04-02 20:00:50] \u001b[32mValid: [ 18/50] Final Prec@1 50.7000%\u001b[0m\n",
            "[2024-04-02 20:00:50] \u001b[32mEpoch 18 LR 0.017823\u001b[0m\n",
            "[2024-04-02 20:00:55] \u001b[32mTrain: [ 19/50] Step 000/520 Loss 2.350 Prec@(1,5) (54.2%, 76.0%)\u001b[0m\n",
            "[2024-04-02 20:00:56] \u001b[32mTrain: [ 19/50] Step 020/520 Loss 2.284 Prec@(1,5) (55.8%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:00:56] \u001b[32mTrain: [ 19/50] Step 040/520 Loss 2.293 Prec@(1,5) (54.5%, 83.1%)\u001b[0m\n",
            "[2024-04-02 20:00:57] \u001b[32mTrain: [ 19/50] Step 060/520 Loss 2.304 Prec@(1,5) (54.2%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:00:57] \u001b[32mTrain: [ 19/50] Step 080/520 Loss 2.308 Prec@(1,5) (54.2%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:00:58] \u001b[32mTrain: [ 19/50] Step 100/520 Loss 2.319 Prec@(1,5) (54.1%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:00:58] \u001b[32mTrain: [ 19/50] Step 120/520 Loss 2.305 Prec@(1,5) (54.3%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:00:59] \u001b[32mTrain: [ 19/50] Step 140/520 Loss 2.292 Prec@(1,5) (54.6%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:00:59] \u001b[32mTrain: [ 19/50] Step 160/520 Loss 2.292 Prec@(1,5) (54.5%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:01:00] \u001b[32mTrain: [ 19/50] Step 180/520 Loss 2.296 Prec@(1,5) (54.4%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:01:00] \u001b[32mTrain: [ 19/50] Step 200/520 Loss 2.297 Prec@(1,5) (54.3%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:01:01] \u001b[32mTrain: [ 19/50] Step 220/520 Loss 2.293 Prec@(1,5) (54.4%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:01:01] \u001b[32mTrain: [ 19/50] Step 240/520 Loss 2.294 Prec@(1,5) (54.5%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:01:02] \u001b[32mTrain: [ 19/50] Step 260/520 Loss 2.304 Prec@(1,5) (54.3%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:01:02] \u001b[32mTrain: [ 19/50] Step 280/520 Loss 2.308 Prec@(1,5) (54.2%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:01:03] \u001b[32mTrain: [ 19/50] Step 300/520 Loss 2.311 Prec@(1,5) (54.0%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:01:03] \u001b[32mTrain: [ 19/50] Step 320/520 Loss 2.313 Prec@(1,5) (53.9%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:01:04] \u001b[32mTrain: [ 19/50] Step 340/520 Loss 2.311 Prec@(1,5) (54.0%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:01:04] \u001b[32mTrain: [ 19/50] Step 360/520 Loss 2.313 Prec@(1,5) (53.9%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:01:05] \u001b[32mTrain: [ 19/50] Step 380/520 Loss 2.314 Prec@(1,5) (53.9%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:01:05] \u001b[32mTrain: [ 19/50] Step 400/520 Loss 2.312 Prec@(1,5) (54.0%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:01:06] \u001b[32mTrain: [ 19/50] Step 420/520 Loss 2.311 Prec@(1,5) (54.1%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:01:06] \u001b[32mTrain: [ 19/50] Step 440/520 Loss 2.312 Prec@(1,5) (54.1%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:01:07] \u001b[32mTrain: [ 19/50] Step 460/520 Loss 2.315 Prec@(1,5) (54.1%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:01:07] \u001b[32mTrain: [ 19/50] Step 480/520 Loss 2.315 Prec@(1,5) (54.0%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:01:08] \u001b[32mTrain: [ 19/50] Step 500/520 Loss 2.315 Prec@(1,5) (54.0%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:01:08] \u001b[32mTrain: [ 19/50] Step 520/520 Loss 2.316 Prec@(1,5) (54.0%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:01:08] \u001b[32mTrain: [ 19/50] Final Prec@1 54.0280%\u001b[0m\n",
            "[2024-04-02 20:01:12] \u001b[32mValid: [ 19/50] Step 000/104 Loss 2.111 Prec@(1,5) (61.5%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:01:12] \u001b[32mValid: [ 19/50] Step 020/104 Loss 2.455 Prec@(1,5) (51.2%, 80.1%)\u001b[0m\n",
            "[2024-04-02 20:01:12] \u001b[32mValid: [ 19/50] Step 040/104 Loss 2.418 Prec@(1,5) (51.0%, 80.0%)\u001b[0m\n",
            "[2024-04-02 20:01:12] \u001b[32mValid: [ 19/50] Step 060/104 Loss 2.395 Prec@(1,5) (51.2%, 80.4%)\u001b[0m\n",
            "[2024-04-02 20:01:12] \u001b[32mValid: [ 19/50] Step 080/104 Loss 2.399 Prec@(1,5) (50.6%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:01:13] \u001b[32mValid: [ 19/50] Step 100/104 Loss 2.380 Prec@(1,5) (51.0%, 80.6%)\u001b[0m\n",
            "[2024-04-02 20:01:13] \u001b[32mValid: [ 19/50] Step 104/104 Loss 2.377 Prec@(1,5) (51.1%, 80.6%)\u001b[0m\n",
            "[2024-04-02 20:01:13] \u001b[32mValid: [ 19/50] Final Prec@1 51.0800%\u001b[0m\n",
            "[2024-04-02 20:01:13] \u001b[32mEpoch 19 LR 0.017102\u001b[0m\n",
            "[2024-04-02 20:01:17] \u001b[32mTrain: [ 20/50] Step 000/520 Loss 2.308 Prec@(1,5) (53.1%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:01:18] \u001b[32mTrain: [ 20/50] Step 020/520 Loss 2.218 Prec@(1,5) (54.8%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:01:18] \u001b[32mTrain: [ 20/50] Step 040/520 Loss 2.250 Prec@(1,5) (54.7%, 83.4%)\u001b[0m\n",
            "[2024-04-02 20:01:19] \u001b[32mTrain: [ 20/50] Step 060/520 Loss 2.222 Prec@(1,5) (55.5%, 83.8%)\u001b[0m\n",
            "[2024-04-02 20:01:19] \u001b[32mTrain: [ 20/50] Step 080/520 Loss 2.242 Prec@(1,5) (55.3%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:01:20] \u001b[32mTrain: [ 20/50] Step 100/520 Loss 2.247 Prec@(1,5) (55.2%, 83.4%)\u001b[0m\n",
            "[2024-04-02 20:01:20] \u001b[32mTrain: [ 20/50] Step 120/520 Loss 2.247 Prec@(1,5) (54.9%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:01:21] \u001b[32mTrain: [ 20/50] Step 140/520 Loss 2.255 Prec@(1,5) (54.9%, 83.5%)\u001b[0m\n",
            "[2024-04-02 20:01:21] \u001b[32mTrain: [ 20/50] Step 160/520 Loss 2.262 Prec@(1,5) (54.8%, 83.5%)\u001b[0m\n",
            "[2024-04-02 20:01:22] \u001b[32mTrain: [ 20/50] Step 180/520 Loss 2.259 Prec@(1,5) (54.9%, 83.5%)\u001b[0m\n",
            "[2024-04-02 20:01:22] \u001b[32mTrain: [ 20/50] Step 200/520 Loss 2.264 Prec@(1,5) (54.9%, 83.5%)\u001b[0m\n",
            "[2024-04-02 20:01:23] \u001b[32mTrain: [ 20/50] Step 220/520 Loss 2.269 Prec@(1,5) (54.9%, 83.4%)\u001b[0m\n",
            "[2024-04-02 20:01:23] \u001b[32mTrain: [ 20/50] Step 240/520 Loss 2.285 Prec@(1,5) (54.6%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:01:24] \u001b[32mTrain: [ 20/50] Step 260/520 Loss 2.284 Prec@(1,5) (54.7%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:01:24] \u001b[32mTrain: [ 20/50] Step 280/520 Loss 2.283 Prec@(1,5) (54.6%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:01:25] \u001b[32mTrain: [ 20/50] Step 300/520 Loss 2.281 Prec@(1,5) (54.6%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:01:25] \u001b[32mTrain: [ 20/50] Step 320/520 Loss 2.282 Prec@(1,5) (54.5%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:01:26] \u001b[32mTrain: [ 20/50] Step 340/520 Loss 2.280 Prec@(1,5) (54.7%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:01:26] \u001b[32mTrain: [ 20/50] Step 360/520 Loss 2.289 Prec@(1,5) (54.4%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:01:27] \u001b[32mTrain: [ 20/50] Step 380/520 Loss 2.289 Prec@(1,5) (54.3%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:01:27] \u001b[32mTrain: [ 20/50] Step 400/520 Loss 2.286 Prec@(1,5) (54.4%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:01:28] \u001b[32mTrain: [ 20/50] Step 420/520 Loss 2.287 Prec@(1,5) (54.4%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:01:28] \u001b[32mTrain: [ 20/50] Step 440/520 Loss 2.289 Prec@(1,5) (54.4%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:01:29] \u001b[32mTrain: [ 20/50] Step 460/520 Loss 2.290 Prec@(1,5) (54.4%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:01:29] \u001b[32mTrain: [ 20/50] Step 480/520 Loss 2.291 Prec@(1,5) (54.4%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:01:30] \u001b[32mTrain: [ 20/50] Step 500/520 Loss 2.290 Prec@(1,5) (54.4%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:01:30] \u001b[32mTrain: [ 20/50] Step 520/520 Loss 2.290 Prec@(1,5) (54.4%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:01:30] \u001b[32mTrain: [ 20/50] Final Prec@1 54.3800%\u001b[0m\n",
            "[2024-04-02 20:01:34] \u001b[32mValid: [ 20/50] Step 000/104 Loss 2.219 Prec@(1,5) (54.2%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:01:34] \u001b[32mValid: [ 20/50] Step 020/104 Loss 2.414 Prec@(1,5) (50.9%, 81.1%)\u001b[0m\n",
            "[2024-04-02 20:01:34] \u001b[32mValid: [ 20/50] Step 040/104 Loss 2.407 Prec@(1,5) (50.4%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:01:34] \u001b[32mValid: [ 20/50] Step 060/104 Loss 2.367 Prec@(1,5) (50.8%, 80.6%)\u001b[0m\n",
            "[2024-04-02 20:01:35] \u001b[32mValid: [ 20/50] Step 080/104 Loss 2.374 Prec@(1,5) (50.3%, 80.8%)\u001b[0m\n",
            "[2024-04-02 20:01:35] \u001b[32mValid: [ 20/50] Step 100/104 Loss 2.352 Prec@(1,5) (50.8%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:01:35] \u001b[32mValid: [ 20/50] Step 104/104 Loss 2.352 Prec@(1,5) (50.8%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:01:35] \u001b[32mValid: [ 20/50] Final Prec@1 50.8300%\u001b[0m\n",
            "[2024-04-02 20:01:35] \u001b[32mEpoch 20 LR 0.016363\u001b[0m\n",
            "[2024-04-02 20:01:40] \u001b[32mTrain: [ 21/50] Step 000/520 Loss 2.041 Prec@(1,5) (56.2%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:01:40] \u001b[32mTrain: [ 21/50] Step 020/520 Loss 2.284 Prec@(1,5) (54.7%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:01:41] \u001b[32mTrain: [ 21/50] Step 040/520 Loss 2.272 Prec@(1,5) (55.0%, 83.4%)\u001b[0m\n",
            "[2024-04-02 20:01:41] \u001b[32mTrain: [ 21/50] Step 060/520 Loss 2.266 Prec@(1,5) (55.0%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:01:42] \u001b[32mTrain: [ 21/50] Step 080/520 Loss 2.250 Prec@(1,5) (55.1%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:01:42] \u001b[32mTrain: [ 21/50] Step 100/520 Loss 2.254 Prec@(1,5) (55.3%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:01:43] \u001b[32mTrain: [ 21/50] Step 120/520 Loss 2.254 Prec@(1,5) (55.2%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:01:43] \u001b[32mTrain: [ 21/50] Step 140/520 Loss 2.268 Prec@(1,5) (55.1%, 83.5%)\u001b[0m\n",
            "[2024-04-02 20:01:44] \u001b[32mTrain: [ 21/50] Step 160/520 Loss 2.257 Prec@(1,5) (55.3%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:01:44] \u001b[32mTrain: [ 21/50] Step 180/520 Loss 2.262 Prec@(1,5) (55.3%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:01:45] \u001b[32mTrain: [ 21/50] Step 200/520 Loss 2.261 Prec@(1,5) (55.3%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:01:45] \u001b[32mTrain: [ 21/50] Step 220/520 Loss 2.259 Prec@(1,5) (55.3%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:01:46] \u001b[32mTrain: [ 21/50] Step 240/520 Loss 2.261 Prec@(1,5) (55.2%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:01:46] \u001b[32mTrain: [ 21/50] Step 260/520 Loss 2.266 Prec@(1,5) (55.1%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:01:47] \u001b[32mTrain: [ 21/50] Step 280/520 Loss 2.267 Prec@(1,5) (55.1%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:01:47] \u001b[32mTrain: [ 21/50] Step 300/520 Loss 2.273 Prec@(1,5) (55.0%, 83.5%)\u001b[0m\n",
            "[2024-04-02 20:01:48] \u001b[32mTrain: [ 21/50] Step 320/520 Loss 2.269 Prec@(1,5) (55.1%, 83.5%)\u001b[0m\n",
            "[2024-04-02 20:01:48] \u001b[32mTrain: [ 21/50] Step 340/520 Loss 2.267 Prec@(1,5) (55.1%, 83.5%)\u001b[0m\n",
            "[2024-04-02 20:01:49] \u001b[32mTrain: [ 21/50] Step 360/520 Loss 2.263 Prec@(1,5) (55.1%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:01:49] \u001b[32mTrain: [ 21/50] Step 380/520 Loss 2.262 Prec@(1,5) (55.1%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:01:50] \u001b[32mTrain: [ 21/50] Step 400/520 Loss 2.258 Prec@(1,5) (55.1%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:01:50] \u001b[32mTrain: [ 21/50] Step 420/520 Loss 2.256 Prec@(1,5) (55.2%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:01:51] \u001b[32mTrain: [ 21/50] Step 440/520 Loss 2.255 Prec@(1,5) (55.1%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:01:51] \u001b[32mTrain: [ 21/50] Step 460/520 Loss 2.253 Prec@(1,5) (55.2%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:01:52] \u001b[32mTrain: [ 21/50] Step 480/520 Loss 2.254 Prec@(1,5) (55.1%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:01:52] \u001b[32mTrain: [ 21/50] Step 500/520 Loss 2.253 Prec@(1,5) (55.2%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:01:53] \u001b[32mTrain: [ 21/50] Step 520/520 Loss 2.254 Prec@(1,5) (55.1%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:01:53] \u001b[32mTrain: [ 21/50] Final Prec@1 55.1240%\u001b[0m\n",
            "[2024-04-02 20:01:56] \u001b[32mValid: [ 21/50] Step 000/104 Loss 2.401 Prec@(1,5) (56.2%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:01:56] \u001b[32mValid: [ 21/50] Step 020/104 Loss 2.525 Prec@(1,5) (51.6%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:01:57] \u001b[32mValid: [ 21/50] Step 040/104 Loss 2.504 Prec@(1,5) (50.7%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:01:57] \u001b[32mValid: [ 21/50] Step 060/104 Loss 2.465 Prec@(1,5) (50.8%, 80.7%)\u001b[0m\n",
            "[2024-04-02 20:01:57] \u001b[32mValid: [ 21/50] Step 080/104 Loss 2.463 Prec@(1,5) (50.5%, 80.8%)\u001b[0m\n",
            "[2024-04-02 20:01:57] \u001b[32mValid: [ 21/50] Step 100/104 Loss 2.443 Prec@(1,5) (50.7%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:01:57] \u001b[32mValid: [ 21/50] Step 104/104 Loss 2.442 Prec@(1,5) (50.7%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:01:57] \u001b[32mValid: [ 21/50] Final Prec@1 50.7200%\u001b[0m\n",
            "[2024-04-02 20:01:57] \u001b[32mEpoch 21 LR 0.015609\u001b[0m\n",
            "[2024-04-02 20:02:02] \u001b[32mTrain: [ 22/50] Step 000/520 Loss 2.233 Prec@(1,5) (51.0%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:02:02] \u001b[32mTrain: [ 22/50] Step 020/520 Loss 2.170 Prec@(1,5) (56.9%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:02:03] \u001b[32mTrain: [ 22/50] Step 040/520 Loss 2.187 Prec@(1,5) (56.6%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:02:03] \u001b[32mTrain: [ 22/50] Step 060/520 Loss 2.167 Prec@(1,5) (56.7%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:02:04] \u001b[32mTrain: [ 22/50] Step 080/520 Loss 2.185 Prec@(1,5) (56.2%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:02:04] \u001b[32mTrain: [ 22/50] Step 100/520 Loss 2.201 Prec@(1,5) (55.9%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:02:05] \u001b[32mTrain: [ 22/50] Step 120/520 Loss 2.200 Prec@(1,5) (56.1%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:02:05] \u001b[32mTrain: [ 22/50] Step 140/520 Loss 2.205 Prec@(1,5) (55.9%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:02:06] \u001b[32mTrain: [ 22/50] Step 160/520 Loss 2.209 Prec@(1,5) (55.9%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:02:06] \u001b[32mTrain: [ 22/50] Step 180/520 Loss 2.215 Prec@(1,5) (55.9%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:02:07] \u001b[32mTrain: [ 22/50] Step 200/520 Loss 2.217 Prec@(1,5) (55.9%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:02:07] \u001b[32mTrain: [ 22/50] Step 220/520 Loss 2.221 Prec@(1,5) (55.7%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:02:08] \u001b[32mTrain: [ 22/50] Step 240/520 Loss 2.220 Prec@(1,5) (55.8%, 83.9%)\u001b[0m\n",
            "[2024-04-02 20:02:08] \u001b[32mTrain: [ 22/50] Step 260/520 Loss 2.232 Prec@(1,5) (55.6%, 83.8%)\u001b[0m\n",
            "[2024-04-02 20:02:09] \u001b[32mTrain: [ 22/50] Step 280/520 Loss 2.229 Prec@(1,5) (55.7%, 83.9%)\u001b[0m\n",
            "[2024-04-02 20:02:09] \u001b[32mTrain: [ 22/50] Step 300/520 Loss 2.224 Prec@(1,5) (55.8%, 83.9%)\u001b[0m\n",
            "[2024-04-02 20:02:10] \u001b[32mTrain: [ 22/50] Step 320/520 Loss 2.226 Prec@(1,5) (55.8%, 83.9%)\u001b[0m\n",
            "[2024-04-02 20:02:10] \u001b[32mTrain: [ 22/50] Step 340/520 Loss 2.224 Prec@(1,5) (55.9%, 83.9%)\u001b[0m\n",
            "[2024-04-02 20:02:11] \u001b[32mTrain: [ 22/50] Step 360/520 Loss 2.224 Prec@(1,5) (55.9%, 83.9%)\u001b[0m\n",
            "[2024-04-02 20:02:11] \u001b[32mTrain: [ 22/50] Step 380/520 Loss 2.223 Prec@(1,5) (56.0%, 83.9%)\u001b[0m\n",
            "[2024-04-02 20:02:12] \u001b[32mTrain: [ 22/50] Step 400/520 Loss 2.221 Prec@(1,5) (56.0%, 83.9%)\u001b[0m\n",
            "[2024-04-02 20:02:12] \u001b[32mTrain: [ 22/50] Step 420/520 Loss 2.220 Prec@(1,5) (56.1%, 83.9%)\u001b[0m\n",
            "[2024-04-02 20:02:13] \u001b[32mTrain: [ 22/50] Step 440/520 Loss 2.218 Prec@(1,5) (56.1%, 84.0%)\u001b[0m\n",
            "[2024-04-02 20:02:13] \u001b[32mTrain: [ 22/50] Step 460/520 Loss 2.221 Prec@(1,5) (56.0%, 83.9%)\u001b[0m\n",
            "[2024-04-02 20:02:14] \u001b[32mTrain: [ 22/50] Step 480/520 Loss 2.223 Prec@(1,5) (56.0%, 83.9%)\u001b[0m\n",
            "[2024-04-02 20:02:14] \u001b[32mTrain: [ 22/50] Step 500/520 Loss 2.223 Prec@(1,5) (55.9%, 83.9%)\u001b[0m\n",
            "[2024-04-02 20:02:15] \u001b[32mTrain: [ 22/50] Step 520/520 Loss 2.225 Prec@(1,5) (55.9%, 83.9%)\u001b[0m\n",
            "[2024-04-02 20:02:15] \u001b[32mTrain: [ 22/50] Final Prec@1 55.8560%\u001b[0m\n",
            "[2024-04-02 20:02:18] \u001b[32mValid: [ 22/50] Step 000/104 Loss 2.230 Prec@(1,5) (58.3%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:02:19] \u001b[32mValid: [ 22/50] Step 020/104 Loss 2.251 Prec@(1,5) (53.4%, 81.3%)\u001b[0m\n",
            "[2024-04-02 20:02:19] \u001b[32mValid: [ 22/50] Step 040/104 Loss 2.235 Prec@(1,5) (53.1%, 81.9%)\u001b[0m\n",
            "[2024-04-02 20:02:19] \u001b[32mValid: [ 22/50] Step 060/104 Loss 2.217 Prec@(1,5) (53.1%, 82.1%)\u001b[0m\n",
            "[2024-04-02 20:02:19] \u001b[32mValid: [ 22/50] Step 080/104 Loss 2.218 Prec@(1,5) (52.9%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:02:19] \u001b[32mValid: [ 22/50] Step 100/104 Loss 2.195 Prec@(1,5) (53.0%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:02:19] \u001b[32mValid: [ 22/50] Step 104/104 Loss 2.196 Prec@(1,5) (53.1%, 82.4%)\u001b[0m\n",
            "[2024-04-02 20:02:20] \u001b[32mValid: [ 22/50] Final Prec@1 53.0700%\u001b[0m\n",
            "[2024-04-02 20:02:20] \u001b[32mEpoch 22 LR 0.014843\u001b[0m\n",
            "[2024-04-02 20:02:24] \u001b[32mTrain: [ 23/50] Step 000/520 Loss 2.061 Prec@(1,5) (62.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:02:25] \u001b[32mTrain: [ 23/50] Step 020/520 Loss 2.230 Prec@(1,5) (54.6%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:02:25] \u001b[32mTrain: [ 23/50] Step 040/520 Loss 2.211 Prec@(1,5) (55.9%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:02:26] \u001b[32mTrain: [ 23/50] Step 060/520 Loss 2.193 Prec@(1,5) (56.2%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:02:26] \u001b[32mTrain: [ 23/50] Step 080/520 Loss 2.182 Prec@(1,5) (56.3%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:02:27] \u001b[32mTrain: [ 23/50] Step 100/520 Loss 2.183 Prec@(1,5) (56.6%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:02:27] \u001b[32mTrain: [ 23/50] Step 120/520 Loss 2.190 Prec@(1,5) (56.6%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:02:28] \u001b[32mTrain: [ 23/50] Step 140/520 Loss 2.188 Prec@(1,5) (56.6%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:02:28] \u001b[32mTrain: [ 23/50] Step 160/520 Loss 2.186 Prec@(1,5) (56.4%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:02:29] \u001b[32mTrain: [ 23/50] Step 180/520 Loss 2.184 Prec@(1,5) (56.4%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:02:29] \u001b[32mTrain: [ 23/50] Step 200/520 Loss 2.189 Prec@(1,5) (56.2%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:02:30] \u001b[32mTrain: [ 23/50] Step 220/520 Loss 2.192 Prec@(1,5) (56.2%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:02:30] \u001b[32mTrain: [ 23/50] Step 240/520 Loss 2.188 Prec@(1,5) (56.3%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:02:31] \u001b[32mTrain: [ 23/50] Step 260/520 Loss 2.186 Prec@(1,5) (56.4%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:02:31] \u001b[32mTrain: [ 23/50] Step 280/520 Loss 2.185 Prec@(1,5) (56.5%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:02:32] \u001b[32mTrain: [ 23/50] Step 300/520 Loss 2.188 Prec@(1,5) (56.3%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:02:32] \u001b[32mTrain: [ 23/50] Step 320/520 Loss 2.186 Prec@(1,5) (56.3%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:02:33] \u001b[32mTrain: [ 23/50] Step 340/520 Loss 2.185 Prec@(1,5) (56.3%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:02:33] \u001b[32mTrain: [ 23/50] Step 360/520 Loss 2.184 Prec@(1,5) (56.2%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:02:34] \u001b[32mTrain: [ 23/50] Step 380/520 Loss 2.186 Prec@(1,5) (56.2%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:02:34] \u001b[32mTrain: [ 23/50] Step 400/520 Loss 2.189 Prec@(1,5) (56.1%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:02:35] \u001b[32mTrain: [ 23/50] Step 420/520 Loss 2.190 Prec@(1,5) (56.1%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:02:35] \u001b[32mTrain: [ 23/50] Step 440/520 Loss 2.195 Prec@(1,5) (56.1%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:02:36] \u001b[32mTrain: [ 23/50] Step 460/520 Loss 2.197 Prec@(1,5) (56.0%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:02:36] \u001b[32mTrain: [ 23/50] Step 480/520 Loss 2.196 Prec@(1,5) (56.0%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:02:37] \u001b[32mTrain: [ 23/50] Step 500/520 Loss 2.194 Prec@(1,5) (56.0%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:02:37] \u001b[32mTrain: [ 23/50] Step 520/520 Loss 2.197 Prec@(1,5) (56.0%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:02:37] \u001b[32mTrain: [ 23/50] Final Prec@1 56.0340%\u001b[0m\n",
            "[2024-04-02 20:02:41] \u001b[32mValid: [ 23/50] Step 000/104 Loss 2.020 Prec@(1,5) (60.4%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:02:41] \u001b[32mValid: [ 23/50] Step 020/104 Loss 2.425 Prec@(1,5) (53.4%, 80.7%)\u001b[0m\n",
            "[2024-04-02 20:02:41] \u001b[32mValid: [ 23/50] Step 040/104 Loss 2.383 Prec@(1,5) (52.6%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:02:41] \u001b[32mValid: [ 23/50] Step 060/104 Loss 2.351 Prec@(1,5) (52.7%, 81.1%)\u001b[0m\n",
            "[2024-04-02 20:02:42] \u001b[32mValid: [ 23/50] Step 080/104 Loss 2.356 Prec@(1,5) (52.5%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:02:42] \u001b[32mValid: [ 23/50] Step 100/104 Loss 2.333 Prec@(1,5) (52.6%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:02:42] \u001b[32mValid: [ 23/50] Step 104/104 Loss 2.338 Prec@(1,5) (52.6%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:02:42] \u001b[32mValid: [ 23/50] Final Prec@1 52.5700%\u001b[0m\n",
            "[2024-04-02 20:02:42] \u001b[32mEpoch 23 LR 0.014067\u001b[0m\n",
            "[2024-04-02 20:02:47] \u001b[32mTrain: [ 24/50] Step 000/520 Loss 2.145 Prec@(1,5) (55.2%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:02:47] \u001b[32mTrain: [ 24/50] Step 020/520 Loss 2.117 Prec@(1,5) (57.1%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:02:48] \u001b[32mTrain: [ 24/50] Step 040/520 Loss 2.121 Prec@(1,5) (58.0%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:02:48] \u001b[32mTrain: [ 24/50] Step 060/520 Loss 2.125 Prec@(1,5) (58.0%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:02:49] \u001b[32mTrain: [ 24/50] Step 080/520 Loss 2.120 Prec@(1,5) (57.9%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:02:49] \u001b[32mTrain: [ 24/50] Step 100/520 Loss 2.130 Prec@(1,5) (57.5%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:02:50] \u001b[32mTrain: [ 24/50] Step 120/520 Loss 2.134 Prec@(1,5) (57.2%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:02:50] \u001b[32mTrain: [ 24/50] Step 140/520 Loss 2.130 Prec@(1,5) (57.1%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:02:51] \u001b[32mTrain: [ 24/50] Step 160/520 Loss 2.136 Prec@(1,5) (57.1%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:02:51] \u001b[32mTrain: [ 24/50] Step 180/520 Loss 2.137 Prec@(1,5) (57.1%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:02:52] \u001b[32mTrain: [ 24/50] Step 200/520 Loss 2.148 Prec@(1,5) (57.0%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:02:52] \u001b[32mTrain: [ 24/50] Step 220/520 Loss 2.151 Prec@(1,5) (57.1%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:02:53] \u001b[32mTrain: [ 24/50] Step 240/520 Loss 2.150 Prec@(1,5) (57.1%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:02:53] \u001b[32mTrain: [ 24/50] Step 260/520 Loss 2.149 Prec@(1,5) (57.2%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:02:54] \u001b[32mTrain: [ 24/50] Step 280/520 Loss 2.153 Prec@(1,5) (57.1%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:02:54] \u001b[32mTrain: [ 24/50] Step 300/520 Loss 2.157 Prec@(1,5) (57.1%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:02:55] \u001b[32mTrain: [ 24/50] Step 320/520 Loss 2.157 Prec@(1,5) (57.1%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:02:55] \u001b[32mTrain: [ 24/50] Step 340/520 Loss 2.156 Prec@(1,5) (57.1%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:02:56] \u001b[32mTrain: [ 24/50] Step 360/520 Loss 2.154 Prec@(1,5) (57.1%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:02:56] \u001b[32mTrain: [ 24/50] Step 380/520 Loss 2.150 Prec@(1,5) (57.2%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:02:57] \u001b[32mTrain: [ 24/50] Step 400/520 Loss 2.150 Prec@(1,5) (57.2%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:02:57] \u001b[32mTrain: [ 24/50] Step 420/520 Loss 2.154 Prec@(1,5) (57.2%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:02:58] \u001b[32mTrain: [ 24/50] Step 440/520 Loss 2.153 Prec@(1,5) (57.2%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:02:58] \u001b[32mTrain: [ 24/50] Step 460/520 Loss 2.159 Prec@(1,5) (57.1%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:02:59] \u001b[32mTrain: [ 24/50] Step 480/520 Loss 2.160 Prec@(1,5) (57.0%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:02:59] \u001b[32mTrain: [ 24/50] Step 500/520 Loss 2.158 Prec@(1,5) (57.0%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:03:00] \u001b[32mTrain: [ 24/50] Step 520/520 Loss 2.159 Prec@(1,5) (57.0%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:03:00] \u001b[32mTrain: [ 24/50] Final Prec@1 56.9680%\u001b[0m\n",
            "[2024-04-02 20:03:04] \u001b[32mValid: [ 24/50] Step 000/104 Loss 2.315 Prec@(1,5) (59.4%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:03:04] \u001b[32mValid: [ 24/50] Step 020/104 Loss 2.416 Prec@(1,5) (51.5%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:03:04] \u001b[32mValid: [ 24/50] Step 040/104 Loss 2.416 Prec@(1,5) (50.7%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:03:04] \u001b[32mValid: [ 24/50] Step 060/104 Loss 2.357 Prec@(1,5) (51.7%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:03:04] \u001b[32mValid: [ 24/50] Step 080/104 Loss 2.355 Prec@(1,5) (51.4%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:03:05] \u001b[32mValid: [ 24/50] Step 100/104 Loss 2.338 Prec@(1,5) (51.3%, 81.1%)\u001b[0m\n",
            "[2024-04-02 20:03:05] \u001b[32mValid: [ 24/50] Step 104/104 Loss 2.343 Prec@(1,5) (51.4%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:03:05] \u001b[32mValid: [ 24/50] Final Prec@1 51.3700%\u001b[0m\n",
            "[2024-04-02 20:03:05] \u001b[32mEpoch 24 LR 0.013285\u001b[0m\n",
            "[2024-04-02 20:03:09] \u001b[32mTrain: [ 25/50] Step 000/520 Loss 1.964 Prec@(1,5) (56.2%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:03:10] \u001b[32mTrain: [ 25/50] Step 020/520 Loss 2.161 Prec@(1,5) (55.0%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:03:10] \u001b[32mTrain: [ 25/50] Step 040/520 Loss 2.159 Prec@(1,5) (56.3%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:03:11] \u001b[32mTrain: [ 25/50] Step 060/520 Loss 2.143 Prec@(1,5) (56.8%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:03:11] \u001b[32mTrain: [ 25/50] Step 080/520 Loss 2.117 Prec@(1,5) (57.6%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:03:12] \u001b[32mTrain: [ 25/50] Step 100/520 Loss 2.117 Prec@(1,5) (57.6%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:03:12] \u001b[32mTrain: [ 25/50] Step 120/520 Loss 2.111 Prec@(1,5) (57.6%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:03:13] \u001b[32mTrain: [ 25/50] Step 140/520 Loss 2.113 Prec@(1,5) (57.5%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:03:13] \u001b[32mTrain: [ 25/50] Step 160/520 Loss 2.113 Prec@(1,5) (57.6%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:03:14] \u001b[32mTrain: [ 25/50] Step 180/520 Loss 2.115 Prec@(1,5) (57.6%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:03:14] \u001b[32mTrain: [ 25/50] Step 200/520 Loss 2.113 Prec@(1,5) (57.7%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:03:15] \u001b[32mTrain: [ 25/50] Step 220/520 Loss 2.110 Prec@(1,5) (57.8%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:03:15] \u001b[32mTrain: [ 25/50] Step 240/520 Loss 2.118 Prec@(1,5) (57.6%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:03:16] \u001b[32mTrain: [ 25/50] Step 260/520 Loss 2.127 Prec@(1,5) (57.6%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:03:16] \u001b[32mTrain: [ 25/50] Step 280/520 Loss 2.129 Prec@(1,5) (57.6%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:03:17] \u001b[32mTrain: [ 25/50] Step 300/520 Loss 2.131 Prec@(1,5) (57.5%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:03:17] \u001b[32mTrain: [ 25/50] Step 320/520 Loss 2.131 Prec@(1,5) (57.5%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:03:18] \u001b[32mTrain: [ 25/50] Step 340/520 Loss 2.130 Prec@(1,5) (57.5%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:03:18] \u001b[32mTrain: [ 25/50] Step 360/520 Loss 2.137 Prec@(1,5) (57.4%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:03:19] \u001b[32mTrain: [ 25/50] Step 380/520 Loss 2.137 Prec@(1,5) (57.4%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:03:19] \u001b[32mTrain: [ 25/50] Step 400/520 Loss 2.136 Prec@(1,5) (57.4%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:03:20] \u001b[32mTrain: [ 25/50] Step 420/520 Loss 2.139 Prec@(1,5) (57.4%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:03:20] \u001b[32mTrain: [ 25/50] Step 440/520 Loss 2.143 Prec@(1,5) (57.2%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:03:21] \u001b[32mTrain: [ 25/50] Step 460/520 Loss 2.144 Prec@(1,5) (57.2%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:03:21] \u001b[32mTrain: [ 25/50] Step 480/520 Loss 2.143 Prec@(1,5) (57.2%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:03:22] \u001b[32mTrain: [ 25/50] Step 500/520 Loss 2.144 Prec@(1,5) (57.2%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:03:22] \u001b[32mTrain: [ 25/50] Step 520/520 Loss 2.146 Prec@(1,5) (57.2%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:03:22] \u001b[32mTrain: [ 25/50] Final Prec@1 57.2220%\u001b[0m\n",
            "[2024-04-02 20:03:26] \u001b[32mValid: [ 25/50] Step 000/104 Loss 2.328 Prec@(1,5) (55.2%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:03:26] \u001b[32mValid: [ 25/50] Step 020/104 Loss 2.527 Prec@(1,5) (50.5%, 81.6%)\u001b[0m\n",
            "[2024-04-02 20:03:26] \u001b[32mValid: [ 25/50] Step 040/104 Loss 2.498 Prec@(1,5) (50.5%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:03:26] \u001b[32mValid: [ 25/50] Step 060/104 Loss 2.443 Prec@(1,5) (51.2%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:03:27] \u001b[32mValid: [ 25/50] Step 080/104 Loss 2.429 Prec@(1,5) (50.9%, 81.4%)\u001b[0m\n",
            "[2024-04-02 20:03:27] \u001b[32mValid: [ 25/50] Step 100/104 Loss 2.417 Prec@(1,5) (51.1%, 81.5%)\u001b[0m\n",
            "[2024-04-02 20:03:27] \u001b[32mValid: [ 25/50] Step 104/104 Loss 2.419 Prec@(1,5) (51.1%, 81.5%)\u001b[0m\n",
            "[2024-04-02 20:03:27] \u001b[32mValid: [ 25/50] Final Prec@1 51.1100%\u001b[0m\n",
            "[2024-04-02 20:03:27] \u001b[32mEpoch 25 LR 0.012500\u001b[0m\n",
            "[2024-04-02 20:03:32] \u001b[32mTrain: [ 26/50] Step 000/520 Loss 2.015 Prec@(1,5) (53.1%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:03:32] \u001b[32mTrain: [ 26/50] Step 020/520 Loss 2.081 Prec@(1,5) (56.7%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:03:33] \u001b[32mTrain: [ 26/50] Step 040/520 Loss 2.095 Prec@(1,5) (57.1%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:03:33] \u001b[32mTrain: [ 26/50] Step 060/520 Loss 2.086 Prec@(1,5) (57.7%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:03:34] \u001b[32mTrain: [ 26/50] Step 080/520 Loss 2.088 Prec@(1,5) (57.6%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:03:34] \u001b[32mTrain: [ 26/50] Step 100/520 Loss 2.084 Prec@(1,5) (58.0%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:03:35] \u001b[32mTrain: [ 26/50] Step 120/520 Loss 2.074 Prec@(1,5) (58.3%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:03:35] \u001b[32mTrain: [ 26/50] Step 140/520 Loss 2.077 Prec@(1,5) (58.3%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:03:36] \u001b[32mTrain: [ 26/50] Step 160/520 Loss 2.083 Prec@(1,5) (58.1%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:03:36] \u001b[32mTrain: [ 26/50] Step 180/520 Loss 2.084 Prec@(1,5) (58.0%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:03:37] \u001b[32mTrain: [ 26/50] Step 200/520 Loss 2.087 Prec@(1,5) (58.0%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:03:37] \u001b[32mTrain: [ 26/50] Step 220/520 Loss 2.092 Prec@(1,5) (57.9%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:03:38] \u001b[32mTrain: [ 26/50] Step 240/520 Loss 2.084 Prec@(1,5) (58.0%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:03:38] \u001b[32mTrain: [ 26/50] Step 260/520 Loss 2.080 Prec@(1,5) (58.0%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:03:39] \u001b[32mTrain: [ 26/50] Step 280/520 Loss 2.085 Prec@(1,5) (57.9%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:03:39] \u001b[32mTrain: [ 26/50] Step 300/520 Loss 2.093 Prec@(1,5) (57.8%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:03:40] \u001b[32mTrain: [ 26/50] Step 320/520 Loss 2.093 Prec@(1,5) (58.0%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:03:40] \u001b[32mTrain: [ 26/50] Step 340/520 Loss 2.097 Prec@(1,5) (57.9%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:03:41] \u001b[32mTrain: [ 26/50] Step 360/520 Loss 2.102 Prec@(1,5) (57.9%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:03:41] \u001b[32mTrain: [ 26/50] Step 380/520 Loss 2.104 Prec@(1,5) (57.9%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:03:42] \u001b[32mTrain: [ 26/50] Step 400/520 Loss 2.104 Prec@(1,5) (57.9%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:03:43] \u001b[32mTrain: [ 26/50] Step 420/520 Loss 2.105 Prec@(1,5) (57.8%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:03:43] \u001b[32mTrain: [ 26/50] Step 440/520 Loss 2.108 Prec@(1,5) (57.8%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:03:44] \u001b[32mTrain: [ 26/50] Step 460/520 Loss 2.107 Prec@(1,5) (57.8%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:03:44] \u001b[32mTrain: [ 26/50] Step 480/520 Loss 2.107 Prec@(1,5) (57.8%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:03:45] \u001b[32mTrain: [ 26/50] Step 500/520 Loss 2.108 Prec@(1,5) (57.8%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:03:45] \u001b[32mTrain: [ 26/50] Step 520/520 Loss 2.112 Prec@(1,5) (57.7%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:03:45] \u001b[32mTrain: [ 26/50] Final Prec@1 57.7240%\u001b[0m\n",
            "[2024-04-02 20:03:49] \u001b[32mValid: [ 26/50] Step 000/104 Loss 2.102 Prec@(1,5) (59.4%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:03:49] \u001b[32mValid: [ 26/50] Step 020/104 Loss 2.294 Prec@(1,5) (53.1%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:03:49] \u001b[32mValid: [ 26/50] Step 040/104 Loss 2.252 Prec@(1,5) (53.1%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:03:49] \u001b[32mValid: [ 26/50] Step 060/104 Loss 2.206 Prec@(1,5) (53.7%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:03:49] \u001b[32mValid: [ 26/50] Step 080/104 Loss 2.210 Prec@(1,5) (53.2%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:03:50] \u001b[32mValid: [ 26/50] Step 100/104 Loss 2.199 Prec@(1,5) (53.5%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:03:50] \u001b[32mValid: [ 26/50] Step 104/104 Loss 2.204 Prec@(1,5) (53.5%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:03:50] \u001b[32mValid: [ 26/50] Final Prec@1 53.5400%\u001b[0m\n",
            "[2024-04-02 20:03:50] \u001b[32mEpoch 26 LR 0.011716\u001b[0m\n",
            "[2024-04-02 20:03:54] \u001b[32mTrain: [ 27/50] Step 000/520 Loss 2.070 Prec@(1,5) (57.3%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:03:55] \u001b[32mTrain: [ 27/50] Step 020/520 Loss 2.050 Prec@(1,5) (59.7%, 86.1%)\u001b[0m\n",
            "[2024-04-02 20:03:55] \u001b[32mTrain: [ 27/50] Step 040/520 Loss 2.082 Prec@(1,5) (58.3%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:03:56] \u001b[32mTrain: [ 27/50] Step 060/520 Loss 2.091 Prec@(1,5) (58.1%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:03:56] \u001b[32mTrain: [ 27/50] Step 080/520 Loss 2.084 Prec@(1,5) (58.4%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:03:57] \u001b[32mTrain: [ 27/50] Step 100/520 Loss 2.077 Prec@(1,5) (58.4%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:03:57] \u001b[32mTrain: [ 27/50] Step 120/520 Loss 2.091 Prec@(1,5) (58.2%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:03:58] \u001b[32mTrain: [ 27/50] Step 140/520 Loss 2.080 Prec@(1,5) (58.3%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:03:59] \u001b[32mTrain: [ 27/50] Step 160/520 Loss 2.083 Prec@(1,5) (58.2%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:03:59] \u001b[32mTrain: [ 27/50] Step 180/520 Loss 2.090 Prec@(1,5) (58.1%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:04:00] \u001b[32mTrain: [ 27/50] Step 200/520 Loss 2.090 Prec@(1,5) (58.1%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:04:00] \u001b[32mTrain: [ 27/50] Step 220/520 Loss 2.093 Prec@(1,5) (57.9%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:04:01] \u001b[32mTrain: [ 27/50] Step 240/520 Loss 2.089 Prec@(1,5) (58.0%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:04:01] \u001b[32mTrain: [ 27/50] Step 260/520 Loss 2.094 Prec@(1,5) (57.9%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:04:02] \u001b[32mTrain: [ 27/50] Step 280/520 Loss 2.096 Prec@(1,5) (57.8%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:04:02] \u001b[32mTrain: [ 27/50] Step 300/520 Loss 2.097 Prec@(1,5) (57.9%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:04:03] \u001b[32mTrain: [ 27/50] Step 320/520 Loss 2.092 Prec@(1,5) (58.0%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:04:03] \u001b[32mTrain: [ 27/50] Step 340/520 Loss 2.094 Prec@(1,5) (57.9%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:04:04] \u001b[32mTrain: [ 27/50] Step 360/520 Loss 2.093 Prec@(1,5) (57.9%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:04:04] \u001b[32mTrain: [ 27/50] Step 380/520 Loss 2.094 Prec@(1,5) (57.9%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:04:05] \u001b[32mTrain: [ 27/50] Step 400/520 Loss 2.092 Prec@(1,5) (58.0%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:04:05] \u001b[32mTrain: [ 27/50] Step 420/520 Loss 2.095 Prec@(1,5) (57.9%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:04:06] \u001b[32mTrain: [ 27/50] Step 440/520 Loss 2.096 Prec@(1,5) (57.9%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:04:06] \u001b[32mTrain: [ 27/50] Step 460/520 Loss 2.096 Prec@(1,5) (57.9%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:04:07] \u001b[32mTrain: [ 27/50] Step 480/520 Loss 2.091 Prec@(1,5) (58.0%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:04:07] \u001b[32mTrain: [ 27/50] Step 500/520 Loss 2.090 Prec@(1,5) (58.0%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:04:08] \u001b[32mTrain: [ 27/50] Step 520/520 Loss 2.086 Prec@(1,5) (58.1%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:04:08] \u001b[32mTrain: [ 27/50] Final Prec@1 58.0900%\u001b[0m\n",
            "[2024-04-02 20:04:11] \u001b[32mValid: [ 27/50] Step 000/104 Loss 2.130 Prec@(1,5) (60.4%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:04:11] \u001b[32mValid: [ 27/50] Step 020/104 Loss 2.150 Prec@(1,5) (56.1%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:04:12] \u001b[32mValid: [ 27/50] Step 040/104 Loss 2.165 Prec@(1,5) (54.8%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:04:12] \u001b[32mValid: [ 27/50] Step 060/104 Loss 2.128 Prec@(1,5) (55.1%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:04:12] \u001b[32mValid: [ 27/50] Step 080/104 Loss 2.132 Prec@(1,5) (54.8%, 83.5%)\u001b[0m\n",
            "[2024-04-02 20:04:12] \u001b[32mValid: [ 27/50] Step 100/104 Loss 2.102 Prec@(1,5) (55.3%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:04:12] \u001b[32mValid: [ 27/50] Step 104/104 Loss 2.107 Prec@(1,5) (55.3%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:04:12] \u001b[32mValid: [ 27/50] Final Prec@1 55.2700%\u001b[0m\n",
            "[2024-04-02 20:04:12] \u001b[32mEpoch 27 LR 0.010934\u001b[0m\n",
            "[2024-04-02 20:04:17] \u001b[32mTrain: [ 28/50] Step 000/520 Loss 2.081 Prec@(1,5) (58.3%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:04:17] \u001b[32mTrain: [ 28/50] Step 020/520 Loss 1.963 Prec@(1,5) (61.3%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:04:18] \u001b[32mTrain: [ 28/50] Step 040/520 Loss 2.021 Prec@(1,5) (59.9%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:04:18] \u001b[32mTrain: [ 28/50] Step 060/520 Loss 2.026 Prec@(1,5) (59.6%, 86.4%)\u001b[0m\n",
            "[2024-04-02 20:04:19] \u001b[32mTrain: [ 28/50] Step 080/520 Loss 2.042 Prec@(1,5) (59.2%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:04:19] \u001b[32mTrain: [ 28/50] Step 100/520 Loss 2.034 Prec@(1,5) (59.4%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:04:20] \u001b[32mTrain: [ 28/50] Step 120/520 Loss 2.030 Prec@(1,5) (59.4%, 86.4%)\u001b[0m\n",
            "[2024-04-02 20:04:20] \u001b[32mTrain: [ 28/50] Step 140/520 Loss 2.039 Prec@(1,5) (59.2%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:04:21] \u001b[32mTrain: [ 28/50] Step 160/520 Loss 2.048 Prec@(1,5) (58.9%, 86.1%)\u001b[0m\n",
            "[2024-04-02 20:04:21] \u001b[32mTrain: [ 28/50] Step 180/520 Loss 2.048 Prec@(1,5) (58.9%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:04:22] \u001b[32mTrain: [ 28/50] Step 200/520 Loss 2.051 Prec@(1,5) (58.8%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:04:22] \u001b[32mTrain: [ 28/50] Step 220/520 Loss 2.051 Prec@(1,5) (58.8%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:04:23] \u001b[32mTrain: [ 28/50] Step 240/520 Loss 2.050 Prec@(1,5) (58.8%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:04:23] \u001b[32mTrain: [ 28/50] Step 260/520 Loss 2.046 Prec@(1,5) (58.9%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:04:24] \u001b[32mTrain: [ 28/50] Step 280/520 Loss 2.045 Prec@(1,5) (58.9%, 86.1%)\u001b[0m\n",
            "[2024-04-02 20:04:24] \u001b[32mTrain: [ 28/50] Step 300/520 Loss 2.048 Prec@(1,5) (58.8%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:04:25] \u001b[32mTrain: [ 28/50] Step 320/520 Loss 2.048 Prec@(1,5) (58.8%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:04:25] \u001b[32mTrain: [ 28/50] Step 340/520 Loss 2.052 Prec@(1,5) (58.7%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:04:26] \u001b[32mTrain: [ 28/50] Step 360/520 Loss 2.053 Prec@(1,5) (58.7%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:04:26] \u001b[32mTrain: [ 28/50] Step 380/520 Loss 2.054 Prec@(1,5) (58.7%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:04:27] \u001b[32mTrain: [ 28/50] Step 400/520 Loss 2.056 Prec@(1,5) (58.6%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:04:27] \u001b[32mTrain: [ 28/50] Step 420/520 Loss 2.057 Prec@(1,5) (58.6%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:04:28] \u001b[32mTrain: [ 28/50] Step 440/520 Loss 2.059 Prec@(1,5) (58.6%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:04:28] \u001b[32mTrain: [ 28/50] Step 460/520 Loss 2.058 Prec@(1,5) (58.6%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:04:29] \u001b[32mTrain: [ 28/50] Step 480/520 Loss 2.057 Prec@(1,5) (58.7%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:04:29] \u001b[32mTrain: [ 28/50] Step 500/520 Loss 2.058 Prec@(1,5) (58.6%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:04:30] \u001b[32mTrain: [ 28/50] Step 520/520 Loss 2.057 Prec@(1,5) (58.7%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:04:30] \u001b[32mTrain: [ 28/50] Final Prec@1 58.6800%\u001b[0m\n",
            "[2024-04-02 20:04:33] \u001b[32mValid: [ 28/50] Step 000/104 Loss 2.060 Prec@(1,5) (58.3%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:04:33] \u001b[32mValid: [ 28/50] Step 020/104 Loss 2.175 Prec@(1,5) (55.0%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:04:34] \u001b[32mValid: [ 28/50] Step 040/104 Loss 2.160 Prec@(1,5) (55.1%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:04:34] \u001b[32mValid: [ 28/50] Step 060/104 Loss 2.119 Prec@(1,5) (55.7%, 83.5%)\u001b[0m\n",
            "[2024-04-02 20:04:34] \u001b[32mValid: [ 28/50] Step 080/104 Loss 2.117 Prec@(1,5) (55.5%, 83.4%)\u001b[0m\n",
            "[2024-04-02 20:04:34] \u001b[32mValid: [ 28/50] Step 100/104 Loss 2.087 Prec@(1,5) (55.8%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:04:34] \u001b[32mValid: [ 28/50] Step 104/104 Loss 2.091 Prec@(1,5) (55.8%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:04:34] \u001b[32mValid: [ 28/50] Final Prec@1 55.8000%\u001b[0m\n",
            "[2024-04-02 20:04:34] \u001b[32mEpoch 28 LR 0.010158\u001b[0m\n",
            "[2024-04-02 20:04:39] \u001b[32mTrain: [ 29/50] Step 000/520 Loss 2.347 Prec@(1,5) (44.8%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:04:40] \u001b[32mTrain: [ 29/50] Step 020/520 Loss 2.058 Prec@(1,5) (56.9%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:04:40] \u001b[32mTrain: [ 29/50] Step 040/520 Loss 2.008 Prec@(1,5) (58.7%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:04:41] \u001b[32mTrain: [ 29/50] Step 060/520 Loss 2.048 Prec@(1,5) (57.9%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:04:41] \u001b[32mTrain: [ 29/50] Step 080/520 Loss 2.046 Prec@(1,5) (58.3%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:04:42] \u001b[32mTrain: [ 29/50] Step 100/520 Loss 2.051 Prec@(1,5) (58.3%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:04:42] \u001b[32mTrain: [ 29/50] Step 120/520 Loss 2.044 Prec@(1,5) (58.5%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:04:43] \u001b[32mTrain: [ 29/50] Step 140/520 Loss 2.038 Prec@(1,5) (58.8%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:04:43] \u001b[32mTrain: [ 29/50] Step 160/520 Loss 2.028 Prec@(1,5) (59.2%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:04:44] \u001b[32mTrain: [ 29/50] Step 180/520 Loss 2.030 Prec@(1,5) (59.2%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:04:44] \u001b[32mTrain: [ 29/50] Step 200/520 Loss 2.033 Prec@(1,5) (59.1%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:04:45] \u001b[32mTrain: [ 29/50] Step 220/520 Loss 2.030 Prec@(1,5) (59.1%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:04:45] \u001b[32mTrain: [ 29/50] Step 240/520 Loss 2.030 Prec@(1,5) (59.1%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:04:46] \u001b[32mTrain: [ 29/50] Step 260/520 Loss 2.033 Prec@(1,5) (59.0%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:04:46] \u001b[32mTrain: [ 29/50] Step 280/520 Loss 2.033 Prec@(1,5) (58.9%, 86.1%)\u001b[0m\n",
            "[2024-04-02 20:04:47] \u001b[32mTrain: [ 29/50] Step 300/520 Loss 2.039 Prec@(1,5) (58.8%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:04:47] \u001b[32mTrain: [ 29/50] Step 320/520 Loss 2.038 Prec@(1,5) (58.8%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:04:48] \u001b[32mTrain: [ 29/50] Step 340/520 Loss 2.041 Prec@(1,5) (58.8%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:04:48] \u001b[32mTrain: [ 29/50] Step 360/520 Loss 2.040 Prec@(1,5) (58.8%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:04:49] \u001b[32mTrain: [ 29/50] Step 380/520 Loss 2.038 Prec@(1,5) (58.8%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:04:49] \u001b[32mTrain: [ 29/50] Step 400/520 Loss 2.041 Prec@(1,5) (58.8%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:04:50] \u001b[32mTrain: [ 29/50] Step 420/520 Loss 2.043 Prec@(1,5) (58.7%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:04:50] \u001b[32mTrain: [ 29/50] Step 440/520 Loss 2.045 Prec@(1,5) (58.7%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:04:51] \u001b[32mTrain: [ 29/50] Step 460/520 Loss 2.044 Prec@(1,5) (58.7%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:04:51] \u001b[32mTrain: [ 29/50] Step 480/520 Loss 2.043 Prec@(1,5) (58.8%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:04:52] \u001b[32mTrain: [ 29/50] Step 500/520 Loss 2.045 Prec@(1,5) (58.7%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:04:52] \u001b[32mTrain: [ 29/50] Step 520/520 Loss 2.045 Prec@(1,5) (58.7%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:04:52] \u001b[32mTrain: [ 29/50] Final Prec@1 58.7300%\u001b[0m\n",
            "[2024-04-02 20:04:56] \u001b[32mValid: [ 29/50] Step 000/104 Loss 2.161 Prec@(1,5) (62.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:04:56] \u001b[32mValid: [ 29/50] Step 020/104 Loss 2.245 Prec@(1,5) (54.9%, 83.1%)\u001b[0m\n",
            "[2024-04-02 20:04:56] \u001b[32mValid: [ 29/50] Step 040/104 Loss 2.183 Prec@(1,5) (55.2%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:04:56] \u001b[32mValid: [ 29/50] Step 060/104 Loss 2.146 Prec@(1,5) (55.3%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:04:57] \u001b[32mValid: [ 29/50] Step 080/104 Loss 2.149 Prec@(1,5) (54.9%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:04:57] \u001b[32mValid: [ 29/50] Step 100/104 Loss 2.126 Prec@(1,5) (55.3%, 83.5%)\u001b[0m\n",
            "[2024-04-02 20:04:57] \u001b[32mValid: [ 29/50] Step 104/104 Loss 2.126 Prec@(1,5) (55.3%, 83.4%)\u001b[0m\n",
            "[2024-04-02 20:04:57] \u001b[32mValid: [ 29/50] Final Prec@1 55.3000%\u001b[0m\n",
            "[2024-04-02 20:04:57] \u001b[32mEpoch 29 LR 0.009392\u001b[0m\n",
            "[2024-04-02 20:05:02] \u001b[32mTrain: [ 30/50] Step 000/520 Loss 1.671 Prec@(1,5) (66.7%, 91.7%)\u001b[0m\n",
            "[2024-04-02 20:05:02] \u001b[32mTrain: [ 30/50] Step 020/520 Loss 1.991 Prec@(1,5) (60.9%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:05:03] \u001b[32mTrain: [ 30/50] Step 040/520 Loss 1.981 Prec@(1,5) (61.0%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:05:03] \u001b[32mTrain: [ 30/50] Step 060/520 Loss 1.980 Prec@(1,5) (60.3%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:05:04] \u001b[32mTrain: [ 30/50] Step 080/520 Loss 1.982 Prec@(1,5) (60.0%, 86.8%)\u001b[0m\n",
            "[2024-04-02 20:05:04] \u001b[32mTrain: [ 30/50] Step 100/520 Loss 1.974 Prec@(1,5) (60.0%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:05:05] \u001b[32mTrain: [ 30/50] Step 120/520 Loss 1.979 Prec@(1,5) (59.8%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:05:05] \u001b[32mTrain: [ 30/50] Step 140/520 Loss 1.980 Prec@(1,5) (60.0%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:05:06] \u001b[32mTrain: [ 30/50] Step 160/520 Loss 1.987 Prec@(1,5) (59.9%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:05:06] \u001b[32mTrain: [ 30/50] Step 180/520 Loss 1.993 Prec@(1,5) (59.9%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:05:07] \u001b[32mTrain: [ 30/50] Step 200/520 Loss 1.995 Prec@(1,5) (59.8%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:05:07] \u001b[32mTrain: [ 30/50] Step 220/520 Loss 1.998 Prec@(1,5) (59.8%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:05:08] \u001b[32mTrain: [ 30/50] Step 240/520 Loss 2.003 Prec@(1,5) (59.6%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:05:08] \u001b[32mTrain: [ 30/50] Step 260/520 Loss 1.998 Prec@(1,5) (59.8%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:05:09] \u001b[32mTrain: [ 30/50] Step 280/520 Loss 2.000 Prec@(1,5) (59.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:05:09] \u001b[32mTrain: [ 30/50] Step 300/520 Loss 1.997 Prec@(1,5) (59.7%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:05:10] \u001b[32mTrain: [ 30/50] Step 320/520 Loss 1.994 Prec@(1,5) (59.8%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:05:10] \u001b[32mTrain: [ 30/50] Step 340/520 Loss 1.999 Prec@(1,5) (59.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:05:11] \u001b[32mTrain: [ 30/50] Step 360/520 Loss 1.996 Prec@(1,5) (59.7%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:05:11] \u001b[32mTrain: [ 30/50] Step 380/520 Loss 1.995 Prec@(1,5) (59.8%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:05:12] \u001b[32mTrain: [ 30/50] Step 400/520 Loss 1.997 Prec@(1,5) (59.8%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:05:12] \u001b[32mTrain: [ 30/50] Step 420/520 Loss 2.001 Prec@(1,5) (59.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:05:13] \u001b[32mTrain: [ 30/50] Step 440/520 Loss 1.999 Prec@(1,5) (59.8%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:05:13] \u001b[32mTrain: [ 30/50] Step 460/520 Loss 2.002 Prec@(1,5) (59.8%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:05:14] \u001b[32mTrain: [ 30/50] Step 480/520 Loss 2.006 Prec@(1,5) (59.7%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:05:14] \u001b[32mTrain: [ 30/50] Step 500/520 Loss 2.010 Prec@(1,5) (59.6%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:05:15] \u001b[32mTrain: [ 30/50] Step 520/520 Loss 2.013 Prec@(1,5) (59.5%, 86.4%)\u001b[0m\n",
            "[2024-04-02 20:05:15] \u001b[32mTrain: [ 30/50] Final Prec@1 59.4840%\u001b[0m\n",
            "[2024-04-02 20:05:18] \u001b[32mValid: [ 30/50] Step 000/104 Loss 2.274 Prec@(1,5) (57.3%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:05:18] \u001b[32mValid: [ 30/50] Step 020/104 Loss 2.386 Prec@(1,5) (54.1%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:05:19] \u001b[32mValid: [ 30/50] Step 040/104 Loss 2.366 Prec@(1,5) (53.6%, 82.4%)\u001b[0m\n",
            "[2024-04-02 20:05:19] \u001b[32mValid: [ 30/50] Step 060/104 Loss 2.311 Prec@(1,5) (54.1%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:05:19] \u001b[32mValid: [ 30/50] Step 080/104 Loss 2.305 Prec@(1,5) (53.9%, 82.4%)\u001b[0m\n",
            "[2024-04-02 20:05:19] \u001b[32mValid: [ 30/50] Step 100/104 Loss 2.285 Prec@(1,5) (54.0%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:05:19] \u001b[32mValid: [ 30/50] Step 104/104 Loss 2.283 Prec@(1,5) (54.0%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:05:19] \u001b[32mValid: [ 30/50] Final Prec@1 53.9700%\u001b[0m\n",
            "[2024-04-02 20:05:19] \u001b[32mEpoch 30 LR 0.008638\u001b[0m\n",
            "[2024-04-02 20:05:24] \u001b[32mTrain: [ 31/50] Step 000/520 Loss 2.101 Prec@(1,5) (55.2%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:05:24] \u001b[32mTrain: [ 31/50] Step 020/520 Loss 1.953 Prec@(1,5) (60.0%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:05:25] \u001b[32mTrain: [ 31/50] Step 040/520 Loss 1.924 Prec@(1,5) (61.2%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:05:25] \u001b[32mTrain: [ 31/50] Step 060/520 Loss 1.917 Prec@(1,5) (61.1%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:05:26] \u001b[32mTrain: [ 31/50] Step 080/520 Loss 1.927 Prec@(1,5) (61.2%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:05:27] \u001b[32mTrain: [ 31/50] Step 100/520 Loss 1.936 Prec@(1,5) (61.2%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:05:27] \u001b[32mTrain: [ 31/50] Step 120/520 Loss 1.948 Prec@(1,5) (60.9%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:05:28] \u001b[32mTrain: [ 31/50] Step 140/520 Loss 1.959 Prec@(1,5) (60.6%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:05:28] \u001b[32mTrain: [ 31/50] Step 160/520 Loss 1.973 Prec@(1,5) (60.3%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:05:29] \u001b[32mTrain: [ 31/50] Step 180/520 Loss 1.976 Prec@(1,5) (60.0%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:05:29] \u001b[32mTrain: [ 31/50] Step 200/520 Loss 1.972 Prec@(1,5) (60.2%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:05:30] \u001b[32mTrain: [ 31/50] Step 220/520 Loss 1.971 Prec@(1,5) (60.3%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:05:30] \u001b[32mTrain: [ 31/50] Step 240/520 Loss 1.975 Prec@(1,5) (60.1%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:05:31] \u001b[32mTrain: [ 31/50] Step 260/520 Loss 1.976 Prec@(1,5) (60.2%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:05:31] \u001b[32mTrain: [ 31/50] Step 280/520 Loss 1.979 Prec@(1,5) (60.1%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:05:32] \u001b[32mTrain: [ 31/50] Step 300/520 Loss 1.979 Prec@(1,5) (60.0%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:05:32] \u001b[32mTrain: [ 31/50] Step 320/520 Loss 1.980 Prec@(1,5) (60.1%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:05:33] \u001b[32mTrain: [ 31/50] Step 340/520 Loss 1.978 Prec@(1,5) (60.2%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:05:33] \u001b[32mTrain: [ 31/50] Step 360/520 Loss 1.979 Prec@(1,5) (60.2%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:05:34] \u001b[32mTrain: [ 31/50] Step 380/520 Loss 1.984 Prec@(1,5) (60.1%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:05:34] \u001b[32mTrain: [ 31/50] Step 400/520 Loss 1.984 Prec@(1,5) (60.1%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:05:35] \u001b[32mTrain: [ 31/50] Step 420/520 Loss 1.984 Prec@(1,5) (60.1%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:05:35] \u001b[32mTrain: [ 31/50] Step 440/520 Loss 1.986 Prec@(1,5) (60.1%, 86.8%)\u001b[0m\n",
            "[2024-04-02 20:05:36] \u001b[32mTrain: [ 31/50] Step 460/520 Loss 1.983 Prec@(1,5) (60.2%, 86.8%)\u001b[0m\n",
            "[2024-04-02 20:05:36] \u001b[32mTrain: [ 31/50] Step 480/520 Loss 1.987 Prec@(1,5) (60.1%, 86.8%)\u001b[0m\n",
            "[2024-04-02 20:05:37] \u001b[32mTrain: [ 31/50] Step 500/520 Loss 1.988 Prec@(1,5) (60.1%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:05:37] \u001b[32mTrain: [ 31/50] Step 520/520 Loss 1.987 Prec@(1,5) (60.1%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:05:37] \u001b[32mTrain: [ 31/50] Final Prec@1 60.0660%\u001b[0m\n",
            "[2024-04-02 20:05:41] \u001b[32mValid: [ 31/50] Step 000/104 Loss 1.927 Prec@(1,5) (64.6%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:05:41] \u001b[32mValid: [ 31/50] Step 020/104 Loss 2.113 Prec@(1,5) (56.5%, 83.8%)\u001b[0m\n",
            "[2024-04-02 20:05:41] \u001b[32mValid: [ 31/50] Step 040/104 Loss 2.096 Prec@(1,5) (56.2%, 84.0%)\u001b[0m\n",
            "[2024-04-02 20:05:41] \u001b[32mValid: [ 31/50] Step 060/104 Loss 2.061 Prec@(1,5) (56.3%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:05:41] \u001b[32mValid: [ 31/50] Step 080/104 Loss 2.063 Prec@(1,5) (55.9%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:05:42] \u001b[32mValid: [ 31/50] Step 100/104 Loss 2.047 Prec@(1,5) (56.2%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:05:42] \u001b[32mValid: [ 31/50] Step 104/104 Loss 2.048 Prec@(1,5) (56.2%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:05:42] \u001b[32mValid: [ 31/50] Final Prec@1 56.1700%\u001b[0m\n",
            "[2024-04-02 20:05:42] \u001b[32mEpoch 31 LR 0.007899\u001b[0m\n",
            "[2024-04-02 20:05:46] \u001b[32mTrain: [ 32/50] Step 000/520 Loss 2.043 Prec@(1,5) (59.4%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:05:47] \u001b[32mTrain: [ 32/50] Step 020/520 Loss 1.893 Prec@(1,5) (62.0%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:05:47] \u001b[32mTrain: [ 32/50] Step 040/520 Loss 1.911 Prec@(1,5) (61.2%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:05:48] \u001b[32mTrain: [ 32/50] Step 060/520 Loss 1.918 Prec@(1,5) (60.8%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:05:48] \u001b[32mTrain: [ 32/50] Step 080/520 Loss 1.931 Prec@(1,5) (60.7%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:05:49] \u001b[32mTrain: [ 32/50] Step 100/520 Loss 1.937 Prec@(1,5) (60.7%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:05:49] \u001b[32mTrain: [ 32/50] Step 120/520 Loss 1.924 Prec@(1,5) (61.1%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:05:50] \u001b[32mTrain: [ 32/50] Step 140/520 Loss 1.913 Prec@(1,5) (61.3%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:05:50] \u001b[32mTrain: [ 32/50] Step 160/520 Loss 1.929 Prec@(1,5) (61.1%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:05:51] \u001b[32mTrain: [ 32/50] Step 180/520 Loss 1.928 Prec@(1,5) (61.2%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:05:51] \u001b[32mTrain: [ 32/50] Step 200/520 Loss 1.926 Prec@(1,5) (61.2%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:05:52] \u001b[32mTrain: [ 32/50] Step 220/520 Loss 1.921 Prec@(1,5) (61.2%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:05:52] \u001b[32mTrain: [ 32/50] Step 240/520 Loss 1.920 Prec@(1,5) (61.2%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:05:53] \u001b[32mTrain: [ 32/50] Step 260/520 Loss 1.927 Prec@(1,5) (61.1%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:05:53] \u001b[32mTrain: [ 32/50] Step 280/520 Loss 1.936 Prec@(1,5) (61.0%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:05:54] \u001b[32mTrain: [ 32/50] Step 300/520 Loss 1.935 Prec@(1,5) (61.1%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:05:54] \u001b[32mTrain: [ 32/50] Step 320/520 Loss 1.939 Prec@(1,5) (60.9%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:05:55] \u001b[32mTrain: [ 32/50] Step 340/520 Loss 1.941 Prec@(1,5) (60.9%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:05:55] \u001b[32mTrain: [ 32/50] Step 360/520 Loss 1.942 Prec@(1,5) (60.9%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:05:56] \u001b[32mTrain: [ 32/50] Step 380/520 Loss 1.942 Prec@(1,5) (60.9%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:05:56] \u001b[32mTrain: [ 32/50] Step 400/520 Loss 1.941 Prec@(1,5) (60.8%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:05:57] \u001b[32mTrain: [ 32/50] Step 420/520 Loss 1.942 Prec@(1,5) (60.8%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:05:57] \u001b[32mTrain: [ 32/50] Step 440/520 Loss 1.941 Prec@(1,5) (60.8%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:05:58] \u001b[32mTrain: [ 32/50] Step 460/520 Loss 1.939 Prec@(1,5) (60.9%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:05:58] \u001b[32mTrain: [ 32/50] Step 480/520 Loss 1.944 Prec@(1,5) (60.8%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:05:59] \u001b[32mTrain: [ 32/50] Step 500/520 Loss 1.945 Prec@(1,5) (60.8%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:05:59] \u001b[32mTrain: [ 32/50] Step 520/520 Loss 1.945 Prec@(1,5) (60.8%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:05:59] \u001b[32mTrain: [ 32/50] Final Prec@1 60.7620%\u001b[0m\n",
            "[2024-04-02 20:06:03] \u001b[32mValid: [ 32/50] Step 000/104 Loss 2.013 Prec@(1,5) (62.5%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:06:03] \u001b[32mValid: [ 32/50] Step 020/104 Loss 2.215 Prec@(1,5) (56.3%, 83.5%)\u001b[0m\n",
            "[2024-04-02 20:06:03] \u001b[32mValid: [ 32/50] Step 040/104 Loss 2.201 Prec@(1,5) (55.8%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:06:03] \u001b[32mValid: [ 32/50] Step 060/104 Loss 2.167 Prec@(1,5) (56.0%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:06:04] \u001b[32mValid: [ 32/50] Step 080/104 Loss 2.179 Prec@(1,5) (55.6%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:06:04] \u001b[32mValid: [ 32/50] Step 100/104 Loss 2.154 Prec@(1,5) (55.9%, 83.4%)\u001b[0m\n",
            "[2024-04-02 20:06:04] \u001b[32mValid: [ 32/50] Step 104/104 Loss 2.158 Prec@(1,5) (56.0%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:06:04] \u001b[32mValid: [ 32/50] Final Prec@1 55.9900%\u001b[0m\n",
            "[2024-04-02 20:06:04] \u001b[32mEpoch 32 LR 0.007178\u001b[0m\n",
            "[2024-04-02 20:06:08] \u001b[32mTrain: [ 33/50] Step 000/520 Loss 2.049 Prec@(1,5) (60.4%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:06:09] \u001b[32mTrain: [ 33/50] Step 020/520 Loss 1.917 Prec@(1,5) (60.5%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:06:09] \u001b[32mTrain: [ 33/50] Step 040/520 Loss 1.917 Prec@(1,5) (60.7%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:06:10] \u001b[32mTrain: [ 33/50] Step 060/520 Loss 1.906 Prec@(1,5) (61.4%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:06:10] \u001b[32mTrain: [ 33/50] Step 080/520 Loss 1.906 Prec@(1,5) (61.4%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:06:11] \u001b[32mTrain: [ 33/50] Step 100/520 Loss 1.902 Prec@(1,5) (61.2%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:06:11] \u001b[32mTrain: [ 33/50] Step 120/520 Loss 1.910 Prec@(1,5) (61.1%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:06:12] \u001b[32mTrain: [ 33/50] Step 140/520 Loss 1.918 Prec@(1,5) (61.1%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:06:12] \u001b[32mTrain: [ 33/50] Step 160/520 Loss 1.933 Prec@(1,5) (60.9%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:06:13] \u001b[32mTrain: [ 33/50] Step 180/520 Loss 1.935 Prec@(1,5) (60.7%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:06:13] \u001b[32mTrain: [ 33/50] Step 200/520 Loss 1.940 Prec@(1,5) (60.6%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:06:14] \u001b[32mTrain: [ 33/50] Step 220/520 Loss 1.941 Prec@(1,5) (60.7%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:06:14] \u001b[32mTrain: [ 33/50] Step 240/520 Loss 1.936 Prec@(1,5) (60.8%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:06:15] \u001b[32mTrain: [ 33/50] Step 260/520 Loss 1.936 Prec@(1,5) (60.8%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:06:15] \u001b[32mTrain: [ 33/50] Step 280/520 Loss 1.933 Prec@(1,5) (60.9%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:06:16] \u001b[32mTrain: [ 33/50] Step 300/520 Loss 1.935 Prec@(1,5) (60.8%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:06:16] \u001b[32mTrain: [ 33/50] Step 320/520 Loss 1.937 Prec@(1,5) (60.8%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:06:17] \u001b[32mTrain: [ 33/50] Step 340/520 Loss 1.936 Prec@(1,5) (60.8%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:06:17] \u001b[32mTrain: [ 33/50] Step 360/520 Loss 1.939 Prec@(1,5) (60.6%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:06:18] \u001b[32mTrain: [ 33/50] Step 380/520 Loss 1.945 Prec@(1,5) (60.5%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:06:18] \u001b[32mTrain: [ 33/50] Step 400/520 Loss 1.946 Prec@(1,5) (60.5%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:06:19] \u001b[32mTrain: [ 33/50] Step 420/520 Loss 1.945 Prec@(1,5) (60.5%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:06:19] \u001b[32mTrain: [ 33/50] Step 440/520 Loss 1.945 Prec@(1,5) (60.5%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:06:20] \u001b[32mTrain: [ 33/50] Step 460/520 Loss 1.946 Prec@(1,5) (60.4%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:06:20] \u001b[32mTrain: [ 33/50] Step 480/520 Loss 1.948 Prec@(1,5) (60.4%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:06:21] \u001b[32mTrain: [ 33/50] Step 500/520 Loss 1.948 Prec@(1,5) (60.4%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:06:21] \u001b[32mTrain: [ 33/50] Step 520/520 Loss 1.949 Prec@(1,5) (60.4%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:06:21] \u001b[32mTrain: [ 33/50] Final Prec@1 60.4280%\u001b[0m\n",
            "[2024-04-02 20:06:25] \u001b[32mValid: [ 33/50] Step 000/104 Loss 1.888 Prec@(1,5) (64.6%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:06:25] \u001b[32mValid: [ 33/50] Step 020/104 Loss 2.161 Prec@(1,5) (55.9%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:06:25] \u001b[32mValid: [ 33/50] Step 040/104 Loss 2.139 Prec@(1,5) (55.8%, 83.9%)\u001b[0m\n",
            "[2024-04-02 20:06:25] \u001b[32mValid: [ 33/50] Step 060/104 Loss 2.111 Prec@(1,5) (56.3%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:06:26] \u001b[32mValid: [ 33/50] Step 080/104 Loss 2.110 Prec@(1,5) (55.8%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:06:26] \u001b[32mValid: [ 33/50] Step 100/104 Loss 2.088 Prec@(1,5) (56.2%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:06:26] \u001b[32mValid: [ 33/50] Step 104/104 Loss 2.090 Prec@(1,5) (56.3%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:06:26] \u001b[32mValid: [ 33/50] Final Prec@1 56.2900%\u001b[0m\n",
            "[2024-04-02 20:06:26] \u001b[32mEpoch 33 LR 0.006479\u001b[0m\n",
            "[2024-04-02 20:06:31] \u001b[32mTrain: [ 34/50] Step 000/520 Loss 1.578 Prec@(1,5) (66.7%, 91.7%)\u001b[0m\n",
            "[2024-04-02 20:06:31] \u001b[32mTrain: [ 34/50] Step 020/520 Loss 1.889 Prec@(1,5) (61.3%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:06:32] \u001b[32mTrain: [ 34/50] Step 040/520 Loss 1.932 Prec@(1,5) (61.4%, 86.8%)\u001b[0m\n",
            "[2024-04-02 20:06:32] \u001b[32mTrain: [ 34/50] Step 060/520 Loss 1.935 Prec@(1,5) (61.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:06:33] \u001b[32mTrain: [ 34/50] Step 080/520 Loss 1.923 Prec@(1,5) (61.7%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:06:33] \u001b[32mTrain: [ 34/50] Step 100/520 Loss 1.915 Prec@(1,5) (61.6%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:06:33] \u001b[32mTrain: [ 34/50] Step 120/520 Loss 1.895 Prec@(1,5) (61.7%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:06:34] \u001b[32mTrain: [ 34/50] Step 140/520 Loss 1.892 Prec@(1,5) (61.8%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:06:34] \u001b[32mTrain: [ 34/50] Step 160/520 Loss 1.898 Prec@(1,5) (61.9%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:06:35] \u001b[32mTrain: [ 34/50] Step 180/520 Loss 1.894 Prec@(1,5) (62.0%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:06:35] \u001b[32mTrain: [ 34/50] Step 200/520 Loss 1.893 Prec@(1,5) (61.9%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:06:36] \u001b[32mTrain: [ 34/50] Step 220/520 Loss 1.900 Prec@(1,5) (61.8%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:06:36] \u001b[32mTrain: [ 34/50] Step 240/520 Loss 1.906 Prec@(1,5) (61.6%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:06:37] \u001b[32mTrain: [ 34/50] Step 260/520 Loss 1.898 Prec@(1,5) (61.7%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:06:37] \u001b[32mTrain: [ 34/50] Step 280/520 Loss 1.901 Prec@(1,5) (61.6%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:06:38] \u001b[32mTrain: [ 34/50] Step 300/520 Loss 1.903 Prec@(1,5) (61.6%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:06:38] \u001b[32mTrain: [ 34/50] Step 320/520 Loss 1.906 Prec@(1,5) (61.6%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:06:39] \u001b[32mTrain: [ 34/50] Step 340/520 Loss 1.906 Prec@(1,5) (61.5%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:06:39] \u001b[32mTrain: [ 34/50] Step 360/520 Loss 1.908 Prec@(1,5) (61.4%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:06:40] \u001b[32mTrain: [ 34/50] Step 380/520 Loss 1.911 Prec@(1,5) (61.3%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:06:40] \u001b[32mTrain: [ 34/50] Step 400/520 Loss 1.906 Prec@(1,5) (61.5%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:06:41] \u001b[32mTrain: [ 34/50] Step 420/520 Loss 1.907 Prec@(1,5) (61.4%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:06:41] \u001b[32mTrain: [ 34/50] Step 440/520 Loss 1.913 Prec@(1,5) (61.3%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:06:42] \u001b[32mTrain: [ 34/50] Step 460/520 Loss 1.911 Prec@(1,5) (61.4%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:06:42] \u001b[32mTrain: [ 34/50] Step 480/520 Loss 1.911 Prec@(1,5) (61.4%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:06:43] \u001b[32mTrain: [ 34/50] Step 500/520 Loss 1.913 Prec@(1,5) (61.4%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:06:43] \u001b[32mTrain: [ 34/50] Step 520/520 Loss 1.913 Prec@(1,5) (61.4%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:06:43] \u001b[32mTrain: [ 34/50] Final Prec@1 61.3940%\u001b[0m\n",
            "[2024-04-02 20:06:47] \u001b[32mValid: [ 34/50] Step 000/104 Loss 1.822 Prec@(1,5) (62.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:06:47] \u001b[32mValid: [ 34/50] Step 020/104 Loss 1.980 Prec@(1,5) (58.2%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:06:47] \u001b[32mValid: [ 34/50] Step 040/104 Loss 1.981 Prec@(1,5) (57.6%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:06:48] \u001b[32mValid: [ 34/50] Step 060/104 Loss 1.943 Prec@(1,5) (58.3%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:06:48] \u001b[32mValid: [ 34/50] Step 080/104 Loss 1.947 Prec@(1,5) (58.0%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:06:48] \u001b[32mValid: [ 34/50] Step 100/104 Loss 1.924 Prec@(1,5) (58.2%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:06:48] \u001b[32mValid: [ 34/50] Step 104/104 Loss 1.927 Prec@(1,5) (58.2%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:06:48] \u001b[32mValid: [ 34/50] Final Prec@1 58.2100%\u001b[0m\n",
            "[2024-04-02 20:06:48] \u001b[32mEpoch 34 LR 0.005803\u001b[0m\n",
            "[2024-04-02 20:06:53] \u001b[32mTrain: [ 35/50] Step 000/520 Loss 1.864 Prec@(1,5) (62.5%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:06:53] \u001b[32mTrain: [ 35/50] Step 020/520 Loss 1.854 Prec@(1,5) (61.5%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:06:54] \u001b[32mTrain: [ 35/50] Step 040/520 Loss 1.839 Prec@(1,5) (61.9%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:06:54] \u001b[32mTrain: [ 35/50] Step 060/520 Loss 1.841 Prec@(1,5) (62.0%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:06:55] \u001b[32mTrain: [ 35/50] Step 080/520 Loss 1.854 Prec@(1,5) (62.2%, 88.1%)\u001b[0m\n",
            "[2024-04-02 20:06:55] \u001b[32mTrain: [ 35/50] Step 100/520 Loss 1.856 Prec@(1,5) (62.4%, 88.1%)\u001b[0m\n",
            "[2024-04-02 20:06:56] \u001b[32mTrain: [ 35/50] Step 120/520 Loss 1.863 Prec@(1,5) (62.2%, 88.1%)\u001b[0m\n",
            "[2024-04-02 20:06:56] \u001b[32mTrain: [ 35/50] Step 140/520 Loss 1.873 Prec@(1,5) (62.1%, 88.1%)\u001b[0m\n",
            "[2024-04-02 20:06:57] \u001b[32mTrain: [ 35/50] Step 160/520 Loss 1.873 Prec@(1,5) (62.1%, 88.1%)\u001b[0m\n",
            "[2024-04-02 20:06:57] \u001b[32mTrain: [ 35/50] Step 180/520 Loss 1.875 Prec@(1,5) (62.2%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:06:58] \u001b[32mTrain: [ 35/50] Step 200/520 Loss 1.866 Prec@(1,5) (62.4%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:06:58] \u001b[32mTrain: [ 35/50] Step 220/520 Loss 1.867 Prec@(1,5) (62.4%, 88.1%)\u001b[0m\n",
            "[2024-04-02 20:06:59] \u001b[32mTrain: [ 35/50] Step 240/520 Loss 1.872 Prec@(1,5) (62.3%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:06:59] \u001b[32mTrain: [ 35/50] Step 260/520 Loss 1.873 Prec@(1,5) (62.2%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:07:00] \u001b[32mTrain: [ 35/50] Step 280/520 Loss 1.873 Prec@(1,5) (62.2%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:07:00] \u001b[32mTrain: [ 35/50] Step 300/520 Loss 1.874 Prec@(1,5) (62.2%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:07:01] \u001b[32mTrain: [ 35/50] Step 320/520 Loss 1.875 Prec@(1,5) (62.2%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:07:01] \u001b[32mTrain: [ 35/50] Step 340/520 Loss 1.876 Prec@(1,5) (62.2%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:07:02] \u001b[32mTrain: [ 35/50] Step 360/520 Loss 1.875 Prec@(1,5) (62.2%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:07:02] \u001b[32mTrain: [ 35/50] Step 380/520 Loss 1.879 Prec@(1,5) (62.0%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:07:03] \u001b[32mTrain: [ 35/50] Step 400/520 Loss 1.880 Prec@(1,5) (62.0%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:07:03] \u001b[32mTrain: [ 35/50] Step 420/520 Loss 1.879 Prec@(1,5) (62.0%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:07:04] \u001b[32mTrain: [ 35/50] Step 440/520 Loss 1.880 Prec@(1,5) (62.0%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:07:04] \u001b[32mTrain: [ 35/50] Step 460/520 Loss 1.881 Prec@(1,5) (62.0%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:07:05] \u001b[32mTrain: [ 35/50] Step 480/520 Loss 1.885 Prec@(1,5) (61.9%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:07:05] \u001b[32mTrain: [ 35/50] Step 500/520 Loss 1.884 Prec@(1,5) (61.9%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:07:06] \u001b[32mTrain: [ 35/50] Step 520/520 Loss 1.882 Prec@(1,5) (62.0%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:07:06] \u001b[32mTrain: [ 35/50] Final Prec@1 62.0040%\u001b[0m\n",
            "[2024-04-02 20:07:09] \u001b[32mValid: [ 35/50] Step 000/104 Loss 1.786 Prec@(1,5) (62.5%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:07:09] \u001b[32mValid: [ 35/50] Step 020/104 Loss 2.055 Prec@(1,5) (57.1%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:07:10] \u001b[32mValid: [ 35/50] Step 040/104 Loss 2.048 Prec@(1,5) (57.2%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:07:10] \u001b[32mValid: [ 35/50] Step 060/104 Loss 2.008 Prec@(1,5) (57.5%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:07:10] \u001b[32mValid: [ 35/50] Step 080/104 Loss 2.009 Prec@(1,5) (57.4%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:07:10] \u001b[32mValid: [ 35/50] Step 100/104 Loss 1.987 Prec@(1,5) (57.9%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:07:10] \u001b[32mValid: [ 35/50] Step 104/104 Loss 1.989 Prec@(1,5) (58.0%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:07:10] \u001b[32mValid: [ 35/50] Final Prec@1 57.9500%\u001b[0m\n",
            "[2024-04-02 20:07:10] \u001b[32mEpoch 35 LR 0.005153\u001b[0m\n",
            "[2024-04-02 20:07:15] \u001b[32mTrain: [ 36/50] Step 000/520 Loss 1.545 Prec@(1,5) (72.9%, 91.7%)\u001b[0m\n",
            "[2024-04-02 20:07:15] \u001b[32mTrain: [ 36/50] Step 020/520 Loss 1.846 Prec@(1,5) (63.0%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:07:16] \u001b[32mTrain: [ 36/50] Step 040/520 Loss 1.823 Prec@(1,5) (63.6%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:07:16] \u001b[32mTrain: [ 36/50] Step 060/520 Loss 1.853 Prec@(1,5) (63.0%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:07:17] \u001b[32mTrain: [ 36/50] Step 080/520 Loss 1.855 Prec@(1,5) (62.9%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:07:17] \u001b[32mTrain: [ 36/50] Step 100/520 Loss 1.862 Prec@(1,5) (62.7%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:07:18] \u001b[32mTrain: [ 36/50] Step 120/520 Loss 1.848 Prec@(1,5) (62.9%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:07:18] \u001b[32mTrain: [ 36/50] Step 140/520 Loss 1.842 Prec@(1,5) (63.1%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:07:19] \u001b[32mTrain: [ 36/50] Step 160/520 Loss 1.841 Prec@(1,5) (63.0%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:07:19] \u001b[32mTrain: [ 36/50] Step 180/520 Loss 1.846 Prec@(1,5) (62.9%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:07:20] \u001b[32mTrain: [ 36/50] Step 200/520 Loss 1.854 Prec@(1,5) (62.7%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:07:20] \u001b[32mTrain: [ 36/50] Step 220/520 Loss 1.848 Prec@(1,5) (62.8%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:07:21] \u001b[32mTrain: [ 36/50] Step 240/520 Loss 1.847 Prec@(1,5) (62.9%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:07:21] \u001b[32mTrain: [ 36/50] Step 260/520 Loss 1.845 Prec@(1,5) (63.0%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:07:22] \u001b[32mTrain: [ 36/50] Step 280/520 Loss 1.847 Prec@(1,5) (62.8%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:07:22] \u001b[32mTrain: [ 36/50] Step 300/520 Loss 1.847 Prec@(1,5) (62.8%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:07:23] \u001b[32mTrain: [ 36/50] Step 320/520 Loss 1.849 Prec@(1,5) (62.8%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:07:23] \u001b[32mTrain: [ 36/50] Step 340/520 Loss 1.845 Prec@(1,5) (62.8%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:07:24] \u001b[32mTrain: [ 36/50] Step 360/520 Loss 1.848 Prec@(1,5) (62.8%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:07:24] \u001b[32mTrain: [ 36/50] Step 380/520 Loss 1.848 Prec@(1,5) (62.8%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:07:25] \u001b[32mTrain: [ 36/50] Step 400/520 Loss 1.850 Prec@(1,5) (62.7%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:07:25] \u001b[32mTrain: [ 36/50] Step 420/520 Loss 1.853 Prec@(1,5) (62.7%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:07:26] \u001b[32mTrain: [ 36/50] Step 440/520 Loss 1.849 Prec@(1,5) (62.7%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:07:26] \u001b[32mTrain: [ 36/50] Step 460/520 Loss 1.851 Prec@(1,5) (62.7%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:07:27] \u001b[32mTrain: [ 36/50] Step 480/520 Loss 1.856 Prec@(1,5) (62.6%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:07:27] \u001b[32mTrain: [ 36/50] Step 500/520 Loss 1.856 Prec@(1,5) (62.5%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:07:28] \u001b[32mTrain: [ 36/50] Step 520/520 Loss 1.858 Prec@(1,5) (62.5%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:07:28] \u001b[32mTrain: [ 36/50] Final Prec@1 62.4900%\u001b[0m\n",
            "[2024-04-02 20:07:31] \u001b[32mValid: [ 36/50] Step 000/104 Loss 1.866 Prec@(1,5) (61.5%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:07:32] \u001b[32mValid: [ 36/50] Step 020/104 Loss 1.973 Prec@(1,5) (58.6%, 86.4%)\u001b[0m\n",
            "[2024-04-02 20:07:32] \u001b[32mValid: [ 36/50] Step 040/104 Loss 1.968 Prec@(1,5) (58.4%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:07:32] \u001b[32mValid: [ 36/50] Step 060/104 Loss 1.934 Prec@(1,5) (58.5%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:07:32] \u001b[32mValid: [ 36/50] Step 080/104 Loss 1.930 Prec@(1,5) (58.3%, 86.1%)\u001b[0m\n",
            "[2024-04-02 20:07:32] \u001b[32mValid: [ 36/50] Step 100/104 Loss 1.910 Prec@(1,5) (58.6%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:07:32] \u001b[32mValid: [ 36/50] Step 104/104 Loss 1.913 Prec@(1,5) (58.6%, 86.1%)\u001b[0m\n",
            "[2024-04-02 20:07:33] \u001b[32mValid: [ 36/50] Final Prec@1 58.5800%\u001b[0m\n",
            "[2024-04-02 20:07:33] \u001b[32mEpoch 36 LR 0.004533\u001b[0m\n",
            "[2024-04-02 20:07:37] \u001b[32mTrain: [ 37/50] Step 000/520 Loss 1.692 Prec@(1,5) (65.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:07:38] \u001b[32mTrain: [ 37/50] Step 020/520 Loss 1.848 Prec@(1,5) (61.9%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:07:38] \u001b[32mTrain: [ 37/50] Step 040/520 Loss 1.847 Prec@(1,5) (63.0%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:07:39] \u001b[32mTrain: [ 37/50] Step 060/520 Loss 1.844 Prec@(1,5) (62.9%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:07:39] \u001b[32mTrain: [ 37/50] Step 080/520 Loss 1.850 Prec@(1,5) (62.6%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:07:40] \u001b[32mTrain: [ 37/50] Step 100/520 Loss 1.843 Prec@(1,5) (62.7%, 88.1%)\u001b[0m\n",
            "[2024-04-02 20:07:40] \u001b[32mTrain: [ 37/50] Step 120/520 Loss 1.833 Prec@(1,5) (62.9%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:07:41] \u001b[32mTrain: [ 37/50] Step 140/520 Loss 1.830 Prec@(1,5) (63.0%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:07:41] \u001b[32mTrain: [ 37/50] Step 160/520 Loss 1.836 Prec@(1,5) (63.0%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:07:42] \u001b[32mTrain: [ 37/50] Step 180/520 Loss 1.842 Prec@(1,5) (62.9%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:07:42] \u001b[32mTrain: [ 37/50] Step 200/520 Loss 1.844 Prec@(1,5) (62.7%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:07:43] \u001b[32mTrain: [ 37/50] Step 220/520 Loss 1.847 Prec@(1,5) (62.7%, 88.1%)\u001b[0m\n",
            "[2024-04-02 20:07:43] \u001b[32mTrain: [ 37/50] Step 240/520 Loss 1.847 Prec@(1,5) (62.8%, 88.1%)\u001b[0m\n",
            "[2024-04-02 20:07:44] \u001b[32mTrain: [ 37/50] Step 260/520 Loss 1.845 Prec@(1,5) (62.9%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:07:44] \u001b[32mTrain: [ 37/50] Step 280/520 Loss 1.839 Prec@(1,5) (63.0%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:07:45] \u001b[32mTrain: [ 37/50] Step 300/520 Loss 1.839 Prec@(1,5) (63.1%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:07:45] \u001b[32mTrain: [ 37/50] Step 320/520 Loss 1.840 Prec@(1,5) (63.0%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:07:46] \u001b[32mTrain: [ 37/50] Step 340/520 Loss 1.837 Prec@(1,5) (63.1%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:07:46] \u001b[32mTrain: [ 37/50] Step 360/520 Loss 1.838 Prec@(1,5) (63.1%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:07:47] \u001b[32mTrain: [ 37/50] Step 380/520 Loss 1.834 Prec@(1,5) (63.1%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:07:47] \u001b[32mTrain: [ 37/50] Step 400/520 Loss 1.834 Prec@(1,5) (63.1%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:07:48] \u001b[32mTrain: [ 37/50] Step 420/520 Loss 1.838 Prec@(1,5) (63.0%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:07:48] \u001b[32mTrain: [ 37/50] Step 440/520 Loss 1.838 Prec@(1,5) (63.0%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:07:49] \u001b[32mTrain: [ 37/50] Step 460/520 Loss 1.842 Prec@(1,5) (62.9%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:07:49] \u001b[32mTrain: [ 37/50] Step 480/520 Loss 1.842 Prec@(1,5) (62.9%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:07:50] \u001b[32mTrain: [ 37/50] Step 500/520 Loss 1.841 Prec@(1,5) (62.9%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:07:50] \u001b[32mTrain: [ 37/50] Step 520/520 Loss 1.842 Prec@(1,5) (62.8%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:07:50] \u001b[32mTrain: [ 37/50] Final Prec@1 62.8480%\u001b[0m\n",
            "[2024-04-02 20:07:54] \u001b[32mValid: [ 37/50] Step 000/104 Loss 1.903 Prec@(1,5) (61.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:07:54] \u001b[32mValid: [ 37/50] Step 020/104 Loss 2.097 Prec@(1,5) (57.7%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:07:54] \u001b[32mValid: [ 37/50] Step 040/104 Loss 2.086 Prec@(1,5) (57.7%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:07:54] \u001b[32mValid: [ 37/50] Step 060/104 Loss 2.049 Prec@(1,5) (58.2%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:07:54] \u001b[32mValid: [ 37/50] Step 080/104 Loss 2.038 Prec@(1,5) (58.0%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:07:55] \u001b[32mValid: [ 37/50] Step 100/104 Loss 2.018 Prec@(1,5) (58.2%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:07:55] \u001b[32mValid: [ 37/50] Step 104/104 Loss 2.023 Prec@(1,5) (58.1%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:07:55] \u001b[32mValid: [ 37/50] Final Prec@1 58.1300%\u001b[0m\n",
            "[2024-04-02 20:07:55] \u001b[32mEpoch 37 LR 0.003944\u001b[0m\n",
            "[2024-04-02 20:07:59] \u001b[32mTrain: [ 38/50] Step 000/520 Loss 1.807 Prec@(1,5) (57.3%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:08:00] \u001b[32mTrain: [ 38/50] Step 020/520 Loss 1.850 Prec@(1,5) (63.4%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:08:00] \u001b[32mTrain: [ 38/50] Step 040/520 Loss 1.821 Prec@(1,5) (63.6%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:08:01] \u001b[32mTrain: [ 38/50] Step 060/520 Loss 1.797 Prec@(1,5) (64.2%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:08:01] \u001b[32mTrain: [ 38/50] Step 080/520 Loss 1.801 Prec@(1,5) (63.5%, 88.7%)\u001b[0m\n",
            "[2024-04-02 20:08:02] \u001b[32mTrain: [ 38/50] Step 100/520 Loss 1.816 Prec@(1,5) (63.1%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:08:02] \u001b[32mTrain: [ 38/50] Step 120/520 Loss 1.818 Prec@(1,5) (63.1%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:08:03] \u001b[32mTrain: [ 38/50] Step 140/520 Loss 1.814 Prec@(1,5) (63.2%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:08:03] \u001b[32mTrain: [ 38/50] Step 160/520 Loss 1.812 Prec@(1,5) (63.5%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:08:04] \u001b[32mTrain: [ 38/50] Step 180/520 Loss 1.810 Prec@(1,5) (63.6%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:08:04] \u001b[32mTrain: [ 38/50] Step 200/520 Loss 1.814 Prec@(1,5) (63.5%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:08:05] \u001b[32mTrain: [ 38/50] Step 220/520 Loss 1.810 Prec@(1,5) (63.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:08:05] \u001b[32mTrain: [ 38/50] Step 240/520 Loss 1.808 Prec@(1,5) (63.7%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:08:06] \u001b[32mTrain: [ 38/50] Step 260/520 Loss 1.807 Prec@(1,5) (63.7%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:08:06] \u001b[32mTrain: [ 38/50] Step 280/520 Loss 1.807 Prec@(1,5) (63.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:08:07] \u001b[32mTrain: [ 38/50] Step 300/520 Loss 1.810 Prec@(1,5) (63.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:08:07] \u001b[32mTrain: [ 38/50] Step 320/520 Loss 1.807 Prec@(1,5) (63.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:08:08] \u001b[32mTrain: [ 38/50] Step 340/520 Loss 1.809 Prec@(1,5) (63.7%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:08:08] \u001b[32mTrain: [ 38/50] Step 360/520 Loss 1.806 Prec@(1,5) (63.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:08:09] \u001b[32mTrain: [ 38/50] Step 380/520 Loss 1.810 Prec@(1,5) (63.6%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:08:09] \u001b[32mTrain: [ 38/50] Step 400/520 Loss 1.811 Prec@(1,5) (63.6%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:08:10] \u001b[32mTrain: [ 38/50] Step 420/520 Loss 1.816 Prec@(1,5) (63.5%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:08:10] \u001b[32mTrain: [ 38/50] Step 440/520 Loss 1.819 Prec@(1,5) (63.5%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:08:11] \u001b[32mTrain: [ 38/50] Step 460/520 Loss 1.820 Prec@(1,5) (63.5%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:08:11] \u001b[32mTrain: [ 38/50] Step 480/520 Loss 1.823 Prec@(1,5) (63.4%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:08:12] \u001b[32mTrain: [ 38/50] Step 500/520 Loss 1.824 Prec@(1,5) (63.3%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:08:12] \u001b[32mTrain: [ 38/50] Step 520/520 Loss 1.824 Prec@(1,5) (63.3%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:08:12] \u001b[32mTrain: [ 38/50] Final Prec@1 63.3080%\u001b[0m\n",
            "[2024-04-02 20:08:16] \u001b[32mValid: [ 38/50] Step 000/104 Loss 1.851 Prec@(1,5) (61.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:08:16] \u001b[32mValid: [ 38/50] Step 020/104 Loss 1.912 Prec@(1,5) (60.0%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:08:16] \u001b[32mValid: [ 38/50] Step 040/104 Loss 1.888 Prec@(1,5) (59.6%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:08:16] \u001b[32mValid: [ 38/50] Step 060/104 Loss 1.860 Prec@(1,5) (59.9%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:08:17] \u001b[32mValid: [ 38/50] Step 080/104 Loss 1.858 Prec@(1,5) (59.7%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:08:17] \u001b[32mValid: [ 38/50] Step 100/104 Loss 1.833 Prec@(1,5) (59.8%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:08:17] \u001b[32mValid: [ 38/50] Step 104/104 Loss 1.837 Prec@(1,5) (59.8%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:08:17] \u001b[32mValid: [ 38/50] Final Prec@1 59.7700%\u001b[0m\n",
            "[2024-04-02 20:08:17] \u001b[32mEpoch 38 LR 0.003389\u001b[0m\n",
            "[2024-04-02 20:08:22] \u001b[32mTrain: [ 39/50] Step 000/520 Loss 1.731 Prec@(1,5) (71.9%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:08:22] \u001b[32mTrain: [ 39/50] Step 020/520 Loss 1.754 Prec@(1,5) (65.3%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:08:23] \u001b[32mTrain: [ 39/50] Step 040/520 Loss 1.731 Prec@(1,5) (65.0%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:08:23] \u001b[32mTrain: [ 39/50] Step 060/520 Loss 1.743 Prec@(1,5) (64.9%, 88.7%)\u001b[0m\n",
            "[2024-04-02 20:08:24] \u001b[32mTrain: [ 39/50] Step 080/520 Loss 1.755 Prec@(1,5) (64.8%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:08:24] \u001b[32mTrain: [ 39/50] Step 100/520 Loss 1.746 Prec@(1,5) (64.7%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:08:24] \u001b[32mTrain: [ 39/50] Step 120/520 Loss 1.759 Prec@(1,5) (64.7%, 88.7%)\u001b[0m\n",
            "[2024-04-02 20:08:25] \u001b[32mTrain: [ 39/50] Step 140/520 Loss 1.770 Prec@(1,5) (64.6%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:08:25] \u001b[32mTrain: [ 39/50] Step 160/520 Loss 1.774 Prec@(1,5) (64.5%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:08:26] \u001b[32mTrain: [ 39/50] Step 180/520 Loss 1.778 Prec@(1,5) (64.5%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:08:26] \u001b[32mTrain: [ 39/50] Step 200/520 Loss 1.780 Prec@(1,5) (64.4%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:08:27] \u001b[32mTrain: [ 39/50] Step 220/520 Loss 1.785 Prec@(1,5) (64.2%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:08:27] \u001b[32mTrain: [ 39/50] Step 240/520 Loss 1.787 Prec@(1,5) (64.1%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:08:28] \u001b[32mTrain: [ 39/50] Step 260/520 Loss 1.797 Prec@(1,5) (63.8%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:08:28] \u001b[32mTrain: [ 39/50] Step 280/520 Loss 1.796 Prec@(1,5) (63.9%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:08:29] \u001b[32mTrain: [ 39/50] Step 300/520 Loss 1.801 Prec@(1,5) (63.7%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:08:29] \u001b[32mTrain: [ 39/50] Step 320/520 Loss 1.803 Prec@(1,5) (63.7%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:08:30] \u001b[32mTrain: [ 39/50] Step 340/520 Loss 1.801 Prec@(1,5) (63.8%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:08:30] \u001b[32mTrain: [ 39/50] Step 360/520 Loss 1.797 Prec@(1,5) (63.9%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:08:31] \u001b[32mTrain: [ 39/50] Step 380/520 Loss 1.798 Prec@(1,5) (63.8%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:08:31] \u001b[32mTrain: [ 39/50] Step 400/520 Loss 1.798 Prec@(1,5) (63.8%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:08:32] \u001b[32mTrain: [ 39/50] Step 420/520 Loss 1.800 Prec@(1,5) (63.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:08:32] \u001b[32mTrain: [ 39/50] Step 440/520 Loss 1.801 Prec@(1,5) (63.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:08:33] \u001b[32mTrain: [ 39/50] Step 460/520 Loss 1.802 Prec@(1,5) (63.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:08:33] \u001b[32mTrain: [ 39/50] Step 480/520 Loss 1.806 Prec@(1,5) (63.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:08:34] \u001b[32mTrain: [ 39/50] Step 500/520 Loss 1.806 Prec@(1,5) (63.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:08:34] \u001b[32mTrain: [ 39/50] Step 520/520 Loss 1.808 Prec@(1,5) (63.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:08:35] \u001b[32mTrain: [ 39/50] Final Prec@1 63.5780%\u001b[0m\n",
            "[2024-04-02 20:08:38] \u001b[32mValid: [ 39/50] Step 000/104 Loss 1.868 Prec@(1,5) (61.5%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:08:38] \u001b[32mValid: [ 39/50] Step 020/104 Loss 2.034 Prec@(1,5) (58.9%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:08:38] \u001b[32mValid: [ 39/50] Step 040/104 Loss 1.995 Prec@(1,5) (58.8%, 86.1%)\u001b[0m\n",
            "[2024-04-02 20:08:39] \u001b[32mValid: [ 39/50] Step 060/104 Loss 1.955 Prec@(1,5) (59.0%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:08:39] \u001b[32mValid: [ 39/50] Step 080/104 Loss 1.952 Prec@(1,5) (58.7%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:08:39] \u001b[32mValid: [ 39/50] Step 100/104 Loss 1.925 Prec@(1,5) (59.0%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:08:39] \u001b[32mValid: [ 39/50] Step 104/104 Loss 1.928 Prec@(1,5) (59.1%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:08:39] \u001b[32mValid: [ 39/50] Final Prec@1 59.0600%\u001b[0m\n",
            "[2024-04-02 20:08:39] \u001b[32mEpoch 39 LR 0.002869\u001b[0m\n",
            "[2024-04-02 20:08:44] \u001b[32mTrain: [ 40/50] Step 000/520 Loss 1.618 Prec@(1,5) (64.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:08:44] \u001b[32mTrain: [ 40/50] Step 020/520 Loss 1.820 Prec@(1,5) (64.2%, 88.7%)\u001b[0m\n",
            "[2024-04-02 20:08:45] \u001b[32mTrain: [ 40/50] Step 040/520 Loss 1.825 Prec@(1,5) (63.8%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:08:45] \u001b[32mTrain: [ 40/50] Step 060/520 Loss 1.795 Prec@(1,5) (64.3%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:08:46] \u001b[32mTrain: [ 40/50] Step 080/520 Loss 1.811 Prec@(1,5) (63.9%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:08:46] \u001b[32mTrain: [ 40/50] Step 100/520 Loss 1.791 Prec@(1,5) (64.2%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:08:47] \u001b[32mTrain: [ 40/50] Step 120/520 Loss 1.791 Prec@(1,5) (64.2%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:08:47] \u001b[32mTrain: [ 40/50] Step 140/520 Loss 1.789 Prec@(1,5) (64.1%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:08:48] \u001b[32mTrain: [ 40/50] Step 160/520 Loss 1.789 Prec@(1,5) (64.1%, 88.7%)\u001b[0m\n",
            "[2024-04-02 20:08:48] \u001b[32mTrain: [ 40/50] Step 180/520 Loss 1.778 Prec@(1,5) (64.3%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:08:49] \u001b[32mTrain: [ 40/50] Step 200/520 Loss 1.777 Prec@(1,5) (64.2%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:08:49] \u001b[32mTrain: [ 40/50] Step 220/520 Loss 1.782 Prec@(1,5) (64.1%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:08:50] \u001b[32mTrain: [ 40/50] Step 240/520 Loss 1.780 Prec@(1,5) (64.1%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:08:50] \u001b[32mTrain: [ 40/50] Step 260/520 Loss 1.788 Prec@(1,5) (63.9%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:08:51] \u001b[32mTrain: [ 40/50] Step 280/520 Loss 1.789 Prec@(1,5) (63.9%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:08:51] \u001b[32mTrain: [ 40/50] Step 300/520 Loss 1.787 Prec@(1,5) (63.9%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:08:52] \u001b[32mTrain: [ 40/50] Step 320/520 Loss 1.789 Prec@(1,5) (63.9%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:08:52] \u001b[32mTrain: [ 40/50] Step 340/520 Loss 1.794 Prec@(1,5) (63.8%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:08:53] \u001b[32mTrain: [ 40/50] Step 360/520 Loss 1.796 Prec@(1,5) (63.8%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:08:54] \u001b[32mTrain: [ 40/50] Step 380/520 Loss 1.795 Prec@(1,5) (63.8%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:08:54] \u001b[32mTrain: [ 40/50] Step 400/520 Loss 1.795 Prec@(1,5) (63.8%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:08:55] \u001b[32mTrain: [ 40/50] Step 420/520 Loss 1.792 Prec@(1,5) (63.9%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:08:55] \u001b[32mTrain: [ 40/50] Step 440/520 Loss 1.790 Prec@(1,5) (63.9%, 88.7%)\u001b[0m\n",
            "[2024-04-02 20:08:56] \u001b[32mTrain: [ 40/50] Step 460/520 Loss 1.792 Prec@(1,5) (63.8%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:08:56] \u001b[32mTrain: [ 40/50] Step 480/520 Loss 1.790 Prec@(1,5) (63.9%, 88.7%)\u001b[0m\n",
            "[2024-04-02 20:08:57] \u001b[32mTrain: [ 40/50] Step 500/520 Loss 1.787 Prec@(1,5) (63.9%, 88.7%)\u001b[0m\n",
            "[2024-04-02 20:08:57] \u001b[32mTrain: [ 40/50] Step 520/520 Loss 1.785 Prec@(1,5) (63.9%, 88.7%)\u001b[0m\n",
            "[2024-04-02 20:08:57] \u001b[32mTrain: [ 40/50] Final Prec@1 63.9240%\u001b[0m\n",
            "[2024-04-02 20:09:01] \u001b[32mValid: [ 40/50] Step 000/104 Loss 1.934 Prec@(1,5) (59.4%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:09:01] \u001b[32mValid: [ 40/50] Step 020/104 Loss 1.971 Prec@(1,5) (58.9%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:09:01] \u001b[32mValid: [ 40/50] Step 040/104 Loss 1.945 Prec@(1,5) (58.7%, 86.1%)\u001b[0m\n",
            "[2024-04-02 20:09:01] \u001b[32mValid: [ 40/50] Step 060/104 Loss 1.902 Prec@(1,5) (59.4%, 86.4%)\u001b[0m\n",
            "[2024-04-02 20:09:01] \u001b[32mValid: [ 40/50] Step 080/104 Loss 1.897 Prec@(1,5) (59.1%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:09:02] \u001b[32mValid: [ 40/50] Step 100/104 Loss 1.873 Prec@(1,5) (59.3%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:09:02] \u001b[32mValid: [ 40/50] Step 104/104 Loss 1.876 Prec@(1,5) (59.4%, 86.4%)\u001b[0m\n",
            "[2024-04-02 20:09:02] \u001b[32mValid: [ 40/50] Final Prec@1 59.3600%\u001b[0m\n",
            "[2024-04-02 20:09:02] \u001b[32mEpoch 40 LR 0.002388\u001b[0m\n",
            "[2024-04-02 20:09:06] \u001b[32mTrain: [ 41/50] Step 000/520 Loss 1.850 Prec@(1,5) (67.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:09:07] \u001b[32mTrain: [ 41/50] Step 020/520 Loss 1.736 Prec@(1,5) (64.5%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:09:07] \u001b[32mTrain: [ 41/50] Step 040/520 Loss 1.731 Prec@(1,5) (65.0%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:09:08] \u001b[32mTrain: [ 41/50] Step 060/520 Loss 1.704 Prec@(1,5) (65.6%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:09:08] \u001b[32mTrain: [ 41/50] Step 080/520 Loss 1.717 Prec@(1,5) (65.5%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:09:09] \u001b[32mTrain: [ 41/50] Step 100/520 Loss 1.722 Prec@(1,5) (65.2%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:09:09] \u001b[32mTrain: [ 41/50] Step 120/520 Loss 1.742 Prec@(1,5) (64.9%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:09:10] \u001b[32mTrain: [ 41/50] Step 140/520 Loss 1.746 Prec@(1,5) (64.7%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:09:10] \u001b[32mTrain: [ 41/50] Step 160/520 Loss 1.752 Prec@(1,5) (64.7%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:09:11] \u001b[32mTrain: [ 41/50] Step 180/520 Loss 1.754 Prec@(1,5) (64.6%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:09:11] \u001b[32mTrain: [ 41/50] Step 200/520 Loss 1.750 Prec@(1,5) (64.8%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:09:12] \u001b[32mTrain: [ 41/50] Step 220/520 Loss 1.748 Prec@(1,5) (64.7%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:09:12] \u001b[32mTrain: [ 41/50] Step 240/520 Loss 1.751 Prec@(1,5) (64.7%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:09:13] \u001b[32mTrain: [ 41/50] Step 260/520 Loss 1.755 Prec@(1,5) (64.7%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:09:13] \u001b[32mTrain: [ 41/50] Step 280/520 Loss 1.751 Prec@(1,5) (64.6%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:09:14] \u001b[32mTrain: [ 41/50] Step 300/520 Loss 1.752 Prec@(1,5) (64.6%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:09:14] \u001b[32mTrain: [ 41/50] Step 320/520 Loss 1.752 Prec@(1,5) (64.6%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:09:15] \u001b[32mTrain: [ 41/50] Step 340/520 Loss 1.755 Prec@(1,5) (64.6%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:09:15] \u001b[32mTrain: [ 41/50] Step 360/520 Loss 1.756 Prec@(1,5) (64.6%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:09:16] \u001b[32mTrain: [ 41/50] Step 380/520 Loss 1.754 Prec@(1,5) (64.6%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:09:16] \u001b[32mTrain: [ 41/50] Step 400/520 Loss 1.755 Prec@(1,5) (64.5%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:09:17] \u001b[32mTrain: [ 41/50] Step 420/520 Loss 1.760 Prec@(1,5) (64.5%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:09:17] \u001b[32mTrain: [ 41/50] Step 440/520 Loss 1.759 Prec@(1,5) (64.5%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:09:18] \u001b[32mTrain: [ 41/50] Step 460/520 Loss 1.760 Prec@(1,5) (64.4%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:09:18] \u001b[32mTrain: [ 41/50] Step 480/520 Loss 1.760 Prec@(1,5) (64.4%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:09:19] \u001b[32mTrain: [ 41/50] Step 500/520 Loss 1.765 Prec@(1,5) (64.3%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:09:19] \u001b[32mTrain: [ 41/50] Step 520/520 Loss 1.766 Prec@(1,5) (64.3%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:09:19] \u001b[32mTrain: [ 41/50] Final Prec@1 64.3040%\u001b[0m\n",
            "[2024-04-02 20:09:23] \u001b[32mValid: [ 41/50] Step 000/104 Loss 1.827 Prec@(1,5) (62.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:09:23] \u001b[32mValid: [ 41/50] Step 020/104 Loss 1.943 Prec@(1,5) (60.2%, 86.8%)\u001b[0m\n",
            "[2024-04-02 20:09:23] \u001b[32mValid: [ 41/50] Step 040/104 Loss 1.910 Prec@(1,5) (59.9%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:09:23] \u001b[32mValid: [ 41/50] Step 060/104 Loss 1.871 Prec@(1,5) (60.2%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:09:24] \u001b[32mValid: [ 41/50] Step 080/104 Loss 1.870 Prec@(1,5) (60.0%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:09:24] \u001b[32mValid: [ 41/50] Step 100/104 Loss 1.848 Prec@(1,5) (60.3%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:09:24] \u001b[32mValid: [ 41/50] Step 104/104 Loss 1.851 Prec@(1,5) (60.3%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:09:24] \u001b[32mValid: [ 41/50] Final Prec@1 60.3000%\u001b[0m\n",
            "[2024-04-02 20:09:24] \u001b[32mEpoch 41 LR 0.001947\u001b[0m\n",
            "[2024-04-02 20:09:29] \u001b[32mTrain: [ 42/50] Step 000/520 Loss 1.775 Prec@(1,5) (66.7%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:09:29] \u001b[32mTrain: [ 42/50] Step 020/520 Loss 1.696 Prec@(1,5) (65.2%, 90.2%)\u001b[0m\n",
            "[2024-04-02 20:09:30] \u001b[32mTrain: [ 42/50] Step 040/520 Loss 1.694 Prec@(1,5) (65.2%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:09:30] \u001b[32mTrain: [ 42/50] Step 060/520 Loss 1.702 Prec@(1,5) (65.0%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:09:31] \u001b[32mTrain: [ 42/50] Step 080/520 Loss 1.714 Prec@(1,5) (64.8%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:09:31] \u001b[32mTrain: [ 42/50] Step 100/520 Loss 1.709 Prec@(1,5) (65.1%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:09:32] \u001b[32mTrain: [ 42/50] Step 120/520 Loss 1.724 Prec@(1,5) (64.8%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:09:32] \u001b[32mTrain: [ 42/50] Step 140/520 Loss 1.727 Prec@(1,5) (64.7%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:09:33] \u001b[32mTrain: [ 42/50] Step 160/520 Loss 1.730 Prec@(1,5) (64.6%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:09:33] \u001b[32mTrain: [ 42/50] Step 180/520 Loss 1.733 Prec@(1,5) (64.6%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:09:33] \u001b[32mTrain: [ 42/50] Step 200/520 Loss 1.725 Prec@(1,5) (64.7%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:09:34] \u001b[32mTrain: [ 42/50] Step 220/520 Loss 1.728 Prec@(1,5) (64.7%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:09:34] \u001b[32mTrain: [ 42/50] Step 240/520 Loss 1.726 Prec@(1,5) (64.8%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:09:35] \u001b[32mTrain: [ 42/50] Step 260/520 Loss 1.727 Prec@(1,5) (64.8%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:09:35] \u001b[32mTrain: [ 42/50] Step 280/520 Loss 1.727 Prec@(1,5) (64.7%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:09:36] \u001b[32mTrain: [ 42/50] Step 300/520 Loss 1.732 Prec@(1,5) (64.7%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:09:36] \u001b[32mTrain: [ 42/50] Step 320/520 Loss 1.738 Prec@(1,5) (64.6%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:09:37] \u001b[32mTrain: [ 42/50] Step 340/520 Loss 1.736 Prec@(1,5) (64.6%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:09:37] \u001b[32mTrain: [ 42/50] Step 360/520 Loss 1.738 Prec@(1,5) (64.6%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:09:38] \u001b[32mTrain: [ 42/50] Step 380/520 Loss 1.741 Prec@(1,5) (64.5%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:09:38] \u001b[32mTrain: [ 42/50] Step 400/520 Loss 1.739 Prec@(1,5) (64.5%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:09:39] \u001b[32mTrain: [ 42/50] Step 420/520 Loss 1.742 Prec@(1,5) (64.4%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:09:39] \u001b[32mTrain: [ 42/50] Step 440/520 Loss 1.745 Prec@(1,5) (64.4%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:09:40] \u001b[32mTrain: [ 42/50] Step 460/520 Loss 1.746 Prec@(1,5) (64.4%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:09:40] \u001b[32mTrain: [ 42/50] Step 480/520 Loss 1.748 Prec@(1,5) (64.4%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:09:41] \u001b[32mTrain: [ 42/50] Step 500/520 Loss 1.751 Prec@(1,5) (64.3%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:09:41] \u001b[32mTrain: [ 42/50] Step 520/520 Loss 1.749 Prec@(1,5) (64.4%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:09:42] \u001b[32mTrain: [ 42/50] Final Prec@1 64.3640%\u001b[0m\n",
            "[2024-04-02 20:09:45] \u001b[32mValid: [ 42/50] Step 000/104 Loss 1.757 Prec@(1,5) (63.5%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:09:45] \u001b[32mValid: [ 42/50] Step 020/104 Loss 1.951 Prec@(1,5) (59.6%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:09:45] \u001b[32mValid: [ 42/50] Step 040/104 Loss 1.915 Prec@(1,5) (59.3%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:09:46] \u001b[32mValid: [ 42/50] Step 060/104 Loss 1.871 Prec@(1,5) (59.9%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:09:46] \u001b[32mValid: [ 42/50] Step 080/104 Loss 1.866 Prec@(1,5) (59.6%, 86.8%)\u001b[0m\n",
            "[2024-04-02 20:09:46] \u001b[32mValid: [ 42/50] Step 100/104 Loss 1.844 Prec@(1,5) (60.0%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:09:46] \u001b[32mValid: [ 42/50] Step 104/104 Loss 1.849 Prec@(1,5) (60.0%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:09:46] \u001b[32mValid: [ 42/50] Final Prec@1 60.0300%\u001b[0m\n",
            "[2024-04-02 20:09:46] \u001b[32mEpoch 42 LR 0.001547\u001b[0m\n",
            "[2024-04-02 20:09:51] \u001b[32mTrain: [ 43/50] Step 000/520 Loss 1.539 Prec@(1,5) (67.7%, 91.7%)\u001b[0m\n",
            "[2024-04-02 20:09:51] \u001b[32mTrain: [ 43/50] Step 020/520 Loss 1.748 Prec@(1,5) (65.0%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:09:52] \u001b[32mTrain: [ 43/50] Step 040/520 Loss 1.738 Prec@(1,5) (65.7%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:09:52] \u001b[32mTrain: [ 43/50] Step 060/520 Loss 1.740 Prec@(1,5) (65.6%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:09:53] \u001b[32mTrain: [ 43/50] Step 080/520 Loss 1.733 Prec@(1,5) (65.1%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:09:53] \u001b[32mTrain: [ 43/50] Step 100/520 Loss 1.731 Prec@(1,5) (65.0%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:09:54] \u001b[32mTrain: [ 43/50] Step 120/520 Loss 1.732 Prec@(1,5) (65.1%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:09:54] \u001b[32mTrain: [ 43/50] Step 140/520 Loss 1.734 Prec@(1,5) (65.0%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:09:55] \u001b[32mTrain: [ 43/50] Step 160/520 Loss 1.737 Prec@(1,5) (64.9%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:09:55] \u001b[32mTrain: [ 43/50] Step 180/520 Loss 1.739 Prec@(1,5) (64.9%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:09:56] \u001b[32mTrain: [ 43/50] Step 200/520 Loss 1.745 Prec@(1,5) (64.6%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:09:56] \u001b[32mTrain: [ 43/50] Step 220/520 Loss 1.746 Prec@(1,5) (64.6%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:09:57] \u001b[32mTrain: [ 43/50] Step 240/520 Loss 1.748 Prec@(1,5) (64.6%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:09:57] \u001b[32mTrain: [ 43/50] Step 260/520 Loss 1.746 Prec@(1,5) (64.6%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:09:58] \u001b[32mTrain: [ 43/50] Step 280/520 Loss 1.745 Prec@(1,5) (64.7%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:09:58] \u001b[32mTrain: [ 43/50] Step 300/520 Loss 1.739 Prec@(1,5) (64.7%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:09:59] \u001b[32mTrain: [ 43/50] Step 320/520 Loss 1.742 Prec@(1,5) (64.6%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:09:59] \u001b[32mTrain: [ 43/50] Step 340/520 Loss 1.741 Prec@(1,5) (64.6%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:10:00] \u001b[32mTrain: [ 43/50] Step 360/520 Loss 1.738 Prec@(1,5) (64.7%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:10:00] \u001b[32mTrain: [ 43/50] Step 380/520 Loss 1.739 Prec@(1,5) (64.8%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:10:01] \u001b[32mTrain: [ 43/50] Step 400/520 Loss 1.738 Prec@(1,5) (64.8%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:10:01] \u001b[32mTrain: [ 43/50] Step 420/520 Loss 1.737 Prec@(1,5) (64.7%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:10:02] \u001b[32mTrain: [ 43/50] Step 440/520 Loss 1.737 Prec@(1,5) (64.8%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:10:02] \u001b[32mTrain: [ 43/50] Step 460/520 Loss 1.737 Prec@(1,5) (64.7%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:10:03] \u001b[32mTrain: [ 43/50] Step 480/520 Loss 1.736 Prec@(1,5) (64.7%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:10:03] \u001b[32mTrain: [ 43/50] Step 500/520 Loss 1.738 Prec@(1,5) (64.7%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:10:04] \u001b[32mTrain: [ 43/50] Step 520/520 Loss 1.739 Prec@(1,5) (64.7%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:10:04] \u001b[32mTrain: [ 43/50] Final Prec@1 64.6760%\u001b[0m\n",
            "[2024-04-02 20:10:08] \u001b[32mValid: [ 43/50] Step 000/104 Loss 1.712 Prec@(1,5) (64.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:10:08] \u001b[32mValid: [ 43/50] Step 020/104 Loss 1.907 Prec@(1,5) (60.3%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:10:08] \u001b[32mValid: [ 43/50] Step 040/104 Loss 1.874 Prec@(1,5) (60.0%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:10:08] \u001b[32mValid: [ 43/50] Step 060/104 Loss 1.836 Prec@(1,5) (60.6%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:10:08] \u001b[32mValid: [ 43/50] Step 080/104 Loss 1.834 Prec@(1,5) (60.3%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:10:08] \u001b[32mValid: [ 43/50] Step 100/104 Loss 1.814 Prec@(1,5) (60.6%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:10:09] \u001b[32mValid: [ 43/50] Step 104/104 Loss 1.819 Prec@(1,5) (60.6%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:10:09] \u001b[32mValid: [ 43/50] Final Prec@1 60.6200%\u001b[0m\n",
            "[2024-04-02 20:10:09] \u001b[32mEpoch 43 LR 0.001191\u001b[0m\n",
            "[2024-04-02 20:10:13] \u001b[32mTrain: [ 44/50] Step 000/520 Loss 1.832 Prec@(1,5) (66.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:10:14] \u001b[32mTrain: [ 44/50] Step 020/520 Loss 1.704 Prec@(1,5) (66.1%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:10:14] \u001b[32mTrain: [ 44/50] Step 040/520 Loss 1.706 Prec@(1,5) (65.4%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:10:15] \u001b[32mTrain: [ 44/50] Step 060/520 Loss 1.716 Prec@(1,5) (65.0%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:10:15] \u001b[32mTrain: [ 44/50] Step 080/520 Loss 1.730 Prec@(1,5) (65.1%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:10:16] \u001b[32mTrain: [ 44/50] Step 100/520 Loss 1.727 Prec@(1,5) (65.2%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:10:16] \u001b[32mTrain: [ 44/50] Step 120/520 Loss 1.724 Prec@(1,5) (65.2%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:10:17] \u001b[32mTrain: [ 44/50] Step 140/520 Loss 1.720 Prec@(1,5) (65.3%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:10:17] \u001b[32mTrain: [ 44/50] Step 160/520 Loss 1.718 Prec@(1,5) (65.3%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:10:18] \u001b[32mTrain: [ 44/50] Step 180/520 Loss 1.710 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:10:18] \u001b[32mTrain: [ 44/50] Step 200/520 Loss 1.712 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:10:19] \u001b[32mTrain: [ 44/50] Step 220/520 Loss 1.713 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:10:19] \u001b[32mTrain: [ 44/50] Step 240/520 Loss 1.707 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:10:20] \u001b[32mTrain: [ 44/50] Step 260/520 Loss 1.707 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:10:20] \u001b[32mTrain: [ 44/50] Step 280/520 Loss 1.711 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:10:21] \u001b[32mTrain: [ 44/50] Step 300/520 Loss 1.718 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:10:21] \u001b[32mTrain: [ 44/50] Step 320/520 Loss 1.717 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:10:22] \u001b[32mTrain: [ 44/50] Step 340/520 Loss 1.717 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:10:22] \u001b[32mTrain: [ 44/50] Step 360/520 Loss 1.720 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:10:23] \u001b[32mTrain: [ 44/50] Step 380/520 Loss 1.722 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:10:23] \u001b[32mTrain: [ 44/50] Step 400/520 Loss 1.724 Prec@(1,5) (65.1%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:10:24] \u001b[32mTrain: [ 44/50] Step 420/520 Loss 1.723 Prec@(1,5) (65.1%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:10:24] \u001b[32mTrain: [ 44/50] Step 440/520 Loss 1.724 Prec@(1,5) (65.1%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:10:25] \u001b[32mTrain: [ 44/50] Step 460/520 Loss 1.721 Prec@(1,5) (65.1%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:10:25] \u001b[32mTrain: [ 44/50] Step 480/520 Loss 1.724 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:10:25] \u001b[32mTrain: [ 44/50] Step 500/520 Loss 1.723 Prec@(1,5) (65.1%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:10:26] \u001b[32mTrain: [ 44/50] Step 520/520 Loss 1.722 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:10:26] \u001b[32mTrain: [ 44/50] Final Prec@1 65.0440%\u001b[0m\n",
            "[2024-04-02 20:10:30] \u001b[32mValid: [ 44/50] Step 000/104 Loss 1.658 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:10:30] \u001b[32mValid: [ 44/50] Step 020/104 Loss 1.897 Prec@(1,5) (60.2%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:10:30] \u001b[32mValid: [ 44/50] Step 040/104 Loss 1.875 Prec@(1,5) (60.1%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:10:30] \u001b[32mValid: [ 44/50] Step 060/104 Loss 1.839 Prec@(1,5) (60.4%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:10:30] \u001b[32mValid: [ 44/50] Step 080/104 Loss 1.834 Prec@(1,5) (60.2%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:10:30] \u001b[32mValid: [ 44/50] Step 100/104 Loss 1.812 Prec@(1,5) (60.5%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:10:31] \u001b[32mValid: [ 44/50] Step 104/104 Loss 1.816 Prec@(1,5) (60.6%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:10:31] \u001b[32mValid: [ 44/50] Final Prec@1 60.5700%\u001b[0m\n",
            "[2024-04-02 20:10:31] \u001b[32mEpoch 44 LR 0.000879\u001b[0m\n",
            "[2024-04-02 20:10:35] \u001b[32mTrain: [ 45/50] Step 000/520 Loss 2.009 Prec@(1,5) (60.4%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:10:36] \u001b[32mTrain: [ 45/50] Step 020/520 Loss 1.716 Prec@(1,5) (65.4%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:10:36] \u001b[32mTrain: [ 45/50] Step 040/520 Loss 1.740 Prec@(1,5) (65.0%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:10:37] \u001b[32mTrain: [ 45/50] Step 060/520 Loss 1.722 Prec@(1,5) (65.2%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:10:37] \u001b[32mTrain: [ 45/50] Step 080/520 Loss 1.720 Prec@(1,5) (65.3%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:10:38] \u001b[32mTrain: [ 45/50] Step 100/520 Loss 1.717 Prec@(1,5) (65.4%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:10:38] \u001b[32mTrain: [ 45/50] Step 120/520 Loss 1.718 Prec@(1,5) (65.5%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:10:39] \u001b[32mTrain: [ 45/50] Step 140/520 Loss 1.712 Prec@(1,5) (65.5%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:10:39] \u001b[32mTrain: [ 45/50] Step 160/520 Loss 1.714 Prec@(1,5) (65.6%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:10:40] \u001b[32mTrain: [ 45/50] Step 180/520 Loss 1.709 Prec@(1,5) (65.7%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:10:40] \u001b[32mTrain: [ 45/50] Step 200/520 Loss 1.704 Prec@(1,5) (65.8%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:10:41] \u001b[32mTrain: [ 45/50] Step 220/520 Loss 1.707 Prec@(1,5) (65.7%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:10:41] \u001b[32mTrain: [ 45/50] Step 240/520 Loss 1.706 Prec@(1,5) (65.8%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:10:42] \u001b[32mTrain: [ 45/50] Step 260/520 Loss 1.704 Prec@(1,5) (65.8%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:10:42] \u001b[32mTrain: [ 45/50] Step 280/520 Loss 1.702 Prec@(1,5) (65.7%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:10:43] \u001b[32mTrain: [ 45/50] Step 300/520 Loss 1.707 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:10:43] \u001b[32mTrain: [ 45/50] Step 320/520 Loss 1.709 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:10:44] \u001b[32mTrain: [ 45/50] Step 340/520 Loss 1.709 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:10:44] \u001b[32mTrain: [ 45/50] Step 360/520 Loss 1.707 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:10:45] \u001b[32mTrain: [ 45/50] Step 380/520 Loss 1.706 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:10:45] \u001b[32mTrain: [ 45/50] Step 400/520 Loss 1.707 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:10:46] \u001b[32mTrain: [ 45/50] Step 420/520 Loss 1.711 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:10:46] \u001b[32mTrain: [ 45/50] Step 440/520 Loss 1.712 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:10:47] \u001b[32mTrain: [ 45/50] Step 460/520 Loss 1.714 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:10:47] \u001b[32mTrain: [ 45/50] Step 480/520 Loss 1.714 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:10:48] \u001b[32mTrain: [ 45/50] Step 500/520 Loss 1.716 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:10:48] \u001b[32mTrain: [ 45/50] Step 520/520 Loss 1.719 Prec@(1,5) (65.3%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:10:49] \u001b[32mTrain: [ 45/50] Final Prec@1 65.3300%\u001b[0m\n",
            "[2024-04-02 20:10:52] \u001b[32mValid: [ 45/50] Step 000/104 Loss 1.693 Prec@(1,5) (64.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:10:52] \u001b[32mValid: [ 45/50] Step 020/104 Loss 1.897 Prec@(1,5) (60.5%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:10:52] \u001b[32mValid: [ 45/50] Step 040/104 Loss 1.874 Prec@(1,5) (60.2%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:10:53] \u001b[32mValid: [ 45/50] Step 060/104 Loss 1.839 Prec@(1,5) (60.5%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:10:53] \u001b[32mValid: [ 45/50] Step 080/104 Loss 1.835 Prec@(1,5) (60.4%, 86.8%)\u001b[0m\n",
            "[2024-04-02 20:10:53] \u001b[32mValid: [ 45/50] Step 100/104 Loss 1.812 Prec@(1,5) (60.7%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:10:53] \u001b[32mValid: [ 45/50] Step 104/104 Loss 1.817 Prec@(1,5) (60.8%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:10:53] \u001b[32mValid: [ 45/50] Final Prec@1 60.7900%\u001b[0m\n",
            "[2024-04-02 20:10:53] \u001b[32mEpoch 45 LR 0.000613\u001b[0m\n",
            "[2024-04-02 20:10:58] \u001b[32mTrain: [ 46/50] Step 000/520 Loss 1.769 Prec@(1,5) (62.5%, 90.6%)\u001b[0m\n",
            "[2024-04-02 20:10:58] \u001b[32mTrain: [ 46/50] Step 020/520 Loss 1.680 Prec@(1,5) (66.1%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:10:59] \u001b[32mTrain: [ 46/50] Step 040/520 Loss 1.682 Prec@(1,5) (66.3%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:10:59] \u001b[32mTrain: [ 46/50] Step 060/520 Loss 1.671 Prec@(1,5) (66.3%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:11:00] \u001b[32mTrain: [ 46/50] Step 080/520 Loss 1.671 Prec@(1,5) (66.6%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:11:00] \u001b[32mTrain: [ 46/50] Step 100/520 Loss 1.675 Prec@(1,5) (66.6%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:11:01] \u001b[32mTrain: [ 46/50] Step 120/520 Loss 1.685 Prec@(1,5) (66.4%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:11:01] \u001b[32mTrain: [ 46/50] Step 140/520 Loss 1.682 Prec@(1,5) (66.2%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:11:02] \u001b[32mTrain: [ 46/50] Step 160/520 Loss 1.700 Prec@(1,5) (65.9%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:11:02] \u001b[32mTrain: [ 46/50] Step 180/520 Loss 1.701 Prec@(1,5) (65.9%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:11:03] \u001b[32mTrain: [ 46/50] Step 200/520 Loss 1.707 Prec@(1,5) (65.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:11:03] \u001b[32mTrain: [ 46/50] Step 220/520 Loss 1.709 Prec@(1,5) (65.7%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:11:04] \u001b[32mTrain: [ 46/50] Step 240/520 Loss 1.708 Prec@(1,5) (65.7%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:11:04] \u001b[32mTrain: [ 46/50] Step 260/520 Loss 1.711 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:11:05] \u001b[32mTrain: [ 46/50] Step 280/520 Loss 1.713 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:11:05] \u001b[32mTrain: [ 46/50] Step 300/520 Loss 1.715 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:11:06] \u001b[32mTrain: [ 46/50] Step 320/520 Loss 1.717 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:11:06] \u001b[32mTrain: [ 46/50] Step 340/520 Loss 1.721 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:11:07] \u001b[32mTrain: [ 46/50] Step 360/520 Loss 1.723 Prec@(1,5) (65.3%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:11:07] \u001b[32mTrain: [ 46/50] Step 380/520 Loss 1.725 Prec@(1,5) (65.3%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:11:08] \u001b[32mTrain: [ 46/50] Step 400/520 Loss 1.723 Prec@(1,5) (65.4%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:11:08] \u001b[32mTrain: [ 46/50] Step 420/520 Loss 1.721 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:11:09] \u001b[32mTrain: [ 46/50] Step 440/520 Loss 1.719 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:11:09] \u001b[32mTrain: [ 46/50] Step 460/520 Loss 1.717 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:11:10] \u001b[32mTrain: [ 46/50] Step 480/520 Loss 1.717 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:11:10] \u001b[32mTrain: [ 46/50] Step 500/520 Loss 1.717 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:11:11] \u001b[32mTrain: [ 46/50] Step 520/520 Loss 1.714 Prec@(1,5) (65.6%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:11:11] \u001b[32mTrain: [ 46/50] Final Prec@1 65.5720%\u001b[0m\n",
            "[2024-04-02 20:11:14] \u001b[32mValid: [ 46/50] Step 000/104 Loss 1.711 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:11:15] \u001b[32mValid: [ 46/50] Step 020/104 Loss 1.896 Prec@(1,5) (60.5%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:11:15] \u001b[32mValid: [ 46/50] Step 040/104 Loss 1.873 Prec@(1,5) (60.3%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:11:15] \u001b[32mValid: [ 46/50] Step 060/104 Loss 1.839 Prec@(1,5) (60.5%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:11:15] \u001b[32mValid: [ 46/50] Step 080/104 Loss 1.834 Prec@(1,5) (60.4%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:11:15] \u001b[32mValid: [ 46/50] Step 100/104 Loss 1.813 Prec@(1,5) (60.7%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:11:15] \u001b[32mValid: [ 46/50] Step 104/104 Loss 1.818 Prec@(1,5) (60.7%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:11:16] \u001b[32mValid: [ 46/50] Final Prec@1 60.7000%\u001b[0m\n",
            "[2024-04-02 20:11:16] \u001b[32mEpoch 46 LR 0.000394\u001b[0m\n",
            "[2024-04-02 20:11:20] \u001b[32mTrain: [ 47/50] Step 000/520 Loss 1.824 Prec@(1,5) (53.1%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:11:21] \u001b[32mTrain: [ 47/50] Step 020/520 Loss 1.718 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:11:21] \u001b[32mTrain: [ 47/50] Step 040/520 Loss 1.685 Prec@(1,5) (65.9%, 90.1%)\u001b[0m\n",
            "[2024-04-02 20:11:22] \u001b[32mTrain: [ 47/50] Step 060/520 Loss 1.688 Prec@(1,5) (66.2%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:11:22] \u001b[32mTrain: [ 47/50] Step 080/520 Loss 1.698 Prec@(1,5) (66.0%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:11:23] \u001b[32mTrain: [ 47/50] Step 100/520 Loss 1.697 Prec@(1,5) (66.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:11:23] \u001b[32mTrain: [ 47/50] Step 120/520 Loss 1.707 Prec@(1,5) (65.8%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:11:24] \u001b[32mTrain: [ 47/50] Step 140/520 Loss 1.706 Prec@(1,5) (65.7%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:11:24] \u001b[32mTrain: [ 47/50] Step 160/520 Loss 1.702 Prec@(1,5) (65.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:11:25] \u001b[32mTrain: [ 47/50] Step 180/520 Loss 1.705 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:11:25] \u001b[32mTrain: [ 47/50] Step 200/520 Loss 1.704 Prec@(1,5) (65.7%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:11:26] \u001b[32mTrain: [ 47/50] Step 220/520 Loss 1.700 Prec@(1,5) (65.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:11:26] \u001b[32mTrain: [ 47/50] Step 240/520 Loss 1.704 Prec@(1,5) (65.7%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:11:27] \u001b[32mTrain: [ 47/50] Step 260/520 Loss 1.701 Prec@(1,5) (65.7%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:11:27] \u001b[32mTrain: [ 47/50] Step 280/520 Loss 1.699 Prec@(1,5) (65.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:11:28] \u001b[32mTrain: [ 47/50] Step 300/520 Loss 1.699 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:11:28] \u001b[32mTrain: [ 47/50] Step 320/520 Loss 1.704 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:11:29] \u001b[32mTrain: [ 47/50] Step 340/520 Loss 1.699 Prec@(1,5) (65.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:11:29] \u001b[32mTrain: [ 47/50] Step 360/520 Loss 1.700 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:11:30] \u001b[32mTrain: [ 47/50] Step 380/520 Loss 1.694 Prec@(1,5) (65.7%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:11:30] \u001b[32mTrain: [ 47/50] Step 400/520 Loss 1.697 Prec@(1,5) (65.7%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:11:31] \u001b[32mTrain: [ 47/50] Step 420/520 Loss 1.699 Prec@(1,5) (65.6%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:11:31] \u001b[32mTrain: [ 47/50] Step 440/520 Loss 1.699 Prec@(1,5) (65.6%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:11:32] \u001b[32mTrain: [ 47/50] Step 460/520 Loss 1.701 Prec@(1,5) (65.6%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:11:32] \u001b[32mTrain: [ 47/50] Step 480/520 Loss 1.700 Prec@(1,5) (65.6%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:11:33] \u001b[32mTrain: [ 47/50] Step 500/520 Loss 1.699 Prec@(1,5) (65.6%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:11:33] \u001b[32mTrain: [ 47/50] Step 520/520 Loss 1.702 Prec@(1,5) (65.5%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:11:34] \u001b[32mTrain: [ 47/50] Final Prec@1 65.5160%\u001b[0m\n",
            "[2024-04-02 20:11:37] \u001b[32mValid: [ 47/50] Step 000/104 Loss 1.645 Prec@(1,5) (63.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:11:37] \u001b[32mValid: [ 47/50] Step 020/104 Loss 1.839 Prec@(1,5) (61.0%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:11:37] \u001b[32mValid: [ 47/50] Step 040/104 Loss 1.822 Prec@(1,5) (60.7%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:11:38] \u001b[32mValid: [ 47/50] Step 060/104 Loss 1.787 Prec@(1,5) (60.9%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:11:38] \u001b[32mValid: [ 47/50] Step 080/104 Loss 1.783 Prec@(1,5) (60.8%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:11:38] \u001b[32mValid: [ 47/50] Step 100/104 Loss 1.763 Prec@(1,5) (61.1%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:11:38] \u001b[32mValid: [ 47/50] Step 104/104 Loss 1.767 Prec@(1,5) (61.2%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:11:38] \u001b[32mValid: [ 47/50] Final Prec@1 61.1500%\u001b[0m\n",
            "[2024-04-02 20:11:38] \u001b[32mEpoch 47 LR 0.000222\u001b[0m\n",
            "[2024-04-02 20:11:43] \u001b[32mTrain: [ 48/50] Step 000/520 Loss 1.879 Prec@(1,5) (58.3%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:11:43] \u001b[32mTrain: [ 48/50] Step 020/520 Loss 1.750 Prec@(1,5) (65.4%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:11:44] \u001b[32mTrain: [ 48/50] Step 040/520 Loss 1.784 Prec@(1,5) (64.7%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:11:44] \u001b[32mTrain: [ 48/50] Step 060/520 Loss 1.739 Prec@(1,5) (65.3%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:11:45] \u001b[32mTrain: [ 48/50] Step 080/520 Loss 1.724 Prec@(1,5) (65.8%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:11:45] \u001b[32mTrain: [ 48/50] Step 100/520 Loss 1.720 Prec@(1,5) (65.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:11:46] \u001b[32mTrain: [ 48/50] Step 120/520 Loss 1.710 Prec@(1,5) (66.0%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:11:46] \u001b[32mTrain: [ 48/50] Step 140/520 Loss 1.713 Prec@(1,5) (65.8%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:11:47] \u001b[32mTrain: [ 48/50] Step 160/520 Loss 1.710 Prec@(1,5) (65.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:11:47] \u001b[32mTrain: [ 48/50] Step 180/520 Loss 1.717 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:11:48] \u001b[32mTrain: [ 48/50] Step 200/520 Loss 1.712 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:11:48] \u001b[32mTrain: [ 48/50] Step 220/520 Loss 1.706 Prec@(1,5) (65.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:11:49] \u001b[32mTrain: [ 48/50] Step 240/520 Loss 1.708 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:11:49] \u001b[32mTrain: [ 48/50] Step 260/520 Loss 1.709 Prec@(1,5) (65.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:11:50] \u001b[32mTrain: [ 48/50] Step 280/520 Loss 1.710 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:11:50] \u001b[32mTrain: [ 48/50] Step 300/520 Loss 1.715 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:11:51] \u001b[32mTrain: [ 48/50] Step 320/520 Loss 1.713 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:11:51] \u001b[32mTrain: [ 48/50] Step 340/520 Loss 1.713 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:11:52] \u001b[32mTrain: [ 48/50] Step 360/520 Loss 1.714 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:11:52] \u001b[32mTrain: [ 48/50] Step 380/520 Loss 1.714 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:11:53] \u001b[32mTrain: [ 48/50] Step 400/520 Loss 1.712 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:11:53] \u001b[32mTrain: [ 48/50] Step 420/520 Loss 1.710 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:11:54] \u001b[32mTrain: [ 48/50] Step 440/520 Loss 1.707 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:11:54] \u001b[32mTrain: [ 48/50] Step 460/520 Loss 1.707 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:11:55] \u001b[32mTrain: [ 48/50] Step 480/520 Loss 1.707 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:11:55] \u001b[32mTrain: [ 48/50] Step 500/520 Loss 1.705 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:11:56] \u001b[32mTrain: [ 48/50] Step 520/520 Loss 1.707 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:11:56] \u001b[32mTrain: [ 48/50] Final Prec@1 65.5480%\u001b[0m\n",
            "[2024-04-02 20:11:59] \u001b[32mValid: [ 48/50] Step 000/104 Loss 1.660 Prec@(1,5) (66.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:11:59] \u001b[32mValid: [ 48/50] Step 020/104 Loss 1.859 Prec@(1,5) (61.0%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:12:00] \u001b[32mValid: [ 48/50] Step 040/104 Loss 1.841 Prec@(1,5) (60.4%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:12:00] \u001b[32mValid: [ 48/50] Step 060/104 Loss 1.806 Prec@(1,5) (60.7%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:12:00] \u001b[32mValid: [ 48/50] Step 080/104 Loss 1.802 Prec@(1,5) (60.6%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:12:00] \u001b[32mValid: [ 48/50] Step 100/104 Loss 1.781 Prec@(1,5) (61.0%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:12:00] \u001b[32mValid: [ 48/50] Step 104/104 Loss 1.785 Prec@(1,5) (61.0%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:12:00] \u001b[32mValid: [ 48/50] Final Prec@1 61.0300%\u001b[0m\n",
            "[2024-04-02 20:12:00] \u001b[32mEpoch 48 LR 0.000100\u001b[0m\n",
            "[2024-04-02 20:12:05] \u001b[32mTrain: [ 49/50] Step 000/520 Loss 1.693 Prec@(1,5) (64.6%, 93.8%)\u001b[0m\n",
            "[2024-04-02 20:12:05] \u001b[32mTrain: [ 49/50] Step 020/520 Loss 1.691 Prec@(1,5) (66.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:12:06] \u001b[32mTrain: [ 49/50] Step 040/520 Loss 1.705 Prec@(1,5) (66.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:12:06] \u001b[32mTrain: [ 49/50] Step 060/520 Loss 1.717 Prec@(1,5) (65.7%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:12:07] \u001b[32mTrain: [ 49/50] Step 080/520 Loss 1.706 Prec@(1,5) (65.9%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:12:07] \u001b[32mTrain: [ 49/50] Step 100/520 Loss 1.698 Prec@(1,5) (66.0%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:12:08] \u001b[32mTrain: [ 49/50] Step 120/520 Loss 1.707 Prec@(1,5) (65.9%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:12:08] \u001b[32mTrain: [ 49/50] Step 140/520 Loss 1.714 Prec@(1,5) (65.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:12:09] \u001b[32mTrain: [ 49/50] Step 160/520 Loss 1.711 Prec@(1,5) (65.6%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:12:09] \u001b[32mTrain: [ 49/50] Step 180/520 Loss 1.710 Prec@(1,5) (65.6%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:12:10] \u001b[32mTrain: [ 49/50] Step 200/520 Loss 1.708 Prec@(1,5) (65.7%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:12:10] \u001b[32mTrain: [ 49/50] Step 220/520 Loss 1.704 Prec@(1,5) (65.8%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:12:11] \u001b[32mTrain: [ 49/50] Step 240/520 Loss 1.701 Prec@(1,5) (65.9%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:12:11] \u001b[32mTrain: [ 49/50] Step 260/520 Loss 1.705 Prec@(1,5) (65.8%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:12:12] \u001b[32mTrain: [ 49/50] Step 280/520 Loss 1.704 Prec@(1,5) (65.8%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:12:12] \u001b[32mTrain: [ 49/50] Step 300/520 Loss 1.703 Prec@(1,5) (65.8%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:12:13] \u001b[32mTrain: [ 49/50] Step 320/520 Loss 1.703 Prec@(1,5) (65.8%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:12:13] \u001b[32mTrain: [ 49/50] Step 340/520 Loss 1.702 Prec@(1,5) (65.8%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:12:14] \u001b[32mTrain: [ 49/50] Step 360/520 Loss 1.706 Prec@(1,5) (65.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:12:14] \u001b[32mTrain: [ 49/50] Step 380/520 Loss 1.707 Prec@(1,5) (65.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:12:15] \u001b[32mTrain: [ 49/50] Step 400/520 Loss 1.707 Prec@(1,5) (65.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:12:15] \u001b[32mTrain: [ 49/50] Step 420/520 Loss 1.708 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:12:16] \u001b[32mTrain: [ 49/50] Step 440/520 Loss 1.711 Prec@(1,5) (65.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:12:16] \u001b[32mTrain: [ 49/50] Step 460/520 Loss 1.712 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:12:17] \u001b[32mTrain: [ 49/50] Step 480/520 Loss 1.711 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:12:17] \u001b[32mTrain: [ 49/50] Step 500/520 Loss 1.711 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:12:18] \u001b[32mTrain: [ 49/50] Step 520/520 Loss 1.712 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:12:18] \u001b[32mTrain: [ 49/50] Final Prec@1 65.5340%\u001b[0m\n",
            "[2024-04-02 20:12:21] \u001b[32mValid: [ 49/50] Step 000/104 Loss 1.671 Prec@(1,5) (65.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:12:22] \u001b[32mValid: [ 49/50] Step 020/104 Loss 1.874 Prec@(1,5) (60.9%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:12:22] \u001b[32mValid: [ 49/50] Step 040/104 Loss 1.852 Prec@(1,5) (60.6%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:12:22] \u001b[32mValid: [ 49/50] Step 060/104 Loss 1.817 Prec@(1,5) (60.9%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:12:22] \u001b[32mValid: [ 49/50] Step 080/104 Loss 1.811 Prec@(1,5) (60.7%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:12:22] \u001b[32mValid: [ 49/50] Step 100/104 Loss 1.790 Prec@(1,5) (61.1%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:12:22] \u001b[32mValid: [ 49/50] Step 104/104 Loss 1.795 Prec@(1,5) (61.1%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:12:22] \u001b[32mValid: [ 49/50] Final Prec@1 61.1000%\u001b[0m\n",
            "[2024-04-02 20:12:22] \u001b[32mEpoch 49 LR 0.000026\u001b[0m\n",
            "[2024-04-02 20:12:27] \u001b[32mTrain: [ 50/50] Step 000/520 Loss 1.929 Prec@(1,5) (65.6%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:12:28] \u001b[32mTrain: [ 50/50] Step 020/520 Loss 1.726 Prec@(1,5) (65.3%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:12:28] \u001b[32mTrain: [ 50/50] Step 040/520 Loss 1.741 Prec@(1,5) (64.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:12:29] \u001b[32mTrain: [ 50/50] Step 060/520 Loss 1.739 Prec@(1,5) (64.7%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:12:29] \u001b[32mTrain: [ 50/50] Step 080/520 Loss 1.738 Prec@(1,5) (64.8%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:12:29] \u001b[32mTrain: [ 50/50] Step 100/520 Loss 1.726 Prec@(1,5) (65.0%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:12:30] \u001b[32mTrain: [ 50/50] Step 120/520 Loss 1.712 Prec@(1,5) (65.2%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:12:30] \u001b[32mTrain: [ 50/50] Step 140/520 Loss 1.709 Prec@(1,5) (65.4%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:12:31] \u001b[32mTrain: [ 50/50] Step 160/520 Loss 1.710 Prec@(1,5) (65.3%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:12:31] \u001b[32mTrain: [ 50/50] Step 180/520 Loss 1.704 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:12:32] \u001b[32mTrain: [ 50/50] Step 200/520 Loss 1.705 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:12:32] \u001b[32mTrain: [ 50/50] Step 220/520 Loss 1.706 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:12:33] \u001b[32mTrain: [ 50/50] Step 240/520 Loss 1.710 Prec@(1,5) (65.4%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:12:33] \u001b[32mTrain: [ 50/50] Step 260/520 Loss 1.713 Prec@(1,5) (65.3%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:12:34] \u001b[32mTrain: [ 50/50] Step 280/520 Loss 1.716 Prec@(1,5) (65.3%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:12:34] \u001b[32mTrain: [ 50/50] Step 300/520 Loss 1.712 Prec@(1,5) (65.3%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:12:35] \u001b[32mTrain: [ 50/50] Step 320/520 Loss 1.711 Prec@(1,5) (65.3%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:12:35] \u001b[32mTrain: [ 50/50] Step 340/520 Loss 1.712 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:12:36] \u001b[32mTrain: [ 50/50] Step 360/520 Loss 1.713 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:12:36] \u001b[32mTrain: [ 50/50] Step 380/520 Loss 1.713 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:12:37] \u001b[32mTrain: [ 50/50] Step 400/520 Loss 1.712 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:12:37] \u001b[32mTrain: [ 50/50] Step 420/520 Loss 1.709 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:12:38] \u001b[32mTrain: [ 50/50] Step 440/520 Loss 1.710 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:12:38] \u001b[32mTrain: [ 50/50] Step 460/520 Loss 1.707 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:12:39] \u001b[32mTrain: [ 50/50] Step 480/520 Loss 1.709 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:12:39] \u001b[32mTrain: [ 50/50] Step 500/520 Loss 1.710 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:12:40] \u001b[32mTrain: [ 50/50] Step 520/520 Loss 1.709 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:12:40] \u001b[32mTrain: [ 50/50] Final Prec@1 65.5020%\u001b[0m\n",
            "[2024-04-02 20:12:44] \u001b[32mValid: [ 50/50] Step 000/104 Loss 1.694 Prec@(1,5) (63.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:12:44] \u001b[32mValid: [ 50/50] Step 020/104 Loss 1.873 Prec@(1,5) (61.2%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:12:44] \u001b[32mValid: [ 50/50] Step 040/104 Loss 1.855 Prec@(1,5) (60.7%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:12:44] \u001b[32mValid: [ 50/50] Step 060/104 Loss 1.819 Prec@(1,5) (60.9%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:12:44] \u001b[32mValid: [ 50/50] Step 080/104 Loss 1.813 Prec@(1,5) (60.7%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:12:44] \u001b[32mValid: [ 50/50] Step 100/104 Loss 1.791 Prec@(1,5) (61.1%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:12:44] \u001b[32mValid: [ 50/50] Step 104/104 Loss 1.795 Prec@(1,5) (61.1%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:12:45] \u001b[32mValid: [ 50/50] Final Prec@1 61.1200%\u001b[0m\n",
            "Final best Prec@1 = 61.1500%\n",
            "{'lambd=1.263157894736842': 0.6138000170707703, 'lambd=1.6842105263157894': 0.6144000166893006, 'lambd=2.1052631578947367': 0.6146000204086304, 'lambd=2.526315789473684': 0.6115000175476074}\n",
            "random_edges/lambd=2.9473684210526314/\n",
            "[2024-04-02 20:12:45] \u001b[32mFixed architecture: {'reduce_n2_p0': 'sepconv5x5', 'reduce_n2_p1': 'sepconv5x5', 'reduce_n3_p0': 'dilconv5x5', 'reduce_n3_p1': 'sepconv5x5', 'reduce_n3_p2': 'sepconv5x5', 'reduce_n4_p0': 'sepconv3x3', 'reduce_n4_p1': 'sepconv5x5', 'reduce_n4_p2': 'sepconv5x5', 'reduce_n4_p3': 'sepconv5x5', 'reduce_n5_p0': 'maxpool', 'reduce_n5_p1': 'sepconv3x3', 'reduce_n5_p2': 'sepconv5x5', 'reduce_n5_p3': 'sepconv5x5', 'reduce_n5_p4': 'maxpool', 'reduce_n2_switch': [1], 'reduce_n3_switch': [1], 'reduce_n4_switch': [0], 'reduce_n5_switch': [4]}\u001b[0m\n",
            "[2024-04-02 20:12:45] \u001b[32mEpoch 0 LR 0.025000\u001b[0m\n",
            "[2024-04-02 20:12:49] \u001b[32mTrain: [  1/50] Step 000/520 Loss 6.537 Prec@(1,5) (2.1%, 3.1%)\u001b[0m\n",
            "[2024-04-02 20:12:50] \u001b[32mTrain: [  1/50] Step 020/520 Loss 6.420 Prec@(1,5) (1.7%, 7.2%)\u001b[0m\n",
            "[2024-04-02 20:12:50] \u001b[32mTrain: [  1/50] Step 040/520 Loss 6.285 Prec@(1,5) (3.0%, 10.8%)\u001b[0m\n",
            "[2024-04-02 20:12:51] \u001b[32mTrain: [  1/50] Step 060/520 Loss 6.169 Prec@(1,5) (4.0%, 13.9%)\u001b[0m\n",
            "[2024-04-02 20:12:51] \u001b[32mTrain: [  1/50] Step 080/520 Loss 6.087 Prec@(1,5) (4.4%, 16.0%)\u001b[0m\n",
            "[2024-04-02 20:12:52] \u001b[32mTrain: [  1/50] Step 100/520 Loss 6.012 Prec@(1,5) (4.9%, 17.6%)\u001b[0m\n",
            "[2024-04-02 20:12:52] \u001b[32mTrain: [  1/50] Step 120/520 Loss 5.947 Prec@(1,5) (5.4%, 18.6%)\u001b[0m\n",
            "[2024-04-02 20:12:53] \u001b[32mTrain: [  1/50] Step 140/520 Loss 5.895 Prec@(1,5) (5.7%, 19.8%)\u001b[0m\n",
            "[2024-04-02 20:12:53] \u001b[32mTrain: [  1/50] Step 160/520 Loss 5.841 Prec@(1,5) (6.1%, 20.9%)\u001b[0m\n",
            "[2024-04-02 20:12:54] \u001b[32mTrain: [  1/50] Step 180/520 Loss 5.798 Prec@(1,5) (6.6%, 21.8%)\u001b[0m\n",
            "[2024-04-02 20:12:54] \u001b[32mTrain: [  1/50] Step 200/520 Loss 5.758 Prec@(1,5) (6.9%, 22.6%)\u001b[0m\n",
            "[2024-04-02 20:12:55] \u001b[32mTrain: [  1/50] Step 220/520 Loss 5.717 Prec@(1,5) (7.2%, 23.6%)\u001b[0m\n",
            "[2024-04-02 20:12:55] \u001b[32mTrain: [  1/50] Step 240/520 Loss 5.678 Prec@(1,5) (7.7%, 24.4%)\u001b[0m\n",
            "[2024-04-02 20:12:56] \u001b[32mTrain: [  1/50] Step 260/520 Loss 5.648 Prec@(1,5) (7.9%, 25.0%)\u001b[0m\n",
            "[2024-04-02 20:12:56] \u001b[32mTrain: [  1/50] Step 280/520 Loss 5.614 Prec@(1,5) (8.3%, 25.8%)\u001b[0m\n",
            "[2024-04-02 20:12:57] \u001b[32mTrain: [  1/50] Step 300/520 Loss 5.584 Prec@(1,5) (8.6%, 26.6%)\u001b[0m\n",
            "[2024-04-02 20:12:57] \u001b[32mTrain: [  1/50] Step 320/520 Loss 5.558 Prec@(1,5) (8.8%, 27.1%)\u001b[0m\n",
            "[2024-04-02 20:12:57] \u001b[32mTrain: [  1/50] Step 340/520 Loss 5.528 Prec@(1,5) (9.1%, 27.8%)\u001b[0m\n",
            "[2024-04-02 20:12:58] \u001b[32mTrain: [  1/50] Step 360/520 Loss 5.501 Prec@(1,5) (9.4%, 28.4%)\u001b[0m\n",
            "[2024-04-02 20:12:58] \u001b[32mTrain: [  1/50] Step 380/520 Loss 5.474 Prec@(1,5) (9.7%, 28.9%)\u001b[0m\n",
            "[2024-04-02 20:12:59] \u001b[32mTrain: [  1/50] Step 400/520 Loss 5.451 Prec@(1,5) (9.9%, 29.4%)\u001b[0m\n",
            "[2024-04-02 20:12:59] \u001b[32mTrain: [  1/50] Step 420/520 Loss 5.430 Prec@(1,5) (10.1%, 29.9%)\u001b[0m\n",
            "[2024-04-02 20:13:00] \u001b[32mTrain: [  1/50] Step 440/520 Loss 5.404 Prec@(1,5) (10.4%, 30.4%)\u001b[0m\n",
            "[2024-04-02 20:13:00] \u001b[32mTrain: [  1/50] Step 460/520 Loss 5.383 Prec@(1,5) (10.6%, 30.9%)\u001b[0m\n",
            "[2024-04-02 20:13:01] \u001b[32mTrain: [  1/50] Step 480/520 Loss 5.358 Prec@(1,5) (10.9%, 31.6%)\u001b[0m\n",
            "[2024-04-02 20:13:01] \u001b[32mTrain: [  1/50] Step 500/520 Loss 5.339 Prec@(1,5) (11.1%, 32.0%)\u001b[0m\n",
            "[2024-04-02 20:13:02] \u001b[32mTrain: [  1/50] Step 520/520 Loss 5.318 Prec@(1,5) (11.3%, 32.4%)\u001b[0m\n",
            "[2024-04-02 20:13:02] \u001b[32mTrain: [  1/50] Final Prec@1 11.2880%\u001b[0m\n",
            "[2024-04-02 20:13:05] \u001b[32mValid: [  1/50] Step 000/104 Loss 4.784 Prec@(1,5) (21.9%, 37.5%)\u001b[0m\n",
            "[2024-04-02 20:13:06] \u001b[32mValid: [  1/50] Step 020/104 Loss 4.623 Prec@(1,5) (16.7%, 41.4%)\u001b[0m\n",
            "[2024-04-02 20:13:06] \u001b[32mValid: [  1/50] Step 040/104 Loss 4.610 Prec@(1,5) (15.6%, 41.4%)\u001b[0m\n",
            "[2024-04-02 20:13:06] \u001b[32mValid: [  1/50] Step 060/104 Loss 4.560 Prec@(1,5) (16.0%, 41.9%)\u001b[0m\n",
            "[2024-04-02 20:13:06] \u001b[32mValid: [  1/50] Step 080/104 Loss 4.570 Prec@(1,5) (16.1%, 41.9%)\u001b[0m\n",
            "[2024-04-02 20:13:06] \u001b[32mValid: [  1/50] Step 100/104 Loss 4.576 Prec@(1,5) (16.0%, 42.0%)\u001b[0m\n",
            "[2024-04-02 20:13:06] \u001b[32mValid: [  1/50] Step 104/104 Loss 4.577 Prec@(1,5) (16.0%, 42.0%)\u001b[0m\n",
            "[2024-04-02 20:13:06] \u001b[32mValid: [  1/50] Final Prec@1 15.9700%\u001b[0m\n",
            "[2024-04-02 20:13:06] \u001b[32mEpoch 1 LR 0.024975\u001b[0m\n",
            "[2024-04-02 20:13:11] \u001b[32mTrain: [  2/50] Step 000/520 Loss 5.407 Prec@(1,5) (10.4%, 32.3%)\u001b[0m\n",
            "[2024-04-02 20:13:12] \u001b[32mTrain: [  2/50] Step 020/520 Loss 4.699 Prec@(1,5) (18.2%, 45.5%)\u001b[0m\n",
            "[2024-04-02 20:13:12] \u001b[32mTrain: [  2/50] Step 040/520 Loss 4.683 Prec@(1,5) (18.1%, 45.9%)\u001b[0m\n",
            "[2024-04-02 20:13:13] \u001b[32mTrain: [  2/50] Step 060/520 Loss 4.668 Prec@(1,5) (18.5%, 45.9%)\u001b[0m\n",
            "[2024-04-02 20:13:13] \u001b[32mTrain: [  2/50] Step 080/520 Loss 4.654 Prec@(1,5) (18.8%, 46.1%)\u001b[0m\n",
            "[2024-04-02 20:13:14] \u001b[32mTrain: [  2/50] Step 100/520 Loss 4.653 Prec@(1,5) (18.6%, 46.0%)\u001b[0m\n",
            "[2024-04-02 20:13:14] \u001b[32mTrain: [  2/50] Step 120/520 Loss 4.643 Prec@(1,5) (19.0%, 46.3%)\u001b[0m\n",
            "[2024-04-02 20:13:15] \u001b[32mTrain: [  2/50] Step 140/520 Loss 4.621 Prec@(1,5) (19.4%, 46.9%)\u001b[0m\n",
            "[2024-04-02 20:13:15] \u001b[32mTrain: [  2/50] Step 160/520 Loss 4.613 Prec@(1,5) (19.6%, 47.1%)\u001b[0m\n",
            "[2024-04-02 20:13:15] \u001b[32mTrain: [  2/50] Step 180/520 Loss 4.604 Prec@(1,5) (19.7%, 47.3%)\u001b[0m\n",
            "[2024-04-02 20:13:16] \u001b[32mTrain: [  2/50] Step 200/520 Loss 4.596 Prec@(1,5) (19.9%, 47.4%)\u001b[0m\n",
            "[2024-04-02 20:13:16] \u001b[32mTrain: [  2/50] Step 220/520 Loss 4.585 Prec@(1,5) (19.9%, 47.7%)\u001b[0m\n",
            "[2024-04-02 20:13:17] \u001b[32mTrain: [  2/50] Step 240/520 Loss 4.567 Prec@(1,5) (20.0%, 47.9%)\u001b[0m\n",
            "[2024-04-02 20:13:17] \u001b[32mTrain: [  2/50] Step 260/520 Loss 4.565 Prec@(1,5) (20.0%, 47.9%)\u001b[0m\n",
            "[2024-04-02 20:13:18] \u001b[32mTrain: [  2/50] Step 280/520 Loss 4.552 Prec@(1,5) (20.1%, 48.1%)\u001b[0m\n",
            "[2024-04-02 20:13:18] \u001b[32mTrain: [  2/50] Step 300/520 Loss 4.541 Prec@(1,5) (20.3%, 48.4%)\u001b[0m\n",
            "[2024-04-02 20:13:19] \u001b[32mTrain: [  2/50] Step 320/520 Loss 4.530 Prec@(1,5) (20.5%, 48.6%)\u001b[0m\n",
            "[2024-04-02 20:13:19] \u001b[32mTrain: [  2/50] Step 340/520 Loss 4.523 Prec@(1,5) (20.6%, 48.8%)\u001b[0m\n",
            "[2024-04-02 20:13:20] \u001b[32mTrain: [  2/50] Step 360/520 Loss 4.511 Prec@(1,5) (20.6%, 49.0%)\u001b[0m\n",
            "[2024-04-02 20:13:20] \u001b[32mTrain: [  2/50] Step 380/520 Loss 4.501 Prec@(1,5) (20.8%, 49.2%)\u001b[0m\n",
            "[2024-04-02 20:13:21] \u001b[32mTrain: [  2/50] Step 400/520 Loss 4.491 Prec@(1,5) (20.9%, 49.4%)\u001b[0m\n",
            "[2024-04-02 20:13:21] \u001b[32mTrain: [  2/50] Step 420/520 Loss 4.481 Prec@(1,5) (21.0%, 49.6%)\u001b[0m\n",
            "[2024-04-02 20:13:22] \u001b[32mTrain: [  2/50] Step 440/520 Loss 4.470 Prec@(1,5) (21.1%, 49.9%)\u001b[0m\n",
            "[2024-04-02 20:13:22] \u001b[32mTrain: [  2/50] Step 460/520 Loss 4.463 Prec@(1,5) (21.2%, 50.0%)\u001b[0m\n",
            "[2024-04-02 20:13:23] \u001b[32mTrain: [  2/50] Step 480/520 Loss 4.452 Prec@(1,5) (21.4%, 50.2%)\u001b[0m\n",
            "[2024-04-02 20:13:23] \u001b[32mTrain: [  2/50] Step 500/520 Loss 4.443 Prec@(1,5) (21.5%, 50.4%)\u001b[0m\n",
            "[2024-04-02 20:13:24] \u001b[32mTrain: [  2/50] Step 520/520 Loss 4.434 Prec@(1,5) (21.6%, 50.5%)\u001b[0m\n",
            "[2024-04-02 20:13:24] \u001b[32mTrain: [  2/50] Final Prec@1 21.6160%\u001b[0m\n",
            "[2024-04-02 20:13:27] \u001b[32mValid: [  2/50] Step 000/104 Loss 4.879 Prec@(1,5) (26.0%, 50.0%)\u001b[0m\n",
            "[2024-04-02 20:13:28] \u001b[32mValid: [  2/50] Step 020/104 Loss 4.497 Prec@(1,5) (22.6%, 51.7%)\u001b[0m\n",
            "[2024-04-02 20:13:28] \u001b[32mValid: [  2/50] Step 040/104 Loss 4.453 Prec@(1,5) (21.9%, 52.0%)\u001b[0m\n",
            "[2024-04-02 20:13:28] \u001b[32mValid: [  2/50] Step 060/104 Loss 4.417 Prec@(1,5) (22.4%, 52.1%)\u001b[0m\n",
            "[2024-04-02 20:13:28] \u001b[32mValid: [  2/50] Step 080/104 Loss 4.429 Prec@(1,5) (22.4%, 51.8%)\u001b[0m\n",
            "[2024-04-02 20:13:28] \u001b[32mValid: [  2/50] Step 100/104 Loss 4.439 Prec@(1,5) (22.1%, 51.6%)\u001b[0m\n",
            "[2024-04-02 20:13:28] \u001b[32mValid: [  2/50] Step 104/104 Loss 4.436 Prec@(1,5) (22.1%, 51.6%)\u001b[0m\n",
            "[2024-04-02 20:13:29] \u001b[32mValid: [  2/50] Final Prec@1 22.1300%\u001b[0m\n",
            "[2024-04-02 20:13:29] \u001b[32mEpoch 2 LR 0.024901\u001b[0m\n",
            "[2024-04-02 20:13:33] \u001b[32mTrain: [  3/50] Step 000/520 Loss 3.936 Prec@(1,5) (30.2%, 61.5%)\u001b[0m\n",
            "[2024-04-02 20:13:34] \u001b[32mTrain: [  3/50] Step 020/520 Loss 4.119 Prec@(1,5) (24.8%, 56.1%)\u001b[0m\n",
            "[2024-04-02 20:13:34] \u001b[32mTrain: [  3/50] Step 040/520 Loss 4.087 Prec@(1,5) (26.2%, 56.3%)\u001b[0m\n",
            "[2024-04-02 20:13:35] \u001b[32mTrain: [  3/50] Step 060/520 Loss 4.063 Prec@(1,5) (26.3%, 56.4%)\u001b[0m\n",
            "[2024-04-02 20:13:35] \u001b[32mTrain: [  3/50] Step 080/520 Loss 4.055 Prec@(1,5) (26.3%, 56.7%)\u001b[0m\n",
            "[2024-04-02 20:13:36] \u001b[32mTrain: [  3/50] Step 100/520 Loss 4.048 Prec@(1,5) (26.5%, 56.9%)\u001b[0m\n",
            "[2024-04-02 20:13:36] \u001b[32mTrain: [  3/50] Step 120/520 Loss 4.061 Prec@(1,5) (26.3%, 56.7%)\u001b[0m\n",
            "[2024-04-02 20:13:37] \u001b[32mTrain: [  3/50] Step 140/520 Loss 4.073 Prec@(1,5) (26.1%, 56.7%)\u001b[0m\n",
            "[2024-04-02 20:13:37] \u001b[32mTrain: [  3/50] Step 160/520 Loss 4.070 Prec@(1,5) (26.0%, 56.9%)\u001b[0m\n",
            "[2024-04-02 20:13:38] \u001b[32mTrain: [  3/50] Step 180/520 Loss 4.067 Prec@(1,5) (26.3%, 56.9%)\u001b[0m\n",
            "[2024-04-02 20:13:38] \u001b[32mTrain: [  3/50] Step 200/520 Loss 4.067 Prec@(1,5) (26.2%, 56.9%)\u001b[0m\n",
            "[2024-04-02 20:13:39] \u001b[32mTrain: [  3/50] Step 220/520 Loss 4.059 Prec@(1,5) (26.2%, 57.0%)\u001b[0m\n",
            "[2024-04-02 20:13:39] \u001b[32mTrain: [  3/50] Step 240/520 Loss 4.058 Prec@(1,5) (26.4%, 57.0%)\u001b[0m\n",
            "[2024-04-02 20:13:40] \u001b[32mTrain: [  3/50] Step 260/520 Loss 4.054 Prec@(1,5) (26.4%, 57.2%)\u001b[0m\n",
            "[2024-04-02 20:13:40] \u001b[32mTrain: [  3/50] Step 280/520 Loss 4.051 Prec@(1,5) (26.5%, 57.3%)\u001b[0m\n",
            "[2024-04-02 20:13:41] \u001b[32mTrain: [  3/50] Step 300/520 Loss 4.047 Prec@(1,5) (26.6%, 57.4%)\u001b[0m\n",
            "[2024-04-02 20:13:41] \u001b[32mTrain: [  3/50] Step 320/520 Loss 4.039 Prec@(1,5) (26.8%, 57.5%)\u001b[0m\n",
            "[2024-04-02 20:13:42] \u001b[32mTrain: [  3/50] Step 340/520 Loss 4.036 Prec@(1,5) (26.8%, 57.5%)\u001b[0m\n",
            "[2024-04-02 20:13:42] \u001b[32mTrain: [  3/50] Step 360/520 Loss 4.033 Prec@(1,5) (26.9%, 57.5%)\u001b[0m\n",
            "[2024-04-02 20:13:42] \u001b[32mTrain: [  3/50] Step 380/520 Loss 4.027 Prec@(1,5) (27.0%, 57.6%)\u001b[0m\n",
            "[2024-04-02 20:13:43] \u001b[32mTrain: [  3/50] Step 400/520 Loss 4.018 Prec@(1,5) (27.2%, 57.7%)\u001b[0m\n",
            "[2024-04-02 20:13:43] \u001b[32mTrain: [  3/50] Step 420/520 Loss 4.009 Prec@(1,5) (27.3%, 57.9%)\u001b[0m\n",
            "[2024-04-02 20:13:44] \u001b[32mTrain: [  3/50] Step 440/520 Loss 4.003 Prec@(1,5) (27.4%, 58.0%)\u001b[0m\n",
            "[2024-04-02 20:13:44] \u001b[32mTrain: [  3/50] Step 460/520 Loss 3.997 Prec@(1,5) (27.5%, 58.1%)\u001b[0m\n",
            "[2024-04-02 20:13:45] \u001b[32mTrain: [  3/50] Step 480/520 Loss 3.991 Prec@(1,5) (27.6%, 58.2%)\u001b[0m\n",
            "[2024-04-02 20:13:45] \u001b[32mTrain: [  3/50] Step 500/520 Loss 3.983 Prec@(1,5) (27.7%, 58.3%)\u001b[0m\n",
            "[2024-04-02 20:13:46] \u001b[32mTrain: [  3/50] Step 520/520 Loss 3.978 Prec@(1,5) (27.8%, 58.4%)\u001b[0m\n",
            "[2024-04-02 20:13:46] \u001b[32mTrain: [  3/50] Final Prec@1 27.8120%\u001b[0m\n",
            "[2024-04-02 20:13:50] \u001b[32mValid: [  3/50] Step 000/104 Loss 4.207 Prec@(1,5) (24.0%, 56.2%)\u001b[0m\n",
            "[2024-04-02 20:13:50] \u001b[32mValid: [  3/50] Step 020/104 Loss 3.994 Prec@(1,5) (27.5%, 57.5%)\u001b[0m\n",
            "[2024-04-02 20:13:50] \u001b[32mValid: [  3/50] Step 040/104 Loss 3.920 Prec@(1,5) (27.5%, 58.6%)\u001b[0m\n",
            "[2024-04-02 20:13:50] \u001b[32mValid: [  3/50] Step 060/104 Loss 3.908 Prec@(1,5) (28.0%, 58.3%)\u001b[0m\n",
            "[2024-04-02 20:13:50] \u001b[32mValid: [  3/50] Step 080/104 Loss 3.924 Prec@(1,5) (27.4%, 58.2%)\u001b[0m\n",
            "[2024-04-02 20:13:50] \u001b[32mValid: [  3/50] Step 100/104 Loss 3.936 Prec@(1,5) (27.3%, 58.0%)\u001b[0m\n",
            "[2024-04-02 20:13:50] \u001b[32mValid: [  3/50] Step 104/104 Loss 3.937 Prec@(1,5) (27.2%, 58.0%)\u001b[0m\n",
            "[2024-04-02 20:13:51] \u001b[32mValid: [  3/50] Final Prec@1 27.1500%\u001b[0m\n",
            "[2024-04-02 20:13:51] \u001b[32mEpoch 3 LR 0.024779\u001b[0m\n",
            "[2024-04-02 20:13:55] \u001b[32mTrain: [  4/50] Step 000/520 Loss 3.912 Prec@(1,5) (29.2%, 61.5%)\u001b[0m\n",
            "[2024-04-02 20:13:56] \u001b[32mTrain: [  4/50] Step 020/520 Loss 3.724 Prec@(1,5) (30.9%, 62.4%)\u001b[0m\n",
            "[2024-04-02 20:13:56] \u001b[32mTrain: [  4/50] Step 040/520 Loss 3.755 Prec@(1,5) (31.3%, 62.1%)\u001b[0m\n",
            "[2024-04-02 20:13:57] \u001b[32mTrain: [  4/50] Step 060/520 Loss 3.781 Prec@(1,5) (30.7%, 61.4%)\u001b[0m\n",
            "[2024-04-02 20:13:57] \u001b[32mTrain: [  4/50] Step 080/520 Loss 3.788 Prec@(1,5) (30.4%, 61.4%)\u001b[0m\n",
            "[2024-04-02 20:13:58] \u001b[32mTrain: [  4/50] Step 100/520 Loss 3.787 Prec@(1,5) (30.2%, 61.6%)\u001b[0m\n",
            "[2024-04-02 20:13:58] \u001b[32mTrain: [  4/50] Step 120/520 Loss 3.780 Prec@(1,5) (30.0%, 61.9%)\u001b[0m\n",
            "[2024-04-02 20:13:59] \u001b[32mTrain: [  4/50] Step 140/520 Loss 3.775 Prec@(1,5) (30.1%, 62.0%)\u001b[0m\n",
            "[2024-04-02 20:13:59] \u001b[32mTrain: [  4/50] Step 160/520 Loss 3.757 Prec@(1,5) (30.3%, 62.3%)\u001b[0m\n",
            "[2024-04-02 20:14:00] \u001b[32mTrain: [  4/50] Step 180/520 Loss 3.745 Prec@(1,5) (30.5%, 62.5%)\u001b[0m\n",
            "[2024-04-02 20:14:00] \u001b[32mTrain: [  4/50] Step 200/520 Loss 3.745 Prec@(1,5) (30.6%, 62.6%)\u001b[0m\n",
            "[2024-04-02 20:14:01] \u001b[32mTrain: [  4/50] Step 220/520 Loss 3.743 Prec@(1,5) (30.6%, 62.5%)\u001b[0m\n",
            "[2024-04-02 20:14:01] \u001b[32mTrain: [  4/50] Step 240/520 Loss 3.738 Prec@(1,5) (30.8%, 62.7%)\u001b[0m\n",
            "[2024-04-02 20:14:02] \u001b[32mTrain: [  4/50] Step 260/520 Loss 3.740 Prec@(1,5) (30.8%, 62.6%)\u001b[0m\n",
            "[2024-04-02 20:14:02] \u001b[32mTrain: [  4/50] Step 280/520 Loss 3.735 Prec@(1,5) (31.0%, 62.7%)\u001b[0m\n",
            "[2024-04-02 20:14:03] \u001b[32mTrain: [  4/50] Step 300/520 Loss 3.732 Prec@(1,5) (31.1%, 62.8%)\u001b[0m\n",
            "[2024-04-02 20:14:03] \u001b[32mTrain: [  4/50] Step 320/520 Loss 3.733 Prec@(1,5) (31.1%, 62.7%)\u001b[0m\n",
            "[2024-04-02 20:14:04] \u001b[32mTrain: [  4/50] Step 340/520 Loss 3.726 Prec@(1,5) (31.2%, 62.9%)\u001b[0m\n",
            "[2024-04-02 20:14:04] \u001b[32mTrain: [  4/50] Step 360/520 Loss 3.725 Prec@(1,5) (31.2%, 62.8%)\u001b[0m\n",
            "[2024-04-02 20:14:05] \u001b[32mTrain: [  4/50] Step 380/520 Loss 3.721 Prec@(1,5) (31.4%, 62.8%)\u001b[0m\n",
            "[2024-04-02 20:14:05] \u001b[32mTrain: [  4/50] Step 400/520 Loss 3.719 Prec@(1,5) (31.4%, 62.9%)\u001b[0m\n",
            "[2024-04-02 20:14:06] \u001b[32mTrain: [  4/50] Step 420/520 Loss 3.713 Prec@(1,5) (31.5%, 63.0%)\u001b[0m\n",
            "[2024-04-02 20:14:06] \u001b[32mTrain: [  4/50] Step 440/520 Loss 3.708 Prec@(1,5) (31.5%, 63.1%)\u001b[0m\n",
            "[2024-04-02 20:14:07] \u001b[32mTrain: [  4/50] Step 460/520 Loss 3.707 Prec@(1,5) (31.6%, 63.2%)\u001b[0m\n",
            "[2024-04-02 20:14:07] \u001b[32mTrain: [  4/50] Step 480/520 Loss 3.702 Prec@(1,5) (31.6%, 63.3%)\u001b[0m\n",
            "[2024-04-02 20:14:08] \u001b[32mTrain: [  4/50] Step 500/520 Loss 3.695 Prec@(1,5) (31.7%, 63.4%)\u001b[0m\n",
            "[2024-04-02 20:14:08] \u001b[32mTrain: [  4/50] Step 520/520 Loss 3.691 Prec@(1,5) (31.8%, 63.4%)\u001b[0m\n",
            "[2024-04-02 20:14:08] \u001b[32mTrain: [  4/50] Final Prec@1 31.7640%\u001b[0m\n",
            "[2024-04-02 20:14:12] \u001b[32mValid: [  4/50] Step 000/104 Loss 3.860 Prec@(1,5) (28.1%, 58.3%)\u001b[0m\n",
            "[2024-04-02 20:14:12] \u001b[32mValid: [  4/50] Step 020/104 Loss 3.631 Prec@(1,5) (29.8%, 62.5%)\u001b[0m\n",
            "[2024-04-02 20:14:12] \u001b[32mValid: [  4/50] Step 040/104 Loss 3.587 Prec@(1,5) (30.1%, 63.0%)\u001b[0m\n",
            "[2024-04-02 20:14:12] \u001b[32mValid: [  4/50] Step 060/104 Loss 3.569 Prec@(1,5) (30.8%, 62.9%)\u001b[0m\n",
            "[2024-04-02 20:14:12] \u001b[32mValid: [  4/50] Step 080/104 Loss 3.595 Prec@(1,5) (30.8%, 62.7%)\u001b[0m\n",
            "[2024-04-02 20:14:13] \u001b[32mValid: [  4/50] Step 100/104 Loss 3.609 Prec@(1,5) (30.6%, 62.5%)\u001b[0m\n",
            "[2024-04-02 20:14:13] \u001b[32mValid: [  4/50] Step 104/104 Loss 3.608 Prec@(1,5) (30.6%, 62.5%)\u001b[0m\n",
            "[2024-04-02 20:14:13] \u001b[32mValid: [  4/50] Final Prec@1 30.5600%\u001b[0m\n",
            "[2024-04-02 20:14:13] \u001b[32mEpoch 4 LR 0.024607\u001b[0m\n",
            "[2024-04-02 20:14:17] \u001b[32mTrain: [  5/50] Step 000/520 Loss 3.398 Prec@(1,5) (41.7%, 69.8%)\u001b[0m\n",
            "[2024-04-02 20:14:18] \u001b[32mTrain: [  5/50] Step 020/520 Loss 3.520 Prec@(1,5) (34.1%, 66.2%)\u001b[0m\n",
            "[2024-04-02 20:14:18] \u001b[32mTrain: [  5/50] Step 040/520 Loss 3.496 Prec@(1,5) (34.2%, 66.3%)\u001b[0m\n",
            "[2024-04-02 20:14:19] \u001b[32mTrain: [  5/50] Step 060/520 Loss 3.497 Prec@(1,5) (34.2%, 66.0%)\u001b[0m\n",
            "[2024-04-02 20:14:19] \u001b[32mTrain: [  5/50] Step 080/520 Loss 3.519 Prec@(1,5) (33.8%, 65.7%)\u001b[0m\n",
            "[2024-04-02 20:14:20] \u001b[32mTrain: [  5/50] Step 100/520 Loss 3.518 Prec@(1,5) (33.7%, 66.0%)\u001b[0m\n",
            "[2024-04-02 20:14:20] \u001b[32mTrain: [  5/50] Step 120/520 Loss 3.523 Prec@(1,5) (33.8%, 66.0%)\u001b[0m\n",
            "[2024-04-02 20:14:21] \u001b[32mTrain: [  5/50] Step 140/520 Loss 3.521 Prec@(1,5) (33.8%, 66.0%)\u001b[0m\n",
            "[2024-04-02 20:14:21] \u001b[32mTrain: [  5/50] Step 160/520 Loss 3.515 Prec@(1,5) (33.8%, 66.2%)\u001b[0m\n",
            "[2024-04-02 20:14:22] \u001b[32mTrain: [  5/50] Step 180/520 Loss 3.514 Prec@(1,5) (34.0%, 66.0%)\u001b[0m\n",
            "[2024-04-02 20:14:22] \u001b[32mTrain: [  5/50] Step 200/520 Loss 3.503 Prec@(1,5) (34.2%, 66.3%)\u001b[0m\n",
            "[2024-04-02 20:14:23] \u001b[32mTrain: [  5/50] Step 220/520 Loss 3.504 Prec@(1,5) (34.1%, 66.3%)\u001b[0m\n",
            "[2024-04-02 20:14:23] \u001b[32mTrain: [  5/50] Step 240/520 Loss 3.502 Prec@(1,5) (34.2%, 66.4%)\u001b[0m\n",
            "[2024-04-02 20:14:24] \u001b[32mTrain: [  5/50] Step 260/520 Loss 3.502 Prec@(1,5) (34.1%, 66.5%)\u001b[0m\n",
            "[2024-04-02 20:14:24] \u001b[32mTrain: [  5/50] Step 280/520 Loss 3.509 Prec@(1,5) (34.0%, 66.4%)\u001b[0m\n",
            "[2024-04-02 20:14:25] \u001b[32mTrain: [  5/50] Step 300/520 Loss 3.509 Prec@(1,5) (34.0%, 66.4%)\u001b[0m\n",
            "[2024-04-02 20:14:25] \u001b[32mTrain: [  5/50] Step 320/520 Loss 3.499 Prec@(1,5) (34.2%, 66.6%)\u001b[0m\n",
            "[2024-04-02 20:14:26] \u001b[32mTrain: [  5/50] Step 340/520 Loss 3.496 Prec@(1,5) (34.3%, 66.6%)\u001b[0m\n",
            "[2024-04-02 20:14:26] \u001b[32mTrain: [  5/50] Step 360/520 Loss 3.499 Prec@(1,5) (34.4%, 66.5%)\u001b[0m\n",
            "[2024-04-02 20:14:27] \u001b[32mTrain: [  5/50] Step 380/520 Loss 3.492 Prec@(1,5) (34.4%, 66.6%)\u001b[0m\n",
            "[2024-04-02 20:14:27] \u001b[32mTrain: [  5/50] Step 400/520 Loss 3.486 Prec@(1,5) (34.4%, 66.7%)\u001b[0m\n",
            "[2024-04-02 20:14:28] \u001b[32mTrain: [  5/50] Step 420/520 Loss 3.483 Prec@(1,5) (34.5%, 66.7%)\u001b[0m\n",
            "[2024-04-02 20:14:28] \u001b[32mTrain: [  5/50] Step 440/520 Loss 3.484 Prec@(1,5) (34.6%, 66.7%)\u001b[0m\n",
            "[2024-04-02 20:14:29] \u001b[32mTrain: [  5/50] Step 460/520 Loss 3.485 Prec@(1,5) (34.6%, 66.7%)\u001b[0m\n",
            "[2024-04-02 20:14:29] \u001b[32mTrain: [  5/50] Step 480/520 Loss 3.483 Prec@(1,5) (34.7%, 66.7%)\u001b[0m\n",
            "[2024-04-02 20:14:30] \u001b[32mTrain: [  5/50] Step 500/520 Loss 3.479 Prec@(1,5) (34.7%, 66.8%)\u001b[0m\n",
            "[2024-04-02 20:14:30] \u001b[32mTrain: [  5/50] Step 520/520 Loss 3.472 Prec@(1,5) (34.8%, 66.9%)\u001b[0m\n",
            "[2024-04-02 20:14:30] \u001b[32mTrain: [  5/50] Final Prec@1 34.8440%\u001b[0m\n",
            "[2024-04-02 20:14:34] \u001b[32mValid: [  5/50] Step 000/104 Loss 3.670 Prec@(1,5) (34.4%, 68.8%)\u001b[0m\n",
            "[2024-04-02 20:14:34] \u001b[32mValid: [  5/50] Step 020/104 Loss 3.445 Prec@(1,5) (33.2%, 67.0%)\u001b[0m\n",
            "[2024-04-02 20:14:34] \u001b[32mValid: [  5/50] Step 040/104 Loss 3.374 Prec@(1,5) (33.9%, 67.9%)\u001b[0m\n",
            "[2024-04-02 20:14:34] \u001b[32mValid: [  5/50] Step 060/104 Loss 3.371 Prec@(1,5) (34.4%, 67.6%)\u001b[0m\n",
            "[2024-04-02 20:14:35] \u001b[32mValid: [  5/50] Step 080/104 Loss 3.382 Prec@(1,5) (34.4%, 67.6%)\u001b[0m\n",
            "[2024-04-02 20:14:35] \u001b[32mValid: [  5/50] Step 100/104 Loss 3.388 Prec@(1,5) (34.4%, 67.6%)\u001b[0m\n",
            "[2024-04-02 20:14:35] \u001b[32mValid: [  5/50] Step 104/104 Loss 3.387 Prec@(1,5) (34.3%, 67.6%)\u001b[0m\n",
            "[2024-04-02 20:14:35] \u001b[32mValid: [  5/50] Final Prec@1 34.2600%\u001b[0m\n",
            "[2024-04-02 20:14:35] \u001b[32mEpoch 5 LR 0.024388\u001b[0m\n",
            "[2024-04-02 20:14:40] \u001b[32mTrain: [  6/50] Step 000/520 Loss 3.914 Prec@(1,5) (29.2%, 60.4%)\u001b[0m\n",
            "[2024-04-02 20:14:40] \u001b[32mTrain: [  6/50] Step 020/520 Loss 3.410 Prec@(1,5) (36.3%, 67.8%)\u001b[0m\n",
            "[2024-04-02 20:14:41] \u001b[32mTrain: [  6/50] Step 040/520 Loss 3.312 Prec@(1,5) (37.5%, 69.4%)\u001b[0m\n",
            "[2024-04-02 20:14:41] \u001b[32mTrain: [  6/50] Step 060/520 Loss 3.322 Prec@(1,5) (37.9%, 69.4%)\u001b[0m\n",
            "[2024-04-02 20:14:42] \u001b[32mTrain: [  6/50] Step 080/520 Loss 3.313 Prec@(1,5) (37.8%, 69.3%)\u001b[0m\n",
            "[2024-04-02 20:14:42] \u001b[32mTrain: [  6/50] Step 100/520 Loss 3.321 Prec@(1,5) (37.6%, 69.0%)\u001b[0m\n",
            "[2024-04-02 20:14:43] \u001b[32mTrain: [  6/50] Step 120/520 Loss 3.334 Prec@(1,5) (37.1%, 68.9%)\u001b[0m\n",
            "[2024-04-02 20:14:43] \u001b[32mTrain: [  6/50] Step 140/520 Loss 3.331 Prec@(1,5) (37.4%, 68.9%)\u001b[0m\n",
            "[2024-04-02 20:14:44] \u001b[32mTrain: [  6/50] Step 160/520 Loss 3.323 Prec@(1,5) (37.6%, 69.1%)\u001b[0m\n",
            "[2024-04-02 20:14:44] \u001b[32mTrain: [  6/50] Step 180/520 Loss 3.314 Prec@(1,5) (37.6%, 69.4%)\u001b[0m\n",
            "[2024-04-02 20:14:45] \u001b[32mTrain: [  6/50] Step 200/520 Loss 3.320 Prec@(1,5) (37.5%, 69.4%)\u001b[0m\n",
            "[2024-04-02 20:14:45] \u001b[32mTrain: [  6/50] Step 220/520 Loss 3.328 Prec@(1,5) (37.3%, 69.2%)\u001b[0m\n",
            "[2024-04-02 20:14:46] \u001b[32mTrain: [  6/50] Step 240/520 Loss 3.326 Prec@(1,5) (37.4%, 69.2%)\u001b[0m\n",
            "[2024-04-02 20:14:46] \u001b[32mTrain: [  6/50] Step 260/520 Loss 3.324 Prec@(1,5) (37.4%, 69.3%)\u001b[0m\n",
            "[2024-04-02 20:14:47] \u001b[32mTrain: [  6/50] Step 280/520 Loss 3.322 Prec@(1,5) (37.4%, 69.4%)\u001b[0m\n",
            "[2024-04-02 20:14:47] \u001b[32mTrain: [  6/50] Step 300/520 Loss 3.317 Prec@(1,5) (37.5%, 69.5%)\u001b[0m\n",
            "[2024-04-02 20:14:48] \u001b[32mTrain: [  6/50] Step 320/520 Loss 3.313 Prec@(1,5) (37.5%, 69.7%)\u001b[0m\n",
            "[2024-04-02 20:14:48] \u001b[32mTrain: [  6/50] Step 340/520 Loss 3.312 Prec@(1,5) (37.5%, 69.6%)\u001b[0m\n",
            "[2024-04-02 20:14:49] \u001b[32mTrain: [  6/50] Step 360/520 Loss 3.306 Prec@(1,5) (37.5%, 69.7%)\u001b[0m\n",
            "[2024-04-02 20:14:49] \u001b[32mTrain: [  6/50] Step 380/520 Loss 3.301 Prec@(1,5) (37.6%, 69.8%)\u001b[0m\n",
            "[2024-04-02 20:14:50] \u001b[32mTrain: [  6/50] Step 400/520 Loss 3.299 Prec@(1,5) (37.7%, 69.8%)\u001b[0m\n",
            "[2024-04-02 20:14:50] \u001b[32mTrain: [  6/50] Step 420/520 Loss 3.297 Prec@(1,5) (37.7%, 69.9%)\u001b[0m\n",
            "[2024-04-02 20:14:51] \u001b[32mTrain: [  6/50] Step 440/520 Loss 3.293 Prec@(1,5) (37.7%, 70.0%)\u001b[0m\n",
            "[2024-04-02 20:14:51] \u001b[32mTrain: [  6/50] Step 460/520 Loss 3.294 Prec@(1,5) (37.8%, 69.9%)\u001b[0m\n",
            "[2024-04-02 20:14:52] \u001b[32mTrain: [  6/50] Step 480/520 Loss 3.291 Prec@(1,5) (37.8%, 70.0%)\u001b[0m\n",
            "[2024-04-02 20:14:52] \u001b[32mTrain: [  6/50] Step 500/520 Loss 3.290 Prec@(1,5) (37.8%, 70.0%)\u001b[0m\n",
            "[2024-04-02 20:14:53] \u001b[32mTrain: [  6/50] Step 520/520 Loss 3.291 Prec@(1,5) (37.8%, 69.9%)\u001b[0m\n",
            "[2024-04-02 20:14:53] \u001b[32mTrain: [  6/50] Final Prec@1 37.7700%\u001b[0m\n",
            "[2024-04-02 20:14:57] \u001b[32mValid: [  6/50] Step 000/104 Loss 3.198 Prec@(1,5) (44.8%, 71.9%)\u001b[0m\n",
            "[2024-04-02 20:14:57] \u001b[32mValid: [  6/50] Step 020/104 Loss 3.182 Prec@(1,5) (37.8%, 69.4%)\u001b[0m\n",
            "[2024-04-02 20:14:57] \u001b[32mValid: [  6/50] Step 040/104 Loss 3.154 Prec@(1,5) (36.6%, 70.0%)\u001b[0m\n",
            "[2024-04-02 20:14:57] \u001b[32mValid: [  6/50] Step 060/104 Loss 3.153 Prec@(1,5) (36.2%, 69.6%)\u001b[0m\n",
            "[2024-04-02 20:14:57] \u001b[32mValid: [  6/50] Step 080/104 Loss 3.185 Prec@(1,5) (35.8%, 69.5%)\u001b[0m\n",
            "[2024-04-02 20:14:57] \u001b[32mValid: [  6/50] Step 100/104 Loss 3.184 Prec@(1,5) (35.8%, 69.3%)\u001b[0m\n",
            "[2024-04-02 20:14:57] \u001b[32mValid: [  6/50] Step 104/104 Loss 3.184 Prec@(1,5) (35.8%, 69.3%)\u001b[0m\n",
            "[2024-04-02 20:14:58] \u001b[32mValid: [  6/50] Final Prec@1 35.7500%\u001b[0m\n",
            "[2024-04-02 20:14:58] \u001b[32mEpoch 6 LR 0.024122\u001b[0m\n",
            "[2024-04-02 20:15:02] \u001b[32mTrain: [  7/50] Step 000/520 Loss 2.953 Prec@(1,5) (50.0%, 76.0%)\u001b[0m\n",
            "[2024-04-02 20:15:03] \u001b[32mTrain: [  7/50] Step 020/520 Loss 3.127 Prec@(1,5) (40.5%, 72.8%)\u001b[0m\n",
            "[2024-04-02 20:15:03] \u001b[32mTrain: [  7/50] Step 040/520 Loss 3.106 Prec@(1,5) (40.7%, 73.1%)\u001b[0m\n",
            "[2024-04-02 20:15:04] \u001b[32mTrain: [  7/50] Step 060/520 Loss 3.152 Prec@(1,5) (39.8%, 72.3%)\u001b[0m\n",
            "[2024-04-02 20:15:04] \u001b[32mTrain: [  7/50] Step 080/520 Loss 3.154 Prec@(1,5) (39.7%, 72.1%)\u001b[0m\n",
            "[2024-04-02 20:15:05] \u001b[32mTrain: [  7/50] Step 100/520 Loss 3.169 Prec@(1,5) (39.7%, 71.9%)\u001b[0m\n",
            "[2024-04-02 20:15:05] \u001b[32mTrain: [  7/50] Step 120/520 Loss 3.169 Prec@(1,5) (39.6%, 71.9%)\u001b[0m\n",
            "[2024-04-02 20:15:06] \u001b[32mTrain: [  7/50] Step 140/520 Loss 3.163 Prec@(1,5) (39.7%, 72.0%)\u001b[0m\n",
            "[2024-04-02 20:15:06] \u001b[32mTrain: [  7/50] Step 160/520 Loss 3.153 Prec@(1,5) (39.9%, 72.1%)\u001b[0m\n",
            "[2024-04-02 20:15:07] \u001b[32mTrain: [  7/50] Step 180/520 Loss 3.147 Prec@(1,5) (40.0%, 72.2%)\u001b[0m\n",
            "[2024-04-02 20:15:07] \u001b[32mTrain: [  7/50] Step 200/520 Loss 3.147 Prec@(1,5) (40.0%, 72.3%)\u001b[0m\n",
            "[2024-04-02 20:15:08] \u001b[32mTrain: [  7/50] Step 220/520 Loss 3.142 Prec@(1,5) (40.0%, 72.4%)\u001b[0m\n",
            "[2024-04-02 20:15:08] \u001b[32mTrain: [  7/50] Step 240/520 Loss 3.148 Prec@(1,5) (40.0%, 72.3%)\u001b[0m\n",
            "[2024-04-02 20:15:09] \u001b[32mTrain: [  7/50] Step 260/520 Loss 3.148 Prec@(1,5) (39.9%, 72.2%)\u001b[0m\n",
            "[2024-04-02 20:15:09] \u001b[32mTrain: [  7/50] Step 280/520 Loss 3.152 Prec@(1,5) (39.9%, 72.1%)\u001b[0m\n",
            "[2024-04-02 20:15:10] \u001b[32mTrain: [  7/50] Step 300/520 Loss 3.153 Prec@(1,5) (39.9%, 72.0%)\u001b[0m\n",
            "[2024-04-02 20:15:10] \u001b[32mTrain: [  7/50] Step 320/520 Loss 3.155 Prec@(1,5) (39.8%, 72.0%)\u001b[0m\n",
            "[2024-04-02 20:15:11] \u001b[32mTrain: [  7/50] Step 340/520 Loss 3.157 Prec@(1,5) (39.8%, 72.0%)\u001b[0m\n",
            "[2024-04-02 20:15:11] \u001b[32mTrain: [  7/50] Step 360/520 Loss 3.157 Prec@(1,5) (39.8%, 72.0%)\u001b[0m\n",
            "[2024-04-02 20:15:12] \u001b[32mTrain: [  7/50] Step 380/520 Loss 3.154 Prec@(1,5) (39.9%, 72.0%)\u001b[0m\n",
            "[2024-04-02 20:15:12] \u001b[32mTrain: [  7/50] Step 400/520 Loss 3.154 Prec@(1,5) (39.9%, 72.0%)\u001b[0m\n",
            "[2024-04-02 20:15:13] \u001b[32mTrain: [  7/50] Step 420/520 Loss 3.153 Prec@(1,5) (40.0%, 72.0%)\u001b[0m\n",
            "[2024-04-02 20:15:13] \u001b[32mTrain: [  7/50] Step 440/520 Loss 3.149 Prec@(1,5) (40.2%, 72.0%)\u001b[0m\n",
            "[2024-04-02 20:15:14] \u001b[32mTrain: [  7/50] Step 460/520 Loss 3.143 Prec@(1,5) (40.2%, 72.1%)\u001b[0m\n",
            "[2024-04-02 20:15:14] \u001b[32mTrain: [  7/50] Step 480/520 Loss 3.145 Prec@(1,5) (40.2%, 72.1%)\u001b[0m\n",
            "[2024-04-02 20:15:15] \u001b[32mTrain: [  7/50] Step 500/520 Loss 3.143 Prec@(1,5) (40.3%, 72.0%)\u001b[0m\n",
            "[2024-04-02 20:15:15] \u001b[32mTrain: [  7/50] Step 520/520 Loss 3.141 Prec@(1,5) (40.3%, 72.1%)\u001b[0m\n",
            "[2024-04-02 20:15:15] \u001b[32mTrain: [  7/50] Final Prec@1 40.2680%\u001b[0m\n",
            "[2024-04-02 20:15:19] \u001b[32mValid: [  7/50] Step 000/104 Loss 3.333 Prec@(1,5) (40.6%, 70.8%)\u001b[0m\n",
            "[2024-04-02 20:15:19] \u001b[32mValid: [  7/50] Step 020/104 Loss 3.042 Prec@(1,5) (39.9%, 72.4%)\u001b[0m\n",
            "[2024-04-02 20:15:19] \u001b[32mValid: [  7/50] Step 040/104 Loss 3.048 Prec@(1,5) (39.6%, 72.5%)\u001b[0m\n",
            "[2024-04-02 20:15:19] \u001b[32mValid: [  7/50] Step 060/104 Loss 3.017 Prec@(1,5) (39.9%, 72.7%)\u001b[0m\n",
            "[2024-04-02 20:15:19] \u001b[32mValid: [  7/50] Step 080/104 Loss 3.030 Prec@(1,5) (39.4%, 72.5%)\u001b[0m\n",
            "[2024-04-02 20:15:20] \u001b[32mValid: [  7/50] Step 100/104 Loss 3.019 Prec@(1,5) (39.5%, 72.3%)\u001b[0m\n",
            "[2024-04-02 20:15:20] \u001b[32mValid: [  7/50] Step 104/104 Loss 3.022 Prec@(1,5) (39.5%, 72.2%)\u001b[0m\n",
            "[2024-04-02 20:15:20] \u001b[32mValid: [  7/50] Final Prec@1 39.4900%\u001b[0m\n",
            "[2024-04-02 20:15:20] \u001b[32mEpoch 7 LR 0.023810\u001b[0m\n",
            "[2024-04-02 20:15:24] \u001b[32mTrain: [  8/50] Step 000/520 Loss 2.699 Prec@(1,5) (42.7%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:15:25] \u001b[32mTrain: [  8/50] Step 020/520 Loss 2.974 Prec@(1,5) (42.0%, 74.1%)\u001b[0m\n",
            "[2024-04-02 20:15:25] \u001b[32mTrain: [  8/50] Step 040/520 Loss 2.999 Prec@(1,5) (41.9%, 73.5%)\u001b[0m\n",
            "[2024-04-02 20:15:26] \u001b[32mTrain: [  8/50] Step 060/520 Loss 2.986 Prec@(1,5) (42.0%, 73.9%)\u001b[0m\n",
            "[2024-04-02 20:15:26] \u001b[32mTrain: [  8/50] Step 080/520 Loss 2.976 Prec@(1,5) (42.1%, 74.1%)\u001b[0m\n",
            "[2024-04-02 20:15:27] \u001b[32mTrain: [  8/50] Step 100/520 Loss 2.992 Prec@(1,5) (42.0%, 73.9%)\u001b[0m\n",
            "[2024-04-02 20:15:27] \u001b[32mTrain: [  8/50] Step 120/520 Loss 2.976 Prec@(1,5) (42.2%, 74.2%)\u001b[0m\n",
            "[2024-04-02 20:15:28] \u001b[32mTrain: [  8/50] Step 140/520 Loss 2.981 Prec@(1,5) (42.4%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:15:28] \u001b[32mTrain: [  8/50] Step 160/520 Loss 2.997 Prec@(1,5) (42.2%, 73.7%)\u001b[0m\n",
            "[2024-04-02 20:15:29] \u001b[32mTrain: [  8/50] Step 180/520 Loss 3.012 Prec@(1,5) (42.0%, 73.5%)\u001b[0m\n",
            "[2024-04-02 20:15:29] \u001b[32mTrain: [  8/50] Step 200/520 Loss 3.012 Prec@(1,5) (42.0%, 73.6%)\u001b[0m\n",
            "[2024-04-02 20:15:30] \u001b[32mTrain: [  8/50] Step 220/520 Loss 3.014 Prec@(1,5) (41.9%, 73.6%)\u001b[0m\n",
            "[2024-04-02 20:15:30] \u001b[32mTrain: [  8/50] Step 240/520 Loss 3.014 Prec@(1,5) (41.9%, 73.7%)\u001b[0m\n",
            "[2024-04-02 20:15:31] \u001b[32mTrain: [  8/50] Step 260/520 Loss 3.018 Prec@(1,5) (41.9%, 73.7%)\u001b[0m\n",
            "[2024-04-02 20:15:31] \u001b[32mTrain: [  8/50] Step 280/520 Loss 3.015 Prec@(1,5) (42.0%, 73.8%)\u001b[0m\n",
            "[2024-04-02 20:15:32] \u001b[32mTrain: [  8/50] Step 300/520 Loss 3.018 Prec@(1,5) (41.9%, 73.8%)\u001b[0m\n",
            "[2024-04-02 20:15:32] \u001b[32mTrain: [  8/50] Step 320/520 Loss 3.021 Prec@(1,5) (41.8%, 73.8%)\u001b[0m\n",
            "[2024-04-02 20:15:33] \u001b[32mTrain: [  8/50] Step 340/520 Loss 3.023 Prec@(1,5) (41.8%, 73.8%)\u001b[0m\n",
            "[2024-04-02 20:15:33] \u001b[32mTrain: [  8/50] Step 360/520 Loss 3.023 Prec@(1,5) (41.9%, 73.7%)\u001b[0m\n",
            "[2024-04-02 20:15:34] \u001b[32mTrain: [  8/50] Step 380/520 Loss 3.021 Prec@(1,5) (41.9%, 73.7%)\u001b[0m\n",
            "[2024-04-02 20:15:34] \u001b[32mTrain: [  8/50] Step 400/520 Loss 3.021 Prec@(1,5) (41.9%, 73.7%)\u001b[0m\n",
            "[2024-04-02 20:15:35] \u001b[32mTrain: [  8/50] Step 420/520 Loss 3.019 Prec@(1,5) (42.0%, 73.7%)\u001b[0m\n",
            "[2024-04-02 20:15:35] \u001b[32mTrain: [  8/50] Step 440/520 Loss 3.018 Prec@(1,5) (42.0%, 73.7%)\u001b[0m\n",
            "[2024-04-02 20:15:36] \u001b[32mTrain: [  8/50] Step 460/520 Loss 3.019 Prec@(1,5) (42.0%, 73.7%)\u001b[0m\n",
            "[2024-04-02 20:15:36] \u001b[32mTrain: [  8/50] Step 480/520 Loss 3.016 Prec@(1,5) (42.1%, 73.8%)\u001b[0m\n",
            "[2024-04-02 20:15:37] \u001b[32mTrain: [  8/50] Step 500/520 Loss 3.013 Prec@(1,5) (42.3%, 73.8%)\u001b[0m\n",
            "[2024-04-02 20:15:37] \u001b[32mTrain: [  8/50] Step 520/520 Loss 3.013 Prec@(1,5) (42.2%, 73.8%)\u001b[0m\n",
            "[2024-04-02 20:15:37] \u001b[32mTrain: [  8/50] Final Prec@1 42.2100%\u001b[0m\n",
            "[2024-04-02 20:15:41] \u001b[32mValid: [  8/50] Step 000/104 Loss 2.863 Prec@(1,5) (43.8%, 75.0%)\u001b[0m\n",
            "[2024-04-02 20:15:41] \u001b[32mValid: [  8/50] Step 020/104 Loss 3.036 Prec@(1,5) (41.1%, 71.6%)\u001b[0m\n",
            "[2024-04-02 20:15:41] \u001b[32mValid: [  8/50] Step 040/104 Loss 3.011 Prec@(1,5) (40.9%, 71.9%)\u001b[0m\n",
            "[2024-04-02 20:15:41] \u001b[32mValid: [  8/50] Step 060/104 Loss 2.975 Prec@(1,5) (41.7%, 72.1%)\u001b[0m\n",
            "[2024-04-02 20:15:42] \u001b[32mValid: [  8/50] Step 080/104 Loss 2.986 Prec@(1,5) (41.1%, 72.3%)\u001b[0m\n",
            "[2024-04-02 20:15:42] \u001b[32mValid: [  8/50] Step 100/104 Loss 2.978 Prec@(1,5) (40.9%, 72.2%)\u001b[0m\n",
            "[2024-04-02 20:15:42] \u001b[32mValid: [  8/50] Step 104/104 Loss 2.980 Prec@(1,5) (40.8%, 72.2%)\u001b[0m\n",
            "[2024-04-02 20:15:42] \u001b[32mValid: [  8/50] Final Prec@1 40.8300%\u001b[0m\n",
            "[2024-04-02 20:15:42] \u001b[32mEpoch 8 LR 0.023454\u001b[0m\n",
            "[2024-04-02 20:15:47] \u001b[32mTrain: [  9/50] Step 000/520 Loss 3.102 Prec@(1,5) (43.8%, 78.1%)\u001b[0m\n",
            "[2024-04-02 20:15:47] \u001b[32mTrain: [  9/50] Step 020/520 Loss 2.948 Prec@(1,5) (42.1%, 74.6%)\u001b[0m\n",
            "[2024-04-02 20:15:48] \u001b[32mTrain: [  9/50] Step 040/520 Loss 2.935 Prec@(1,5) (43.5%, 75.1%)\u001b[0m\n",
            "[2024-04-02 20:15:48] \u001b[32mTrain: [  9/50] Step 060/520 Loss 2.936 Prec@(1,5) (43.1%, 74.8%)\u001b[0m\n",
            "[2024-04-02 20:15:49] \u001b[32mTrain: [  9/50] Step 080/520 Loss 2.911 Prec@(1,5) (43.4%, 75.2%)\u001b[0m\n",
            "[2024-04-02 20:15:49] \u001b[32mTrain: [  9/50] Step 100/520 Loss 2.889 Prec@(1,5) (43.8%, 75.7%)\u001b[0m\n",
            "[2024-04-02 20:15:50] \u001b[32mTrain: [  9/50] Step 120/520 Loss 2.901 Prec@(1,5) (43.4%, 75.5%)\u001b[0m\n",
            "[2024-04-02 20:15:50] \u001b[32mTrain: [  9/50] Step 140/520 Loss 2.908 Prec@(1,5) (43.5%, 75.3%)\u001b[0m\n",
            "[2024-04-02 20:15:51] \u001b[32mTrain: [  9/50] Step 160/520 Loss 2.921 Prec@(1,5) (43.5%, 75.1%)\u001b[0m\n",
            "[2024-04-02 20:15:51] \u001b[32mTrain: [  9/50] Step 180/520 Loss 2.921 Prec@(1,5) (43.4%, 75.2%)\u001b[0m\n",
            "[2024-04-02 20:15:52] \u001b[32mTrain: [  9/50] Step 200/520 Loss 2.914 Prec@(1,5) (43.6%, 75.2%)\u001b[0m\n",
            "[2024-04-02 20:15:52] \u001b[32mTrain: [  9/50] Step 220/520 Loss 2.913 Prec@(1,5) (43.7%, 75.2%)\u001b[0m\n",
            "[2024-04-02 20:15:53] \u001b[32mTrain: [  9/50] Step 240/520 Loss 2.919 Prec@(1,5) (43.6%, 75.2%)\u001b[0m\n",
            "[2024-04-02 20:15:53] \u001b[32mTrain: [  9/50] Step 260/520 Loss 2.925 Prec@(1,5) (43.5%, 75.2%)\u001b[0m\n",
            "[2024-04-02 20:15:54] \u001b[32mTrain: [  9/50] Step 280/520 Loss 2.926 Prec@(1,5) (43.5%, 75.2%)\u001b[0m\n",
            "[2024-04-02 20:15:54] \u001b[32mTrain: [  9/50] Step 300/520 Loss 2.928 Prec@(1,5) (43.4%, 75.1%)\u001b[0m\n",
            "[2024-04-02 20:15:55] \u001b[32mTrain: [  9/50] Step 320/520 Loss 2.928 Prec@(1,5) (43.4%, 75.1%)\u001b[0m\n",
            "[2024-04-02 20:15:55] \u001b[32mTrain: [  9/50] Step 340/520 Loss 2.930 Prec@(1,5) (43.3%, 75.1%)\u001b[0m\n",
            "[2024-04-02 20:15:56] \u001b[32mTrain: [  9/50] Step 360/520 Loss 2.924 Prec@(1,5) (43.4%, 75.2%)\u001b[0m\n",
            "[2024-04-02 20:15:56] \u001b[32mTrain: [  9/50] Step 380/520 Loss 2.924 Prec@(1,5) (43.5%, 75.2%)\u001b[0m\n",
            "[2024-04-02 20:15:57] \u001b[32mTrain: [  9/50] Step 400/520 Loss 2.916 Prec@(1,5) (43.7%, 75.3%)\u001b[0m\n",
            "[2024-04-02 20:15:57] \u001b[32mTrain: [  9/50] Step 420/520 Loss 2.916 Prec@(1,5) (43.7%, 75.3%)\u001b[0m\n",
            "[2024-04-02 20:15:58] \u001b[32mTrain: [  9/50] Step 440/520 Loss 2.914 Prec@(1,5) (43.7%, 75.3%)\u001b[0m\n",
            "[2024-04-02 20:15:58] \u001b[32mTrain: [  9/50] Step 460/520 Loss 2.918 Prec@(1,5) (43.6%, 75.3%)\u001b[0m\n",
            "[2024-04-02 20:15:59] \u001b[32mTrain: [  9/50] Step 480/520 Loss 2.913 Prec@(1,5) (43.7%, 75.4%)\u001b[0m\n",
            "[2024-04-02 20:15:59] \u001b[32mTrain: [  9/50] Step 500/520 Loss 2.915 Prec@(1,5) (43.7%, 75.4%)\u001b[0m\n",
            "[2024-04-02 20:16:00] \u001b[32mTrain: [  9/50] Step 520/520 Loss 2.911 Prec@(1,5) (43.7%, 75.5%)\u001b[0m\n",
            "[2024-04-02 20:16:00] \u001b[32mTrain: [  9/50] Final Prec@1 43.7320%\u001b[0m\n",
            "[2024-04-02 20:16:03] \u001b[32mValid: [  9/50] Step 000/104 Loss 3.076 Prec@(1,5) (44.8%, 72.9%)\u001b[0m\n",
            "[2024-04-02 20:16:04] \u001b[32mValid: [  9/50] Step 020/104 Loss 2.985 Prec@(1,5) (41.7%, 73.0%)\u001b[0m\n",
            "[2024-04-02 20:16:04] \u001b[32mValid: [  9/50] Step 040/104 Loss 2.968 Prec@(1,5) (41.2%, 72.7%)\u001b[0m\n",
            "[2024-04-02 20:16:04] \u001b[32mValid: [  9/50] Step 060/104 Loss 2.928 Prec@(1,5) (41.9%, 72.8%)\u001b[0m\n",
            "[2024-04-02 20:16:04] \u001b[32mValid: [  9/50] Step 080/104 Loss 2.930 Prec@(1,5) (41.7%, 72.9%)\u001b[0m\n",
            "[2024-04-02 20:16:04] \u001b[32mValid: [  9/50] Step 100/104 Loss 2.925 Prec@(1,5) (41.6%, 72.8%)\u001b[0m\n",
            "[2024-04-02 20:16:04] \u001b[32mValid: [  9/50] Step 104/104 Loss 2.925 Prec@(1,5) (41.5%, 72.9%)\u001b[0m\n",
            "[2024-04-02 20:16:04] \u001b[32mValid: [  9/50] Final Prec@1 41.4700%\u001b[0m\n",
            "[2024-04-02 20:16:04] \u001b[32mEpoch 9 LR 0.023054\u001b[0m\n",
            "[2024-04-02 20:16:09] \u001b[32mTrain: [ 10/50] Step 000/520 Loss 3.032 Prec@(1,5) (35.4%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:16:09] \u001b[32mTrain: [ 10/50] Step 020/520 Loss 2.772 Prec@(1,5) (45.9%, 77.8%)\u001b[0m\n",
            "[2024-04-02 20:16:10] \u001b[32mTrain: [ 10/50] Step 040/520 Loss 2.805 Prec@(1,5) (45.7%, 77.2%)\u001b[0m\n",
            "[2024-04-02 20:16:10] \u001b[32mTrain: [ 10/50] Step 060/520 Loss 2.830 Prec@(1,5) (44.8%, 77.2%)\u001b[0m\n",
            "[2024-04-02 20:16:11] \u001b[32mTrain: [ 10/50] Step 080/520 Loss 2.819 Prec@(1,5) (45.0%, 77.4%)\u001b[0m\n",
            "[2024-04-02 20:16:11] \u001b[32mTrain: [ 10/50] Step 100/520 Loss 2.840 Prec@(1,5) (44.7%, 77.0%)\u001b[0m\n",
            "[2024-04-02 20:16:12] \u001b[32mTrain: [ 10/50] Step 120/520 Loss 2.830 Prec@(1,5) (45.1%, 77.1%)\u001b[0m\n",
            "[2024-04-02 20:16:12] \u001b[32mTrain: [ 10/50] Step 140/520 Loss 2.840 Prec@(1,5) (45.0%, 76.8%)\u001b[0m\n",
            "[2024-04-02 20:16:13] \u001b[32mTrain: [ 10/50] Step 160/520 Loss 2.833 Prec@(1,5) (45.1%, 76.8%)\u001b[0m\n",
            "[2024-04-02 20:16:13] \u001b[32mTrain: [ 10/50] Step 180/520 Loss 2.828 Prec@(1,5) (45.4%, 76.8%)\u001b[0m\n",
            "[2024-04-02 20:16:14] \u001b[32mTrain: [ 10/50] Step 200/520 Loss 2.822 Prec@(1,5) (45.5%, 76.9%)\u001b[0m\n",
            "[2024-04-02 20:16:14] \u001b[32mTrain: [ 10/50] Step 220/520 Loss 2.821 Prec@(1,5) (45.5%, 76.9%)\u001b[0m\n",
            "[2024-04-02 20:16:15] \u001b[32mTrain: [ 10/50] Step 240/520 Loss 2.821 Prec@(1,5) (45.6%, 76.8%)\u001b[0m\n",
            "[2024-04-02 20:16:15] \u001b[32mTrain: [ 10/50] Step 260/520 Loss 2.827 Prec@(1,5) (45.5%, 76.7%)\u001b[0m\n",
            "[2024-04-02 20:16:16] \u001b[32mTrain: [ 10/50] Step 280/520 Loss 2.819 Prec@(1,5) (45.7%, 76.9%)\u001b[0m\n",
            "[2024-04-02 20:16:16] \u001b[32mTrain: [ 10/50] Step 300/520 Loss 2.820 Prec@(1,5) (45.6%, 76.9%)\u001b[0m\n",
            "[2024-04-02 20:16:17] \u001b[32mTrain: [ 10/50] Step 320/520 Loss 2.819 Prec@(1,5) (45.6%, 76.9%)\u001b[0m\n",
            "[2024-04-02 20:16:17] \u001b[32mTrain: [ 10/50] Step 340/520 Loss 2.816 Prec@(1,5) (45.6%, 76.9%)\u001b[0m\n",
            "[2024-04-02 20:16:18] \u001b[32mTrain: [ 10/50] Step 360/520 Loss 2.821 Prec@(1,5) (45.4%, 76.9%)\u001b[0m\n",
            "[2024-04-02 20:16:18] \u001b[32mTrain: [ 10/50] Step 380/520 Loss 2.822 Prec@(1,5) (45.4%, 76.9%)\u001b[0m\n",
            "[2024-04-02 20:16:19] \u001b[32mTrain: [ 10/50] Step 400/520 Loss 2.816 Prec@(1,5) (45.4%, 77.0%)\u001b[0m\n",
            "[2024-04-02 20:16:19] \u001b[32mTrain: [ 10/50] Step 420/520 Loss 2.819 Prec@(1,5) (45.4%, 76.9%)\u001b[0m\n",
            "[2024-04-02 20:16:20] \u001b[32mTrain: [ 10/50] Step 440/520 Loss 2.819 Prec@(1,5) (45.4%, 76.9%)\u001b[0m\n",
            "[2024-04-02 20:16:20] \u001b[32mTrain: [ 10/50] Step 460/520 Loss 2.818 Prec@(1,5) (45.4%, 77.0%)\u001b[0m\n",
            "[2024-04-02 20:16:21] \u001b[32mTrain: [ 10/50] Step 480/520 Loss 2.818 Prec@(1,5) (45.4%, 77.0%)\u001b[0m\n",
            "[2024-04-02 20:16:21] \u001b[32mTrain: [ 10/50] Step 500/520 Loss 2.817 Prec@(1,5) (45.4%, 77.0%)\u001b[0m\n",
            "[2024-04-02 20:16:22] \u001b[32mTrain: [ 10/50] Step 520/520 Loss 2.817 Prec@(1,5) (45.4%, 77.0%)\u001b[0m\n",
            "[2024-04-02 20:16:22] \u001b[32mTrain: [ 10/50] Final Prec@1 45.4260%\u001b[0m\n",
            "[2024-04-02 20:16:25] \u001b[32mValid: [ 10/50] Step 000/104 Loss 2.964 Prec@(1,5) (47.9%, 75.0%)\u001b[0m\n",
            "[2024-04-02 20:16:26] \u001b[32mValid: [ 10/50] Step 020/104 Loss 3.096 Prec@(1,5) (41.8%, 73.7%)\u001b[0m\n",
            "[2024-04-02 20:16:26] \u001b[32mValid: [ 10/50] Step 040/104 Loss 3.076 Prec@(1,5) (41.2%, 73.5%)\u001b[0m\n",
            "[2024-04-02 20:16:26] \u001b[32mValid: [ 10/50] Step 060/104 Loss 3.025 Prec@(1,5) (41.8%, 74.1%)\u001b[0m\n",
            "[2024-04-02 20:16:26] \u001b[32mValid: [ 10/50] Step 080/104 Loss 3.032 Prec@(1,5) (41.4%, 74.1%)\u001b[0m\n",
            "[2024-04-02 20:16:26] \u001b[32mValid: [ 10/50] Step 100/104 Loss 3.030 Prec@(1,5) (41.6%, 74.1%)\u001b[0m\n",
            "[2024-04-02 20:16:26] \u001b[32mValid: [ 10/50] Step 104/104 Loss 3.028 Prec@(1,5) (41.6%, 74.1%)\u001b[0m\n",
            "[2024-04-02 20:16:26] \u001b[32mValid: [ 10/50] Final Prec@1 41.6000%\u001b[0m\n",
            "[2024-04-02 20:16:26] \u001b[32mEpoch 10 LR 0.022613\u001b[0m\n",
            "[2024-04-02 20:16:31] \u001b[32mTrain: [ 11/50] Step 000/520 Loss 2.474 Prec@(1,5) (55.2%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:16:32] \u001b[32mTrain: [ 11/50] Step 020/520 Loss 2.743 Prec@(1,5) (46.8%, 77.1%)\u001b[0m\n",
            "[2024-04-02 20:16:32] \u001b[32mTrain: [ 11/50] Step 040/520 Loss 2.756 Prec@(1,5) (46.3%, 77.2%)\u001b[0m\n",
            "[2024-04-02 20:16:33] \u001b[32mTrain: [ 11/50] Step 060/520 Loss 2.759 Prec@(1,5) (46.5%, 77.6%)\u001b[0m\n",
            "[2024-04-02 20:16:33] \u001b[32mTrain: [ 11/50] Step 080/520 Loss 2.744 Prec@(1,5) (46.6%, 77.6%)\u001b[0m\n",
            "[2024-04-02 20:16:33] \u001b[32mTrain: [ 11/50] Step 100/520 Loss 2.766 Prec@(1,5) (46.1%, 77.3%)\u001b[0m\n",
            "[2024-04-02 20:16:34] \u001b[32mTrain: [ 11/50] Step 120/520 Loss 2.750 Prec@(1,5) (46.3%, 77.4%)\u001b[0m\n",
            "[2024-04-02 20:16:34] \u001b[32mTrain: [ 11/50] Step 140/520 Loss 2.752 Prec@(1,5) (46.2%, 77.5%)\u001b[0m\n",
            "[2024-04-02 20:16:35] \u001b[32mTrain: [ 11/50] Step 160/520 Loss 2.762 Prec@(1,5) (46.2%, 77.3%)\u001b[0m\n",
            "[2024-04-02 20:16:36] \u001b[32mTrain: [ 11/50] Step 180/520 Loss 2.767 Prec@(1,5) (46.2%, 77.2%)\u001b[0m\n",
            "[2024-04-02 20:16:36] \u001b[32mTrain: [ 11/50] Step 200/520 Loss 2.763 Prec@(1,5) (46.3%, 77.3%)\u001b[0m\n",
            "[2024-04-02 20:16:37] \u001b[32mTrain: [ 11/50] Step 220/520 Loss 2.759 Prec@(1,5) (46.4%, 77.2%)\u001b[0m\n",
            "[2024-04-02 20:16:37] \u001b[32mTrain: [ 11/50] Step 240/520 Loss 2.756 Prec@(1,5) (46.4%, 77.3%)\u001b[0m\n",
            "[2024-04-02 20:16:38] \u001b[32mTrain: [ 11/50] Step 260/520 Loss 2.755 Prec@(1,5) (46.4%, 77.4%)\u001b[0m\n",
            "[2024-04-02 20:16:38] \u001b[32mTrain: [ 11/50] Step 280/520 Loss 2.752 Prec@(1,5) (46.5%, 77.4%)\u001b[0m\n",
            "[2024-04-02 20:16:39] \u001b[32mTrain: [ 11/50] Step 300/520 Loss 2.752 Prec@(1,5) (46.4%, 77.4%)\u001b[0m\n",
            "[2024-04-02 20:16:39] \u001b[32mTrain: [ 11/50] Step 320/520 Loss 2.743 Prec@(1,5) (46.6%, 77.5%)\u001b[0m\n",
            "[2024-04-02 20:16:40] \u001b[32mTrain: [ 11/50] Step 340/520 Loss 2.740 Prec@(1,5) (46.6%, 77.5%)\u001b[0m\n",
            "[2024-04-02 20:16:40] \u001b[32mTrain: [ 11/50] Step 360/520 Loss 2.741 Prec@(1,5) (46.6%, 77.5%)\u001b[0m\n",
            "[2024-04-02 20:16:41] \u001b[32mTrain: [ 11/50] Step 380/520 Loss 2.738 Prec@(1,5) (46.7%, 77.5%)\u001b[0m\n",
            "[2024-04-02 20:16:41] \u001b[32mTrain: [ 11/50] Step 400/520 Loss 2.738 Prec@(1,5) (46.7%, 77.5%)\u001b[0m\n",
            "[2024-04-02 20:16:42] \u001b[32mTrain: [ 11/50] Step 420/520 Loss 2.738 Prec@(1,5) (46.7%, 77.5%)\u001b[0m\n",
            "[2024-04-02 20:16:42] \u001b[32mTrain: [ 11/50] Step 440/520 Loss 2.738 Prec@(1,5) (46.7%, 77.5%)\u001b[0m\n",
            "[2024-04-02 20:16:43] \u001b[32mTrain: [ 11/50] Step 460/520 Loss 2.735 Prec@(1,5) (46.8%, 77.6%)\u001b[0m\n",
            "[2024-04-02 20:16:43] \u001b[32mTrain: [ 11/50] Step 480/520 Loss 2.736 Prec@(1,5) (46.7%, 77.6%)\u001b[0m\n",
            "[2024-04-02 20:16:44] \u001b[32mTrain: [ 11/50] Step 500/520 Loss 2.737 Prec@(1,5) (46.7%, 77.6%)\u001b[0m\n",
            "[2024-04-02 20:16:44] \u001b[32mTrain: [ 11/50] Step 520/520 Loss 2.735 Prec@(1,5) (46.7%, 77.6%)\u001b[0m\n",
            "[2024-04-02 20:16:44] \u001b[32mTrain: [ 11/50] Final Prec@1 46.7020%\u001b[0m\n",
            "[2024-04-02 20:16:48] \u001b[32mValid: [ 11/50] Step 000/104 Loss 2.928 Prec@(1,5) (45.8%, 71.9%)\u001b[0m\n",
            "[2024-04-02 20:16:48] \u001b[32mValid: [ 11/50] Step 020/104 Loss 3.024 Prec@(1,5) (43.2%, 73.1%)\u001b[0m\n",
            "[2024-04-02 20:16:48] \u001b[32mValid: [ 11/50] Step 040/104 Loss 3.001 Prec@(1,5) (42.7%, 73.1%)\u001b[0m\n",
            "[2024-04-02 20:16:48] \u001b[32mValid: [ 11/50] Step 060/104 Loss 2.949 Prec@(1,5) (43.5%, 73.5%)\u001b[0m\n",
            "[2024-04-02 20:16:49] \u001b[32mValid: [ 11/50] Step 080/104 Loss 2.958 Prec@(1,5) (43.1%, 73.6%)\u001b[0m\n",
            "[2024-04-02 20:16:49] \u001b[32mValid: [ 11/50] Step 100/104 Loss 2.945 Prec@(1,5) (43.3%, 73.6%)\u001b[0m\n",
            "[2024-04-02 20:16:49] \u001b[32mValid: [ 11/50] Step 104/104 Loss 2.947 Prec@(1,5) (43.3%, 73.6%)\u001b[0m\n",
            "[2024-04-02 20:16:49] \u001b[32mValid: [ 11/50] Final Prec@1 43.3400%\u001b[0m\n",
            "[2024-04-02 20:16:49] \u001b[32mEpoch 11 LR 0.022132\u001b[0m\n",
            "[2024-04-02 20:16:54] \u001b[32mTrain: [ 12/50] Step 000/520 Loss 2.424 Prec@(1,5) (52.1%, 79.2%)\u001b[0m\n",
            "[2024-04-02 20:16:54] \u001b[32mTrain: [ 12/50] Step 020/520 Loss 2.625 Prec@(1,5) (48.8%, 78.2%)\u001b[0m\n",
            "[2024-04-02 20:16:55] \u001b[32mTrain: [ 12/50] Step 040/520 Loss 2.641 Prec@(1,5) (48.6%, 78.7%)\u001b[0m\n",
            "[2024-04-02 20:16:55] \u001b[32mTrain: [ 12/50] Step 060/520 Loss 2.629 Prec@(1,5) (48.6%, 79.1%)\u001b[0m\n",
            "[2024-04-02 20:16:56] \u001b[32mTrain: [ 12/50] Step 080/520 Loss 2.635 Prec@(1,5) (48.5%, 79.1%)\u001b[0m\n",
            "[2024-04-02 20:16:56] \u001b[32mTrain: [ 12/50] Step 100/520 Loss 2.636 Prec@(1,5) (48.3%, 79.0%)\u001b[0m\n",
            "[2024-04-02 20:16:57] \u001b[32mTrain: [ 12/50] Step 120/520 Loss 2.637 Prec@(1,5) (48.3%, 79.0%)\u001b[0m\n",
            "[2024-04-02 20:16:57] \u001b[32mTrain: [ 12/50] Step 140/520 Loss 2.652 Prec@(1,5) (48.1%, 78.9%)\u001b[0m\n",
            "[2024-04-02 20:16:58] \u001b[32mTrain: [ 12/50] Step 160/520 Loss 2.655 Prec@(1,5) (48.0%, 78.8%)\u001b[0m\n",
            "[2024-04-02 20:16:58] \u001b[32mTrain: [ 12/50] Step 180/520 Loss 2.661 Prec@(1,5) (47.8%, 78.5%)\u001b[0m\n",
            "[2024-04-02 20:16:59] \u001b[32mTrain: [ 12/50] Step 200/520 Loss 2.670 Prec@(1,5) (47.8%, 78.6%)\u001b[0m\n",
            "[2024-04-02 20:16:59] \u001b[32mTrain: [ 12/50] Step 220/520 Loss 2.667 Prec@(1,5) (47.9%, 78.7%)\u001b[0m\n",
            "[2024-04-02 20:17:00] \u001b[32mTrain: [ 12/50] Step 240/520 Loss 2.669 Prec@(1,5) (47.7%, 78.6%)\u001b[0m\n",
            "[2024-04-02 20:17:00] \u001b[32mTrain: [ 12/50] Step 260/520 Loss 2.674 Prec@(1,5) (47.7%, 78.5%)\u001b[0m\n",
            "[2024-04-02 20:17:01] \u001b[32mTrain: [ 12/50] Step 280/520 Loss 2.674 Prec@(1,5) (47.7%, 78.6%)\u001b[0m\n",
            "[2024-04-02 20:17:01] \u001b[32mTrain: [ 12/50] Step 300/520 Loss 2.674 Prec@(1,5) (47.7%, 78.5%)\u001b[0m\n",
            "[2024-04-02 20:17:02] \u001b[32mTrain: [ 12/50] Step 320/520 Loss 2.677 Prec@(1,5) (47.7%, 78.5%)\u001b[0m\n",
            "[2024-04-02 20:17:02] \u001b[32mTrain: [ 12/50] Step 340/520 Loss 2.679 Prec@(1,5) (47.6%, 78.4%)\u001b[0m\n",
            "[2024-04-02 20:17:03] \u001b[32mTrain: [ 12/50] Step 360/520 Loss 2.681 Prec@(1,5) (47.6%, 78.4%)\u001b[0m\n",
            "[2024-04-02 20:17:03] \u001b[32mTrain: [ 12/50] Step 380/520 Loss 2.678 Prec@(1,5) (47.6%, 78.5%)\u001b[0m\n",
            "[2024-04-02 20:17:04] \u001b[32mTrain: [ 12/50] Step 400/520 Loss 2.680 Prec@(1,5) (47.5%, 78.4%)\u001b[0m\n",
            "[2024-04-02 20:17:04] \u001b[32mTrain: [ 12/50] Step 420/520 Loss 2.683 Prec@(1,5) (47.5%, 78.4%)\u001b[0m\n",
            "[2024-04-02 20:17:05] \u001b[32mTrain: [ 12/50] Step 440/520 Loss 2.678 Prec@(1,5) (47.6%, 78.4%)\u001b[0m\n",
            "[2024-04-02 20:17:05] \u001b[32mTrain: [ 12/50] Step 460/520 Loss 2.680 Prec@(1,5) (47.6%, 78.4%)\u001b[0m\n",
            "[2024-04-02 20:17:06] \u001b[32mTrain: [ 12/50] Step 480/520 Loss 2.679 Prec@(1,5) (47.6%, 78.4%)\u001b[0m\n",
            "[2024-04-02 20:17:06] \u001b[32mTrain: [ 12/50] Step 500/520 Loss 2.679 Prec@(1,5) (47.6%, 78.5%)\u001b[0m\n",
            "[2024-04-02 20:17:07] \u001b[32mTrain: [ 12/50] Step 520/520 Loss 2.677 Prec@(1,5) (47.6%, 78.4%)\u001b[0m\n",
            "[2024-04-02 20:17:07] \u001b[32mTrain: [ 12/50] Final Prec@1 47.6440%\u001b[0m\n",
            "[2024-04-02 20:17:10] \u001b[32mValid: [ 12/50] Step 000/104 Loss 2.743 Prec@(1,5) (49.0%, 77.1%)\u001b[0m\n",
            "[2024-04-02 20:17:10] \u001b[32mValid: [ 12/50] Step 020/104 Loss 2.789 Prec@(1,5) (46.4%, 77.1%)\u001b[0m\n",
            "[2024-04-02 20:17:11] \u001b[32mValid: [ 12/50] Step 040/104 Loss 2.737 Prec@(1,5) (45.5%, 77.8%)\u001b[0m\n",
            "[2024-04-02 20:17:11] \u001b[32mValid: [ 12/50] Step 060/104 Loss 2.714 Prec@(1,5) (45.5%, 77.3%)\u001b[0m\n",
            "[2024-04-02 20:17:11] \u001b[32mValid: [ 12/50] Step 080/104 Loss 2.733 Prec@(1,5) (44.9%, 77.5%)\u001b[0m\n",
            "[2024-04-02 20:17:11] \u001b[32mValid: [ 12/50] Step 100/104 Loss 2.727 Prec@(1,5) (45.0%, 77.3%)\u001b[0m\n",
            "[2024-04-02 20:17:11] \u001b[32mValid: [ 12/50] Step 104/104 Loss 2.731 Prec@(1,5) (44.9%, 77.3%)\u001b[0m\n",
            "[2024-04-02 20:17:11] \u001b[32mValid: [ 12/50] Final Prec@1 44.8600%\u001b[0m\n",
            "[2024-04-02 20:17:11] \u001b[32mEpoch 12 LR 0.021612\u001b[0m\n",
            "[2024-04-02 20:17:16] \u001b[32mTrain: [ 13/50] Step 000/520 Loss 2.408 Prec@(1,5) (56.2%, 78.1%)\u001b[0m\n",
            "[2024-04-02 20:17:17] \u001b[32mTrain: [ 13/50] Step 020/520 Loss 2.632 Prec@(1,5) (48.3%, 78.7%)\u001b[0m\n",
            "[2024-04-02 20:17:17] \u001b[32mTrain: [ 13/50] Step 040/520 Loss 2.576 Prec@(1,5) (49.4%, 80.0%)\u001b[0m\n",
            "[2024-04-02 20:17:18] \u001b[32mTrain: [ 13/50] Step 060/520 Loss 2.572 Prec@(1,5) (50.0%, 80.0%)\u001b[0m\n",
            "[2024-04-02 20:17:18] \u001b[32mTrain: [ 13/50] Step 080/520 Loss 2.594 Prec@(1,5) (49.5%, 79.6%)\u001b[0m\n",
            "[2024-04-02 20:17:19] \u001b[32mTrain: [ 13/50] Step 100/520 Loss 2.591 Prec@(1,5) (49.6%, 79.6%)\u001b[0m\n",
            "[2024-04-02 20:17:19] \u001b[32mTrain: [ 13/50] Step 120/520 Loss 2.594 Prec@(1,5) (49.6%, 79.6%)\u001b[0m\n",
            "[2024-04-02 20:17:20] \u001b[32mTrain: [ 13/50] Step 140/520 Loss 2.599 Prec@(1,5) (49.3%, 79.6%)\u001b[0m\n",
            "[2024-04-02 20:17:20] \u001b[32mTrain: [ 13/50] Step 160/520 Loss 2.607 Prec@(1,5) (49.2%, 79.3%)\u001b[0m\n",
            "[2024-04-02 20:17:21] \u001b[32mTrain: [ 13/50] Step 180/520 Loss 2.608 Prec@(1,5) (49.2%, 79.2%)\u001b[0m\n",
            "[2024-04-02 20:17:21] \u001b[32mTrain: [ 13/50] Step 200/520 Loss 2.607 Prec@(1,5) (49.1%, 79.3%)\u001b[0m\n",
            "[2024-04-02 20:17:22] \u001b[32mTrain: [ 13/50] Step 220/520 Loss 2.607 Prec@(1,5) (49.1%, 79.3%)\u001b[0m\n",
            "[2024-04-02 20:17:22] \u001b[32mTrain: [ 13/50] Step 240/520 Loss 2.605 Prec@(1,5) (49.2%, 79.4%)\u001b[0m\n",
            "[2024-04-02 20:17:23] \u001b[32mTrain: [ 13/50] Step 260/520 Loss 2.603 Prec@(1,5) (49.3%, 79.5%)\u001b[0m\n",
            "[2024-04-02 20:17:23] \u001b[32mTrain: [ 13/50] Step 280/520 Loss 2.602 Prec@(1,5) (49.4%, 79.5%)\u001b[0m\n",
            "[2024-04-02 20:17:24] \u001b[32mTrain: [ 13/50] Step 300/520 Loss 2.605 Prec@(1,5) (49.3%, 79.4%)\u001b[0m\n",
            "[2024-04-02 20:17:24] \u001b[32mTrain: [ 13/50] Step 320/520 Loss 2.607 Prec@(1,5) (49.3%, 79.3%)\u001b[0m\n",
            "[2024-04-02 20:17:25] \u001b[32mTrain: [ 13/50] Step 340/520 Loss 2.609 Prec@(1,5) (49.2%, 79.3%)\u001b[0m\n",
            "[2024-04-02 20:17:25] \u001b[32mTrain: [ 13/50] Step 360/520 Loss 2.603 Prec@(1,5) (49.3%, 79.4%)\u001b[0m\n",
            "[2024-04-02 20:17:26] \u001b[32mTrain: [ 13/50] Step 380/520 Loss 2.603 Prec@(1,5) (49.2%, 79.4%)\u001b[0m\n",
            "[2024-04-02 20:17:26] \u001b[32mTrain: [ 13/50] Step 400/520 Loss 2.604 Prec@(1,5) (49.2%, 79.4%)\u001b[0m\n",
            "[2024-04-02 20:17:27] \u001b[32mTrain: [ 13/50] Step 420/520 Loss 2.606 Prec@(1,5) (49.1%, 79.3%)\u001b[0m\n",
            "[2024-04-02 20:17:27] \u001b[32mTrain: [ 13/50] Step 440/520 Loss 2.602 Prec@(1,5) (49.2%, 79.4%)\u001b[0m\n",
            "[2024-04-02 20:17:28] \u001b[32mTrain: [ 13/50] Step 460/520 Loss 2.601 Prec@(1,5) (49.2%, 79.4%)\u001b[0m\n",
            "[2024-04-02 20:17:28] \u001b[32mTrain: [ 13/50] Step 480/520 Loss 2.602 Prec@(1,5) (49.2%, 79.4%)\u001b[0m\n",
            "[2024-04-02 20:17:29] \u001b[32mTrain: [ 13/50] Step 500/520 Loss 2.599 Prec@(1,5) (49.3%, 79.4%)\u001b[0m\n",
            "[2024-04-02 20:17:29] \u001b[32mTrain: [ 13/50] Step 520/520 Loss 2.597 Prec@(1,5) (49.4%, 79.4%)\u001b[0m\n",
            "[2024-04-02 20:17:29] \u001b[32mTrain: [ 13/50] Final Prec@1 49.3540%\u001b[0m\n",
            "[2024-04-02 20:17:33] \u001b[32mValid: [ 13/50] Step 000/104 Loss 2.571 Prec@(1,5) (52.1%, 76.0%)\u001b[0m\n",
            "[2024-04-02 20:17:33] \u001b[32mValid: [ 13/50] Step 020/104 Loss 2.646 Prec@(1,5) (45.9%, 77.5%)\u001b[0m\n",
            "[2024-04-02 20:17:33] \u001b[32mValid: [ 13/50] Step 040/104 Loss 2.624 Prec@(1,5) (46.5%, 77.2%)\u001b[0m\n",
            "[2024-04-02 20:17:33] \u001b[32mValid: [ 13/50] Step 060/104 Loss 2.578 Prec@(1,5) (47.0%, 77.5%)\u001b[0m\n",
            "[2024-04-02 20:17:34] \u001b[32mValid: [ 13/50] Step 080/104 Loss 2.593 Prec@(1,5) (46.4%, 77.5%)\u001b[0m\n",
            "[2024-04-02 20:17:34] \u001b[32mValid: [ 13/50] Step 100/104 Loss 2.591 Prec@(1,5) (46.5%, 77.4%)\u001b[0m\n",
            "[2024-04-02 20:17:34] \u001b[32mValid: [ 13/50] Step 104/104 Loss 2.589 Prec@(1,5) (46.5%, 77.4%)\u001b[0m\n",
            "[2024-04-02 20:17:34] \u001b[32mValid: [ 13/50] Final Prec@1 46.4700%\u001b[0m\n",
            "[2024-04-02 20:17:34] \u001b[32mEpoch 13 LR 0.021057\u001b[0m\n",
            "[2024-04-02 20:17:39] \u001b[32mTrain: [ 14/50] Step 000/520 Loss 2.693 Prec@(1,5) (51.0%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:17:39] \u001b[32mTrain: [ 14/50] Step 020/520 Loss 2.532 Prec@(1,5) (51.2%, 79.8%)\u001b[0m\n",
            "[2024-04-02 20:17:40] \u001b[32mTrain: [ 14/50] Step 040/520 Loss 2.528 Prec@(1,5) (50.6%, 80.4%)\u001b[0m\n",
            "[2024-04-02 20:17:40] \u001b[32mTrain: [ 14/50] Step 060/520 Loss 2.537 Prec@(1,5) (50.2%, 80.1%)\u001b[0m\n",
            "[2024-04-02 20:17:41] \u001b[32mTrain: [ 14/50] Step 080/520 Loss 2.557 Prec@(1,5) (50.0%, 80.1%)\u001b[0m\n",
            "[2024-04-02 20:17:41] \u001b[32mTrain: [ 14/50] Step 100/520 Loss 2.549 Prec@(1,5) (50.0%, 80.1%)\u001b[0m\n",
            "[2024-04-02 20:17:42] \u001b[32mTrain: [ 14/50] Step 120/520 Loss 2.550 Prec@(1,5) (50.0%, 80.0%)\u001b[0m\n",
            "[2024-04-02 20:17:42] \u001b[32mTrain: [ 14/50] Step 140/520 Loss 2.557 Prec@(1,5) (49.8%, 79.8%)\u001b[0m\n",
            "[2024-04-02 20:17:43] \u001b[32mTrain: [ 14/50] Step 160/520 Loss 2.552 Prec@(1,5) (49.9%, 79.9%)\u001b[0m\n",
            "[2024-04-02 20:17:43] \u001b[32mTrain: [ 14/50] Step 180/520 Loss 2.558 Prec@(1,5) (49.8%, 79.9%)\u001b[0m\n",
            "[2024-04-02 20:17:44] \u001b[32mTrain: [ 14/50] Step 200/520 Loss 2.544 Prec@(1,5) (50.0%, 80.1%)\u001b[0m\n",
            "[2024-04-02 20:17:44] \u001b[32mTrain: [ 14/50] Step 220/520 Loss 2.543 Prec@(1,5) (50.0%, 80.1%)\u001b[0m\n",
            "[2024-04-02 20:17:45] \u001b[32mTrain: [ 14/50] Step 240/520 Loss 2.548 Prec@(1,5) (49.9%, 80.1%)\u001b[0m\n",
            "[2024-04-02 20:17:45] \u001b[32mTrain: [ 14/50] Step 260/520 Loss 2.547 Prec@(1,5) (49.9%, 80.0%)\u001b[0m\n",
            "[2024-04-02 20:17:46] \u001b[32mTrain: [ 14/50] Step 280/520 Loss 2.547 Prec@(1,5) (49.8%, 80.1%)\u001b[0m\n",
            "[2024-04-02 20:17:46] \u001b[32mTrain: [ 14/50] Step 300/520 Loss 2.548 Prec@(1,5) (49.8%, 80.1%)\u001b[0m\n",
            "[2024-04-02 20:17:47] \u001b[32mTrain: [ 14/50] Step 320/520 Loss 2.550 Prec@(1,5) (49.8%, 80.1%)\u001b[0m\n",
            "[2024-04-02 20:17:47] \u001b[32mTrain: [ 14/50] Step 340/520 Loss 2.551 Prec@(1,5) (49.8%, 80.1%)\u001b[0m\n",
            "[2024-04-02 20:17:48] \u001b[32mTrain: [ 14/50] Step 360/520 Loss 2.555 Prec@(1,5) (49.7%, 80.0%)\u001b[0m\n",
            "[2024-04-02 20:17:48] \u001b[32mTrain: [ 14/50] Step 380/520 Loss 2.551 Prec@(1,5) (49.9%, 80.1%)\u001b[0m\n",
            "[2024-04-02 20:17:49] \u001b[32mTrain: [ 14/50] Step 400/520 Loss 2.550 Prec@(1,5) (50.0%, 80.2%)\u001b[0m\n",
            "[2024-04-02 20:17:49] \u001b[32mTrain: [ 14/50] Step 420/520 Loss 2.547 Prec@(1,5) (50.0%, 80.2%)\u001b[0m\n",
            "[2024-04-02 20:17:50] \u001b[32mTrain: [ 14/50] Step 440/520 Loss 2.546 Prec@(1,5) (49.9%, 80.2%)\u001b[0m\n",
            "[2024-04-02 20:17:50] \u001b[32mTrain: [ 14/50] Step 460/520 Loss 2.548 Prec@(1,5) (49.9%, 80.2%)\u001b[0m\n",
            "[2024-04-02 20:17:51] \u001b[32mTrain: [ 14/50] Step 480/520 Loss 2.549 Prec@(1,5) (49.9%, 80.2%)\u001b[0m\n",
            "[2024-04-02 20:17:51] \u001b[32mTrain: [ 14/50] Step 500/520 Loss 2.547 Prec@(1,5) (49.9%, 80.2%)\u001b[0m\n",
            "[2024-04-02 20:17:52] \u001b[32mTrain: [ 14/50] Step 520/520 Loss 2.547 Prec@(1,5) (49.9%, 80.2%)\u001b[0m\n",
            "[2024-04-02 20:17:52] \u001b[32mTrain: [ 14/50] Final Prec@1 49.9140%\u001b[0m\n",
            "[2024-04-02 20:17:55] \u001b[32mValid: [ 14/50] Step 000/104 Loss 2.578 Prec@(1,5) (55.2%, 78.1%)\u001b[0m\n",
            "[2024-04-02 20:17:55] \u001b[32mValid: [ 14/50] Step 020/104 Loss 2.769 Prec@(1,5) (46.8%, 77.1%)\u001b[0m\n",
            "[2024-04-02 20:17:56] \u001b[32mValid: [ 14/50] Step 040/104 Loss 2.722 Prec@(1,5) (46.3%, 77.5%)\u001b[0m\n",
            "[2024-04-02 20:17:56] \u001b[32mValid: [ 14/50] Step 060/104 Loss 2.703 Prec@(1,5) (46.5%, 77.2%)\u001b[0m\n",
            "[2024-04-02 20:17:56] \u001b[32mValid: [ 14/50] Step 080/104 Loss 2.712 Prec@(1,5) (46.0%, 77.3%)\u001b[0m\n",
            "[2024-04-02 20:17:56] \u001b[32mValid: [ 14/50] Step 100/104 Loss 2.704 Prec@(1,5) (46.3%, 77.4%)\u001b[0m\n",
            "[2024-04-02 20:17:56] \u001b[32mValid: [ 14/50] Step 104/104 Loss 2.702 Prec@(1,5) (46.3%, 77.3%)\u001b[0m\n",
            "[2024-04-02 20:17:56] \u001b[32mValid: [ 14/50] Final Prec@1 46.3100%\u001b[0m\n",
            "[2024-04-02 20:17:56] \u001b[32mEpoch 14 LR 0.020468\u001b[0m\n",
            "[2024-04-02 20:18:01] \u001b[32mTrain: [ 15/50] Step 000/520 Loss 2.504 Prec@(1,5) (51.0%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:18:01] \u001b[32mTrain: [ 15/50] Step 020/520 Loss 2.544 Prec@(1,5) (50.0%, 80.8%)\u001b[0m\n",
            "[2024-04-02 20:18:02] \u001b[32mTrain: [ 15/50] Step 040/520 Loss 2.527 Prec@(1,5) (49.6%, 80.8%)\u001b[0m\n",
            "[2024-04-02 20:18:02] \u001b[32mTrain: [ 15/50] Step 060/520 Loss 2.519 Prec@(1,5) (49.8%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:18:03] \u001b[32mTrain: [ 15/50] Step 080/520 Loss 2.517 Prec@(1,5) (50.0%, 80.7%)\u001b[0m\n",
            "[2024-04-02 20:18:03] \u001b[32mTrain: [ 15/50] Step 100/520 Loss 2.513 Prec@(1,5) (50.2%, 80.8%)\u001b[0m\n",
            "[2024-04-02 20:18:04] \u001b[32mTrain: [ 15/50] Step 120/520 Loss 2.500 Prec@(1,5) (50.5%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:18:04] \u001b[32mTrain: [ 15/50] Step 140/520 Loss 2.495 Prec@(1,5) (50.6%, 81.1%)\u001b[0m\n",
            "[2024-04-02 20:18:05] \u001b[32mTrain: [ 15/50] Step 160/520 Loss 2.490 Prec@(1,5) (50.8%, 81.1%)\u001b[0m\n",
            "[2024-04-02 20:18:05] \u001b[32mTrain: [ 15/50] Step 180/520 Loss 2.495 Prec@(1,5) (50.6%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:18:06] \u001b[32mTrain: [ 15/50] Step 200/520 Loss 2.495 Prec@(1,5) (50.7%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:18:06] \u001b[32mTrain: [ 15/50] Step 220/520 Loss 2.493 Prec@(1,5) (50.7%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:18:07] \u001b[32mTrain: [ 15/50] Step 240/520 Loss 2.493 Prec@(1,5) (50.8%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:18:07] \u001b[32mTrain: [ 15/50] Step 260/520 Loss 2.493 Prec@(1,5) (50.9%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:18:08] \u001b[32mTrain: [ 15/50] Step 280/520 Loss 2.490 Prec@(1,5) (51.0%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:18:08] \u001b[32mTrain: [ 15/50] Step 300/520 Loss 2.491 Prec@(1,5) (50.9%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:18:09] \u001b[32mTrain: [ 15/50] Step 320/520 Loss 2.499 Prec@(1,5) (50.8%, 80.8%)\u001b[0m\n",
            "[2024-04-02 20:18:09] \u001b[32mTrain: [ 15/50] Step 340/520 Loss 2.504 Prec@(1,5) (50.6%, 80.8%)\u001b[0m\n",
            "[2024-04-02 20:18:10] \u001b[32mTrain: [ 15/50] Step 360/520 Loss 2.505 Prec@(1,5) (50.6%, 80.8%)\u001b[0m\n",
            "[2024-04-02 20:18:10] \u001b[32mTrain: [ 15/50] Step 380/520 Loss 2.506 Prec@(1,5) (50.6%, 80.8%)\u001b[0m\n",
            "[2024-04-02 20:18:11] \u001b[32mTrain: [ 15/50] Step 400/520 Loss 2.503 Prec@(1,5) (50.6%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:18:11] \u001b[32mTrain: [ 15/50] Step 420/520 Loss 2.505 Prec@(1,5) (50.6%, 80.8%)\u001b[0m\n",
            "[2024-04-02 20:18:12] \u001b[32mTrain: [ 15/50] Step 440/520 Loss 2.505 Prec@(1,5) (50.5%, 80.8%)\u001b[0m\n",
            "[2024-04-02 20:18:12] \u001b[32mTrain: [ 15/50] Step 460/520 Loss 2.505 Prec@(1,5) (50.5%, 80.8%)\u001b[0m\n",
            "[2024-04-02 20:18:13] \u001b[32mTrain: [ 15/50] Step 480/520 Loss 2.505 Prec@(1,5) (50.5%, 80.8%)\u001b[0m\n",
            "[2024-04-02 20:18:13] \u001b[32mTrain: [ 15/50] Step 500/520 Loss 2.505 Prec@(1,5) (50.5%, 80.8%)\u001b[0m\n",
            "[2024-04-02 20:18:14] \u001b[32mTrain: [ 15/50] Step 520/520 Loss 2.508 Prec@(1,5) (50.4%, 80.8%)\u001b[0m\n",
            "[2024-04-02 20:18:14] \u001b[32mTrain: [ 15/50] Final Prec@1 50.4160%\u001b[0m\n",
            "[2024-04-02 20:18:17] \u001b[32mValid: [ 15/50] Step 000/104 Loss 2.813 Prec@(1,5) (47.9%, 79.2%)\u001b[0m\n",
            "[2024-04-02 20:18:18] \u001b[32mValid: [ 15/50] Step 020/104 Loss 2.876 Prec@(1,5) (45.4%, 76.1%)\u001b[0m\n",
            "[2024-04-02 20:18:18] \u001b[32mValid: [ 15/50] Step 040/104 Loss 2.849 Prec@(1,5) (45.5%, 76.2%)\u001b[0m\n",
            "[2024-04-02 20:18:18] \u001b[32mValid: [ 15/50] Step 060/104 Loss 2.814 Prec@(1,5) (46.4%, 76.6%)\u001b[0m\n",
            "[2024-04-02 20:18:18] \u001b[32mValid: [ 15/50] Step 080/104 Loss 2.808 Prec@(1,5) (46.1%, 76.6%)\u001b[0m\n",
            "[2024-04-02 20:18:18] \u001b[32mValid: [ 15/50] Step 100/104 Loss 2.830 Prec@(1,5) (45.7%, 76.3%)\u001b[0m\n",
            "[2024-04-02 20:18:18] \u001b[32mValid: [ 15/50] Step 104/104 Loss 2.829 Prec@(1,5) (45.6%, 76.3%)\u001b[0m\n",
            "[2024-04-02 20:18:19] \u001b[32mValid: [ 15/50] Final Prec@1 45.6200%\u001b[0m\n",
            "[2024-04-02 20:18:19] \u001b[32mEpoch 15 LR 0.019848\u001b[0m\n",
            "[2024-04-02 20:18:23] \u001b[32mTrain: [ 16/50] Step 000/520 Loss 2.640 Prec@(1,5) (52.1%, 79.2%)\u001b[0m\n",
            "[2024-04-02 20:18:24] \u001b[32mTrain: [ 16/50] Step 020/520 Loss 2.464 Prec@(1,5) (52.6%, 81.3%)\u001b[0m\n",
            "[2024-04-02 20:18:24] \u001b[32mTrain: [ 16/50] Step 040/520 Loss 2.433 Prec@(1,5) (52.2%, 81.4%)\u001b[0m\n",
            "[2024-04-02 20:18:25] \u001b[32mTrain: [ 16/50] Step 060/520 Loss 2.421 Prec@(1,5) (52.9%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:18:25] \u001b[32mTrain: [ 16/50] Step 080/520 Loss 2.454 Prec@(1,5) (52.2%, 81.4%)\u001b[0m\n",
            "[2024-04-02 20:18:26] \u001b[32mTrain: [ 16/50] Step 100/520 Loss 2.458 Prec@(1,5) (51.9%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:18:26] \u001b[32mTrain: [ 16/50] Step 120/520 Loss 2.444 Prec@(1,5) (51.9%, 81.4%)\u001b[0m\n",
            "[2024-04-02 20:18:27] \u001b[32mTrain: [ 16/50] Step 140/520 Loss 2.440 Prec@(1,5) (52.0%, 81.4%)\u001b[0m\n",
            "[2024-04-02 20:18:27] \u001b[32mTrain: [ 16/50] Step 160/520 Loss 2.438 Prec@(1,5) (52.1%, 81.4%)\u001b[0m\n",
            "[2024-04-02 20:18:28] \u001b[32mTrain: [ 16/50] Step 180/520 Loss 2.443 Prec@(1,5) (51.9%, 81.3%)\u001b[0m\n",
            "[2024-04-02 20:18:28] \u001b[32mTrain: [ 16/50] Step 200/520 Loss 2.444 Prec@(1,5) (51.8%, 81.4%)\u001b[0m\n",
            "[2024-04-02 20:18:29] \u001b[32mTrain: [ 16/50] Step 220/520 Loss 2.445 Prec@(1,5) (51.9%, 81.4%)\u001b[0m\n",
            "[2024-04-02 20:18:29] \u001b[32mTrain: [ 16/50] Step 240/520 Loss 2.449 Prec@(1,5) (51.8%, 81.4%)\u001b[0m\n",
            "[2024-04-02 20:18:30] \u001b[32mTrain: [ 16/50] Step 260/520 Loss 2.451 Prec@(1,5) (51.8%, 81.3%)\u001b[0m\n",
            "[2024-04-02 20:18:30] \u001b[32mTrain: [ 16/50] Step 280/520 Loss 2.452 Prec@(1,5) (51.8%, 81.3%)\u001b[0m\n",
            "[2024-04-02 20:18:31] \u001b[32mTrain: [ 16/50] Step 300/520 Loss 2.456 Prec@(1,5) (51.7%, 81.3%)\u001b[0m\n",
            "[2024-04-02 20:18:31] \u001b[32mTrain: [ 16/50] Step 320/520 Loss 2.457 Prec@(1,5) (51.6%, 81.3%)\u001b[0m\n",
            "[2024-04-02 20:18:32] \u001b[32mTrain: [ 16/50] Step 340/520 Loss 2.457 Prec@(1,5) (51.7%, 81.3%)\u001b[0m\n",
            "[2024-04-02 20:18:32] \u001b[32mTrain: [ 16/50] Step 360/520 Loss 2.461 Prec@(1,5) (51.6%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:18:33] \u001b[32mTrain: [ 16/50] Step 380/520 Loss 2.456 Prec@(1,5) (51.6%, 81.3%)\u001b[0m\n",
            "[2024-04-02 20:18:33] \u001b[32mTrain: [ 16/50] Step 400/520 Loss 2.458 Prec@(1,5) (51.6%, 81.3%)\u001b[0m\n",
            "[2024-04-02 20:18:33] \u001b[32mTrain: [ 16/50] Step 420/520 Loss 2.456 Prec@(1,5) (51.6%, 81.3%)\u001b[0m\n",
            "[2024-04-02 20:18:34] \u001b[32mTrain: [ 16/50] Step 440/520 Loss 2.457 Prec@(1,5) (51.6%, 81.3%)\u001b[0m\n",
            "[2024-04-02 20:18:34] \u001b[32mTrain: [ 16/50] Step 460/520 Loss 2.456 Prec@(1,5) (51.6%, 81.3%)\u001b[0m\n",
            "[2024-04-02 20:18:35] \u001b[32mTrain: [ 16/50] Step 480/520 Loss 2.458 Prec@(1,5) (51.5%, 81.3%)\u001b[0m\n",
            "[2024-04-02 20:18:35] \u001b[32mTrain: [ 16/50] Step 500/520 Loss 2.460 Prec@(1,5) (51.6%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:18:36] \u001b[32mTrain: [ 16/50] Step 520/520 Loss 2.459 Prec@(1,5) (51.6%, 81.3%)\u001b[0m\n",
            "[2024-04-02 20:18:36] \u001b[32mTrain: [ 16/50] Final Prec@1 51.6040%\u001b[0m\n",
            "[2024-04-02 20:18:40] \u001b[32mValid: [ 16/50] Step 000/104 Loss 2.447 Prec@(1,5) (54.2%, 79.2%)\u001b[0m\n",
            "[2024-04-02 20:18:40] \u001b[32mValid: [ 16/50] Step 020/104 Loss 2.442 Prec@(1,5) (50.5%, 79.5%)\u001b[0m\n",
            "[2024-04-02 20:18:40] \u001b[32mValid: [ 16/50] Step 040/104 Loss 2.423 Prec@(1,5) (48.9%, 79.7%)\u001b[0m\n",
            "[2024-04-02 20:18:40] \u001b[32mValid: [ 16/50] Step 060/104 Loss 2.415 Prec@(1,5) (49.1%, 79.7%)\u001b[0m\n",
            "[2024-04-02 20:18:40] \u001b[32mValid: [ 16/50] Step 080/104 Loss 2.425 Prec@(1,5) (48.9%, 79.6%)\u001b[0m\n",
            "[2024-04-02 20:18:41] \u001b[32mValid: [ 16/50] Step 100/104 Loss 2.419 Prec@(1,5) (49.0%, 79.7%)\u001b[0m\n",
            "[2024-04-02 20:18:41] \u001b[32mValid: [ 16/50] Step 104/104 Loss 2.419 Prec@(1,5) (49.0%, 79.7%)\u001b[0m\n",
            "[2024-04-02 20:18:41] \u001b[32mValid: [ 16/50] Final Prec@1 48.9600%\u001b[0m\n",
            "[2024-04-02 20:18:41] \u001b[32mEpoch 16 LR 0.019198\u001b[0m\n",
            "[2024-04-02 20:18:45] \u001b[32mTrain: [ 17/50] Step 000/520 Loss 2.338 Prec@(1,5) (56.2%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:18:46] \u001b[32mTrain: [ 17/50] Step 020/520 Loss 2.375 Prec@(1,5) (51.8%, 81.4%)\u001b[0m\n",
            "[2024-04-02 20:18:46] \u001b[32mTrain: [ 17/50] Step 040/520 Loss 2.354 Prec@(1,5) (52.6%, 81.9%)\u001b[0m\n",
            "[2024-04-02 20:18:47] \u001b[32mTrain: [ 17/50] Step 060/520 Loss 2.371 Prec@(1,5) (52.5%, 82.0%)\u001b[0m\n",
            "[2024-04-02 20:18:47] \u001b[32mTrain: [ 17/50] Step 080/520 Loss 2.366 Prec@(1,5) (52.9%, 82.2%)\u001b[0m\n",
            "[2024-04-02 20:18:48] \u001b[32mTrain: [ 17/50] Step 100/520 Loss 2.365 Prec@(1,5) (53.1%, 82.1%)\u001b[0m\n",
            "[2024-04-02 20:18:48] \u001b[32mTrain: [ 17/50] Step 120/520 Loss 2.361 Prec@(1,5) (53.2%, 82.2%)\u001b[0m\n",
            "[2024-04-02 20:18:49] \u001b[32mTrain: [ 17/50] Step 140/520 Loss 2.365 Prec@(1,5) (52.9%, 82.1%)\u001b[0m\n",
            "[2024-04-02 20:18:49] \u001b[32mTrain: [ 17/50] Step 160/520 Loss 2.365 Prec@(1,5) (52.9%, 82.2%)\u001b[0m\n",
            "[2024-04-02 20:18:50] \u001b[32mTrain: [ 17/50] Step 180/520 Loss 2.373 Prec@(1,5) (52.8%, 82.1%)\u001b[0m\n",
            "[2024-04-02 20:18:50] \u001b[32mTrain: [ 17/50] Step 200/520 Loss 2.383 Prec@(1,5) (52.8%, 82.0%)\u001b[0m\n",
            "[2024-04-02 20:18:51] \u001b[32mTrain: [ 17/50] Step 220/520 Loss 2.381 Prec@(1,5) (52.9%, 82.1%)\u001b[0m\n",
            "[2024-04-02 20:18:51] \u001b[32mTrain: [ 17/50] Step 240/520 Loss 2.379 Prec@(1,5) (53.0%, 82.1%)\u001b[0m\n",
            "[2024-04-02 20:18:52] \u001b[32mTrain: [ 17/50] Step 260/520 Loss 2.380 Prec@(1,5) (52.9%, 82.1%)\u001b[0m\n",
            "[2024-04-02 20:18:52] \u001b[32mTrain: [ 17/50] Step 280/520 Loss 2.381 Prec@(1,5) (52.9%, 82.1%)\u001b[0m\n",
            "[2024-04-02 20:18:53] \u001b[32mTrain: [ 17/50] Step 300/520 Loss 2.382 Prec@(1,5) (52.9%, 82.1%)\u001b[0m\n",
            "[2024-04-02 20:18:53] \u001b[32mTrain: [ 17/50] Step 320/520 Loss 2.387 Prec@(1,5) (52.7%, 82.1%)\u001b[0m\n",
            "[2024-04-02 20:18:54] \u001b[32mTrain: [ 17/50] Step 340/520 Loss 2.385 Prec@(1,5) (52.7%, 82.1%)\u001b[0m\n",
            "[2024-04-02 20:18:54] \u001b[32mTrain: [ 17/50] Step 360/520 Loss 2.393 Prec@(1,5) (52.6%, 82.0%)\u001b[0m\n",
            "[2024-04-02 20:18:55] \u001b[32mTrain: [ 17/50] Step 380/520 Loss 2.398 Prec@(1,5) (52.5%, 81.9%)\u001b[0m\n",
            "[2024-04-02 20:18:55] \u001b[32mTrain: [ 17/50] Step 400/520 Loss 2.399 Prec@(1,5) (52.4%, 81.9%)\u001b[0m\n",
            "[2024-04-02 20:18:56] \u001b[32mTrain: [ 17/50] Step 420/520 Loss 2.402 Prec@(1,5) (52.3%, 81.9%)\u001b[0m\n",
            "[2024-04-02 20:18:57] \u001b[32mTrain: [ 17/50] Step 440/520 Loss 2.402 Prec@(1,5) (52.4%, 81.9%)\u001b[0m\n",
            "[2024-04-02 20:18:57] \u001b[32mTrain: [ 17/50] Step 460/520 Loss 2.405 Prec@(1,5) (52.3%, 81.9%)\u001b[0m\n",
            "[2024-04-02 20:18:58] \u001b[32mTrain: [ 17/50] Step 480/520 Loss 2.407 Prec@(1,5) (52.3%, 81.9%)\u001b[0m\n",
            "[2024-04-02 20:18:58] \u001b[32mTrain: [ 17/50] Step 500/520 Loss 2.408 Prec@(1,5) (52.2%, 81.8%)\u001b[0m\n",
            "[2024-04-02 20:18:59] \u001b[32mTrain: [ 17/50] Step 520/520 Loss 2.407 Prec@(1,5) (52.3%, 81.9%)\u001b[0m\n",
            "[2024-04-02 20:18:59] \u001b[32mTrain: [ 17/50] Final Prec@1 52.3120%\u001b[0m\n",
            "[2024-04-02 20:19:02] \u001b[32mValid: [ 17/50] Step 000/104 Loss 2.550 Prec@(1,5) (54.2%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:19:02] \u001b[32mValid: [ 17/50] Step 020/104 Loss 2.834 Prec@(1,5) (46.8%, 76.7%)\u001b[0m\n",
            "[2024-04-02 20:19:03] \u001b[32mValid: [ 17/50] Step 040/104 Loss 2.794 Prec@(1,5) (45.8%, 76.9%)\u001b[0m\n",
            "[2024-04-02 20:19:03] \u001b[32mValid: [ 17/50] Step 060/104 Loss 2.776 Prec@(1,5) (46.4%, 77.1%)\u001b[0m\n",
            "[2024-04-02 20:19:03] \u001b[32mValid: [ 17/50] Step 080/104 Loss 2.777 Prec@(1,5) (46.0%, 77.1%)\u001b[0m\n",
            "[2024-04-02 20:19:03] \u001b[32mValid: [ 17/50] Step 100/104 Loss 2.770 Prec@(1,5) (45.9%, 77.2%)\u001b[0m\n",
            "[2024-04-02 20:19:03] \u001b[32mValid: [ 17/50] Step 104/104 Loss 2.775 Prec@(1,5) (45.9%, 77.1%)\u001b[0m\n",
            "[2024-04-02 20:19:03] \u001b[32mValid: [ 17/50] Final Prec@1 45.8600%\u001b[0m\n",
            "[2024-04-02 20:19:03] \u001b[32mEpoch 17 LR 0.018522\u001b[0m\n",
            "[2024-04-02 20:19:08] \u001b[32mTrain: [ 18/50] Step 000/520 Loss 2.324 Prec@(1,5) (57.3%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:19:08] \u001b[32mTrain: [ 18/50] Step 020/520 Loss 2.320 Prec@(1,5) (54.5%, 82.1%)\u001b[0m\n",
            "[2024-04-02 20:19:09] \u001b[32mTrain: [ 18/50] Step 040/520 Loss 2.332 Prec@(1,5) (54.2%, 82.0%)\u001b[0m\n",
            "[2024-04-02 20:19:09] \u001b[32mTrain: [ 18/50] Step 060/520 Loss 2.351 Prec@(1,5) (54.0%, 82.0%)\u001b[0m\n",
            "[2024-04-02 20:19:10] \u001b[32mTrain: [ 18/50] Step 080/520 Loss 2.334 Prec@(1,5) (54.1%, 82.0%)\u001b[0m\n",
            "[2024-04-02 20:19:10] \u001b[32mTrain: [ 18/50] Step 100/520 Loss 2.331 Prec@(1,5) (53.9%, 82.1%)\u001b[0m\n",
            "[2024-04-02 20:19:11] \u001b[32mTrain: [ 18/50] Step 120/520 Loss 2.338 Prec@(1,5) (53.5%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:19:11] \u001b[32mTrain: [ 18/50] Step 140/520 Loss 2.336 Prec@(1,5) (53.5%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:19:12] \u001b[32mTrain: [ 18/50] Step 160/520 Loss 2.331 Prec@(1,5) (53.6%, 82.4%)\u001b[0m\n",
            "[2024-04-02 20:19:12] \u001b[32mTrain: [ 18/50] Step 180/520 Loss 2.331 Prec@(1,5) (53.6%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:19:13] \u001b[32mTrain: [ 18/50] Step 200/520 Loss 2.329 Prec@(1,5) (53.6%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:19:13] \u001b[32mTrain: [ 18/50] Step 220/520 Loss 2.328 Prec@(1,5) (53.7%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:19:14] \u001b[32mTrain: [ 18/50] Step 240/520 Loss 2.336 Prec@(1,5) (53.6%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:19:14] \u001b[32mTrain: [ 18/50] Step 260/520 Loss 2.336 Prec@(1,5) (53.7%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:19:15] \u001b[32mTrain: [ 18/50] Step 280/520 Loss 2.338 Prec@(1,5) (53.7%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:19:15] \u001b[32mTrain: [ 18/50] Step 300/520 Loss 2.342 Prec@(1,5) (53.6%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:19:16] \u001b[32mTrain: [ 18/50] Step 320/520 Loss 2.344 Prec@(1,5) (53.6%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:19:16] \u001b[32mTrain: [ 18/50] Step 340/520 Loss 2.351 Prec@(1,5) (53.4%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:19:17] \u001b[32mTrain: [ 18/50] Step 360/520 Loss 2.357 Prec@(1,5) (53.3%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:19:17] \u001b[32mTrain: [ 18/50] Step 380/520 Loss 2.356 Prec@(1,5) (53.4%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:19:18] \u001b[32mTrain: [ 18/50] Step 400/520 Loss 2.361 Prec@(1,5) (53.3%, 82.4%)\u001b[0m\n",
            "[2024-04-02 20:19:18] \u001b[32mTrain: [ 18/50] Step 420/520 Loss 2.360 Prec@(1,5) (53.4%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:19:19] \u001b[32mTrain: [ 18/50] Step 440/520 Loss 2.359 Prec@(1,5) (53.5%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:19:19] \u001b[32mTrain: [ 18/50] Step 460/520 Loss 2.360 Prec@(1,5) (53.5%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:19:20] \u001b[32mTrain: [ 18/50] Step 480/520 Loss 2.357 Prec@(1,5) (53.5%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:19:20] \u001b[32mTrain: [ 18/50] Step 500/520 Loss 2.362 Prec@(1,5) (53.5%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:19:21] \u001b[32mTrain: [ 18/50] Step 520/520 Loss 2.362 Prec@(1,5) (53.4%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:19:21] \u001b[32mTrain: [ 18/50] Final Prec@1 53.4000%\u001b[0m\n",
            "[2024-04-02 20:19:24] \u001b[32mValid: [ 18/50] Step 000/104 Loss 2.975 Prec@(1,5) (50.0%, 75.0%)\u001b[0m\n",
            "[2024-04-02 20:19:25] \u001b[32mValid: [ 18/50] Step 020/104 Loss 2.609 Prec@(1,5) (49.6%, 79.6%)\u001b[0m\n",
            "[2024-04-02 20:19:25] \u001b[32mValid: [ 18/50] Step 040/104 Loss 2.569 Prec@(1,5) (49.0%, 80.0%)\u001b[0m\n",
            "[2024-04-02 20:19:25] \u001b[32mValid: [ 18/50] Step 060/104 Loss 2.547 Prec@(1,5) (49.1%, 79.7%)\u001b[0m\n",
            "[2024-04-02 20:19:25] \u001b[32mValid: [ 18/50] Step 080/104 Loss 2.559 Prec@(1,5) (48.9%, 79.9%)\u001b[0m\n",
            "[2024-04-02 20:19:25] \u001b[32mValid: [ 18/50] Step 100/104 Loss 2.550 Prec@(1,5) (48.9%, 79.8%)\u001b[0m\n",
            "[2024-04-02 20:19:25] \u001b[32mValid: [ 18/50] Step 104/104 Loss 2.547 Prec@(1,5) (49.0%, 79.8%)\u001b[0m\n",
            "[2024-04-02 20:19:25] \u001b[32mValid: [ 18/50] Final Prec@1 48.9500%\u001b[0m\n",
            "[2024-04-02 20:19:25] \u001b[32mEpoch 18 LR 0.017823\u001b[0m\n",
            "[2024-04-02 20:19:30] \u001b[32mTrain: [ 19/50] Step 000/520 Loss 2.253 Prec@(1,5) (49.0%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:19:31] \u001b[32mTrain: [ 19/50] Step 020/520 Loss 2.291 Prec@(1,5) (52.6%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:19:31] \u001b[32mTrain: [ 19/50] Step 040/520 Loss 2.307 Prec@(1,5) (53.0%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:19:32] \u001b[32mTrain: [ 19/50] Step 060/520 Loss 2.311 Prec@(1,5) (53.3%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:19:32] \u001b[32mTrain: [ 19/50] Step 080/520 Loss 2.316 Prec@(1,5) (53.2%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:19:33] \u001b[32mTrain: [ 19/50] Step 100/520 Loss 2.313 Prec@(1,5) (53.4%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:19:33] \u001b[32mTrain: [ 19/50] Step 120/520 Loss 2.325 Prec@(1,5) (53.2%, 83.4%)\u001b[0m\n",
            "[2024-04-02 20:19:33] \u001b[32mTrain: [ 19/50] Step 140/520 Loss 2.326 Prec@(1,5) (53.3%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:19:34] \u001b[32mTrain: [ 19/50] Step 160/520 Loss 2.327 Prec@(1,5) (53.2%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:19:34] \u001b[32mTrain: [ 19/50] Step 180/520 Loss 2.328 Prec@(1,5) (53.4%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:19:35] \u001b[32mTrain: [ 19/50] Step 200/520 Loss 2.327 Prec@(1,5) (53.5%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:19:35] \u001b[32mTrain: [ 19/50] Step 220/520 Loss 2.326 Prec@(1,5) (53.7%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:19:36] \u001b[32mTrain: [ 19/50] Step 240/520 Loss 2.329 Prec@(1,5) (53.6%, 83.1%)\u001b[0m\n",
            "[2024-04-02 20:19:36] \u001b[32mTrain: [ 19/50] Step 260/520 Loss 2.333 Prec@(1,5) (53.6%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:19:37] \u001b[32mTrain: [ 19/50] Step 280/520 Loss 2.328 Prec@(1,5) (53.8%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:19:37] \u001b[32mTrain: [ 19/50] Step 300/520 Loss 2.327 Prec@(1,5) (53.8%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:19:38] \u001b[32mTrain: [ 19/50] Step 320/520 Loss 2.326 Prec@(1,5) (53.8%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:19:38] \u001b[32mTrain: [ 19/50] Step 340/520 Loss 2.328 Prec@(1,5) (53.8%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:19:39] \u001b[32mTrain: [ 19/50] Step 360/520 Loss 2.328 Prec@(1,5) (53.8%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:19:39] \u001b[32mTrain: [ 19/50] Step 380/520 Loss 2.326 Prec@(1,5) (53.8%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:19:40] \u001b[32mTrain: [ 19/50] Step 400/520 Loss 2.322 Prec@(1,5) (53.9%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:19:40] \u001b[32mTrain: [ 19/50] Step 420/520 Loss 2.324 Prec@(1,5) (53.9%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:19:41] \u001b[32mTrain: [ 19/50] Step 440/520 Loss 2.324 Prec@(1,5) (53.9%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:19:41] \u001b[32mTrain: [ 19/50] Step 460/520 Loss 2.326 Prec@(1,5) (53.8%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:19:42] \u001b[32mTrain: [ 19/50] Step 480/520 Loss 2.327 Prec@(1,5) (53.8%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:19:42] \u001b[32mTrain: [ 19/50] Step 500/520 Loss 2.329 Prec@(1,5) (53.8%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:19:43] \u001b[32mTrain: [ 19/50] Step 520/520 Loss 2.328 Prec@(1,5) (53.9%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:19:43] \u001b[32mTrain: [ 19/50] Final Prec@1 53.8580%\u001b[0m\n",
            "[2024-04-02 20:19:46] \u001b[32mValid: [ 19/50] Step 000/104 Loss 2.302 Prec@(1,5) (53.1%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:19:47] \u001b[32mValid: [ 19/50] Step 020/104 Loss 2.492 Prec@(1,5) (50.9%, 80.3%)\u001b[0m\n",
            "[2024-04-02 20:19:47] \u001b[32mValid: [ 19/50] Step 040/104 Loss 2.477 Prec@(1,5) (49.8%, 80.3%)\u001b[0m\n",
            "[2024-04-02 20:19:47] \u001b[32mValid: [ 19/50] Step 060/104 Loss 2.452 Prec@(1,5) (50.4%, 80.4%)\u001b[0m\n",
            "[2024-04-02 20:19:47] \u001b[32mValid: [ 19/50] Step 080/104 Loss 2.454 Prec@(1,5) (50.0%, 80.7%)\u001b[0m\n",
            "[2024-04-02 20:19:47] \u001b[32mValid: [ 19/50] Step 100/104 Loss 2.438 Prec@(1,5) (50.1%, 80.7%)\u001b[0m\n",
            "[2024-04-02 20:19:47] \u001b[32mValid: [ 19/50] Step 104/104 Loss 2.441 Prec@(1,5) (50.0%, 80.6%)\u001b[0m\n",
            "[2024-04-02 20:19:48] \u001b[32mValid: [ 19/50] Final Prec@1 49.9900%\u001b[0m\n",
            "[2024-04-02 20:19:48] \u001b[32mEpoch 19 LR 0.017102\u001b[0m\n",
            "[2024-04-02 20:19:52] \u001b[32mTrain: [ 20/50] Step 000/520 Loss 2.319 Prec@(1,5) (55.2%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:19:53] \u001b[32mTrain: [ 20/50] Step 020/520 Loss 2.335 Prec@(1,5) (54.7%, 82.1%)\u001b[0m\n",
            "[2024-04-02 20:19:53] \u001b[32mTrain: [ 20/50] Step 040/520 Loss 2.325 Prec@(1,5) (54.2%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:19:54] \u001b[32mTrain: [ 20/50] Step 060/520 Loss 2.302 Prec@(1,5) (54.0%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:19:54] \u001b[32mTrain: [ 20/50] Step 080/520 Loss 2.296 Prec@(1,5) (54.1%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:19:55] \u001b[32mTrain: [ 20/50] Step 100/520 Loss 2.300 Prec@(1,5) (54.3%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:19:55] \u001b[32mTrain: [ 20/50] Step 120/520 Loss 2.294 Prec@(1,5) (54.4%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:19:56] \u001b[32mTrain: [ 20/50] Step 140/520 Loss 2.285 Prec@(1,5) (54.5%, 83.5%)\u001b[0m\n",
            "[2024-04-02 20:19:56] \u001b[32mTrain: [ 20/50] Step 160/520 Loss 2.286 Prec@(1,5) (54.6%, 83.4%)\u001b[0m\n",
            "[2024-04-02 20:19:57] \u001b[32mTrain: [ 20/50] Step 180/520 Loss 2.292 Prec@(1,5) (54.4%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:19:57] \u001b[32mTrain: [ 20/50] Step 200/520 Loss 2.290 Prec@(1,5) (54.4%, 83.1%)\u001b[0m\n",
            "[2024-04-02 20:19:58] \u001b[32mTrain: [ 20/50] Step 220/520 Loss 2.296 Prec@(1,5) (54.4%, 83.1%)\u001b[0m\n",
            "[2024-04-02 20:19:58] \u001b[32mTrain: [ 20/50] Step 240/520 Loss 2.292 Prec@(1,5) (54.5%, 83.1%)\u001b[0m\n",
            "[2024-04-02 20:19:59] \u001b[32mTrain: [ 20/50] Step 260/520 Loss 2.295 Prec@(1,5) (54.3%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:19:59] \u001b[32mTrain: [ 20/50] Step 280/520 Loss 2.297 Prec@(1,5) (54.2%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:20:00] \u001b[32mTrain: [ 20/50] Step 300/520 Loss 2.293 Prec@(1,5) (54.2%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:20:00] \u001b[32mTrain: [ 20/50] Step 320/520 Loss 2.291 Prec@(1,5) (54.4%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:20:01] \u001b[32mTrain: [ 20/50] Step 340/520 Loss 2.295 Prec@(1,5) (54.2%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:20:01] \u001b[32mTrain: [ 20/50] Step 360/520 Loss 2.297 Prec@(1,5) (54.2%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:20:02] \u001b[32mTrain: [ 20/50] Step 380/520 Loss 2.300 Prec@(1,5) (54.2%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:20:02] \u001b[32mTrain: [ 20/50] Step 400/520 Loss 2.301 Prec@(1,5) (54.2%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:20:02] \u001b[32mTrain: [ 20/50] Step 420/520 Loss 2.302 Prec@(1,5) (54.2%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:20:03] \u001b[32mTrain: [ 20/50] Step 440/520 Loss 2.300 Prec@(1,5) (54.2%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:20:03] \u001b[32mTrain: [ 20/50] Step 460/520 Loss 2.297 Prec@(1,5) (54.3%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:20:04] \u001b[32mTrain: [ 20/50] Step 480/520 Loss 2.295 Prec@(1,5) (54.3%, 83.4%)\u001b[0m\n",
            "[2024-04-02 20:20:04] \u001b[32mTrain: [ 20/50] Step 500/520 Loss 2.297 Prec@(1,5) (54.3%, 83.4%)\u001b[0m\n",
            "[2024-04-02 20:20:05] \u001b[32mTrain: [ 20/50] Step 520/520 Loss 2.298 Prec@(1,5) (54.3%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:20:05] \u001b[32mTrain: [ 20/50] Final Prec@1 54.3100%\u001b[0m\n",
            "[2024-04-02 20:20:09] \u001b[32mValid: [ 20/50] Step 000/104 Loss 2.238 Prec@(1,5) (55.2%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:20:09] \u001b[32mValid: [ 20/50] Step 020/104 Loss 2.440 Prec@(1,5) (51.4%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:20:09] \u001b[32mValid: [ 20/50] Step 040/104 Loss 2.413 Prec@(1,5) (50.7%, 80.7%)\u001b[0m\n",
            "[2024-04-02 20:20:09] \u001b[32mValid: [ 20/50] Step 060/104 Loss 2.375 Prec@(1,5) (51.7%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:20:09] \u001b[32mValid: [ 20/50] Step 080/104 Loss 2.382 Prec@(1,5) (51.2%, 80.7%)\u001b[0m\n",
            "[2024-04-02 20:20:09] \u001b[32mValid: [ 20/50] Step 100/104 Loss 2.374 Prec@(1,5) (51.2%, 80.7%)\u001b[0m\n",
            "[2024-04-02 20:20:09] \u001b[32mValid: [ 20/50] Step 104/104 Loss 2.373 Prec@(1,5) (51.3%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:20:10] \u001b[32mValid: [ 20/50] Final Prec@1 51.2600%\u001b[0m\n",
            "[2024-04-02 20:20:10] \u001b[32mEpoch 20 LR 0.016363\u001b[0m\n",
            "[2024-04-02 20:20:14] \u001b[32mTrain: [ 21/50] Step 000/520 Loss 2.458 Prec@(1,5) (47.9%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:20:15] \u001b[32mTrain: [ 21/50] Step 020/520 Loss 2.241 Prec@(1,5) (54.4%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:20:15] \u001b[32mTrain: [ 21/50] Step 040/520 Loss 2.207 Prec@(1,5) (55.4%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:20:16] \u001b[32mTrain: [ 21/50] Step 060/520 Loss 2.202 Prec@(1,5) (55.8%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:20:16] \u001b[32mTrain: [ 21/50] Step 080/520 Loss 2.223 Prec@(1,5) (55.7%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:20:17] \u001b[32mTrain: [ 21/50] Step 100/520 Loss 2.229 Prec@(1,5) (55.9%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:20:17] \u001b[32mTrain: [ 21/50] Step 120/520 Loss 2.230 Prec@(1,5) (55.7%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:20:18] \u001b[32mTrain: [ 21/50] Step 140/520 Loss 2.229 Prec@(1,5) (55.6%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:20:18] \u001b[32mTrain: [ 21/50] Step 160/520 Loss 2.223 Prec@(1,5) (55.7%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:20:19] \u001b[32mTrain: [ 21/50] Step 180/520 Loss 2.229 Prec@(1,5) (55.5%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:20:19] \u001b[32mTrain: [ 21/50] Step 200/520 Loss 2.231 Prec@(1,5) (55.5%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:20:20] \u001b[32mTrain: [ 21/50] Step 220/520 Loss 2.232 Prec@(1,5) (55.4%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:20:20] \u001b[32mTrain: [ 21/50] Step 240/520 Loss 2.240 Prec@(1,5) (55.3%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:20:21] \u001b[32mTrain: [ 21/50] Step 260/520 Loss 2.244 Prec@(1,5) (55.2%, 84.0%)\u001b[0m\n",
            "[2024-04-02 20:20:21] \u001b[32mTrain: [ 21/50] Step 280/520 Loss 2.246 Prec@(1,5) (55.1%, 84.0%)\u001b[0m\n",
            "[2024-04-02 20:20:22] \u001b[32mTrain: [ 21/50] Step 300/520 Loss 2.248 Prec@(1,5) (55.1%, 83.9%)\u001b[0m\n",
            "[2024-04-02 20:20:22] \u001b[32mTrain: [ 21/50] Step 320/520 Loss 2.247 Prec@(1,5) (55.2%, 84.0%)\u001b[0m\n",
            "[2024-04-02 20:20:23] \u001b[32mTrain: [ 21/50] Step 340/520 Loss 2.250 Prec@(1,5) (55.2%, 83.9%)\u001b[0m\n",
            "[2024-04-02 20:20:23] \u001b[32mTrain: [ 21/50] Step 360/520 Loss 2.249 Prec@(1,5) (55.1%, 83.9%)\u001b[0m\n",
            "[2024-04-02 20:20:24] \u001b[32mTrain: [ 21/50] Step 380/520 Loss 2.254 Prec@(1,5) (54.9%, 83.8%)\u001b[0m\n",
            "[2024-04-02 20:20:24] \u001b[32mTrain: [ 21/50] Step 400/520 Loss 2.254 Prec@(1,5) (54.9%, 83.8%)\u001b[0m\n",
            "[2024-04-02 20:20:25] \u001b[32mTrain: [ 21/50] Step 420/520 Loss 2.257 Prec@(1,5) (54.9%, 83.8%)\u001b[0m\n",
            "[2024-04-02 20:20:25] \u001b[32mTrain: [ 21/50] Step 440/520 Loss 2.261 Prec@(1,5) (54.8%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:20:25] \u001b[32mTrain: [ 21/50] Step 460/520 Loss 2.263 Prec@(1,5) (54.7%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:20:26] \u001b[32mTrain: [ 21/50] Step 480/520 Loss 2.265 Prec@(1,5) (54.6%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:20:26] \u001b[32mTrain: [ 21/50] Step 500/520 Loss 2.265 Prec@(1,5) (54.7%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:20:27] \u001b[32mTrain: [ 21/50] Step 520/520 Loss 2.269 Prec@(1,5) (54.6%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:20:27] \u001b[32mTrain: [ 21/50] Final Prec@1 54.5540%\u001b[0m\n",
            "[2024-04-02 20:20:31] \u001b[32mValid: [ 21/50] Step 000/104 Loss 2.363 Prec@(1,5) (54.2%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:20:31] \u001b[32mValid: [ 21/50] Step 020/104 Loss 2.627 Prec@(1,5) (49.9%, 79.1%)\u001b[0m\n",
            "[2024-04-02 20:20:31] \u001b[32mValid: [ 21/50] Step 040/104 Loss 2.617 Prec@(1,5) (48.6%, 79.3%)\u001b[0m\n",
            "[2024-04-02 20:20:31] \u001b[32mValid: [ 21/50] Step 060/104 Loss 2.603 Prec@(1,5) (49.1%, 79.2%)\u001b[0m\n",
            "[2024-04-02 20:20:31] \u001b[32mValid: [ 21/50] Step 080/104 Loss 2.612 Prec@(1,5) (49.0%, 79.2%)\u001b[0m\n",
            "[2024-04-02 20:20:31] \u001b[32mValid: [ 21/50] Step 100/104 Loss 2.596 Prec@(1,5) (49.2%, 79.3%)\u001b[0m\n",
            "[2024-04-02 20:20:32] \u001b[32mValid: [ 21/50] Step 104/104 Loss 2.597 Prec@(1,5) (49.3%, 79.2%)\u001b[0m\n",
            "[2024-04-02 20:20:32] \u001b[32mValid: [ 21/50] Final Prec@1 49.2500%\u001b[0m\n",
            "[2024-04-02 20:20:32] \u001b[32mEpoch 21 LR 0.015609\u001b[0m\n",
            "[2024-04-02 20:20:36] \u001b[32mTrain: [ 22/50] Step 000/520 Loss 2.389 Prec@(1,5) (53.1%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:20:37] \u001b[32mTrain: [ 22/50] Step 020/520 Loss 2.114 Prec@(1,5) (57.7%, 86.1%)\u001b[0m\n",
            "[2024-04-02 20:20:37] \u001b[32mTrain: [ 22/50] Step 040/520 Loss 2.183 Prec@(1,5) (57.2%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:20:38] \u001b[32mTrain: [ 22/50] Step 060/520 Loss 2.192 Prec@(1,5) (56.5%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:20:38] \u001b[32mTrain: [ 22/50] Step 080/520 Loss 2.199 Prec@(1,5) (56.4%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:20:39] \u001b[32mTrain: [ 22/50] Step 100/520 Loss 2.185 Prec@(1,5) (56.4%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:20:39] \u001b[32mTrain: [ 22/50] Step 120/520 Loss 2.193 Prec@(1,5) (56.2%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:20:40] \u001b[32mTrain: [ 22/50] Step 140/520 Loss 2.197 Prec@(1,5) (56.3%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:20:40] \u001b[32mTrain: [ 22/50] Step 160/520 Loss 2.210 Prec@(1,5) (56.2%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:20:41] \u001b[32mTrain: [ 22/50] Step 180/520 Loss 2.212 Prec@(1,5) (56.0%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:20:41] \u001b[32mTrain: [ 22/50] Step 200/520 Loss 2.210 Prec@(1,5) (56.2%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:20:42] \u001b[32mTrain: [ 22/50] Step 220/520 Loss 2.209 Prec@(1,5) (56.2%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:20:42] \u001b[32mTrain: [ 22/50] Step 240/520 Loss 2.217 Prec@(1,5) (56.0%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:20:43] \u001b[32mTrain: [ 22/50] Step 260/520 Loss 2.220 Prec@(1,5) (55.9%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:20:43] \u001b[32mTrain: [ 22/50] Step 280/520 Loss 2.220 Prec@(1,5) (55.9%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:20:44] \u001b[32mTrain: [ 22/50] Step 300/520 Loss 2.223 Prec@(1,5) (55.9%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:20:44] \u001b[32mTrain: [ 22/50] Step 320/520 Loss 2.225 Prec@(1,5) (55.7%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:20:45] \u001b[32mTrain: [ 22/50] Step 340/520 Loss 2.225 Prec@(1,5) (55.7%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:20:46] \u001b[32mTrain: [ 22/50] Step 360/520 Loss 2.226 Prec@(1,5) (55.8%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:20:46] \u001b[32mTrain: [ 22/50] Step 380/520 Loss 2.227 Prec@(1,5) (55.7%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:20:47] \u001b[32mTrain: [ 22/50] Step 400/520 Loss 2.230 Prec@(1,5) (55.6%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:20:47] \u001b[32mTrain: [ 22/50] Step 420/520 Loss 2.229 Prec@(1,5) (55.6%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:20:48] \u001b[32mTrain: [ 22/50] Step 440/520 Loss 2.230 Prec@(1,5) (55.5%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:20:48] \u001b[32mTrain: [ 22/50] Step 460/520 Loss 2.232 Prec@(1,5) (55.5%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:20:49] \u001b[32mTrain: [ 22/50] Step 480/520 Loss 2.235 Prec@(1,5) (55.4%, 84.0%)\u001b[0m\n",
            "[2024-04-02 20:20:49] \u001b[32mTrain: [ 22/50] Step 500/520 Loss 2.235 Prec@(1,5) (55.4%, 84.0%)\u001b[0m\n",
            "[2024-04-02 20:20:50] \u001b[32mTrain: [ 22/50] Step 520/520 Loss 2.232 Prec@(1,5) (55.5%, 84.0%)\u001b[0m\n",
            "[2024-04-02 20:20:50] \u001b[32mTrain: [ 22/50] Final Prec@1 55.4900%\u001b[0m\n",
            "[2024-04-02 20:20:53] \u001b[32mValid: [ 22/50] Step 000/104 Loss 2.364 Prec@(1,5) (55.2%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:20:53] \u001b[32mValid: [ 22/50] Step 020/104 Loss 2.525 Prec@(1,5) (50.8%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:20:54] \u001b[32mValid: [ 22/50] Step 040/104 Loss 2.470 Prec@(1,5) (50.9%, 81.6%)\u001b[0m\n",
            "[2024-04-02 20:20:54] \u001b[32mValid: [ 22/50] Step 060/104 Loss 2.449 Prec@(1,5) (51.3%, 81.5%)\u001b[0m\n",
            "[2024-04-02 20:20:54] \u001b[32mValid: [ 22/50] Step 080/104 Loss 2.457 Prec@(1,5) (50.8%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:20:54] \u001b[32mValid: [ 22/50] Step 100/104 Loss 2.452 Prec@(1,5) (51.0%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:20:54] \u001b[32mValid: [ 22/50] Step 104/104 Loss 2.453 Prec@(1,5) (50.9%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:20:54] \u001b[32mValid: [ 22/50] Final Prec@1 50.9400%\u001b[0m\n",
            "[2024-04-02 20:20:54] \u001b[32mEpoch 22 LR 0.014843\u001b[0m\n",
            "[2024-04-02 20:20:59] \u001b[32mTrain: [ 23/50] Step 000/520 Loss 2.120 Prec@(1,5) (50.0%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:20:59] \u001b[32mTrain: [ 23/50] Step 020/520 Loss 2.142 Prec@(1,5) (56.1%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:21:00] \u001b[32mTrain: [ 23/50] Step 040/520 Loss 2.107 Prec@(1,5) (56.9%, 86.4%)\u001b[0m\n",
            "[2024-04-02 20:21:01] \u001b[32mTrain: [ 23/50] Step 060/520 Loss 2.124 Prec@(1,5) (56.6%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:21:01] \u001b[32mTrain: [ 23/50] Step 080/520 Loss 2.144 Prec@(1,5) (56.3%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:21:02] \u001b[32mTrain: [ 23/50] Step 100/520 Loss 2.159 Prec@(1,5) (56.3%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:21:02] \u001b[32mTrain: [ 23/50] Step 120/520 Loss 2.166 Prec@(1,5) (56.4%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:21:03] \u001b[32mTrain: [ 23/50] Step 140/520 Loss 2.165 Prec@(1,5) (56.4%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:21:03] \u001b[32mTrain: [ 23/50] Step 160/520 Loss 2.174 Prec@(1,5) (56.2%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:21:04] \u001b[32mTrain: [ 23/50] Step 180/520 Loss 2.176 Prec@(1,5) (56.2%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:21:04] \u001b[32mTrain: [ 23/50] Step 200/520 Loss 2.169 Prec@(1,5) (56.4%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:21:05] \u001b[32mTrain: [ 23/50] Step 220/520 Loss 2.176 Prec@(1,5) (56.3%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:21:05] \u001b[32mTrain: [ 23/50] Step 240/520 Loss 2.182 Prec@(1,5) (56.3%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:21:06] \u001b[32mTrain: [ 23/50] Step 260/520 Loss 2.180 Prec@(1,5) (56.3%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:21:06] \u001b[32mTrain: [ 23/50] Step 280/520 Loss 2.189 Prec@(1,5) (56.1%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:21:07] \u001b[32mTrain: [ 23/50] Step 300/520 Loss 2.187 Prec@(1,5) (56.1%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:21:07] \u001b[32mTrain: [ 23/50] Step 320/520 Loss 2.188 Prec@(1,5) (56.2%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:21:07] \u001b[32mTrain: [ 23/50] Step 340/520 Loss 2.187 Prec@(1,5) (56.2%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:21:08] \u001b[32mTrain: [ 23/50] Step 360/520 Loss 2.186 Prec@(1,5) (56.2%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:21:08] \u001b[32mTrain: [ 23/50] Step 380/520 Loss 2.190 Prec@(1,5) (56.2%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:21:09] \u001b[32mTrain: [ 23/50] Step 400/520 Loss 2.192 Prec@(1,5) (56.1%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:21:09] \u001b[32mTrain: [ 23/50] Step 420/520 Loss 2.190 Prec@(1,5) (56.2%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:21:10] \u001b[32mTrain: [ 23/50] Step 440/520 Loss 2.192 Prec@(1,5) (56.1%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:21:10] \u001b[32mTrain: [ 23/50] Step 460/520 Loss 2.190 Prec@(1,5) (56.3%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:21:11] \u001b[32mTrain: [ 23/50] Step 480/520 Loss 2.190 Prec@(1,5) (56.2%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:21:11] \u001b[32mTrain: [ 23/50] Step 500/520 Loss 2.189 Prec@(1,5) (56.2%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:21:12] \u001b[32mTrain: [ 23/50] Step 520/520 Loss 2.190 Prec@(1,5) (56.2%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:21:12] \u001b[32mTrain: [ 23/50] Final Prec@1 56.1740%\u001b[0m\n",
            "[2024-04-02 20:21:16] \u001b[32mValid: [ 23/50] Step 000/104 Loss 2.108 Prec@(1,5) (56.2%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:21:16] \u001b[32mValid: [ 23/50] Step 020/104 Loss 2.299 Prec@(1,5) (54.0%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:21:16] \u001b[32mValid: [ 23/50] Step 040/104 Loss 2.263 Prec@(1,5) (53.0%, 82.4%)\u001b[0m\n",
            "[2024-04-02 20:21:16] \u001b[32mValid: [ 23/50] Step 060/104 Loss 2.237 Prec@(1,5) (53.5%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:21:16] \u001b[32mValid: [ 23/50] Step 080/104 Loss 2.249 Prec@(1,5) (53.1%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:21:16] \u001b[32mValid: [ 23/50] Step 100/104 Loss 2.242 Prec@(1,5) (53.0%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:21:16] \u001b[32mValid: [ 23/50] Step 104/104 Loss 2.241 Prec@(1,5) (52.9%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:21:17] \u001b[32mValid: [ 23/50] Final Prec@1 52.9300%\u001b[0m\n",
            "[2024-04-02 20:21:17] \u001b[32mEpoch 23 LR 0.014067\u001b[0m\n",
            "[2024-04-02 20:21:21] \u001b[32mTrain: [ 24/50] Step 000/520 Loss 2.453 Prec@(1,5) (54.2%, 79.2%)\u001b[0m\n",
            "[2024-04-02 20:21:22] \u001b[32mTrain: [ 24/50] Step 020/520 Loss 2.159 Prec@(1,5) (56.8%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:21:22] \u001b[32mTrain: [ 24/50] Step 040/520 Loss 2.112 Prec@(1,5) (57.5%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:21:23] \u001b[32mTrain: [ 24/50] Step 060/520 Loss 2.157 Prec@(1,5) (56.6%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:21:23] \u001b[32mTrain: [ 24/50] Step 080/520 Loss 2.155 Prec@(1,5) (56.9%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:21:24] \u001b[32mTrain: [ 24/50] Step 100/520 Loss 2.138 Prec@(1,5) (57.0%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:21:24] \u001b[32mTrain: [ 24/50] Step 120/520 Loss 2.143 Prec@(1,5) (57.0%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:21:25] \u001b[32mTrain: [ 24/50] Step 140/520 Loss 2.141 Prec@(1,5) (57.1%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:21:25] \u001b[32mTrain: [ 24/50] Step 160/520 Loss 2.139 Prec@(1,5) (57.1%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:21:26] \u001b[32mTrain: [ 24/50] Step 180/520 Loss 2.139 Prec@(1,5) (57.0%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:21:26] \u001b[32mTrain: [ 24/50] Step 200/520 Loss 2.134 Prec@(1,5) (57.2%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:21:27] \u001b[32mTrain: [ 24/50] Step 220/520 Loss 2.144 Prec@(1,5) (57.1%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:21:27] \u001b[32mTrain: [ 24/50] Step 240/520 Loss 2.152 Prec@(1,5) (57.0%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:21:28] \u001b[32mTrain: [ 24/50] Step 260/520 Loss 2.151 Prec@(1,5) (57.0%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:21:28] \u001b[32mTrain: [ 24/50] Step 280/520 Loss 2.153 Prec@(1,5) (57.0%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:21:29] \u001b[32mTrain: [ 24/50] Step 300/520 Loss 2.157 Prec@(1,5) (57.0%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:21:29] \u001b[32mTrain: [ 24/50] Step 320/520 Loss 2.154 Prec@(1,5) (57.0%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:21:30] \u001b[32mTrain: [ 24/50] Step 340/520 Loss 2.159 Prec@(1,5) (56.9%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:21:30] \u001b[32mTrain: [ 24/50] Step 360/520 Loss 2.161 Prec@(1,5) (56.9%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:21:30] \u001b[32mTrain: [ 24/50] Step 380/520 Loss 2.158 Prec@(1,5) (56.9%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:21:31] \u001b[32mTrain: [ 24/50] Step 400/520 Loss 2.161 Prec@(1,5) (56.8%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:21:31] \u001b[32mTrain: [ 24/50] Step 420/520 Loss 2.164 Prec@(1,5) (56.8%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:21:32] \u001b[32mTrain: [ 24/50] Step 440/520 Loss 2.165 Prec@(1,5) (56.8%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:21:32] \u001b[32mTrain: [ 24/50] Step 460/520 Loss 2.164 Prec@(1,5) (56.8%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:21:33] \u001b[32mTrain: [ 24/50] Step 480/520 Loss 2.166 Prec@(1,5) (56.8%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:21:33] \u001b[32mTrain: [ 24/50] Step 500/520 Loss 2.168 Prec@(1,5) (56.7%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:21:34] \u001b[32mTrain: [ 24/50] Step 520/520 Loss 2.169 Prec@(1,5) (56.7%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:21:34] \u001b[32mTrain: [ 24/50] Final Prec@1 56.7060%\u001b[0m\n",
            "[2024-04-02 20:21:38] \u001b[32mValid: [ 24/50] Step 000/104 Loss 2.266 Prec@(1,5) (56.2%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:21:38] \u001b[32mValid: [ 24/50] Step 020/104 Loss 2.244 Prec@(1,5) (55.0%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:21:38] \u001b[32mValid: [ 24/50] Step 040/104 Loss 2.200 Prec@(1,5) (54.4%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:21:38] \u001b[32mValid: [ 24/50] Step 060/104 Loss 2.176 Prec@(1,5) (54.6%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:21:38] \u001b[32mValid: [ 24/50] Step 080/104 Loss 2.183 Prec@(1,5) (54.4%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:21:38] \u001b[32mValid: [ 24/50] Step 100/104 Loss 2.172 Prec@(1,5) (54.4%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:21:38] \u001b[32mValid: [ 24/50] Step 104/104 Loss 2.170 Prec@(1,5) (54.5%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:21:39] \u001b[32mValid: [ 24/50] Final Prec@1 54.4600%\u001b[0m\n",
            "[2024-04-02 20:21:39] \u001b[32mEpoch 24 LR 0.013285\u001b[0m\n",
            "[2024-04-02 20:21:43] \u001b[32mTrain: [ 25/50] Step 000/520 Loss 2.195 Prec@(1,5) (55.2%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:21:44] \u001b[32mTrain: [ 25/50] Step 020/520 Loss 2.125 Prec@(1,5) (57.7%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:21:44] \u001b[32mTrain: [ 25/50] Step 040/520 Loss 2.106 Prec@(1,5) (58.1%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:21:45] \u001b[32mTrain: [ 25/50] Step 060/520 Loss 2.113 Prec@(1,5) (58.1%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:21:45] \u001b[32mTrain: [ 25/50] Step 080/520 Loss 2.126 Prec@(1,5) (57.4%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:21:46] \u001b[32mTrain: [ 25/50] Step 100/520 Loss 2.130 Prec@(1,5) (57.1%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:21:46] \u001b[32mTrain: [ 25/50] Step 120/520 Loss 2.125 Prec@(1,5) (57.2%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:21:47] \u001b[32mTrain: [ 25/50] Step 140/520 Loss 2.128 Prec@(1,5) (57.2%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:21:47] \u001b[32mTrain: [ 25/50] Step 160/520 Loss 2.133 Prec@(1,5) (57.2%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:21:48] \u001b[32mTrain: [ 25/50] Step 180/520 Loss 2.134 Prec@(1,5) (57.2%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:21:48] \u001b[32mTrain: [ 25/50] Step 200/520 Loss 2.136 Prec@(1,5) (57.1%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:21:49] \u001b[32mTrain: [ 25/50] Step 220/520 Loss 2.134 Prec@(1,5) (57.1%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:21:49] \u001b[32mTrain: [ 25/50] Step 240/520 Loss 2.131 Prec@(1,5) (57.1%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:21:50] \u001b[32mTrain: [ 25/50] Step 260/520 Loss 2.131 Prec@(1,5) (57.2%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:21:50] \u001b[32mTrain: [ 25/50] Step 280/520 Loss 2.131 Prec@(1,5) (57.2%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:21:51] \u001b[32mTrain: [ 25/50] Step 300/520 Loss 2.133 Prec@(1,5) (57.2%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:21:51] \u001b[32mTrain: [ 25/50] Step 320/520 Loss 2.133 Prec@(1,5) (57.2%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:21:52] \u001b[32mTrain: [ 25/50] Step 340/520 Loss 2.136 Prec@(1,5) (57.2%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:21:52] \u001b[32mTrain: [ 25/50] Step 360/520 Loss 2.136 Prec@(1,5) (57.2%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:21:53] \u001b[32mTrain: [ 25/50] Step 380/520 Loss 2.134 Prec@(1,5) (57.3%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:21:53] \u001b[32mTrain: [ 25/50] Step 400/520 Loss 2.135 Prec@(1,5) (57.2%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:21:54] \u001b[32mTrain: [ 25/50] Step 420/520 Loss 2.134 Prec@(1,5) (57.3%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:21:54] \u001b[32mTrain: [ 25/50] Step 440/520 Loss 2.134 Prec@(1,5) (57.3%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:21:55] \u001b[32mTrain: [ 25/50] Step 460/520 Loss 2.134 Prec@(1,5) (57.3%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:21:55] \u001b[32mTrain: [ 25/50] Step 480/520 Loss 2.135 Prec@(1,5) (57.2%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:21:56] \u001b[32mTrain: [ 25/50] Step 500/520 Loss 2.137 Prec@(1,5) (57.2%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:21:56] \u001b[32mTrain: [ 25/50] Step 520/520 Loss 2.136 Prec@(1,5) (57.2%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:21:57] \u001b[32mTrain: [ 25/50] Final Prec@1 57.2380%\u001b[0m\n",
            "[2024-04-02 20:22:00] \u001b[32mValid: [ 25/50] Step 000/104 Loss 2.189 Prec@(1,5) (56.2%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:22:00] \u001b[32mValid: [ 25/50] Step 020/104 Loss 2.258 Prec@(1,5) (53.2%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:22:00] \u001b[32mValid: [ 25/50] Step 040/104 Loss 2.235 Prec@(1,5) (52.6%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:22:01] \u001b[32mValid: [ 25/50] Step 060/104 Loss 2.206 Prec@(1,5) (53.2%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:22:01] \u001b[32mValid: [ 25/50] Step 080/104 Loss 2.226 Prec@(1,5) (52.8%, 82.4%)\u001b[0m\n",
            "[2024-04-02 20:22:01] \u001b[32mValid: [ 25/50] Step 100/104 Loss 2.218 Prec@(1,5) (52.9%, 82.4%)\u001b[0m\n",
            "[2024-04-02 20:22:01] \u001b[32mValid: [ 25/50] Step 104/104 Loss 2.219 Prec@(1,5) (52.9%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:22:01] \u001b[32mValid: [ 25/50] Final Prec@1 52.9400%\u001b[0m\n",
            "[2024-04-02 20:22:01] \u001b[32mEpoch 25 LR 0.012500\u001b[0m\n",
            "[2024-04-02 20:22:06] \u001b[32mTrain: [ 26/50] Step 000/520 Loss 2.201 Prec@(1,5) (61.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:22:06] \u001b[32mTrain: [ 26/50] Step 020/520 Loss 2.113 Prec@(1,5) (58.3%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:22:07] \u001b[32mTrain: [ 26/50] Step 040/520 Loss 2.051 Prec@(1,5) (58.8%, 86.8%)\u001b[0m\n",
            "[2024-04-02 20:22:07] \u001b[32mTrain: [ 26/50] Step 060/520 Loss 2.091 Prec@(1,5) (58.2%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:22:08] \u001b[32mTrain: [ 26/50] Step 080/520 Loss 2.100 Prec@(1,5) (57.7%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:22:08] \u001b[32mTrain: [ 26/50] Step 100/520 Loss 2.097 Prec@(1,5) (58.0%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:22:09] \u001b[32mTrain: [ 26/50] Step 120/520 Loss 2.097 Prec@(1,5) (58.0%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:22:09] \u001b[32mTrain: [ 26/50] Step 140/520 Loss 2.107 Prec@(1,5) (57.6%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:22:10] \u001b[32mTrain: [ 26/50] Step 160/520 Loss 2.107 Prec@(1,5) (57.6%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:22:10] \u001b[32mTrain: [ 26/50] Step 180/520 Loss 2.101 Prec@(1,5) (57.6%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:22:11] \u001b[32mTrain: [ 26/50] Step 200/520 Loss 2.102 Prec@(1,5) (57.7%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:22:11] \u001b[32mTrain: [ 26/50] Step 220/520 Loss 2.101 Prec@(1,5) (57.7%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:22:12] \u001b[32mTrain: [ 26/50] Step 240/520 Loss 2.096 Prec@(1,5) (57.9%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:22:12] \u001b[32mTrain: [ 26/50] Step 260/520 Loss 2.092 Prec@(1,5) (57.9%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:22:13] \u001b[32mTrain: [ 26/50] Step 280/520 Loss 2.094 Prec@(1,5) (57.9%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:22:13] \u001b[32mTrain: [ 26/50] Step 300/520 Loss 2.096 Prec@(1,5) (57.9%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:22:14] \u001b[32mTrain: [ 26/50] Step 320/520 Loss 2.099 Prec@(1,5) (57.8%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:22:14] \u001b[32mTrain: [ 26/50] Step 340/520 Loss 2.104 Prec@(1,5) (57.8%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:22:15] \u001b[32mTrain: [ 26/50] Step 360/520 Loss 2.104 Prec@(1,5) (57.9%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:22:15] \u001b[32mTrain: [ 26/50] Step 380/520 Loss 2.107 Prec@(1,5) (57.8%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:22:16] \u001b[32mTrain: [ 26/50] Step 400/520 Loss 2.112 Prec@(1,5) (57.7%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:22:16] \u001b[32mTrain: [ 26/50] Step 420/520 Loss 2.110 Prec@(1,5) (57.7%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:22:17] \u001b[32mTrain: [ 26/50] Step 440/520 Loss 2.109 Prec@(1,5) (57.7%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:22:17] \u001b[32mTrain: [ 26/50] Step 460/520 Loss 2.109 Prec@(1,5) (57.7%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:22:17] \u001b[32mTrain: [ 26/50] Step 480/520 Loss 2.109 Prec@(1,5) (57.7%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:22:18] \u001b[32mTrain: [ 26/50] Step 500/520 Loss 2.107 Prec@(1,5) (57.8%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:22:18] \u001b[32mTrain: [ 26/50] Step 520/520 Loss 2.109 Prec@(1,5) (57.7%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:22:19] \u001b[32mTrain: [ 26/50] Final Prec@1 57.6800%\u001b[0m\n",
            "[2024-04-02 20:22:22] \u001b[32mValid: [ 26/50] Step 000/104 Loss 2.060 Prec@(1,5) (64.6%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:22:22] \u001b[32mValid: [ 26/50] Step 020/104 Loss 2.115 Prec@(1,5) (55.0%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:22:22] \u001b[32mValid: [ 26/50] Step 040/104 Loss 2.101 Prec@(1,5) (54.7%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:22:23] \u001b[32mValid: [ 26/50] Step 060/104 Loss 2.070 Prec@(1,5) (55.0%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:22:23] \u001b[32mValid: [ 26/50] Step 080/104 Loss 2.087 Prec@(1,5) (54.5%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:22:23] \u001b[32mValid: [ 26/50] Step 100/104 Loss 2.091 Prec@(1,5) (54.6%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:22:23] \u001b[32mValid: [ 26/50] Step 104/104 Loss 2.092 Prec@(1,5) (54.6%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:22:23] \u001b[32mValid: [ 26/50] Final Prec@1 54.6000%\u001b[0m\n",
            "[2024-04-02 20:22:23] \u001b[32mEpoch 26 LR 0.011716\u001b[0m\n",
            "[2024-04-02 20:22:28] \u001b[32mTrain: [ 27/50] Step 000/520 Loss 1.822 Prec@(1,5) (64.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:22:28] \u001b[32mTrain: [ 27/50] Step 020/520 Loss 2.057 Prec@(1,5) (59.4%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:22:29] \u001b[32mTrain: [ 27/50] Step 040/520 Loss 2.058 Prec@(1,5) (59.5%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:22:29] \u001b[32mTrain: [ 27/50] Step 060/520 Loss 2.052 Prec@(1,5) (59.2%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:22:30] \u001b[32mTrain: [ 27/50] Step 080/520 Loss 2.048 Prec@(1,5) (59.2%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:22:30] \u001b[32mTrain: [ 27/50] Step 100/520 Loss 2.041 Prec@(1,5) (59.3%, 86.1%)\u001b[0m\n",
            "[2024-04-02 20:22:31] \u001b[32mTrain: [ 27/50] Step 120/520 Loss 2.048 Prec@(1,5) (59.1%, 86.1%)\u001b[0m\n",
            "[2024-04-02 20:22:31] \u001b[32mTrain: [ 27/50] Step 140/520 Loss 2.044 Prec@(1,5) (59.1%, 86.1%)\u001b[0m\n",
            "[2024-04-02 20:22:32] \u001b[32mTrain: [ 27/50] Step 160/520 Loss 2.060 Prec@(1,5) (58.6%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:22:32] \u001b[32mTrain: [ 27/50] Step 180/520 Loss 2.065 Prec@(1,5) (58.6%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:22:33] \u001b[32mTrain: [ 27/50] Step 200/520 Loss 2.063 Prec@(1,5) (58.5%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:22:33] \u001b[32mTrain: [ 27/50] Step 220/520 Loss 2.067 Prec@(1,5) (58.6%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:22:34] \u001b[32mTrain: [ 27/50] Step 240/520 Loss 2.069 Prec@(1,5) (58.4%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:22:34] \u001b[32mTrain: [ 27/50] Step 260/520 Loss 2.072 Prec@(1,5) (58.4%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:22:35] \u001b[32mTrain: [ 27/50] Step 280/520 Loss 2.079 Prec@(1,5) (58.3%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:22:35] \u001b[32mTrain: [ 27/50] Step 300/520 Loss 2.080 Prec@(1,5) (58.3%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:22:36] \u001b[32mTrain: [ 27/50] Step 320/520 Loss 2.086 Prec@(1,5) (58.3%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:22:36] \u001b[32mTrain: [ 27/50] Step 340/520 Loss 2.090 Prec@(1,5) (58.1%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:22:37] \u001b[32mTrain: [ 27/50] Step 360/520 Loss 2.085 Prec@(1,5) (58.2%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:22:37] \u001b[32mTrain: [ 27/50] Step 380/520 Loss 2.082 Prec@(1,5) (58.3%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:22:38] \u001b[32mTrain: [ 27/50] Step 400/520 Loss 2.083 Prec@(1,5) (58.2%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:22:38] \u001b[32mTrain: [ 27/50] Step 420/520 Loss 2.081 Prec@(1,5) (58.3%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:22:39] \u001b[32mTrain: [ 27/50] Step 440/520 Loss 2.082 Prec@(1,5) (58.2%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:22:39] \u001b[32mTrain: [ 27/50] Step 460/520 Loss 2.080 Prec@(1,5) (58.3%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:22:40] \u001b[32mTrain: [ 27/50] Step 480/520 Loss 2.082 Prec@(1,5) (58.2%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:22:40] \u001b[32mTrain: [ 27/50] Step 500/520 Loss 2.081 Prec@(1,5) (58.2%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:22:41] \u001b[32mTrain: [ 27/50] Step 520/520 Loss 2.081 Prec@(1,5) (58.3%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:22:41] \u001b[32mTrain: [ 27/50] Final Prec@1 58.2660%\u001b[0m\n",
            "[2024-04-02 20:22:44] \u001b[32mValid: [ 27/50] Step 000/104 Loss 1.882 Prec@(1,5) (62.5%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:22:45] \u001b[32mValid: [ 27/50] Step 020/104 Loss 2.077 Prec@(1,5) (57.7%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:22:45] \u001b[32mValid: [ 27/50] Step 040/104 Loss 2.071 Prec@(1,5) (56.9%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:22:45] \u001b[32mValid: [ 27/50] Step 060/104 Loss 2.050 Prec@(1,5) (56.5%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:22:45] \u001b[32mValid: [ 27/50] Step 080/104 Loss 2.055 Prec@(1,5) (55.9%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:22:45] \u001b[32mValid: [ 27/50] Step 100/104 Loss 2.051 Prec@(1,5) (55.9%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:22:45] \u001b[32mValid: [ 27/50] Step 104/104 Loss 2.055 Prec@(1,5) (55.9%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:22:46] \u001b[32mValid: [ 27/50] Final Prec@1 55.8700%\u001b[0m\n",
            "[2024-04-02 20:22:46] \u001b[32mEpoch 27 LR 0.010934\u001b[0m\n",
            "[2024-04-02 20:22:50] \u001b[32mTrain: [ 28/50] Step 000/520 Loss 2.300 Prec@(1,5) (50.0%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:22:51] \u001b[32mTrain: [ 28/50] Step 020/520 Loss 2.088 Prec@(1,5) (58.4%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:22:51] \u001b[32mTrain: [ 28/50] Step 040/520 Loss 2.060 Prec@(1,5) (58.6%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:22:52] \u001b[32mTrain: [ 28/50] Step 060/520 Loss 2.062 Prec@(1,5) (58.7%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:22:52] \u001b[32mTrain: [ 28/50] Step 080/520 Loss 2.048 Prec@(1,5) (58.9%, 86.1%)\u001b[0m\n",
            "[2024-04-02 20:22:53] \u001b[32mTrain: [ 28/50] Step 100/520 Loss 2.038 Prec@(1,5) (59.2%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:22:53] \u001b[32mTrain: [ 28/50] Step 120/520 Loss 2.041 Prec@(1,5) (59.2%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:22:54] \u001b[32mTrain: [ 28/50] Step 140/520 Loss 2.047 Prec@(1,5) (59.0%, 86.1%)\u001b[0m\n",
            "[2024-04-02 20:22:54] \u001b[32mTrain: [ 28/50] Step 160/520 Loss 2.057 Prec@(1,5) (59.0%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:22:55] \u001b[32mTrain: [ 28/50] Step 180/520 Loss 2.051 Prec@(1,5) (59.0%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:22:55] \u001b[32mTrain: [ 28/50] Step 200/520 Loss 2.051 Prec@(1,5) (59.1%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:22:56] \u001b[32mTrain: [ 28/50] Step 220/520 Loss 2.050 Prec@(1,5) (59.0%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:22:56] \u001b[32mTrain: [ 28/50] Step 240/520 Loss 2.044 Prec@(1,5) (59.1%, 86.1%)\u001b[0m\n",
            "[2024-04-02 20:22:57] \u001b[32mTrain: [ 28/50] Step 260/520 Loss 2.042 Prec@(1,5) (59.1%, 86.1%)\u001b[0m\n",
            "[2024-04-02 20:22:57] \u001b[32mTrain: [ 28/50] Step 280/520 Loss 2.041 Prec@(1,5) (59.1%, 86.1%)\u001b[0m\n",
            "[2024-04-02 20:22:58] \u001b[32mTrain: [ 28/50] Step 300/520 Loss 2.045 Prec@(1,5) (59.0%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:22:58] \u001b[32mTrain: [ 28/50] Step 320/520 Loss 2.040 Prec@(1,5) (59.0%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:22:59] \u001b[32mTrain: [ 28/50] Step 340/520 Loss 2.033 Prec@(1,5) (59.1%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:22:59] \u001b[32mTrain: [ 28/50] Step 360/520 Loss 2.037 Prec@(1,5) (59.0%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:23:00] \u001b[32mTrain: [ 28/50] Step 380/520 Loss 2.036 Prec@(1,5) (59.0%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:23:00] \u001b[32mTrain: [ 28/50] Step 400/520 Loss 2.035 Prec@(1,5) (59.1%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:23:01] \u001b[32mTrain: [ 28/50] Step 420/520 Loss 2.037 Prec@(1,5) (59.1%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:23:01] \u001b[32mTrain: [ 28/50] Step 440/520 Loss 2.040 Prec@(1,5) (59.1%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:23:02] \u001b[32mTrain: [ 28/50] Step 460/520 Loss 2.041 Prec@(1,5) (59.0%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:23:02] \u001b[32mTrain: [ 28/50] Step 480/520 Loss 2.042 Prec@(1,5) (59.0%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:23:03] \u001b[32mTrain: [ 28/50] Step 500/520 Loss 2.042 Prec@(1,5) (59.1%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:23:03] \u001b[32mTrain: [ 28/50] Step 520/520 Loss 2.045 Prec@(1,5) (59.0%, 86.1%)\u001b[0m\n",
            "[2024-04-02 20:23:04] \u001b[32mTrain: [ 28/50] Final Prec@1 59.0420%\u001b[0m\n",
            "[2024-04-02 20:23:07] \u001b[32mValid: [ 28/50] Step 000/104 Loss 2.107 Prec@(1,5) (60.4%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:23:07] \u001b[32mValid: [ 28/50] Step 020/104 Loss 2.142 Prec@(1,5) (55.5%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:23:07] \u001b[32mValid: [ 28/50] Step 040/104 Loss 2.167 Prec@(1,5) (54.4%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:23:08] \u001b[32mValid: [ 28/50] Step 060/104 Loss 2.137 Prec@(1,5) (55.1%, 83.8%)\u001b[0m\n",
            "[2024-04-02 20:23:08] \u001b[32mValid: [ 28/50] Step 080/104 Loss 2.140 Prec@(1,5) (54.9%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:23:08] \u001b[32mValid: [ 28/50] Step 100/104 Loss 2.132 Prec@(1,5) (55.0%, 83.8%)\u001b[0m\n",
            "[2024-04-02 20:23:08] \u001b[32mValid: [ 28/50] Step 104/104 Loss 2.132 Prec@(1,5) (55.1%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:23:08] \u001b[32mValid: [ 28/50] Final Prec@1 55.0500%\u001b[0m\n",
            "[2024-04-02 20:23:08] \u001b[32mEpoch 28 LR 0.010158\u001b[0m\n",
            "[2024-04-02 20:23:13] \u001b[32mTrain: [ 29/50] Step 000/520 Loss 1.685 Prec@(1,5) (65.6%, 91.7%)\u001b[0m\n",
            "[2024-04-02 20:23:13] \u001b[32mTrain: [ 29/50] Step 020/520 Loss 1.952 Prec@(1,5) (60.8%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:23:14] \u001b[32mTrain: [ 29/50] Step 040/520 Loss 1.958 Prec@(1,5) (61.1%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:23:14] \u001b[32mTrain: [ 29/50] Step 060/520 Loss 1.958 Prec@(1,5) (60.7%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:23:15] \u001b[32mTrain: [ 29/50] Step 080/520 Loss 1.970 Prec@(1,5) (60.4%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:23:15] \u001b[32mTrain: [ 29/50] Step 100/520 Loss 1.977 Prec@(1,5) (60.1%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:23:16] \u001b[32mTrain: [ 29/50] Step 120/520 Loss 1.983 Prec@(1,5) (59.8%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:23:16] \u001b[32mTrain: [ 29/50] Step 140/520 Loss 1.982 Prec@(1,5) (60.2%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:23:17] \u001b[32mTrain: [ 29/50] Step 160/520 Loss 1.981 Prec@(1,5) (60.3%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:23:17] \u001b[32mTrain: [ 29/50] Step 180/520 Loss 1.978 Prec@(1,5) (60.4%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:23:18] \u001b[32mTrain: [ 29/50] Step 200/520 Loss 1.979 Prec@(1,5) (60.3%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:23:18] \u001b[32mTrain: [ 29/50] Step 220/520 Loss 1.982 Prec@(1,5) (60.2%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:23:19] \u001b[32mTrain: [ 29/50] Step 240/520 Loss 1.983 Prec@(1,5) (60.2%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:23:19] \u001b[32mTrain: [ 29/50] Step 260/520 Loss 1.987 Prec@(1,5) (60.1%, 86.8%)\u001b[0m\n",
            "[2024-04-02 20:23:20] \u001b[32mTrain: [ 29/50] Step 280/520 Loss 1.990 Prec@(1,5) (60.1%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:23:20] \u001b[32mTrain: [ 29/50] Step 300/520 Loss 1.996 Prec@(1,5) (59.9%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:23:21] \u001b[32mTrain: [ 29/50] Step 320/520 Loss 2.004 Prec@(1,5) (59.8%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:23:21] \u001b[32mTrain: [ 29/50] Step 340/520 Loss 2.007 Prec@(1,5) (59.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:23:22] \u001b[32mTrain: [ 29/50] Step 360/520 Loss 2.008 Prec@(1,5) (59.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:23:22] \u001b[32mTrain: [ 29/50] Step 380/520 Loss 2.011 Prec@(1,5) (59.6%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:23:23] \u001b[32mTrain: [ 29/50] Step 400/520 Loss 2.015 Prec@(1,5) (59.6%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:23:23] \u001b[32mTrain: [ 29/50] Step 420/520 Loss 2.017 Prec@(1,5) (59.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:23:24] \u001b[32mTrain: [ 29/50] Step 440/520 Loss 2.019 Prec@(1,5) (59.6%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:23:24] \u001b[32mTrain: [ 29/50] Step 460/520 Loss 2.024 Prec@(1,5) (59.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:23:25] \u001b[32mTrain: [ 29/50] Step 480/520 Loss 2.024 Prec@(1,5) (59.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:23:25] \u001b[32mTrain: [ 29/50] Step 500/520 Loss 2.025 Prec@(1,5) (59.4%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:23:26] \u001b[32mTrain: [ 29/50] Step 520/520 Loss 2.028 Prec@(1,5) (59.4%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:23:26] \u001b[32mTrain: [ 29/50] Final Prec@1 59.3640%\u001b[0m\n",
            "[2024-04-02 20:23:30] \u001b[32mValid: [ 29/50] Step 000/104 Loss 2.064 Prec@(1,5) (59.4%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:23:30] \u001b[32mValid: [ 29/50] Step 020/104 Loss 2.216 Prec@(1,5) (55.0%, 83.8%)\u001b[0m\n",
            "[2024-04-02 20:23:30] \u001b[32mValid: [ 29/50] Step 040/104 Loss 2.195 Prec@(1,5) (54.6%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:23:30] \u001b[32mValid: [ 29/50] Step 060/104 Loss 2.167 Prec@(1,5) (55.3%, 83.8%)\u001b[0m\n",
            "[2024-04-02 20:23:30] \u001b[32mValid: [ 29/50] Step 080/104 Loss 2.185 Prec@(1,5) (54.9%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:23:30] \u001b[32mValid: [ 29/50] Step 100/104 Loss 2.165 Prec@(1,5) (54.9%, 83.8%)\u001b[0m\n",
            "[2024-04-02 20:23:30] \u001b[32mValid: [ 29/50] Step 104/104 Loss 2.166 Prec@(1,5) (54.9%, 83.8%)\u001b[0m\n",
            "[2024-04-02 20:23:31] \u001b[32mValid: [ 29/50] Final Prec@1 54.8800%\u001b[0m\n",
            "[2024-04-02 20:23:31] \u001b[32mEpoch 29 LR 0.009392\u001b[0m\n",
            "[2024-04-02 20:23:35] \u001b[32mTrain: [ 30/50] Step 000/520 Loss 1.803 Prec@(1,5) (64.6%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:23:36] \u001b[32mTrain: [ 30/50] Step 020/520 Loss 2.000 Prec@(1,5) (60.2%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:23:36] \u001b[32mTrain: [ 30/50] Step 040/520 Loss 1.982 Prec@(1,5) (60.5%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:23:37] \u001b[32mTrain: [ 30/50] Step 060/520 Loss 1.964 Prec@(1,5) (60.6%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:23:37] \u001b[32mTrain: [ 30/50] Step 080/520 Loss 1.961 Prec@(1,5) (60.8%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:23:38] \u001b[32mTrain: [ 30/50] Step 100/520 Loss 1.959 Prec@(1,5) (60.8%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:23:38] \u001b[32mTrain: [ 30/50] Step 120/520 Loss 1.972 Prec@(1,5) (60.6%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:23:39] \u001b[32mTrain: [ 30/50] Step 140/520 Loss 1.984 Prec@(1,5) (60.3%, 86.8%)\u001b[0m\n",
            "[2024-04-02 20:23:39] \u001b[32mTrain: [ 30/50] Step 160/520 Loss 1.989 Prec@(1,5) (60.3%, 86.8%)\u001b[0m\n",
            "[2024-04-02 20:23:40] \u001b[32mTrain: [ 30/50] Step 180/520 Loss 1.988 Prec@(1,5) (60.4%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:23:40] \u001b[32mTrain: [ 30/50] Step 200/520 Loss 1.991 Prec@(1,5) (60.3%, 86.8%)\u001b[0m\n",
            "[2024-04-02 20:23:41] \u001b[32mTrain: [ 30/50] Step 220/520 Loss 1.992 Prec@(1,5) (60.3%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:23:41] \u001b[32mTrain: [ 30/50] Step 240/520 Loss 1.991 Prec@(1,5) (60.3%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:23:42] \u001b[32mTrain: [ 30/50] Step 260/520 Loss 1.992 Prec@(1,5) (60.3%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:23:42] \u001b[32mTrain: [ 30/50] Step 280/520 Loss 1.988 Prec@(1,5) (60.3%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:23:43] \u001b[32mTrain: [ 30/50] Step 300/520 Loss 1.986 Prec@(1,5) (60.3%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:23:43] \u001b[32mTrain: [ 30/50] Step 320/520 Loss 1.986 Prec@(1,5) (60.2%, 86.8%)\u001b[0m\n",
            "[2024-04-02 20:23:44] \u001b[32mTrain: [ 30/50] Step 340/520 Loss 1.989 Prec@(1,5) (60.1%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:23:44] \u001b[32mTrain: [ 30/50] Step 360/520 Loss 1.988 Prec@(1,5) (60.1%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:23:45] \u001b[32mTrain: [ 30/50] Step 380/520 Loss 1.989 Prec@(1,5) (60.1%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:23:45] \u001b[32mTrain: [ 30/50] Step 400/520 Loss 1.990 Prec@(1,5) (60.1%, 86.8%)\u001b[0m\n",
            "[2024-04-02 20:23:46] \u001b[32mTrain: [ 30/50] Step 420/520 Loss 1.992 Prec@(1,5) (60.1%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:23:46] \u001b[32mTrain: [ 30/50] Step 440/520 Loss 1.996 Prec@(1,5) (60.0%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:23:47] \u001b[32mTrain: [ 30/50] Step 460/520 Loss 1.998 Prec@(1,5) (59.9%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:23:47] \u001b[32mTrain: [ 30/50] Step 480/520 Loss 2.001 Prec@(1,5) (59.9%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:23:48] \u001b[32mTrain: [ 30/50] Step 500/520 Loss 2.001 Prec@(1,5) (59.9%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:23:48] \u001b[32mTrain: [ 30/50] Step 520/520 Loss 1.999 Prec@(1,5) (59.9%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:23:48] \u001b[32mTrain: [ 30/50] Final Prec@1 59.9400%\u001b[0m\n",
            "[2024-04-02 20:23:52] \u001b[32mValid: [ 30/50] Step 000/104 Loss 1.998 Prec@(1,5) (67.7%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:23:52] \u001b[32mValid: [ 30/50] Step 020/104 Loss 2.128 Prec@(1,5) (57.1%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:23:52] \u001b[32mValid: [ 30/50] Step 040/104 Loss 2.127 Prec@(1,5) (55.8%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:23:52] \u001b[32mValid: [ 30/50] Step 060/104 Loss 2.096 Prec@(1,5) (56.0%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:23:52] \u001b[32mValid: [ 30/50] Step 080/104 Loss 2.097 Prec@(1,5) (55.5%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:23:53] \u001b[32mValid: [ 30/50] Step 100/104 Loss 2.087 Prec@(1,5) (55.5%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:23:53] \u001b[32mValid: [ 30/50] Step 104/104 Loss 2.084 Prec@(1,5) (55.6%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:23:53] \u001b[32mValid: [ 30/50] Final Prec@1 55.5600%\u001b[0m\n",
            "[2024-04-02 20:23:53] \u001b[32mEpoch 30 LR 0.008638\u001b[0m\n",
            "[2024-04-02 20:23:58] \u001b[32mTrain: [ 31/50] Step 000/520 Loss 1.870 Prec@(1,5) (65.6%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:23:58] \u001b[32mTrain: [ 31/50] Step 020/520 Loss 1.931 Prec@(1,5) (61.6%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:23:58] \u001b[32mTrain: [ 31/50] Step 040/520 Loss 1.937 Prec@(1,5) (61.4%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:23:59] \u001b[32mTrain: [ 31/50] Step 060/520 Loss 1.917 Prec@(1,5) (61.9%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:23:59] \u001b[32mTrain: [ 31/50] Step 080/520 Loss 1.904 Prec@(1,5) (61.8%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:24:00] \u001b[32mTrain: [ 31/50] Step 100/520 Loss 1.916 Prec@(1,5) (61.4%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:24:00] \u001b[32mTrain: [ 31/50] Step 120/520 Loss 1.916 Prec@(1,5) (61.3%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:24:01] \u001b[32mTrain: [ 31/50] Step 140/520 Loss 1.929 Prec@(1,5) (61.0%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:24:01] \u001b[32mTrain: [ 31/50] Step 160/520 Loss 1.937 Prec@(1,5) (60.8%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:24:02] \u001b[32mTrain: [ 31/50] Step 180/520 Loss 1.938 Prec@(1,5) (61.0%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:24:02] \u001b[32mTrain: [ 31/50] Step 200/520 Loss 1.939 Prec@(1,5) (61.1%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:24:03] \u001b[32mTrain: [ 31/50] Step 220/520 Loss 1.945 Prec@(1,5) (61.0%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:24:03] \u001b[32mTrain: [ 31/50] Step 240/520 Loss 1.947 Prec@(1,5) (61.1%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:24:04] \u001b[32mTrain: [ 31/50] Step 260/520 Loss 1.945 Prec@(1,5) (61.3%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:24:04] \u001b[32mTrain: [ 31/50] Step 280/520 Loss 1.947 Prec@(1,5) (61.2%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:24:05] \u001b[32mTrain: [ 31/50] Step 300/520 Loss 1.951 Prec@(1,5) (61.0%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:24:05] \u001b[32mTrain: [ 31/50] Step 320/520 Loss 1.954 Prec@(1,5) (60.9%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:24:06] \u001b[32mTrain: [ 31/50] Step 340/520 Loss 1.956 Prec@(1,5) (60.9%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:24:06] \u001b[32mTrain: [ 31/50] Step 360/520 Loss 1.957 Prec@(1,5) (60.9%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:24:07] \u001b[32mTrain: [ 31/50] Step 380/520 Loss 1.958 Prec@(1,5) (60.9%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:24:07] \u001b[32mTrain: [ 31/50] Step 400/520 Loss 1.961 Prec@(1,5) (60.9%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:24:08] \u001b[32mTrain: [ 31/50] Step 420/520 Loss 1.963 Prec@(1,5) (60.8%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:24:08] \u001b[32mTrain: [ 31/50] Step 440/520 Loss 1.967 Prec@(1,5) (60.7%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:24:09] \u001b[32mTrain: [ 31/50] Step 460/520 Loss 1.968 Prec@(1,5) (60.7%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:24:09] \u001b[32mTrain: [ 31/50] Step 480/520 Loss 1.969 Prec@(1,5) (60.6%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:24:10] \u001b[32mTrain: [ 31/50] Step 500/520 Loss 1.970 Prec@(1,5) (60.6%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:24:10] \u001b[32mTrain: [ 31/50] Step 520/520 Loss 1.972 Prec@(1,5) (60.6%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:24:10] \u001b[32mTrain: [ 31/50] Final Prec@1 60.5560%\u001b[0m\n",
            "[2024-04-02 20:24:14] \u001b[32mValid: [ 31/50] Step 000/104 Loss 2.114 Prec@(1,5) (57.3%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:24:14] \u001b[32mValid: [ 31/50] Step 020/104 Loss 2.179 Prec@(1,5) (55.7%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:24:14] \u001b[32mValid: [ 31/50] Step 040/104 Loss 2.179 Prec@(1,5) (55.2%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:24:14] \u001b[32mValid: [ 31/50] Step 060/104 Loss 2.157 Prec@(1,5) (55.4%, 83.4%)\u001b[0m\n",
            "[2024-04-02 20:24:15] \u001b[32mValid: [ 31/50] Step 080/104 Loss 2.173 Prec@(1,5) (54.8%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:24:15] \u001b[32mValid: [ 31/50] Step 100/104 Loss 2.150 Prec@(1,5) (54.9%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:24:15] \u001b[32mValid: [ 31/50] Step 104/104 Loss 2.154 Prec@(1,5) (54.9%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:24:15] \u001b[32mValid: [ 31/50] Final Prec@1 54.9300%\u001b[0m\n",
            "[2024-04-02 20:24:15] \u001b[32mEpoch 31 LR 0.007899\u001b[0m\n",
            "[2024-04-02 20:24:20] \u001b[32mTrain: [ 32/50] Step 000/520 Loss 2.167 Prec@(1,5) (56.2%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:24:20] \u001b[32mTrain: [ 32/50] Step 020/520 Loss 1.919 Prec@(1,5) (61.8%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:24:21] \u001b[32mTrain: [ 32/50] Step 040/520 Loss 1.924 Prec@(1,5) (61.4%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:24:21] \u001b[32mTrain: [ 32/50] Step 060/520 Loss 1.939 Prec@(1,5) (61.2%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:24:22] \u001b[32mTrain: [ 32/50] Step 080/520 Loss 1.926 Prec@(1,5) (61.7%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:24:22] \u001b[32mTrain: [ 32/50] Step 100/520 Loss 1.930 Prec@(1,5) (61.8%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:24:23] \u001b[32mTrain: [ 32/50] Step 120/520 Loss 1.937 Prec@(1,5) (61.5%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:24:23] \u001b[32mTrain: [ 32/50] Step 140/520 Loss 1.936 Prec@(1,5) (61.6%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:24:24] \u001b[32mTrain: [ 32/50] Step 160/520 Loss 1.937 Prec@(1,5) (61.6%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:24:24] \u001b[32mTrain: [ 32/50] Step 180/520 Loss 1.941 Prec@(1,5) (61.4%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:24:25] \u001b[32mTrain: [ 32/50] Step 200/520 Loss 1.944 Prec@(1,5) (61.3%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:24:25] \u001b[32mTrain: [ 32/50] Step 220/520 Loss 1.947 Prec@(1,5) (61.2%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:24:26] \u001b[32mTrain: [ 32/50] Step 240/520 Loss 1.940 Prec@(1,5) (61.3%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:24:26] \u001b[32mTrain: [ 32/50] Step 260/520 Loss 1.937 Prec@(1,5) (61.4%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:24:26] \u001b[32mTrain: [ 32/50] Step 280/520 Loss 1.945 Prec@(1,5) (61.2%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:24:27] \u001b[32mTrain: [ 32/50] Step 300/520 Loss 1.944 Prec@(1,5) (61.2%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:24:27] \u001b[32mTrain: [ 32/50] Step 320/520 Loss 1.944 Prec@(1,5) (61.1%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:24:28] \u001b[32mTrain: [ 32/50] Step 340/520 Loss 1.944 Prec@(1,5) (61.1%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:24:28] \u001b[32mTrain: [ 32/50] Step 360/520 Loss 1.947 Prec@(1,5) (61.1%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:24:29] \u001b[32mTrain: [ 32/50] Step 380/520 Loss 1.946 Prec@(1,5) (61.0%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:24:29] \u001b[32mTrain: [ 32/50] Step 400/520 Loss 1.946 Prec@(1,5) (61.1%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:24:30] \u001b[32mTrain: [ 32/50] Step 420/520 Loss 1.946 Prec@(1,5) (61.1%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:24:30] \u001b[32mTrain: [ 32/50] Step 440/520 Loss 1.947 Prec@(1,5) (61.1%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:24:31] \u001b[32mTrain: [ 32/50] Step 460/520 Loss 1.949 Prec@(1,5) (61.0%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:24:31] \u001b[32mTrain: [ 32/50] Step 480/520 Loss 1.947 Prec@(1,5) (61.0%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:24:32] \u001b[32mTrain: [ 32/50] Step 500/520 Loss 1.946 Prec@(1,5) (60.9%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:24:32] \u001b[32mTrain: [ 32/50] Step 520/520 Loss 1.946 Prec@(1,5) (60.9%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:24:33] \u001b[32mTrain: [ 32/50] Final Prec@1 60.9460%\u001b[0m\n",
            "[2024-04-02 20:24:36] \u001b[32mValid: [ 32/50] Step 000/104 Loss 1.877 Prec@(1,5) (63.5%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:24:36] \u001b[32mValid: [ 32/50] Step 020/104 Loss 2.100 Prec@(1,5) (57.3%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:24:36] \u001b[32mValid: [ 32/50] Step 040/104 Loss 2.099 Prec@(1,5) (56.0%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:24:37] \u001b[32mValid: [ 32/50] Step 060/104 Loss 2.065 Prec@(1,5) (56.2%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:24:37] \u001b[32mValid: [ 32/50] Step 080/104 Loss 2.073 Prec@(1,5) (56.2%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:24:37] \u001b[32mValid: [ 32/50] Step 100/104 Loss 2.063 Prec@(1,5) (56.2%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:24:37] \u001b[32mValid: [ 32/50] Step 104/104 Loss 2.065 Prec@(1,5) (56.3%, 84.0%)\u001b[0m\n",
            "[2024-04-02 20:24:37] \u001b[32mValid: [ 32/50] Final Prec@1 56.2500%\u001b[0m\n",
            "[2024-04-02 20:24:37] \u001b[32mEpoch 32 LR 0.007178\u001b[0m\n",
            "[2024-04-02 20:24:42] \u001b[32mTrain: [ 33/50] Step 000/520 Loss 2.074 Prec@(1,5) (62.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:24:42] \u001b[32mTrain: [ 33/50] Step 020/520 Loss 1.888 Prec@(1,5) (62.9%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:24:43] \u001b[32mTrain: [ 33/50] Step 040/520 Loss 1.865 Prec@(1,5) (62.7%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:24:43] \u001b[32mTrain: [ 33/50] Step 060/520 Loss 1.872 Prec@(1,5) (62.3%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:24:44] \u001b[32mTrain: [ 33/50] Step 080/520 Loss 1.860 Prec@(1,5) (62.7%, 88.1%)\u001b[0m\n",
            "[2024-04-02 20:24:44] \u001b[32mTrain: [ 33/50] Step 100/520 Loss 1.886 Prec@(1,5) (62.2%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:24:45] \u001b[32mTrain: [ 33/50] Step 120/520 Loss 1.881 Prec@(1,5) (62.2%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:24:45] \u001b[32mTrain: [ 33/50] Step 140/520 Loss 1.877 Prec@(1,5) (62.2%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:24:46] \u001b[32mTrain: [ 33/50] Step 160/520 Loss 1.885 Prec@(1,5) (62.0%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:24:46] \u001b[32mTrain: [ 33/50] Step 180/520 Loss 1.890 Prec@(1,5) (61.9%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:24:47] \u001b[32mTrain: [ 33/50] Step 200/520 Loss 1.886 Prec@(1,5) (62.0%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:24:47] \u001b[32mTrain: [ 33/50] Step 220/520 Loss 1.891 Prec@(1,5) (61.9%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:24:48] \u001b[32mTrain: [ 33/50] Step 240/520 Loss 1.891 Prec@(1,5) (61.9%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:24:48] \u001b[32mTrain: [ 33/50] Step 260/520 Loss 1.890 Prec@(1,5) (61.9%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:24:49] \u001b[32mTrain: [ 33/50] Step 280/520 Loss 1.896 Prec@(1,5) (61.7%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:24:49] \u001b[32mTrain: [ 33/50] Step 300/520 Loss 1.904 Prec@(1,5) (61.6%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:24:50] \u001b[32mTrain: [ 33/50] Step 320/520 Loss 1.911 Prec@(1,5) (61.5%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:24:50] \u001b[32mTrain: [ 33/50] Step 340/520 Loss 1.910 Prec@(1,5) (61.5%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:24:51] \u001b[32mTrain: [ 33/50] Step 360/520 Loss 1.907 Prec@(1,5) (61.6%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:24:51] \u001b[32mTrain: [ 33/50] Step 380/520 Loss 1.907 Prec@(1,5) (61.6%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:24:52] \u001b[32mTrain: [ 33/50] Step 400/520 Loss 1.907 Prec@(1,5) (61.6%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:24:52] \u001b[32mTrain: [ 33/50] Step 420/520 Loss 1.909 Prec@(1,5) (61.5%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:24:53] \u001b[32mTrain: [ 33/50] Step 440/520 Loss 1.910 Prec@(1,5) (61.5%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:24:53] \u001b[32mTrain: [ 33/50] Step 460/520 Loss 1.911 Prec@(1,5) (61.5%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:24:54] \u001b[32mTrain: [ 33/50] Step 480/520 Loss 1.913 Prec@(1,5) (61.5%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:24:54] \u001b[32mTrain: [ 33/50] Step 500/520 Loss 1.914 Prec@(1,5) (61.5%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:24:55] \u001b[32mTrain: [ 33/50] Step 520/520 Loss 1.915 Prec@(1,5) (61.4%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:24:55] \u001b[32mTrain: [ 33/50] Final Prec@1 61.4260%\u001b[0m\n",
            "[2024-04-02 20:24:59] \u001b[32mValid: [ 33/50] Step 000/104 Loss 1.850 Prec@(1,5) (63.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:24:59] \u001b[32mValid: [ 33/50] Step 020/104 Loss 1.985 Prec@(1,5) (58.8%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:24:59] \u001b[32mValid: [ 33/50] Step 040/104 Loss 1.987 Prec@(1,5) (58.2%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:24:59] \u001b[32mValid: [ 33/50] Step 060/104 Loss 1.962 Prec@(1,5) (58.2%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:24:59] \u001b[32mValid: [ 33/50] Step 080/104 Loss 1.965 Prec@(1,5) (57.9%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:24:59] \u001b[32mValid: [ 33/50] Step 100/104 Loss 1.947 Prec@(1,5) (58.1%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:24:59] \u001b[32mValid: [ 33/50] Step 104/104 Loss 1.946 Prec@(1,5) (58.2%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:25:00] \u001b[32mValid: [ 33/50] Final Prec@1 58.1500%\u001b[0m\n",
            "[2024-04-02 20:25:00] \u001b[32mEpoch 33 LR 0.006479\u001b[0m\n",
            "[2024-04-02 20:25:04] \u001b[32mTrain: [ 34/50] Step 000/520 Loss 1.654 Prec@(1,5) (69.8%, 91.7%)\u001b[0m\n",
            "[2024-04-02 20:25:05] \u001b[32mTrain: [ 34/50] Step 020/520 Loss 1.882 Prec@(1,5) (62.3%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:25:05] \u001b[32mTrain: [ 34/50] Step 040/520 Loss 1.907 Prec@(1,5) (62.4%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:25:06] \u001b[32mTrain: [ 34/50] Step 060/520 Loss 1.893 Prec@(1,5) (62.8%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:25:06] \u001b[32mTrain: [ 34/50] Step 080/520 Loss 1.887 Prec@(1,5) (62.6%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:25:07] \u001b[32mTrain: [ 34/50] Step 100/520 Loss 1.890 Prec@(1,5) (62.3%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:25:07] \u001b[32mTrain: [ 34/50] Step 120/520 Loss 1.897 Prec@(1,5) (62.2%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:25:08] \u001b[32mTrain: [ 34/50] Step 140/520 Loss 1.891 Prec@(1,5) (62.3%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:25:08] \u001b[32mTrain: [ 34/50] Step 160/520 Loss 1.887 Prec@(1,5) (62.5%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:25:09] \u001b[32mTrain: [ 34/50] Step 180/520 Loss 1.889 Prec@(1,5) (62.5%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:25:09] \u001b[32mTrain: [ 34/50] Step 200/520 Loss 1.885 Prec@(1,5) (62.5%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:25:10] \u001b[32mTrain: [ 34/50] Step 220/520 Loss 1.882 Prec@(1,5) (62.5%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:25:10] \u001b[32mTrain: [ 34/50] Step 240/520 Loss 1.881 Prec@(1,5) (62.5%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:25:11] \u001b[32mTrain: [ 34/50] Step 260/520 Loss 1.884 Prec@(1,5) (62.3%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:25:11] \u001b[32mTrain: [ 34/50] Step 280/520 Loss 1.879 Prec@(1,5) (62.4%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:25:12] \u001b[32mTrain: [ 34/50] Step 300/520 Loss 1.882 Prec@(1,5) (62.4%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:25:12] \u001b[32mTrain: [ 34/50] Step 320/520 Loss 1.885 Prec@(1,5) (62.3%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:25:13] \u001b[32mTrain: [ 34/50] Step 340/520 Loss 1.884 Prec@(1,5) (62.3%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:25:13] \u001b[32mTrain: [ 34/50] Step 360/520 Loss 1.888 Prec@(1,5) (62.2%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:25:14] \u001b[32mTrain: [ 34/50] Step 380/520 Loss 1.889 Prec@(1,5) (62.2%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:25:14] \u001b[32mTrain: [ 34/50] Step 400/520 Loss 1.891 Prec@(1,5) (62.1%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:25:15] \u001b[32mTrain: [ 34/50] Step 420/520 Loss 1.892 Prec@(1,5) (62.0%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:25:15] \u001b[32mTrain: [ 34/50] Step 440/520 Loss 1.893 Prec@(1,5) (62.0%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:25:16] \u001b[32mTrain: [ 34/50] Step 460/520 Loss 1.897 Prec@(1,5) (62.0%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:25:16] \u001b[32mTrain: [ 34/50] Step 480/520 Loss 1.895 Prec@(1,5) (62.0%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:25:17] \u001b[32mTrain: [ 34/50] Step 500/520 Loss 1.899 Prec@(1,5) (61.8%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:25:17] \u001b[32mTrain: [ 34/50] Step 520/520 Loss 1.898 Prec@(1,5) (61.8%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:25:17] \u001b[32mTrain: [ 34/50] Final Prec@1 61.8160%\u001b[0m\n",
            "[2024-04-02 20:25:21] \u001b[32mValid: [ 34/50] Step 000/104 Loss 1.835 Prec@(1,5) (60.4%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:25:21] \u001b[32mValid: [ 34/50] Step 020/104 Loss 1.947 Prec@(1,5) (58.0%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:25:21] \u001b[32mValid: [ 34/50] Step 040/104 Loss 1.942 Prec@(1,5) (58.1%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:25:21] \u001b[32mValid: [ 34/50] Step 060/104 Loss 1.924 Prec@(1,5) (58.4%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:25:21] \u001b[32mValid: [ 34/50] Step 080/104 Loss 1.915 Prec@(1,5) (58.4%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:25:22] \u001b[32mValid: [ 34/50] Step 100/104 Loss 1.899 Prec@(1,5) (58.5%, 86.1%)\u001b[0m\n",
            "[2024-04-02 20:25:22] \u001b[32mValid: [ 34/50] Step 104/104 Loss 1.896 Prec@(1,5) (58.5%, 86.1%)\u001b[0m\n",
            "[2024-04-02 20:25:22] \u001b[32mValid: [ 34/50] Final Prec@1 58.5300%\u001b[0m\n",
            "[2024-04-02 20:25:22] \u001b[32mEpoch 34 LR 0.005803\u001b[0m\n",
            "[2024-04-02 20:25:26] \u001b[32mTrain: [ 35/50] Step 000/520 Loss 2.350 Prec@(1,5) (52.1%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:25:27] \u001b[32mTrain: [ 35/50] Step 020/520 Loss 1.965 Prec@(1,5) (60.7%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:25:27] \u001b[32mTrain: [ 35/50] Step 040/520 Loss 1.904 Prec@(1,5) (61.7%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:25:28] \u001b[32mTrain: [ 35/50] Step 060/520 Loss 1.908 Prec@(1,5) (61.2%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:25:28] \u001b[32mTrain: [ 35/50] Step 080/520 Loss 1.934 Prec@(1,5) (60.9%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:25:29] \u001b[32mTrain: [ 35/50] Step 100/520 Loss 1.918 Prec@(1,5) (61.3%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:25:29] \u001b[32mTrain: [ 35/50] Step 120/520 Loss 1.914 Prec@(1,5) (61.3%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:25:30] \u001b[32mTrain: [ 35/50] Step 140/520 Loss 1.907 Prec@(1,5) (61.5%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:25:30] \u001b[32mTrain: [ 35/50] Step 160/520 Loss 1.898 Prec@(1,5) (61.6%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:25:31] \u001b[32mTrain: [ 35/50] Step 180/520 Loss 1.898 Prec@(1,5) (61.5%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:25:31] \u001b[32mTrain: [ 35/50] Step 200/520 Loss 1.890 Prec@(1,5) (61.8%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:25:32] \u001b[32mTrain: [ 35/50] Step 220/520 Loss 1.895 Prec@(1,5) (61.7%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:25:32] \u001b[32mTrain: [ 35/50] Step 240/520 Loss 1.891 Prec@(1,5) (61.9%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:25:33] \u001b[32mTrain: [ 35/50] Step 260/520 Loss 1.889 Prec@(1,5) (61.9%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:25:33] \u001b[32mTrain: [ 35/50] Step 280/520 Loss 1.885 Prec@(1,5) (62.0%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:25:34] \u001b[32mTrain: [ 35/50] Step 300/520 Loss 1.884 Prec@(1,5) (62.1%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:25:34] \u001b[32mTrain: [ 35/50] Step 320/520 Loss 1.885 Prec@(1,5) (62.0%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:25:35] \u001b[32mTrain: [ 35/50] Step 340/520 Loss 1.889 Prec@(1,5) (62.0%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:25:35] \u001b[32mTrain: [ 35/50] Step 360/520 Loss 1.888 Prec@(1,5) (61.9%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:25:36] \u001b[32mTrain: [ 35/50] Step 380/520 Loss 1.886 Prec@(1,5) (62.0%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:25:36] \u001b[32mTrain: [ 35/50] Step 400/520 Loss 1.882 Prec@(1,5) (62.0%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:25:37] \u001b[32mTrain: [ 35/50] Step 420/520 Loss 1.882 Prec@(1,5) (62.0%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:25:37] \u001b[32mTrain: [ 35/50] Step 440/520 Loss 1.882 Prec@(1,5) (62.0%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:25:38] \u001b[32mTrain: [ 35/50] Step 460/520 Loss 1.880 Prec@(1,5) (62.0%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:25:38] \u001b[32mTrain: [ 35/50] Step 480/520 Loss 1.882 Prec@(1,5) (61.9%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:25:39] \u001b[32mTrain: [ 35/50] Step 500/520 Loss 1.881 Prec@(1,5) (61.9%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:25:39] \u001b[32mTrain: [ 35/50] Step 520/520 Loss 1.880 Prec@(1,5) (62.0%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:25:39] \u001b[32mTrain: [ 35/50] Final Prec@1 61.9500%\u001b[0m\n",
            "[2024-04-02 20:25:43] \u001b[32mValid: [ 35/50] Step 000/104 Loss 1.869 Prec@(1,5) (61.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:25:43] \u001b[32mValid: [ 35/50] Step 020/104 Loss 1.987 Prec@(1,5) (58.0%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:25:43] \u001b[32mValid: [ 35/50] Step 040/104 Loss 1.979 Prec@(1,5) (57.2%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:25:43] \u001b[32mValid: [ 35/50] Step 060/104 Loss 1.942 Prec@(1,5) (57.8%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:25:44] \u001b[32mValid: [ 35/50] Step 080/104 Loss 1.939 Prec@(1,5) (57.8%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:25:44] \u001b[32mValid: [ 35/50] Step 100/104 Loss 1.920 Prec@(1,5) (58.2%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:25:44] \u001b[32mValid: [ 35/50] Step 104/104 Loss 1.921 Prec@(1,5) (58.2%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:25:44] \u001b[32mValid: [ 35/50] Final Prec@1 58.2300%\u001b[0m\n",
            "[2024-04-02 20:25:44] \u001b[32mEpoch 35 LR 0.005153\u001b[0m\n",
            "[2024-04-02 20:25:49] \u001b[32mTrain: [ 36/50] Step 000/520 Loss 1.786 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:25:49] \u001b[32mTrain: [ 36/50] Step 020/520 Loss 1.821 Prec@(1,5) (63.5%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:25:50] \u001b[32mTrain: [ 36/50] Step 040/520 Loss 1.823 Prec@(1,5) (63.0%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:25:50] \u001b[32mTrain: [ 36/50] Step 060/520 Loss 1.818 Prec@(1,5) (63.3%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:25:51] \u001b[32mTrain: [ 36/50] Step 080/520 Loss 1.833 Prec@(1,5) (63.1%, 88.7%)\u001b[0m\n",
            "[2024-04-02 20:25:51] \u001b[32mTrain: [ 36/50] Step 100/520 Loss 1.827 Prec@(1,5) (63.1%, 88.7%)\u001b[0m\n",
            "[2024-04-02 20:25:52] \u001b[32mTrain: [ 36/50] Step 120/520 Loss 1.817 Prec@(1,5) (63.2%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:25:52] \u001b[32mTrain: [ 36/50] Step 140/520 Loss 1.819 Prec@(1,5) (63.2%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:25:53] \u001b[32mTrain: [ 36/50] Step 160/520 Loss 1.820 Prec@(1,5) (63.2%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:25:53] \u001b[32mTrain: [ 36/50] Step 180/520 Loss 1.827 Prec@(1,5) (63.1%, 88.7%)\u001b[0m\n",
            "[2024-04-02 20:25:54] \u001b[32mTrain: [ 36/50] Step 200/520 Loss 1.827 Prec@(1,5) (63.2%, 88.7%)\u001b[0m\n",
            "[2024-04-02 20:25:54] \u001b[32mTrain: [ 36/50] Step 220/520 Loss 1.823 Prec@(1,5) (63.3%, 88.7%)\u001b[0m\n",
            "[2024-04-02 20:25:55] \u001b[32mTrain: [ 36/50] Step 240/520 Loss 1.827 Prec@(1,5) (63.3%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:25:55] \u001b[32mTrain: [ 36/50] Step 260/520 Loss 1.831 Prec@(1,5) (63.3%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:25:55] \u001b[32mTrain: [ 36/50] Step 280/520 Loss 1.835 Prec@(1,5) (63.3%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:25:56] \u001b[32mTrain: [ 36/50] Step 300/520 Loss 1.834 Prec@(1,5) (63.2%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:25:56] \u001b[32mTrain: [ 36/50] Step 320/520 Loss 1.834 Prec@(1,5) (63.2%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:25:57] \u001b[32mTrain: [ 36/50] Step 340/520 Loss 1.835 Prec@(1,5) (63.2%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:25:57] \u001b[32mTrain: [ 36/50] Step 360/520 Loss 1.835 Prec@(1,5) (63.2%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:25:58] \u001b[32mTrain: [ 36/50] Step 380/520 Loss 1.836 Prec@(1,5) (63.2%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:25:58] \u001b[32mTrain: [ 36/50] Step 400/520 Loss 1.832 Prec@(1,5) (63.3%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:25:59] \u001b[32mTrain: [ 36/50] Step 420/520 Loss 1.836 Prec@(1,5) (63.1%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:25:59] \u001b[32mTrain: [ 36/50] Step 440/520 Loss 1.839 Prec@(1,5) (63.1%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:26:00] \u001b[32mTrain: [ 36/50] Step 460/520 Loss 1.840 Prec@(1,5) (63.1%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:26:00] \u001b[32mTrain: [ 36/50] Step 480/520 Loss 1.842 Prec@(1,5) (63.0%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:26:01] \u001b[32mTrain: [ 36/50] Step 500/520 Loss 1.841 Prec@(1,5) (63.0%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:26:01] \u001b[32mTrain: [ 36/50] Step 520/520 Loss 1.840 Prec@(1,5) (63.0%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:26:02] \u001b[32mTrain: [ 36/50] Final Prec@1 63.0120%\u001b[0m\n",
            "[2024-04-02 20:26:05] \u001b[32mValid: [ 36/50] Step 000/104 Loss 1.870 Prec@(1,5) (65.6%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:26:05] \u001b[32mValid: [ 36/50] Step 020/104 Loss 1.925 Prec@(1,5) (60.8%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:26:05] \u001b[32mValid: [ 36/50] Step 040/104 Loss 1.915 Prec@(1,5) (59.1%, 86.4%)\u001b[0m\n",
            "[2024-04-02 20:26:06] \u001b[32mValid: [ 36/50] Step 060/104 Loss 1.881 Prec@(1,5) (59.7%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:26:06] \u001b[32mValid: [ 36/50] Step 080/104 Loss 1.881 Prec@(1,5) (59.5%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:26:06] \u001b[32mValid: [ 36/50] Step 100/104 Loss 1.872 Prec@(1,5) (59.6%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:26:06] \u001b[32mValid: [ 36/50] Step 104/104 Loss 1.874 Prec@(1,5) (59.5%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:26:06] \u001b[32mValid: [ 36/50] Final Prec@1 59.5100%\u001b[0m\n",
            "[2024-04-02 20:26:06] \u001b[32mEpoch 36 LR 0.004533\u001b[0m\n",
            "[2024-04-02 20:26:11] \u001b[32mTrain: [ 37/50] Step 000/520 Loss 1.914 Prec@(1,5) (57.3%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:26:11] \u001b[32mTrain: [ 37/50] Step 020/520 Loss 1.823 Prec@(1,5) (63.4%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:26:12] \u001b[32mTrain: [ 37/50] Step 040/520 Loss 1.797 Prec@(1,5) (63.6%, 88.7%)\u001b[0m\n",
            "[2024-04-02 20:26:12] \u001b[32mTrain: [ 37/50] Step 060/520 Loss 1.801 Prec@(1,5) (63.4%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:26:13] \u001b[32mTrain: [ 37/50] Step 080/520 Loss 1.796 Prec@(1,5) (63.8%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:26:13] \u001b[32mTrain: [ 37/50] Step 100/520 Loss 1.800 Prec@(1,5) (63.8%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:26:14] \u001b[32mTrain: [ 37/50] Step 120/520 Loss 1.795 Prec@(1,5) (63.9%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:26:14] \u001b[32mTrain: [ 37/50] Step 140/520 Loss 1.805 Prec@(1,5) (63.5%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:26:15] \u001b[32mTrain: [ 37/50] Step 160/520 Loss 1.823 Prec@(1,5) (63.3%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:26:15] \u001b[32mTrain: [ 37/50] Step 180/520 Loss 1.816 Prec@(1,5) (63.4%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:26:16] \u001b[32mTrain: [ 37/50] Step 200/520 Loss 1.812 Prec@(1,5) (63.5%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:26:16] \u001b[32mTrain: [ 37/50] Step 220/520 Loss 1.808 Prec@(1,5) (63.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:26:17] \u001b[32mTrain: [ 37/50] Step 240/520 Loss 1.802 Prec@(1,5) (63.7%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:26:17] \u001b[32mTrain: [ 37/50] Step 260/520 Loss 1.806 Prec@(1,5) (63.6%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:26:18] \u001b[32mTrain: [ 37/50] Step 280/520 Loss 1.808 Prec@(1,5) (63.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:26:18] \u001b[32mTrain: [ 37/50] Step 300/520 Loss 1.808 Prec@(1,5) (63.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:26:19] \u001b[32mTrain: [ 37/50] Step 320/520 Loss 1.808 Prec@(1,5) (63.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:26:19] \u001b[32mTrain: [ 37/50] Step 340/520 Loss 1.811 Prec@(1,5) (63.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:26:20] \u001b[32mTrain: [ 37/50] Step 360/520 Loss 1.810 Prec@(1,5) (63.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:26:20] \u001b[32mTrain: [ 37/50] Step 380/520 Loss 1.809 Prec@(1,5) (63.5%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:26:21] \u001b[32mTrain: [ 37/50] Step 400/520 Loss 1.810 Prec@(1,5) (63.5%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:26:21] \u001b[32mTrain: [ 37/50] Step 420/520 Loss 1.810 Prec@(1,5) (63.5%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:26:22] \u001b[32mTrain: [ 37/50] Step 440/520 Loss 1.811 Prec@(1,5) (63.5%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:26:22] \u001b[32mTrain: [ 37/50] Step 460/520 Loss 1.812 Prec@(1,5) (63.4%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:26:23] \u001b[32mTrain: [ 37/50] Step 480/520 Loss 1.812 Prec@(1,5) (63.4%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:26:23] \u001b[32mTrain: [ 37/50] Step 500/520 Loss 1.815 Prec@(1,5) (63.4%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:26:24] \u001b[32mTrain: [ 37/50] Step 520/520 Loss 1.814 Prec@(1,5) (63.4%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:26:24] \u001b[32mTrain: [ 37/50] Final Prec@1 63.4080%\u001b[0m\n",
            "[2024-04-02 20:26:27] \u001b[32mValid: [ 37/50] Step 000/104 Loss 1.968 Prec@(1,5) (62.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:26:27] \u001b[32mValid: [ 37/50] Step 020/104 Loss 1.984 Prec@(1,5) (59.7%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:26:28] \u001b[32mValid: [ 37/50] Step 040/104 Loss 1.954 Prec@(1,5) (58.5%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:26:28] \u001b[32mValid: [ 37/50] Step 060/104 Loss 1.925 Prec@(1,5) (58.9%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:26:28] \u001b[32mValid: [ 37/50] Step 080/104 Loss 1.909 Prec@(1,5) (58.9%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:26:28] \u001b[32mValid: [ 37/50] Step 100/104 Loss 1.894 Prec@(1,5) (59.1%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:26:28] \u001b[32mValid: [ 37/50] Step 104/104 Loss 1.891 Prec@(1,5) (59.1%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:26:28] \u001b[32mValid: [ 37/50] Final Prec@1 59.0700%\u001b[0m\n",
            "[2024-04-02 20:26:28] \u001b[32mEpoch 37 LR 0.003944\u001b[0m\n",
            "[2024-04-02 20:26:33] \u001b[32mTrain: [ 38/50] Step 000/520 Loss 1.550 Prec@(1,5) (71.9%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:26:33] \u001b[32mTrain: [ 38/50] Step 020/520 Loss 1.704 Prec@(1,5) (66.6%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:26:34] \u001b[32mTrain: [ 38/50] Step 040/520 Loss 1.767 Prec@(1,5) (64.8%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:26:34] \u001b[32mTrain: [ 38/50] Step 060/520 Loss 1.761 Prec@(1,5) (64.6%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:26:35] \u001b[32mTrain: [ 38/50] Step 080/520 Loss 1.773 Prec@(1,5) (64.4%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:26:35] \u001b[32mTrain: [ 38/50] Step 100/520 Loss 1.787 Prec@(1,5) (64.2%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:26:36] \u001b[32mTrain: [ 38/50] Step 120/520 Loss 1.784 Prec@(1,5) (64.3%, 88.7%)\u001b[0m\n",
            "[2024-04-02 20:26:36] \u001b[32mTrain: [ 38/50] Step 140/520 Loss 1.784 Prec@(1,5) (64.1%, 88.7%)\u001b[0m\n",
            "[2024-04-02 20:26:37] \u001b[32mTrain: [ 38/50] Step 160/520 Loss 1.795 Prec@(1,5) (63.8%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:26:37] \u001b[32mTrain: [ 38/50] Step 180/520 Loss 1.801 Prec@(1,5) (63.7%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:26:38] \u001b[32mTrain: [ 38/50] Step 200/520 Loss 1.799 Prec@(1,5) (63.7%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:26:38] \u001b[32mTrain: [ 38/50] Step 220/520 Loss 1.799 Prec@(1,5) (63.7%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:26:39] \u001b[32mTrain: [ 38/50] Step 240/520 Loss 1.803 Prec@(1,5) (63.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:26:39] \u001b[32mTrain: [ 38/50] Step 260/520 Loss 1.802 Prec@(1,5) (63.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:26:40] \u001b[32mTrain: [ 38/50] Step 280/520 Loss 1.798 Prec@(1,5) (63.7%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:26:40] \u001b[32mTrain: [ 38/50] Step 300/520 Loss 1.806 Prec@(1,5) (63.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:26:41] \u001b[32mTrain: [ 38/50] Step 320/520 Loss 1.811 Prec@(1,5) (63.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:26:41] \u001b[32mTrain: [ 38/50] Step 340/520 Loss 1.813 Prec@(1,5) (63.4%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:26:42] \u001b[32mTrain: [ 38/50] Step 360/520 Loss 1.815 Prec@(1,5) (63.4%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:26:42] \u001b[32mTrain: [ 38/50] Step 380/520 Loss 1.819 Prec@(1,5) (63.3%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:26:43] \u001b[32mTrain: [ 38/50] Step 400/520 Loss 1.821 Prec@(1,5) (63.3%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:26:44] \u001b[32mTrain: [ 38/50] Step 420/520 Loss 1.819 Prec@(1,5) (63.2%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:26:44] \u001b[32mTrain: [ 38/50] Step 440/520 Loss 1.820 Prec@(1,5) (63.2%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:26:45] \u001b[32mTrain: [ 38/50] Step 460/520 Loss 1.819 Prec@(1,5) (63.2%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:26:45] \u001b[32mTrain: [ 38/50] Step 480/520 Loss 1.817 Prec@(1,5) (63.2%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:26:46] \u001b[32mTrain: [ 38/50] Step 500/520 Loss 1.817 Prec@(1,5) (63.2%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:26:46] \u001b[32mTrain: [ 38/50] Step 520/520 Loss 1.814 Prec@(1,5) (63.3%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:26:46] \u001b[32mTrain: [ 38/50] Final Prec@1 63.2860%\u001b[0m\n",
            "[2024-04-02 20:26:50] \u001b[32mValid: [ 38/50] Step 000/104 Loss 1.943 Prec@(1,5) (65.6%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:26:50] \u001b[32mValid: [ 38/50] Step 020/104 Loss 1.973 Prec@(1,5) (59.8%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:26:50] \u001b[32mValid: [ 38/50] Step 040/104 Loss 1.957 Prec@(1,5) (59.1%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:26:50] \u001b[32mValid: [ 38/50] Step 060/104 Loss 1.930 Prec@(1,5) (59.2%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:26:50] \u001b[32mValid: [ 38/50] Step 080/104 Loss 1.925 Prec@(1,5) (58.9%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:26:51] \u001b[32mValid: [ 38/50] Step 100/104 Loss 1.910 Prec@(1,5) (59.0%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:26:51] \u001b[32mValid: [ 38/50] Step 104/104 Loss 1.910 Prec@(1,5) (59.0%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:26:51] \u001b[32mValid: [ 38/50] Final Prec@1 58.9900%\u001b[0m\n",
            "[2024-04-02 20:26:51] \u001b[32mEpoch 38 LR 0.003389\u001b[0m\n",
            "[2024-04-02 20:26:55] \u001b[32mTrain: [ 39/50] Step 000/520 Loss 2.050 Prec@(1,5) (61.5%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:26:56] \u001b[32mTrain: [ 39/50] Step 020/520 Loss 1.778 Prec@(1,5) (64.9%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:26:56] \u001b[32mTrain: [ 39/50] Step 040/520 Loss 1.770 Prec@(1,5) (65.2%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:26:57] \u001b[32mTrain: [ 39/50] Step 060/520 Loss 1.769 Prec@(1,5) (65.2%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:26:57] \u001b[32mTrain: [ 39/50] Step 080/520 Loss 1.773 Prec@(1,5) (64.9%, 88.7%)\u001b[0m\n",
            "[2024-04-02 20:26:58] \u001b[32mTrain: [ 39/50] Step 100/520 Loss 1.763 Prec@(1,5) (64.9%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:26:59] \u001b[32mTrain: [ 39/50] Step 120/520 Loss 1.760 Prec@(1,5) (65.0%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:26:59] \u001b[32mTrain: [ 39/50] Step 140/520 Loss 1.763 Prec@(1,5) (64.9%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:27:00] \u001b[32mTrain: [ 39/50] Step 160/520 Loss 1.765 Prec@(1,5) (64.9%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:27:00] \u001b[32mTrain: [ 39/50] Step 180/520 Loss 1.762 Prec@(1,5) (64.9%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:27:01] \u001b[32mTrain: [ 39/50] Step 200/520 Loss 1.757 Prec@(1,5) (65.0%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:27:01] \u001b[32mTrain: [ 39/50] Step 220/520 Loss 1.764 Prec@(1,5) (64.8%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:27:02] \u001b[32mTrain: [ 39/50] Step 240/520 Loss 1.758 Prec@(1,5) (64.8%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:27:02] \u001b[32mTrain: [ 39/50] Step 260/520 Loss 1.762 Prec@(1,5) (64.7%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:27:03] \u001b[32mTrain: [ 39/50] Step 280/520 Loss 1.760 Prec@(1,5) (64.7%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:27:03] \u001b[32mTrain: [ 39/50] Step 300/520 Loss 1.761 Prec@(1,5) (64.6%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:27:04] \u001b[32mTrain: [ 39/50] Step 320/520 Loss 1.768 Prec@(1,5) (64.5%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:27:04] \u001b[32mTrain: [ 39/50] Step 340/520 Loss 1.770 Prec@(1,5) (64.4%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:27:05] \u001b[32mTrain: [ 39/50] Step 360/520 Loss 1.776 Prec@(1,5) (64.3%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:27:05] \u001b[32mTrain: [ 39/50] Step 380/520 Loss 1.777 Prec@(1,5) (64.3%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:27:06] \u001b[32mTrain: [ 39/50] Step 400/520 Loss 1.776 Prec@(1,5) (64.3%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:27:06] \u001b[32mTrain: [ 39/50] Step 420/520 Loss 1.780 Prec@(1,5) (64.2%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:27:07] \u001b[32mTrain: [ 39/50] Step 440/520 Loss 1.781 Prec@(1,5) (64.2%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:27:07] \u001b[32mTrain: [ 39/50] Step 460/520 Loss 1.782 Prec@(1,5) (64.2%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:27:07] \u001b[32mTrain: [ 39/50] Step 480/520 Loss 1.781 Prec@(1,5) (64.2%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:27:08] \u001b[32mTrain: [ 39/50] Step 500/520 Loss 1.782 Prec@(1,5) (64.2%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:27:08] \u001b[32mTrain: [ 39/50] Step 520/520 Loss 1.783 Prec@(1,5) (64.2%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:27:09] \u001b[32mTrain: [ 39/50] Final Prec@1 64.2140%\u001b[0m\n",
            "[2024-04-02 20:27:12] \u001b[32mValid: [ 39/50] Step 000/104 Loss 1.713 Prec@(1,5) (68.8%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:27:12] \u001b[32mValid: [ 39/50] Step 020/104 Loss 1.924 Prec@(1,5) (59.6%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:27:12] \u001b[32mValid: [ 39/50] Step 040/104 Loss 1.912 Prec@(1,5) (59.2%, 86.1%)\u001b[0m\n",
            "[2024-04-02 20:27:13] \u001b[32mValid: [ 39/50] Step 060/104 Loss 1.884 Prec@(1,5) (59.8%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:27:13] \u001b[32mValid: [ 39/50] Step 080/104 Loss 1.879 Prec@(1,5) (59.6%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:27:13] \u001b[32mValid: [ 39/50] Step 100/104 Loss 1.867 Prec@(1,5) (59.8%, 86.4%)\u001b[0m\n",
            "[2024-04-02 20:27:13] \u001b[32mValid: [ 39/50] Step 104/104 Loss 1.866 Prec@(1,5) (59.8%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:27:13] \u001b[32mValid: [ 39/50] Final Prec@1 59.8400%\u001b[0m\n",
            "[2024-04-02 20:27:13] \u001b[32mEpoch 39 LR 0.002869\u001b[0m\n",
            "[2024-04-02 20:27:18] \u001b[32mTrain: [ 40/50] Step 000/520 Loss 1.943 Prec@(1,5) (60.4%, 90.6%)\u001b[0m\n",
            "[2024-04-02 20:27:18] \u001b[32mTrain: [ 40/50] Step 020/520 Loss 1.693 Prec@(1,5) (66.0%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:27:19] \u001b[32mTrain: [ 40/50] Step 040/520 Loss 1.692 Prec@(1,5) (65.5%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:27:19] \u001b[32mTrain: [ 40/50] Step 060/520 Loss 1.707 Prec@(1,5) (64.9%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:27:20] \u001b[32mTrain: [ 40/50] Step 080/520 Loss 1.721 Prec@(1,5) (65.0%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:27:20] \u001b[32mTrain: [ 40/50] Step 100/520 Loss 1.730 Prec@(1,5) (64.8%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:27:21] \u001b[32mTrain: [ 40/50] Step 120/520 Loss 1.726 Prec@(1,5) (64.8%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:27:21] \u001b[32mTrain: [ 40/50] Step 140/520 Loss 1.728 Prec@(1,5) (64.8%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:27:22] \u001b[32mTrain: [ 40/50] Step 160/520 Loss 1.737 Prec@(1,5) (64.8%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:27:22] \u001b[32mTrain: [ 40/50] Step 180/520 Loss 1.733 Prec@(1,5) (64.9%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:27:23] \u001b[32mTrain: [ 40/50] Step 200/520 Loss 1.738 Prec@(1,5) (64.8%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:27:23] \u001b[32mTrain: [ 40/50] Step 220/520 Loss 1.739 Prec@(1,5) (64.8%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:27:24] \u001b[32mTrain: [ 40/50] Step 240/520 Loss 1.738 Prec@(1,5) (64.8%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:27:24] \u001b[32mTrain: [ 40/50] Step 260/520 Loss 1.746 Prec@(1,5) (64.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:27:25] \u001b[32mTrain: [ 40/50] Step 280/520 Loss 1.745 Prec@(1,5) (64.7%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:27:25] \u001b[32mTrain: [ 40/50] Step 300/520 Loss 1.747 Prec@(1,5) (64.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:27:26] \u001b[32mTrain: [ 40/50] Step 320/520 Loss 1.748 Prec@(1,5) (64.6%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:27:26] \u001b[32mTrain: [ 40/50] Step 340/520 Loss 1.750 Prec@(1,5) (64.6%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:27:27] \u001b[32mTrain: [ 40/50] Step 360/520 Loss 1.746 Prec@(1,5) (64.6%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:27:27] \u001b[32mTrain: [ 40/50] Step 380/520 Loss 1.749 Prec@(1,5) (64.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:27:28] \u001b[32mTrain: [ 40/50] Step 400/520 Loss 1.747 Prec@(1,5) (64.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:27:28] \u001b[32mTrain: [ 40/50] Step 420/520 Loss 1.750 Prec@(1,5) (64.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:27:29] \u001b[32mTrain: [ 40/50] Step 440/520 Loss 1.754 Prec@(1,5) (64.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:27:29] \u001b[32mTrain: [ 40/50] Step 460/520 Loss 1.755 Prec@(1,5) (64.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:27:30] \u001b[32mTrain: [ 40/50] Step 480/520 Loss 1.755 Prec@(1,5) (64.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:27:30] \u001b[32mTrain: [ 40/50] Step 500/520 Loss 1.754 Prec@(1,5) (64.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:27:30] \u001b[32mTrain: [ 40/50] Step 520/520 Loss 1.753 Prec@(1,5) (64.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:27:31] \u001b[32mTrain: [ 40/50] Final Prec@1 64.4900%\u001b[0m\n",
            "[2024-04-02 20:27:34] \u001b[32mValid: [ 40/50] Step 000/104 Loss 1.845 Prec@(1,5) (60.4%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:27:34] \u001b[32mValid: [ 40/50] Step 020/104 Loss 1.857 Prec@(1,5) (59.9%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:27:35] \u001b[32mValid: [ 40/50] Step 040/104 Loss 1.842 Prec@(1,5) (59.7%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:27:35] \u001b[32mValid: [ 40/50] Step 060/104 Loss 1.816 Prec@(1,5) (60.0%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:27:35] \u001b[32mValid: [ 40/50] Step 080/104 Loss 1.815 Prec@(1,5) (59.9%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:27:35] \u001b[32mValid: [ 40/50] Step 100/104 Loss 1.807 Prec@(1,5) (60.2%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:27:35] \u001b[32mValid: [ 40/50] Step 104/104 Loss 1.806 Prec@(1,5) (60.2%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:27:35] \u001b[32mValid: [ 40/50] Final Prec@1 60.2200%\u001b[0m\n",
            "[2024-04-02 20:27:35] \u001b[32mEpoch 40 LR 0.002388\u001b[0m\n",
            "[2024-04-02 20:27:40] \u001b[32mTrain: [ 41/50] Step 000/520 Loss 1.474 Prec@(1,5) (69.8%, 91.7%)\u001b[0m\n",
            "[2024-04-02 20:27:40] \u001b[32mTrain: [ 41/50] Step 020/520 Loss 1.732 Prec@(1,5) (65.2%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:27:41] \u001b[32mTrain: [ 41/50] Step 040/520 Loss 1.734 Prec@(1,5) (65.0%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:27:41] \u001b[32mTrain: [ 41/50] Step 060/520 Loss 1.732 Prec@(1,5) (64.9%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:27:42] \u001b[32mTrain: [ 41/50] Step 080/520 Loss 1.732 Prec@(1,5) (64.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:27:42] \u001b[32mTrain: [ 41/50] Step 100/520 Loss 1.723 Prec@(1,5) (64.9%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:27:43] \u001b[32mTrain: [ 41/50] Step 120/520 Loss 1.721 Prec@(1,5) (65.1%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:27:43] \u001b[32mTrain: [ 41/50] Step 140/520 Loss 1.720 Prec@(1,5) (65.3%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:27:44] \u001b[32mTrain: [ 41/50] Step 160/520 Loss 1.719 Prec@(1,5) (65.2%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:27:44] \u001b[32mTrain: [ 41/50] Step 180/520 Loss 1.722 Prec@(1,5) (65.2%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:27:45] \u001b[32mTrain: [ 41/50] Step 200/520 Loss 1.730 Prec@(1,5) (65.1%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:27:45] \u001b[32mTrain: [ 41/50] Step 220/520 Loss 1.728 Prec@(1,5) (65.0%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:27:46] \u001b[32mTrain: [ 41/50] Step 240/520 Loss 1.731 Prec@(1,5) (65.0%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:27:46] \u001b[32mTrain: [ 41/50] Step 260/520 Loss 1.732 Prec@(1,5) (65.0%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:27:47] \u001b[32mTrain: [ 41/50] Step 280/520 Loss 1.731 Prec@(1,5) (65.1%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:27:47] \u001b[32mTrain: [ 41/50] Step 300/520 Loss 1.732 Prec@(1,5) (65.0%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:27:48] \u001b[32mTrain: [ 41/50] Step 320/520 Loss 1.731 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:27:48] \u001b[32mTrain: [ 41/50] Step 340/520 Loss 1.735 Prec@(1,5) (64.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:27:49] \u001b[32mTrain: [ 41/50] Step 360/520 Loss 1.735 Prec@(1,5) (64.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:27:49] \u001b[32mTrain: [ 41/50] Step 380/520 Loss 1.737 Prec@(1,5) (64.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:27:50] \u001b[32mTrain: [ 41/50] Step 400/520 Loss 1.738 Prec@(1,5) (64.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:27:50] \u001b[32mTrain: [ 41/50] Step 420/520 Loss 1.740 Prec@(1,5) (64.8%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:27:51] \u001b[32mTrain: [ 41/50] Step 440/520 Loss 1.744 Prec@(1,5) (64.7%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:27:51] \u001b[32mTrain: [ 41/50] Step 460/520 Loss 1.744 Prec@(1,5) (64.7%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:27:52] \u001b[32mTrain: [ 41/50] Step 480/520 Loss 1.744 Prec@(1,5) (64.7%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:27:52] \u001b[32mTrain: [ 41/50] Step 500/520 Loss 1.745 Prec@(1,5) (64.6%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:27:53] \u001b[32mTrain: [ 41/50] Step 520/520 Loss 1.742 Prec@(1,5) (64.7%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:27:53] \u001b[32mTrain: [ 41/50] Final Prec@1 64.6820%\u001b[0m\n",
            "[2024-04-02 20:27:57] \u001b[32mValid: [ 41/50] Step 000/104 Loss 1.773 Prec@(1,5) (63.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:27:57] \u001b[32mValid: [ 41/50] Step 020/104 Loss 1.829 Prec@(1,5) (60.8%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:27:57] \u001b[32mValid: [ 41/50] Step 040/104 Loss 1.821 Prec@(1,5) (60.2%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:27:57] \u001b[32mValid: [ 41/50] Step 060/104 Loss 1.792 Prec@(1,5) (60.7%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:27:57] \u001b[32mValid: [ 41/50] Step 080/104 Loss 1.785 Prec@(1,5) (60.9%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:27:57] \u001b[32mValid: [ 41/50] Step 100/104 Loss 1.772 Prec@(1,5) (61.1%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:27:58] \u001b[32mValid: [ 41/50] Step 104/104 Loss 1.773 Prec@(1,5) (61.2%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:27:58] \u001b[32mValid: [ 41/50] Final Prec@1 61.1700%\u001b[0m\n",
            "[2024-04-02 20:27:58] \u001b[32mEpoch 41 LR 0.001947\u001b[0m\n",
            "[2024-04-02 20:28:02] \u001b[32mTrain: [ 42/50] Step 000/520 Loss 1.742 Prec@(1,5) (66.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:28:03] \u001b[32mTrain: [ 42/50] Step 020/520 Loss 1.653 Prec@(1,5) (66.8%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:28:03] \u001b[32mTrain: [ 42/50] Step 040/520 Loss 1.709 Prec@(1,5) (65.7%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:28:04] \u001b[32mTrain: [ 42/50] Step 060/520 Loss 1.690 Prec@(1,5) (65.8%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:28:04] \u001b[32mTrain: [ 42/50] Step 080/520 Loss 1.703 Prec@(1,5) (65.7%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:28:05] \u001b[32mTrain: [ 42/50] Step 100/520 Loss 1.700 Prec@(1,5) (65.8%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:28:05] \u001b[32mTrain: [ 42/50] Step 120/520 Loss 1.700 Prec@(1,5) (65.5%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:28:06] \u001b[32mTrain: [ 42/50] Step 140/520 Loss 1.701 Prec@(1,5) (65.3%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:28:06] \u001b[32mTrain: [ 42/50] Step 160/520 Loss 1.711 Prec@(1,5) (65.2%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:28:07] \u001b[32mTrain: [ 42/50] Step 180/520 Loss 1.713 Prec@(1,5) (65.1%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:28:07] \u001b[32mTrain: [ 42/50] Step 200/520 Loss 1.717 Prec@(1,5) (65.0%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:28:08] \u001b[32mTrain: [ 42/50] Step 220/520 Loss 1.715 Prec@(1,5) (65.1%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:28:08] \u001b[32mTrain: [ 42/50] Step 240/520 Loss 1.707 Prec@(1,5) (65.2%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:28:09] \u001b[32mTrain: [ 42/50] Step 260/520 Loss 1.711 Prec@(1,5) (65.1%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:28:09] \u001b[32mTrain: [ 42/50] Step 280/520 Loss 1.711 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:28:10] \u001b[32mTrain: [ 42/50] Step 300/520 Loss 1.711 Prec@(1,5) (65.3%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:28:10] \u001b[32mTrain: [ 42/50] Step 320/520 Loss 1.713 Prec@(1,5) (65.3%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:28:11] \u001b[32mTrain: [ 42/50] Step 340/520 Loss 1.719 Prec@(1,5) (65.1%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:28:11] \u001b[32mTrain: [ 42/50] Step 360/520 Loss 1.717 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:28:12] \u001b[32mTrain: [ 42/50] Step 380/520 Loss 1.715 Prec@(1,5) (65.3%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:28:12] \u001b[32mTrain: [ 42/50] Step 400/520 Loss 1.713 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:28:13] \u001b[32mTrain: [ 42/50] Step 420/520 Loss 1.717 Prec@(1,5) (65.3%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:28:13] \u001b[32mTrain: [ 42/50] Step 440/520 Loss 1.720 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:28:14] \u001b[32mTrain: [ 42/50] Step 460/520 Loss 1.720 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:28:14] \u001b[32mTrain: [ 42/50] Step 480/520 Loss 1.721 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:28:15] \u001b[32mTrain: [ 42/50] Step 500/520 Loss 1.727 Prec@(1,5) (65.1%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:28:15] \u001b[32mTrain: [ 42/50] Step 520/520 Loss 1.729 Prec@(1,5) (65.1%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:28:16] \u001b[32mTrain: [ 42/50] Final Prec@1 65.0700%\u001b[0m\n",
            "[2024-04-02 20:28:19] \u001b[32mValid: [ 42/50] Step 000/104 Loss 1.639 Prec@(1,5) (68.8%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:28:19] \u001b[32mValid: [ 42/50] Step 020/104 Loss 1.767 Prec@(1,5) (62.4%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:28:19] \u001b[32mValid: [ 42/50] Step 040/104 Loss 1.761 Prec@(1,5) (61.4%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:28:20] \u001b[32mValid: [ 42/50] Step 060/104 Loss 1.736 Prec@(1,5) (61.6%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:28:20] \u001b[32mValid: [ 42/50] Step 080/104 Loss 1.731 Prec@(1,5) (61.6%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:28:20] \u001b[32mValid: [ 42/50] Step 100/104 Loss 1.723 Prec@(1,5) (61.8%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:28:20] \u001b[32mValid: [ 42/50] Step 104/104 Loss 1.722 Prec@(1,5) (61.9%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:28:20] \u001b[32mValid: [ 42/50] Final Prec@1 61.8600%\u001b[0m\n",
            "[2024-04-02 20:28:20] \u001b[32mEpoch 42 LR 0.001547\u001b[0m\n",
            "[2024-04-02 20:28:25] \u001b[32mTrain: [ 43/50] Step 000/520 Loss 1.674 Prec@(1,5) (67.7%, 92.7%)\u001b[0m\n",
            "[2024-04-02 20:28:25] \u001b[32mTrain: [ 43/50] Step 020/520 Loss 1.689 Prec@(1,5) (65.6%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:28:26] \u001b[32mTrain: [ 43/50] Step 040/520 Loss 1.692 Prec@(1,5) (65.6%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:28:26] \u001b[32mTrain: [ 43/50] Step 060/520 Loss 1.697 Prec@(1,5) (65.6%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:28:27] \u001b[32mTrain: [ 43/50] Step 080/520 Loss 1.672 Prec@(1,5) (66.1%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:28:27] \u001b[32mTrain: [ 43/50] Step 100/520 Loss 1.688 Prec@(1,5) (65.9%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:28:28] \u001b[32mTrain: [ 43/50] Step 120/520 Loss 1.690 Prec@(1,5) (65.8%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:28:28] \u001b[32mTrain: [ 43/50] Step 140/520 Loss 1.697 Prec@(1,5) (65.7%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:28:29] \u001b[32mTrain: [ 43/50] Step 160/520 Loss 1.694 Prec@(1,5) (65.8%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:28:29] \u001b[32mTrain: [ 43/50] Step 180/520 Loss 1.696 Prec@(1,5) (65.7%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:28:30] \u001b[32mTrain: [ 43/50] Step 200/520 Loss 1.697 Prec@(1,5) (65.8%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:28:30] \u001b[32mTrain: [ 43/50] Step 220/520 Loss 1.697 Prec@(1,5) (65.7%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:28:31] \u001b[32mTrain: [ 43/50] Step 240/520 Loss 1.694 Prec@(1,5) (65.7%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:28:31] \u001b[32mTrain: [ 43/50] Step 260/520 Loss 1.699 Prec@(1,5) (65.6%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:28:32] \u001b[32mTrain: [ 43/50] Step 280/520 Loss 1.703 Prec@(1,5) (65.4%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:28:32] \u001b[32mTrain: [ 43/50] Step 300/520 Loss 1.705 Prec@(1,5) (65.4%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:28:32] \u001b[32mTrain: [ 43/50] Step 320/520 Loss 1.708 Prec@(1,5) (65.3%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:28:33] \u001b[32mTrain: [ 43/50] Step 340/520 Loss 1.705 Prec@(1,5) (65.4%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:28:33] \u001b[32mTrain: [ 43/50] Step 360/520 Loss 1.706 Prec@(1,5) (65.4%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:28:34] \u001b[32mTrain: [ 43/50] Step 380/520 Loss 1.704 Prec@(1,5) (65.4%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:28:34] \u001b[32mTrain: [ 43/50] Step 400/520 Loss 1.705 Prec@(1,5) (65.3%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:28:35] \u001b[32mTrain: [ 43/50] Step 420/520 Loss 1.702 Prec@(1,5) (65.4%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:28:35] \u001b[32mTrain: [ 43/50] Step 440/520 Loss 1.705 Prec@(1,5) (65.4%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:28:36] \u001b[32mTrain: [ 43/50] Step 460/520 Loss 1.704 Prec@(1,5) (65.4%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:28:37] \u001b[32mTrain: [ 43/50] Step 480/520 Loss 1.704 Prec@(1,5) (65.4%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:28:37] \u001b[32mTrain: [ 43/50] Step 500/520 Loss 1.704 Prec@(1,5) (65.4%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:28:38] \u001b[32mTrain: [ 43/50] Step 520/520 Loss 1.707 Prec@(1,5) (65.3%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:28:38] \u001b[32mTrain: [ 43/50] Final Prec@1 65.3420%\u001b[0m\n",
            "[2024-04-02 20:28:41] \u001b[32mValid: [ 43/50] Step 000/104 Loss 1.651 Prec@(1,5) (66.7%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:28:41] \u001b[32mValid: [ 43/50] Step 020/104 Loss 1.821 Prec@(1,5) (61.8%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:28:42] \u001b[32mValid: [ 43/50] Step 040/104 Loss 1.803 Prec@(1,5) (61.1%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:28:42] \u001b[32mValid: [ 43/50] Step 060/104 Loss 1.774 Prec@(1,5) (61.2%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:28:42] \u001b[32mValid: [ 43/50] Step 080/104 Loss 1.763 Prec@(1,5) (61.4%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:28:42] \u001b[32mValid: [ 43/50] Step 100/104 Loss 1.753 Prec@(1,5) (61.6%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:28:42] \u001b[32mValid: [ 43/50] Step 104/104 Loss 1.753 Prec@(1,5) (61.7%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:28:42] \u001b[32mValid: [ 43/50] Final Prec@1 61.6500%\u001b[0m\n",
            "[2024-04-02 20:28:42] \u001b[32mEpoch 43 LR 0.001191\u001b[0m\n",
            "[2024-04-02 20:28:47] \u001b[32mTrain: [ 44/50] Step 000/520 Loss 1.534 Prec@(1,5) (70.8%, 90.6%)\u001b[0m\n",
            "[2024-04-02 20:28:47] \u001b[32mTrain: [ 44/50] Step 020/520 Loss 1.766 Prec@(1,5) (64.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:28:48] \u001b[32mTrain: [ 44/50] Step 040/520 Loss 1.761 Prec@(1,5) (65.2%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:28:48] \u001b[32mTrain: [ 44/50] Step 060/520 Loss 1.723 Prec@(1,5) (65.8%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:28:49] \u001b[32mTrain: [ 44/50] Step 080/520 Loss 1.744 Prec@(1,5) (65.1%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:28:49] \u001b[32mTrain: [ 44/50] Step 100/520 Loss 1.732 Prec@(1,5) (65.6%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:28:50] \u001b[32mTrain: [ 44/50] Step 120/520 Loss 1.733 Prec@(1,5) (65.5%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:28:50] \u001b[32mTrain: [ 44/50] Step 140/520 Loss 1.727 Prec@(1,5) (65.5%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:28:51] \u001b[32mTrain: [ 44/50] Step 160/520 Loss 1.731 Prec@(1,5) (65.4%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:28:51] \u001b[32mTrain: [ 44/50] Step 180/520 Loss 1.722 Prec@(1,5) (65.4%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:28:52] \u001b[32mTrain: [ 44/50] Step 200/520 Loss 1.718 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:28:53] \u001b[32mTrain: [ 44/50] Step 220/520 Loss 1.714 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:28:53] \u001b[32mTrain: [ 44/50] Step 240/520 Loss 1.719 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:28:54] \u001b[32mTrain: [ 44/50] Step 260/520 Loss 1.720 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:28:54] \u001b[32mTrain: [ 44/50] Step 280/520 Loss 1.715 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:28:55] \u001b[32mTrain: [ 44/50] Step 300/520 Loss 1.720 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:28:55] \u001b[32mTrain: [ 44/50] Step 320/520 Loss 1.715 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:28:56] \u001b[32mTrain: [ 44/50] Step 340/520 Loss 1.713 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:28:56] \u001b[32mTrain: [ 44/50] Step 360/520 Loss 1.713 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:28:57] \u001b[32mTrain: [ 44/50] Step 380/520 Loss 1.714 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:28:57] \u001b[32mTrain: [ 44/50] Step 400/520 Loss 1.711 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:28:58] \u001b[32mTrain: [ 44/50] Step 420/520 Loss 1.713 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:28:58] \u001b[32mTrain: [ 44/50] Step 440/520 Loss 1.712 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:28:59] \u001b[32mTrain: [ 44/50] Step 460/520 Loss 1.709 Prec@(1,5) (65.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:28:59] \u001b[32mTrain: [ 44/50] Step 480/520 Loss 1.710 Prec@(1,5) (65.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:29:00] \u001b[32mTrain: [ 44/50] Step 500/520 Loss 1.710 Prec@(1,5) (65.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:29:00] \u001b[32mTrain: [ 44/50] Step 520/520 Loss 1.713 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:29:00] \u001b[32mTrain: [ 44/50] Final Prec@1 65.6300%\u001b[0m\n",
            "[2024-04-02 20:29:04] \u001b[32mValid: [ 44/50] Step 000/104 Loss 1.668 Prec@(1,5) (66.7%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:29:04] \u001b[32mValid: [ 44/50] Step 020/104 Loss 1.792 Prec@(1,5) (62.3%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:29:04] \u001b[32mValid: [ 44/50] Step 040/104 Loss 1.778 Prec@(1,5) (61.5%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:29:04] \u001b[32mValid: [ 44/50] Step 060/104 Loss 1.747 Prec@(1,5) (61.9%, 88.1%)\u001b[0m\n",
            "[2024-04-02 20:29:05] \u001b[32mValid: [ 44/50] Step 080/104 Loss 1.738 Prec@(1,5) (61.9%, 88.1%)\u001b[0m\n",
            "[2024-04-02 20:29:05] \u001b[32mValid: [ 44/50] Step 100/104 Loss 1.728 Prec@(1,5) (62.1%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:29:05] \u001b[32mValid: [ 44/50] Step 104/104 Loss 1.728 Prec@(1,5) (62.1%, 88.1%)\u001b[0m\n",
            "[2024-04-02 20:29:05] \u001b[32mValid: [ 44/50] Final Prec@1 62.0600%\u001b[0m\n",
            "[2024-04-02 20:29:05] \u001b[32mEpoch 44 LR 0.000879\u001b[0m\n",
            "[2024-04-02 20:29:10] \u001b[32mTrain: [ 45/50] Step 000/520 Loss 1.398 Prec@(1,5) (74.0%, 93.8%)\u001b[0m\n",
            "[2024-04-02 20:29:10] \u001b[32mTrain: [ 45/50] Step 020/520 Loss 1.743 Prec@(1,5) (65.8%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:29:11] \u001b[32mTrain: [ 45/50] Step 040/520 Loss 1.679 Prec@(1,5) (66.3%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:29:11] \u001b[32mTrain: [ 45/50] Step 060/520 Loss 1.665 Prec@(1,5) (66.6%, 90.3%)\u001b[0m\n",
            "[2024-04-02 20:29:12] \u001b[32mTrain: [ 45/50] Step 080/520 Loss 1.651 Prec@(1,5) (66.7%, 90.5%)\u001b[0m\n",
            "[2024-04-02 20:29:12] \u001b[32mTrain: [ 45/50] Step 100/520 Loss 1.656 Prec@(1,5) (66.6%, 90.4%)\u001b[0m\n",
            "[2024-04-02 20:29:13] \u001b[32mTrain: [ 45/50] Step 120/520 Loss 1.672 Prec@(1,5) (66.2%, 90.2%)\u001b[0m\n",
            "[2024-04-02 20:29:13] \u001b[32mTrain: [ 45/50] Step 140/520 Loss 1.682 Prec@(1,5) (66.1%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:29:14] \u001b[32mTrain: [ 45/50] Step 160/520 Loss 1.678 Prec@(1,5) (66.1%, 90.1%)\u001b[0m\n",
            "[2024-04-02 20:29:14] \u001b[32mTrain: [ 45/50] Step 180/520 Loss 1.681 Prec@(1,5) (66.0%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:29:15] \u001b[32mTrain: [ 45/50] Step 200/520 Loss 1.682 Prec@(1,5) (65.9%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:29:15] \u001b[32mTrain: [ 45/50] Step 220/520 Loss 1.678 Prec@(1,5) (66.1%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:29:16] \u001b[32mTrain: [ 45/50] Step 240/520 Loss 1.683 Prec@(1,5) (66.0%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:29:16] \u001b[32mTrain: [ 45/50] Step 260/520 Loss 1.685 Prec@(1,5) (66.0%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:29:17] \u001b[32mTrain: [ 45/50] Step 280/520 Loss 1.684 Prec@(1,5) (66.1%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:29:17] \u001b[32mTrain: [ 45/50] Step 300/520 Loss 1.686 Prec@(1,5) (66.1%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:29:18] \u001b[32mTrain: [ 45/50] Step 320/520 Loss 1.687 Prec@(1,5) (66.0%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:29:18] \u001b[32mTrain: [ 45/50] Step 340/520 Loss 1.687 Prec@(1,5) (66.0%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:29:19] \u001b[32mTrain: [ 45/50] Step 360/520 Loss 1.684 Prec@(1,5) (66.1%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:29:19] \u001b[32mTrain: [ 45/50] Step 380/520 Loss 1.684 Prec@(1,5) (66.0%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:29:20] \u001b[32mTrain: [ 45/50] Step 400/520 Loss 1.688 Prec@(1,5) (65.9%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:29:20] \u001b[32mTrain: [ 45/50] Step 420/520 Loss 1.687 Prec@(1,5) (66.0%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:29:21] \u001b[32mTrain: [ 45/50] Step 440/520 Loss 1.685 Prec@(1,5) (66.0%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:29:21] \u001b[32mTrain: [ 45/50] Step 460/520 Loss 1.686 Prec@(1,5) (66.0%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:29:22] \u001b[32mTrain: [ 45/50] Step 480/520 Loss 1.687 Prec@(1,5) (65.9%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:29:22] \u001b[32mTrain: [ 45/50] Step 500/520 Loss 1.688 Prec@(1,5) (66.0%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:29:23] \u001b[32mTrain: [ 45/50] Step 520/520 Loss 1.690 Prec@(1,5) (65.9%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:29:23] \u001b[32mTrain: [ 45/50] Final Prec@1 65.9140%\u001b[0m\n",
            "[2024-04-02 20:29:26] \u001b[32mValid: [ 45/50] Step 000/104 Loss 1.642 Prec@(1,5) (66.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:29:26] \u001b[32mValid: [ 45/50] Step 020/104 Loss 1.788 Prec@(1,5) (62.0%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:29:27] \u001b[32mValid: [ 45/50] Step 040/104 Loss 1.772 Prec@(1,5) (61.4%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:29:27] \u001b[32mValid: [ 45/50] Step 060/104 Loss 1.742 Prec@(1,5) (61.9%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:29:27] \u001b[32mValid: [ 45/50] Step 080/104 Loss 1.738 Prec@(1,5) (61.8%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:29:27] \u001b[32mValid: [ 45/50] Step 100/104 Loss 1.724 Prec@(1,5) (62.0%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:29:27] \u001b[32mValid: [ 45/50] Step 104/104 Loss 1.725 Prec@(1,5) (62.1%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:29:27] \u001b[32mValid: [ 45/50] Final Prec@1 62.0500%\u001b[0m\n",
            "[2024-04-02 20:29:27] \u001b[32mEpoch 45 LR 0.000613\u001b[0m\n",
            "[2024-04-02 20:29:32] \u001b[32mTrain: [ 46/50] Step 000/520 Loss 1.439 Prec@(1,5) (74.0%, 92.7%)\u001b[0m\n",
            "[2024-04-02 20:29:32] \u001b[32mTrain: [ 46/50] Step 020/520 Loss 1.703 Prec@(1,5) (66.3%, 90.1%)\u001b[0m\n",
            "[2024-04-02 20:29:33] \u001b[32mTrain: [ 46/50] Step 040/520 Loss 1.686 Prec@(1,5) (66.8%, 90.2%)\u001b[0m\n",
            "[2024-04-02 20:29:34] \u001b[32mTrain: [ 46/50] Step 060/520 Loss 1.702 Prec@(1,5) (66.2%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:29:34] \u001b[32mTrain: [ 46/50] Step 080/520 Loss 1.703 Prec@(1,5) (66.3%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:29:35] \u001b[32mTrain: [ 46/50] Step 100/520 Loss 1.696 Prec@(1,5) (66.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:29:35] \u001b[32mTrain: [ 46/50] Step 120/520 Loss 1.707 Prec@(1,5) (66.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:29:35] \u001b[32mTrain: [ 46/50] Step 140/520 Loss 1.696 Prec@(1,5) (66.2%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:29:36] \u001b[32mTrain: [ 46/50] Step 160/520 Loss 1.694 Prec@(1,5) (66.2%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:29:36] \u001b[32mTrain: [ 46/50] Step 180/520 Loss 1.687 Prec@(1,5) (66.3%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:29:37] \u001b[32mTrain: [ 46/50] Step 200/520 Loss 1.684 Prec@(1,5) (66.2%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:29:37] \u001b[32mTrain: [ 46/50] Step 220/520 Loss 1.680 Prec@(1,5) (66.3%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:29:38] \u001b[32mTrain: [ 46/50] Step 240/520 Loss 1.678 Prec@(1,5) (66.3%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:29:38] \u001b[32mTrain: [ 46/50] Step 260/520 Loss 1.675 Prec@(1,5) (66.3%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:29:39] \u001b[32mTrain: [ 46/50] Step 280/520 Loss 1.673 Prec@(1,5) (66.4%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:29:39] \u001b[32mTrain: [ 46/50] Step 300/520 Loss 1.677 Prec@(1,5) (66.3%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:29:40] \u001b[32mTrain: [ 46/50] Step 320/520 Loss 1.678 Prec@(1,5) (66.3%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:29:40] \u001b[32mTrain: [ 46/50] Step 340/520 Loss 1.678 Prec@(1,5) (66.3%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:29:41] \u001b[32mTrain: [ 46/50] Step 360/520 Loss 1.678 Prec@(1,5) (66.3%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:29:41] \u001b[32mTrain: [ 46/50] Step 380/520 Loss 1.682 Prec@(1,5) (66.2%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:29:42] \u001b[32mTrain: [ 46/50] Step 400/520 Loss 1.683 Prec@(1,5) (66.2%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:29:42] \u001b[32mTrain: [ 46/50] Step 420/520 Loss 1.685 Prec@(1,5) (66.2%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:29:43] \u001b[32mTrain: [ 46/50] Step 440/520 Loss 1.685 Prec@(1,5) (66.2%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:29:43] \u001b[32mTrain: [ 46/50] Step 460/520 Loss 1.686 Prec@(1,5) (66.2%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:29:44] \u001b[32mTrain: [ 46/50] Step 480/520 Loss 1.689 Prec@(1,5) (66.1%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:29:44] \u001b[32mTrain: [ 46/50] Step 500/520 Loss 1.691 Prec@(1,5) (66.0%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:29:45] \u001b[32mTrain: [ 46/50] Step 520/520 Loss 1.691 Prec@(1,5) (66.0%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:29:45] \u001b[32mTrain: [ 46/50] Final Prec@1 66.0300%\u001b[0m\n",
            "[2024-04-02 20:29:48] \u001b[32mValid: [ 46/50] Step 000/104 Loss 1.649 Prec@(1,5) (67.7%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:29:49] \u001b[32mValid: [ 46/50] Step 020/104 Loss 1.793 Prec@(1,5) (62.2%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:29:49] \u001b[32mValid: [ 46/50] Step 040/104 Loss 1.784 Prec@(1,5) (61.5%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:29:49] \u001b[32mValid: [ 46/50] Step 060/104 Loss 1.755 Prec@(1,5) (61.9%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:29:49] \u001b[32mValid: [ 46/50] Step 080/104 Loss 1.751 Prec@(1,5) (61.8%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:29:49] \u001b[32mValid: [ 46/50] Step 100/104 Loss 1.740 Prec@(1,5) (62.0%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:29:49] \u001b[32mValid: [ 46/50] Step 104/104 Loss 1.741 Prec@(1,5) (62.0%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:29:50] \u001b[32mValid: [ 46/50] Final Prec@1 61.9500%\u001b[0m\n",
            "[2024-04-02 20:29:50] \u001b[32mEpoch 46 LR 0.000394\u001b[0m\n",
            "[2024-04-02 20:29:54] \u001b[32mTrain: [ 47/50] Step 000/520 Loss 1.917 Prec@(1,5) (62.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:29:55] \u001b[32mTrain: [ 47/50] Step 020/520 Loss 1.658 Prec@(1,5) (66.1%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:29:55] \u001b[32mTrain: [ 47/50] Step 040/520 Loss 1.665 Prec@(1,5) (66.1%, 90.2%)\u001b[0m\n",
            "[2024-04-02 20:29:56] \u001b[32mTrain: [ 47/50] Step 060/520 Loss 1.662 Prec@(1,5) (66.3%, 90.6%)\u001b[0m\n",
            "[2024-04-02 20:29:56] \u001b[32mTrain: [ 47/50] Step 080/520 Loss 1.659 Prec@(1,5) (66.4%, 90.4%)\u001b[0m\n",
            "[2024-04-02 20:29:57] \u001b[32mTrain: [ 47/50] Step 100/520 Loss 1.669 Prec@(1,5) (66.3%, 90.2%)\u001b[0m\n",
            "[2024-04-02 20:29:57] \u001b[32mTrain: [ 47/50] Step 120/520 Loss 1.675 Prec@(1,5) (66.0%, 90.2%)\u001b[0m\n",
            "[2024-04-02 20:29:58] \u001b[32mTrain: [ 47/50] Step 140/520 Loss 1.677 Prec@(1,5) (66.2%, 90.1%)\u001b[0m\n",
            "[2024-04-02 20:29:58] \u001b[32mTrain: [ 47/50] Step 160/520 Loss 1.681 Prec@(1,5) (66.1%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:29:59] \u001b[32mTrain: [ 47/50] Step 180/520 Loss 1.679 Prec@(1,5) (66.2%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:29:59] \u001b[32mTrain: [ 47/50] Step 200/520 Loss 1.678 Prec@(1,5) (66.4%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:30:00] \u001b[32mTrain: [ 47/50] Step 220/520 Loss 1.683 Prec@(1,5) (66.2%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:30:00] \u001b[32mTrain: [ 47/50] Step 240/520 Loss 1.680 Prec@(1,5) (66.2%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:30:01] \u001b[32mTrain: [ 47/50] Step 260/520 Loss 1.675 Prec@(1,5) (66.3%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:01] \u001b[32mTrain: [ 47/50] Step 280/520 Loss 1.676 Prec@(1,5) (66.3%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:02] \u001b[32mTrain: [ 47/50] Step 300/520 Loss 1.677 Prec@(1,5) (66.3%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:02] \u001b[32mTrain: [ 47/50] Step 320/520 Loss 1.678 Prec@(1,5) (66.3%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:03] \u001b[32mTrain: [ 47/50] Step 340/520 Loss 1.676 Prec@(1,5) (66.3%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:03] \u001b[32mTrain: [ 47/50] Step 360/520 Loss 1.677 Prec@(1,5) (66.3%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:04] \u001b[32mTrain: [ 47/50] Step 380/520 Loss 1.679 Prec@(1,5) (66.2%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:30:04] \u001b[32mTrain: [ 47/50] Step 400/520 Loss 1.678 Prec@(1,5) (66.3%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:05] \u001b[32mTrain: [ 47/50] Step 420/520 Loss 1.677 Prec@(1,5) (66.3%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:05] \u001b[32mTrain: [ 47/50] Step 440/520 Loss 1.679 Prec@(1,5) (66.3%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:06] \u001b[32mTrain: [ 47/50] Step 460/520 Loss 1.678 Prec@(1,5) (66.3%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:30:06] \u001b[32mTrain: [ 47/50] Step 480/520 Loss 1.680 Prec@(1,5) (66.2%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:30:07] \u001b[32mTrain: [ 47/50] Step 500/520 Loss 1.680 Prec@(1,5) (66.2%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:30:07] \u001b[32mTrain: [ 47/50] Step 520/520 Loss 1.680 Prec@(1,5) (66.2%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:30:07] \u001b[32mTrain: [ 47/50] Final Prec@1 66.2040%\u001b[0m\n",
            "[2024-04-02 20:30:11] \u001b[32mValid: [ 47/50] Step 000/104 Loss 1.615 Prec@(1,5) (66.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:30:11] \u001b[32mValid: [ 47/50] Step 020/104 Loss 1.800 Prec@(1,5) (62.0%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:30:11] \u001b[32mValid: [ 47/50] Step 040/104 Loss 1.786 Prec@(1,5) (61.3%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:30:11] \u001b[32mValid: [ 47/50] Step 060/104 Loss 1.754 Prec@(1,5) (61.7%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:30:11] \u001b[32mValid: [ 47/50] Step 080/104 Loss 1.744 Prec@(1,5) (61.9%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:30:11] \u001b[32mValid: [ 47/50] Step 100/104 Loss 1.732 Prec@(1,5) (62.0%, 88.1%)\u001b[0m\n",
            "[2024-04-02 20:30:12] \u001b[32mValid: [ 47/50] Step 104/104 Loss 1.733 Prec@(1,5) (62.0%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:30:12] \u001b[32mValid: [ 47/50] Final Prec@1 61.9700%\u001b[0m\n",
            "[2024-04-02 20:30:12] \u001b[32mEpoch 47 LR 0.000222\u001b[0m\n",
            "[2024-04-02 20:30:16] \u001b[32mTrain: [ 48/50] Step 000/520 Loss 1.742 Prec@(1,5) (63.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:30:17] \u001b[32mTrain: [ 48/50] Step 020/520 Loss 1.720 Prec@(1,5) (65.1%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:30:17] \u001b[32mTrain: [ 48/50] Step 040/520 Loss 1.697 Prec@(1,5) (66.0%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:30:18] \u001b[32mTrain: [ 48/50] Step 060/520 Loss 1.712 Prec@(1,5) (65.6%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:30:18] \u001b[32mTrain: [ 48/50] Step 080/520 Loss 1.699 Prec@(1,5) (65.8%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:30:19] \u001b[32mTrain: [ 48/50] Step 100/520 Loss 1.681 Prec@(1,5) (66.3%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:30:19] \u001b[32mTrain: [ 48/50] Step 120/520 Loss 1.675 Prec@(1,5) (66.3%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:20] \u001b[32mTrain: [ 48/50] Step 140/520 Loss 1.674 Prec@(1,5) (66.3%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:20] \u001b[32mTrain: [ 48/50] Step 160/520 Loss 1.689 Prec@(1,5) (66.1%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:30:21] \u001b[32mTrain: [ 48/50] Step 180/520 Loss 1.697 Prec@(1,5) (65.9%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:30:21] \u001b[32mTrain: [ 48/50] Step 200/520 Loss 1.694 Prec@(1,5) (65.9%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:30:22] \u001b[32mTrain: [ 48/50] Step 220/520 Loss 1.691 Prec@(1,5) (65.8%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:30:22] \u001b[32mTrain: [ 48/50] Step 240/520 Loss 1.684 Prec@(1,5) (65.9%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:30:23] \u001b[32mTrain: [ 48/50] Step 260/520 Loss 1.681 Prec@(1,5) (66.0%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:30:23] \u001b[32mTrain: [ 48/50] Step 280/520 Loss 1.679 Prec@(1,5) (66.0%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:30:24] \u001b[32mTrain: [ 48/50] Step 300/520 Loss 1.678 Prec@(1,5) (65.9%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:30:24] \u001b[32mTrain: [ 48/50] Step 320/520 Loss 1.673 Prec@(1,5) (66.1%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:25] \u001b[32mTrain: [ 48/50] Step 340/520 Loss 1.674 Prec@(1,5) (66.1%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:25] \u001b[32mTrain: [ 48/50] Step 360/520 Loss 1.674 Prec@(1,5) (66.0%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:30:26] \u001b[32mTrain: [ 48/50] Step 380/520 Loss 1.674 Prec@(1,5) (66.0%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:30:26] \u001b[32mTrain: [ 48/50] Step 400/520 Loss 1.676 Prec@(1,5) (66.0%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:30:27] \u001b[32mTrain: [ 48/50] Step 420/520 Loss 1.675 Prec@(1,5) (66.0%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:27] \u001b[32mTrain: [ 48/50] Step 440/520 Loss 1.675 Prec@(1,5) (66.0%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:30:28] \u001b[32mTrain: [ 48/50] Step 460/520 Loss 1.672 Prec@(1,5) (66.1%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:28] \u001b[32mTrain: [ 48/50] Step 480/520 Loss 1.671 Prec@(1,5) (66.1%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:29] \u001b[32mTrain: [ 48/50] Step 500/520 Loss 1.670 Prec@(1,5) (66.2%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:29] \u001b[32mTrain: [ 48/50] Step 520/520 Loss 1.670 Prec@(1,5) (66.2%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:29] \u001b[32mTrain: [ 48/50] Final Prec@1 66.2100%\u001b[0m\n",
            "[2024-04-02 20:30:33] \u001b[32mValid: [ 48/50] Step 000/104 Loss 1.644 Prec@(1,5) (64.6%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:30:33] \u001b[32mValid: [ 48/50] Step 020/104 Loss 1.777 Prec@(1,5) (61.8%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:30:33] \u001b[32mValid: [ 48/50] Step 040/104 Loss 1.767 Prec@(1,5) (61.3%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:30:33] \u001b[32mValid: [ 48/50] Step 060/104 Loss 1.736 Prec@(1,5) (61.8%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:30:33] \u001b[32mValid: [ 48/50] Step 080/104 Loss 1.727 Prec@(1,5) (61.9%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:30:34] \u001b[32mValid: [ 48/50] Step 100/104 Loss 1.716 Prec@(1,5) (62.1%, 88.1%)\u001b[0m\n",
            "[2024-04-02 20:30:34] \u001b[32mValid: [ 48/50] Step 104/104 Loss 1.716 Prec@(1,5) (62.1%, 88.1%)\u001b[0m\n",
            "[2024-04-02 20:30:34] \u001b[32mValid: [ 48/50] Final Prec@1 62.1000%\u001b[0m\n",
            "[2024-04-02 20:30:34] \u001b[32mEpoch 48 LR 0.000100\u001b[0m\n",
            "[2024-04-02 20:30:38] \u001b[32mTrain: [ 49/50] Step 000/520 Loss 1.653 Prec@(1,5) (63.5%, 91.7%)\u001b[0m\n",
            "[2024-04-02 20:30:39] \u001b[32mTrain: [ 49/50] Step 020/520 Loss 1.695 Prec@(1,5) (66.1%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:30:39] \u001b[32mTrain: [ 49/50] Step 040/520 Loss 1.660 Prec@(1,5) (66.3%, 90.2%)\u001b[0m\n",
            "[2024-04-02 20:30:40] \u001b[32mTrain: [ 49/50] Step 060/520 Loss 1.664 Prec@(1,5) (66.1%, 90.1%)\u001b[0m\n",
            "[2024-04-02 20:30:40] \u001b[32mTrain: [ 49/50] Step 080/520 Loss 1.666 Prec@(1,5) (65.9%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:30:41] \u001b[32mTrain: [ 49/50] Step 100/520 Loss 1.665 Prec@(1,5) (66.0%, 90.1%)\u001b[0m\n",
            "[2024-04-02 20:30:41] \u001b[32mTrain: [ 49/50] Step 120/520 Loss 1.662 Prec@(1,5) (66.2%, 90.1%)\u001b[0m\n",
            "[2024-04-02 20:30:42] \u001b[32mTrain: [ 49/50] Step 140/520 Loss 1.668 Prec@(1,5) (66.2%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:42] \u001b[32mTrain: [ 49/50] Step 160/520 Loss 1.670 Prec@(1,5) (66.2%, 89.9%)\u001b[0m\n",
            "[2024-04-02 20:30:43] \u001b[32mTrain: [ 49/50] Step 180/520 Loss 1.670 Prec@(1,5) (66.2%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:43] \u001b[32mTrain: [ 49/50] Step 200/520 Loss 1.670 Prec@(1,5) (66.2%, 90.1%)\u001b[0m\n",
            "[2024-04-02 20:30:44] \u001b[32mTrain: [ 49/50] Step 220/520 Loss 1.670 Prec@(1,5) (66.2%, 90.1%)\u001b[0m\n",
            "[2024-04-02 20:30:44] \u001b[32mTrain: [ 49/50] Step 240/520 Loss 1.672 Prec@(1,5) (66.1%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:45] \u001b[32mTrain: [ 49/50] Step 260/520 Loss 1.667 Prec@(1,5) (66.2%, 90.1%)\u001b[0m\n",
            "[2024-04-02 20:30:45] \u001b[32mTrain: [ 49/50] Step 280/520 Loss 1.669 Prec@(1,5) (66.2%, 90.1%)\u001b[0m\n",
            "[2024-04-02 20:30:46] \u001b[32mTrain: [ 49/50] Step 300/520 Loss 1.668 Prec@(1,5) (66.2%, 90.1%)\u001b[0m\n",
            "[2024-04-02 20:30:46] \u001b[32mTrain: [ 49/50] Step 320/520 Loss 1.671 Prec@(1,5) (66.2%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:47] \u001b[32mTrain: [ 49/50] Step 340/520 Loss 1.674 Prec@(1,5) (66.1%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:47] \u001b[32mTrain: [ 49/50] Step 360/520 Loss 1.673 Prec@(1,5) (66.1%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:48] \u001b[32mTrain: [ 49/50] Step 380/520 Loss 1.672 Prec@(1,5) (66.2%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:48] \u001b[32mTrain: [ 49/50] Step 400/520 Loss 1.676 Prec@(1,5) (66.1%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:49] \u001b[32mTrain: [ 49/50] Step 420/520 Loss 1.675 Prec@(1,5) (66.1%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:49] \u001b[32mTrain: [ 49/50] Step 440/520 Loss 1.675 Prec@(1,5) (66.2%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:50] \u001b[32mTrain: [ 49/50] Step 460/520 Loss 1.675 Prec@(1,5) (66.2%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:50] \u001b[32mTrain: [ 49/50] Step 480/520 Loss 1.674 Prec@(1,5) (66.2%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:51] \u001b[32mTrain: [ 49/50] Step 500/520 Loss 1.675 Prec@(1,5) (66.2%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:51] \u001b[32mTrain: [ 49/50] Step 520/520 Loss 1.673 Prec@(1,5) (66.2%, 90.0%)\u001b[0m\n",
            "[2024-04-02 20:30:52] \u001b[32mTrain: [ 49/50] Final Prec@1 66.2020%\u001b[0m\n",
            "[2024-04-02 20:30:55] \u001b[32mValid: [ 49/50] Step 000/104 Loss 1.619 Prec@(1,5) (66.7%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:30:55] \u001b[32mValid: [ 49/50] Step 020/104 Loss 1.780 Prec@(1,5) (62.0%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:30:55] \u001b[32mValid: [ 49/50] Step 040/104 Loss 1.766 Prec@(1,5) (61.6%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:30:56] \u001b[32mValid: [ 49/50] Step 060/104 Loss 1.733 Prec@(1,5) (62.0%, 88.1%)\u001b[0m\n",
            "[2024-04-02 20:30:56] \u001b[32mValid: [ 49/50] Step 080/104 Loss 1.723 Prec@(1,5) (62.2%, 88.1%)\u001b[0m\n",
            "[2024-04-02 20:30:56] \u001b[32mValid: [ 49/50] Step 100/104 Loss 1.713 Prec@(1,5) (62.3%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:30:56] \u001b[32mValid: [ 49/50] Step 104/104 Loss 1.712 Prec@(1,5) (62.3%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:30:56] \u001b[32mValid: [ 49/50] Final Prec@1 62.3200%\u001b[0m\n",
            "[2024-04-02 20:30:56] \u001b[32mEpoch 49 LR 0.000026\u001b[0m\n",
            "[2024-04-02 20:31:01] \u001b[32mTrain: [ 50/50] Step 000/520 Loss 1.777 Prec@(1,5) (60.4%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:31:01] \u001b[32mTrain: [ 50/50] Step 020/520 Loss 1.605 Prec@(1,5) (67.3%, 90.7%)\u001b[0m\n",
            "[2024-04-02 20:31:02] \u001b[32mTrain: [ 50/50] Step 040/520 Loss 1.610 Prec@(1,5) (67.2%, 90.8%)\u001b[0m\n",
            "[2024-04-02 20:31:02] \u001b[32mTrain: [ 50/50] Step 060/520 Loss 1.672 Prec@(1,5) (66.3%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:31:03] \u001b[32mTrain: [ 50/50] Step 080/520 Loss 1.680 Prec@(1,5) (66.1%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:31:03] \u001b[32mTrain: [ 50/50] Step 100/520 Loss 1.684 Prec@(1,5) (66.0%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:31:04] \u001b[32mTrain: [ 50/50] Step 120/520 Loss 1.678 Prec@(1,5) (66.3%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:31:04] \u001b[32mTrain: [ 50/50] Step 140/520 Loss 1.683 Prec@(1,5) (66.1%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:31:05] \u001b[32mTrain: [ 50/50] Step 160/520 Loss 1.683 Prec@(1,5) (66.0%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:31:05] \u001b[32mTrain: [ 50/50] Step 180/520 Loss 1.686 Prec@(1,5) (66.0%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:31:06] \u001b[32mTrain: [ 50/50] Step 200/520 Loss 1.689 Prec@(1,5) (66.1%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:31:06] \u001b[32mTrain: [ 50/50] Step 220/520 Loss 1.687 Prec@(1,5) (66.1%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:31:07] \u001b[32mTrain: [ 50/50] Step 240/520 Loss 1.687 Prec@(1,5) (66.1%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:31:07] \u001b[32mTrain: [ 50/50] Step 260/520 Loss 1.684 Prec@(1,5) (66.2%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:31:08] \u001b[32mTrain: [ 50/50] Step 280/520 Loss 1.683 Prec@(1,5) (66.2%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:31:08] \u001b[32mTrain: [ 50/50] Step 300/520 Loss 1.685 Prec@(1,5) (66.2%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:31:09] \u001b[32mTrain: [ 50/50] Step 320/520 Loss 1.679 Prec@(1,5) (66.3%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:31:09] \u001b[32mTrain: [ 50/50] Step 340/520 Loss 1.680 Prec@(1,5) (66.3%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:31:10] \u001b[32mTrain: [ 50/50] Step 360/520 Loss 1.683 Prec@(1,5) (66.2%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:31:10] \u001b[32mTrain: [ 50/50] Step 380/520 Loss 1.685 Prec@(1,5) (66.1%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:31:11] \u001b[32mTrain: [ 50/50] Step 400/520 Loss 1.686 Prec@(1,5) (66.1%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:31:11] \u001b[32mTrain: [ 50/50] Step 420/520 Loss 1.686 Prec@(1,5) (66.1%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:31:12] \u001b[32mTrain: [ 50/50] Step 440/520 Loss 1.686 Prec@(1,5) (66.1%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:31:12] \u001b[32mTrain: [ 50/50] Step 460/520 Loss 1.683 Prec@(1,5) (66.2%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:31:13] \u001b[32mTrain: [ 50/50] Step 480/520 Loss 1.681 Prec@(1,5) (66.3%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:31:13] \u001b[32mTrain: [ 50/50] Step 500/520 Loss 1.682 Prec@(1,5) (66.2%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:31:14] \u001b[32mTrain: [ 50/50] Step 520/520 Loss 1.681 Prec@(1,5) (66.2%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:31:14] \u001b[32mTrain: [ 50/50] Final Prec@1 66.2320%\u001b[0m\n",
            "[2024-04-02 20:31:17] \u001b[32mValid: [ 50/50] Step 000/104 Loss 1.624 Prec@(1,5) (66.7%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:31:17] \u001b[32mValid: [ 50/50] Step 020/104 Loss 1.780 Prec@(1,5) (62.0%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:31:18] \u001b[32mValid: [ 50/50] Step 040/104 Loss 1.768 Prec@(1,5) (61.6%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:31:18] \u001b[32mValid: [ 50/50] Step 060/104 Loss 1.736 Prec@(1,5) (62.1%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:31:18] \u001b[32mValid: [ 50/50] Step 080/104 Loss 1.729 Prec@(1,5) (62.3%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:31:18] \u001b[32mValid: [ 50/50] Step 100/104 Loss 1.719 Prec@(1,5) (62.4%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:31:18] \u001b[32mValid: [ 50/50] Step 104/104 Loss 1.719 Prec@(1,5) (62.4%, 88.1%)\u001b[0m\n",
            "[2024-04-02 20:31:18] \u001b[32mValid: [ 50/50] Final Prec@1 62.3500%\u001b[0m\n",
            "Final best Prec@1 = 62.3500%\n",
            "{'lambd=1.263157894736842': 0.6138000170707703, 'lambd=1.6842105263157894': 0.6144000166893006, 'lambd=2.1052631578947367': 0.6146000204086304, 'lambd=2.526315789473684': 0.6115000175476074, 'lambd=2.9473684210526314': 0.6235000196456909}\n",
            "random_edges/lambd=3.3684210526315788/\n",
            "[2024-04-02 20:31:18] \u001b[32mFixed architecture: {'reduce_n2_p0': 'sepconv5x5', 'reduce_n2_p1': 'sepconv5x5', 'reduce_n3_p0': 'dilconv5x5', 'reduce_n3_p1': 'sepconv5x5', 'reduce_n3_p2': 'sepconv5x5', 'reduce_n4_p0': 'sepconv3x3', 'reduce_n4_p1': 'sepconv5x5', 'reduce_n4_p2': 'sepconv5x5', 'reduce_n4_p3': 'sepconv5x5', 'reduce_n5_p0': 'maxpool', 'reduce_n5_p1': 'sepconv3x3', 'reduce_n5_p2': 'sepconv5x5', 'reduce_n5_p3': 'sepconv5x5', 'reduce_n5_p4': 'maxpool', 'reduce_n2_switch': [1], 'reduce_n3_switch': [1], 'reduce_n4_switch': [0], 'reduce_n5_switch': [4]}\u001b[0m\n",
            "[2024-04-02 20:31:18] \u001b[32mEpoch 0 LR 0.025000\u001b[0m\n",
            "[2024-04-02 20:31:23] \u001b[32mTrain: [  1/50] Step 000/520 Loss 6.488 Prec@(1,5) (2.1%, 5.2%)\u001b[0m\n",
            "[2024-04-02 20:31:23] \u001b[32mTrain: [  1/50] Step 020/520 Loss 6.388 Prec@(1,5) (2.0%, 8.8%)\u001b[0m\n",
            "[2024-04-02 20:31:24] \u001b[32mTrain: [  1/50] Step 040/520 Loss 6.286 Prec@(1,5) (3.1%, 11.8%)\u001b[0m\n",
            "[2024-04-02 20:31:24] \u001b[32mTrain: [  1/50] Step 060/520 Loss 6.155 Prec@(1,5) (3.9%, 14.4%)\u001b[0m\n",
            "[2024-04-02 20:31:25] \u001b[32mTrain: [  1/50] Step 080/520 Loss 6.086 Prec@(1,5) (4.2%, 16.0%)\u001b[0m\n",
            "[2024-04-02 20:31:25] \u001b[32mTrain: [  1/50] Step 100/520 Loss 6.014 Prec@(1,5) (4.8%, 17.6%)\u001b[0m\n",
            "[2024-04-02 20:31:26] \u001b[32mTrain: [  1/50] Step 120/520 Loss 5.952 Prec@(1,5) (5.2%, 18.8%)\u001b[0m\n",
            "[2024-04-02 20:31:26] \u001b[32mTrain: [  1/50] Step 140/520 Loss 5.895 Prec@(1,5) (5.8%, 20.1%)\u001b[0m\n",
            "[2024-04-02 20:31:27] \u001b[32mTrain: [  1/50] Step 160/520 Loss 5.837 Prec@(1,5) (6.2%, 21.3%)\u001b[0m\n",
            "[2024-04-02 20:31:27] \u001b[32mTrain: [  1/50] Step 180/520 Loss 5.792 Prec@(1,5) (6.6%, 22.2%)\u001b[0m\n",
            "[2024-04-02 20:31:28] \u001b[32mTrain: [  1/50] Step 200/520 Loss 5.748 Prec@(1,5) (7.1%, 23.3%)\u001b[0m\n",
            "[2024-04-02 20:31:28] \u001b[32mTrain: [  1/50] Step 220/520 Loss 5.712 Prec@(1,5) (7.4%, 24.1%)\u001b[0m\n",
            "[2024-04-02 20:31:29] \u001b[32mTrain: [  1/50] Step 240/520 Loss 5.677 Prec@(1,5) (7.8%, 24.9%)\u001b[0m\n",
            "[2024-04-02 20:31:29] \u001b[32mTrain: [  1/50] Step 260/520 Loss 5.644 Prec@(1,5) (8.0%, 25.5%)\u001b[0m\n",
            "[2024-04-02 20:31:29] \u001b[32mTrain: [  1/50] Step 280/520 Loss 5.608 Prec@(1,5) (8.3%, 26.4%)\u001b[0m\n",
            "[2024-04-02 20:31:30] \u001b[32mTrain: [  1/50] Step 300/520 Loss 5.579 Prec@(1,5) (8.6%, 27.0%)\u001b[0m\n",
            "[2024-04-02 20:31:30] \u001b[32mTrain: [  1/50] Step 320/520 Loss 5.552 Prec@(1,5) (8.9%, 27.6%)\u001b[0m\n",
            "[2024-04-02 20:31:31] \u001b[32mTrain: [  1/50] Step 340/520 Loss 5.520 Prec@(1,5) (9.2%, 28.3%)\u001b[0m\n",
            "[2024-04-02 20:31:31] \u001b[32mTrain: [  1/50] Step 360/520 Loss 5.496 Prec@(1,5) (9.4%, 28.7%)\u001b[0m\n",
            "[2024-04-02 20:31:32] \u001b[32mTrain: [  1/50] Step 380/520 Loss 5.469 Prec@(1,5) (9.6%, 29.2%)\u001b[0m\n",
            "[2024-04-02 20:31:32] \u001b[32mTrain: [  1/50] Step 400/520 Loss 5.447 Prec@(1,5) (9.8%, 29.8%)\u001b[0m\n",
            "[2024-04-02 20:31:33] \u001b[32mTrain: [  1/50] Step 420/520 Loss 5.422 Prec@(1,5) (10.1%, 30.3%)\u001b[0m\n",
            "[2024-04-02 20:31:33] \u001b[32mTrain: [  1/50] Step 440/520 Loss 5.398 Prec@(1,5) (10.3%, 30.9%)\u001b[0m\n",
            "[2024-04-02 20:31:34] \u001b[32mTrain: [  1/50] Step 460/520 Loss 5.375 Prec@(1,5) (10.6%, 31.4%)\u001b[0m\n",
            "[2024-04-02 20:31:34] \u001b[32mTrain: [  1/50] Step 480/520 Loss 5.352 Prec@(1,5) (10.8%, 31.8%)\u001b[0m\n",
            "[2024-04-02 20:31:35] \u001b[32mTrain: [  1/50] Step 500/520 Loss 5.329 Prec@(1,5) (11.1%, 32.3%)\u001b[0m\n",
            "[2024-04-02 20:31:35] \u001b[32mTrain: [  1/50] Step 520/520 Loss 5.307 Prec@(1,5) (11.3%, 32.8%)\u001b[0m\n",
            "[2024-04-02 20:31:35] \u001b[32mTrain: [  1/50] Final Prec@1 11.3240%\u001b[0m\n",
            "[2024-04-02 20:31:39] \u001b[32mValid: [  1/50] Step 000/104 Loss 4.678 Prec@(1,5) (17.7%, 44.8%)\u001b[0m\n",
            "[2024-04-02 20:31:39] \u001b[32mValid: [  1/50] Step 020/104 Loss 4.659 Prec@(1,5) (15.9%, 40.9%)\u001b[0m\n",
            "[2024-04-02 20:31:39] \u001b[32mValid: [  1/50] Step 040/104 Loss 4.638 Prec@(1,5) (15.7%, 40.8%)\u001b[0m\n",
            "[2024-04-02 20:31:39] \u001b[32mValid: [  1/50] Step 060/104 Loss 4.592 Prec@(1,5) (16.1%, 41.3%)\u001b[0m\n",
            "[2024-04-02 20:31:39] \u001b[32mValid: [  1/50] Step 080/104 Loss 4.594 Prec@(1,5) (16.0%, 41.2%)\u001b[0m\n",
            "[2024-04-02 20:31:40] \u001b[32mValid: [  1/50] Step 100/104 Loss 4.596 Prec@(1,5) (15.9%, 41.2%)\u001b[0m\n",
            "[2024-04-02 20:31:40] \u001b[32mValid: [  1/50] Step 104/104 Loss 4.600 Prec@(1,5) (15.9%, 41.2%)\u001b[0m\n",
            "[2024-04-02 20:31:40] \u001b[32mValid: [  1/50] Final Prec@1 15.8800%\u001b[0m\n",
            "[2024-04-02 20:31:40] \u001b[32mEpoch 1 LR 0.024975\u001b[0m\n",
            "[2024-04-02 20:31:44] \u001b[32mTrain: [  2/50] Step 000/520 Loss 4.782 Prec@(1,5) (17.7%, 42.7%)\u001b[0m\n",
            "[2024-04-02 20:31:45] \u001b[32mTrain: [  2/50] Step 020/520 Loss 4.681 Prec@(1,5) (17.7%, 45.6%)\u001b[0m\n",
            "[2024-04-02 20:31:45] \u001b[32mTrain: [  2/50] Step 040/520 Loss 4.685 Prec@(1,5) (17.6%, 45.2%)\u001b[0m\n",
            "[2024-04-02 20:31:46] \u001b[32mTrain: [  2/50] Step 060/520 Loss 4.678 Prec@(1,5) (18.0%, 45.6%)\u001b[0m\n",
            "[2024-04-02 20:31:46] \u001b[32mTrain: [  2/50] Step 080/520 Loss 4.679 Prec@(1,5) (18.1%, 45.7%)\u001b[0m\n",
            "[2024-04-02 20:31:47] \u001b[32mTrain: [  2/50] Step 100/520 Loss 4.676 Prec@(1,5) (18.3%, 45.7%)\u001b[0m\n",
            "[2024-04-02 20:31:47] \u001b[32mTrain: [  2/50] Step 120/520 Loss 4.665 Prec@(1,5) (18.4%, 46.0%)\u001b[0m\n",
            "[2024-04-02 20:31:48] \u001b[32mTrain: [  2/50] Step 140/520 Loss 4.642 Prec@(1,5) (18.7%, 46.4%)\u001b[0m\n",
            "[2024-04-02 20:31:48] \u001b[32mTrain: [  2/50] Step 160/520 Loss 4.624 Prec@(1,5) (19.0%, 46.8%)\u001b[0m\n",
            "[2024-04-02 20:31:49] \u001b[32mTrain: [  2/50] Step 180/520 Loss 4.614 Prec@(1,5) (19.0%, 47.0%)\u001b[0m\n",
            "[2024-04-02 20:31:49] \u001b[32mTrain: [  2/50] Step 200/520 Loss 4.606 Prec@(1,5) (19.1%, 47.1%)\u001b[0m\n",
            "[2024-04-02 20:31:50] \u001b[32mTrain: [  2/50] Step 220/520 Loss 4.594 Prec@(1,5) (19.3%, 47.3%)\u001b[0m\n",
            "[2024-04-02 20:31:50] \u001b[32mTrain: [  2/50] Step 240/520 Loss 4.582 Prec@(1,5) (19.5%, 47.6%)\u001b[0m\n",
            "[2024-04-02 20:31:51] \u001b[32mTrain: [  2/50] Step 260/520 Loss 4.571 Prec@(1,5) (19.6%, 47.9%)\u001b[0m\n",
            "[2024-04-02 20:31:51] \u001b[32mTrain: [  2/50] Step 280/520 Loss 4.558 Prec@(1,5) (19.8%, 48.2%)\u001b[0m\n",
            "[2024-04-02 20:31:52] \u001b[32mTrain: [  2/50] Step 300/520 Loss 4.544 Prec@(1,5) (19.9%, 48.5%)\u001b[0m\n",
            "[2024-04-02 20:31:52] \u001b[32mTrain: [  2/50] Step 320/520 Loss 4.532 Prec@(1,5) (20.0%, 48.7%)\u001b[0m\n",
            "[2024-04-02 20:31:53] \u001b[32mTrain: [  2/50] Step 340/520 Loss 4.516 Prec@(1,5) (20.3%, 49.0%)\u001b[0m\n",
            "[2024-04-02 20:31:53] \u001b[32mTrain: [  2/50] Step 360/520 Loss 4.502 Prec@(1,5) (20.5%, 49.3%)\u001b[0m\n",
            "[2024-04-02 20:31:54] \u001b[32mTrain: [  2/50] Step 380/520 Loss 4.494 Prec@(1,5) (20.6%, 49.4%)\u001b[0m\n",
            "[2024-04-02 20:31:54] \u001b[32mTrain: [  2/50] Step 400/520 Loss 4.481 Prec@(1,5) (20.7%, 49.7%)\u001b[0m\n",
            "[2024-04-02 20:31:55] \u001b[32mTrain: [  2/50] Step 420/520 Loss 4.473 Prec@(1,5) (20.8%, 49.9%)\u001b[0m\n",
            "[2024-04-02 20:31:55] \u001b[32mTrain: [  2/50] Step 440/520 Loss 4.462 Prec@(1,5) (21.0%, 50.0%)\u001b[0m\n",
            "[2024-04-02 20:31:56] \u001b[32mTrain: [  2/50] Step 460/520 Loss 4.451 Prec@(1,5) (21.2%, 50.3%)\u001b[0m\n",
            "[2024-04-02 20:31:56] \u001b[32mTrain: [  2/50] Step 480/520 Loss 4.438 Prec@(1,5) (21.3%, 50.5%)\u001b[0m\n",
            "[2024-04-02 20:31:57] \u001b[32mTrain: [  2/50] Step 500/520 Loss 4.429 Prec@(1,5) (21.4%, 50.7%)\u001b[0m\n",
            "[2024-04-02 20:31:57] \u001b[32mTrain: [  2/50] Step 520/520 Loss 4.421 Prec@(1,5) (21.6%, 50.8%)\u001b[0m\n",
            "[2024-04-02 20:31:57] \u001b[32mTrain: [  2/50] Final Prec@1 21.6120%\u001b[0m\n",
            "[2024-04-02 20:32:01] \u001b[32mValid: [  2/50] Step 000/104 Loss 4.746 Prec@(1,5) (18.8%, 52.1%)\u001b[0m\n",
            "[2024-04-02 20:32:01] \u001b[32mValid: [  2/50] Step 020/104 Loss 4.265 Prec@(1,5) (22.1%, 51.7%)\u001b[0m\n",
            "[2024-04-02 20:32:01] \u001b[32mValid: [  2/50] Step 040/104 Loss 4.233 Prec@(1,5) (22.0%, 52.5%)\u001b[0m\n",
            "[2024-04-02 20:32:01] \u001b[32mValid: [  2/50] Step 060/104 Loss 4.176 Prec@(1,5) (22.7%, 52.8%)\u001b[0m\n",
            "[2024-04-02 20:32:02] \u001b[32mValid: [  2/50] Step 080/104 Loss 4.222 Prec@(1,5) (22.1%, 52.4%)\u001b[0m\n",
            "[2024-04-02 20:32:02] \u001b[32mValid: [  2/50] Step 100/104 Loss 4.233 Prec@(1,5) (21.9%, 52.1%)\u001b[0m\n",
            "[2024-04-02 20:32:02] \u001b[32mValid: [  2/50] Step 104/104 Loss 4.230 Prec@(1,5) (21.9%, 52.1%)\u001b[0m\n",
            "[2024-04-02 20:32:02] \u001b[32mValid: [  2/50] Final Prec@1 21.9000%\u001b[0m\n",
            "[2024-04-02 20:32:02] \u001b[32mEpoch 2 LR 0.024901\u001b[0m\n",
            "[2024-04-02 20:32:07] \u001b[32mTrain: [  3/50] Step 000/520 Loss 4.117 Prec@(1,5) (29.2%, 53.1%)\u001b[0m\n",
            "[2024-04-02 20:32:07] \u001b[32mTrain: [  3/50] Step 020/520 Loss 4.070 Prec@(1,5) (27.2%, 56.6%)\u001b[0m\n",
            "[2024-04-02 20:32:08] \u001b[32mTrain: [  3/50] Step 040/520 Loss 4.094 Prec@(1,5) (27.4%, 56.5%)\u001b[0m\n",
            "[2024-04-02 20:32:08] \u001b[32mTrain: [  3/50] Step 060/520 Loss 4.084 Prec@(1,5) (27.1%, 57.0%)\u001b[0m\n",
            "[2024-04-02 20:32:09] \u001b[32mTrain: [  3/50] Step 080/520 Loss 4.063 Prec@(1,5) (27.3%, 57.4%)\u001b[0m\n",
            "[2024-04-02 20:32:09] \u001b[32mTrain: [  3/50] Step 100/520 Loss 4.063 Prec@(1,5) (27.2%, 57.4%)\u001b[0m\n",
            "[2024-04-02 20:32:10] \u001b[32mTrain: [  3/50] Step 120/520 Loss 4.066 Prec@(1,5) (26.9%, 57.1%)\u001b[0m\n",
            "[2024-04-02 20:32:10] \u001b[32mTrain: [  3/50] Step 140/520 Loss 4.064 Prec@(1,5) (26.9%, 57.0%)\u001b[0m\n",
            "[2024-04-02 20:32:10] \u001b[32mTrain: [  3/50] Step 160/520 Loss 4.052 Prec@(1,5) (26.9%, 57.3%)\u001b[0m\n",
            "[2024-04-02 20:32:11] \u001b[32mTrain: [  3/50] Step 180/520 Loss 4.054 Prec@(1,5) (26.8%, 57.1%)\u001b[0m\n",
            "[2024-04-02 20:32:11] \u001b[32mTrain: [  3/50] Step 200/520 Loss 4.041 Prec@(1,5) (27.0%, 57.3%)\u001b[0m\n",
            "[2024-04-02 20:32:12] \u001b[32mTrain: [  3/50] Step 220/520 Loss 4.032 Prec@(1,5) (27.2%, 57.5%)\u001b[0m\n",
            "[2024-04-02 20:32:12] \u001b[32mTrain: [  3/50] Step 240/520 Loss 4.032 Prec@(1,5) (27.1%, 57.4%)\u001b[0m\n",
            "[2024-04-02 20:32:13] \u001b[32mTrain: [  3/50] Step 260/520 Loss 4.024 Prec@(1,5) (27.2%, 57.6%)\u001b[0m\n",
            "[2024-04-02 20:32:13] \u001b[32mTrain: [  3/50] Step 280/520 Loss 4.021 Prec@(1,5) (27.2%, 57.7%)\u001b[0m\n",
            "[2024-04-02 20:32:14] \u001b[32mTrain: [  3/50] Step 300/520 Loss 4.015 Prec@(1,5) (27.3%, 57.8%)\u001b[0m\n",
            "[2024-04-02 20:32:14] \u001b[32mTrain: [  3/50] Step 320/520 Loss 4.014 Prec@(1,5) (27.4%, 57.9%)\u001b[0m\n",
            "[2024-04-02 20:32:15] \u001b[32mTrain: [  3/50] Step 340/520 Loss 4.006 Prec@(1,5) (27.5%, 58.0%)\u001b[0m\n",
            "[2024-04-02 20:32:15] \u001b[32mTrain: [  3/50] Step 360/520 Loss 4.000 Prec@(1,5) (27.6%, 58.1%)\u001b[0m\n",
            "[2024-04-02 20:32:16] \u001b[32mTrain: [  3/50] Step 380/520 Loss 3.995 Prec@(1,5) (27.6%, 58.2%)\u001b[0m\n",
            "[2024-04-02 20:32:16] \u001b[32mTrain: [  3/50] Step 400/520 Loss 3.990 Prec@(1,5) (27.5%, 58.4%)\u001b[0m\n",
            "[2024-04-02 20:32:17] \u001b[32mTrain: [  3/50] Step 420/520 Loss 3.984 Prec@(1,5) (27.6%, 58.4%)\u001b[0m\n",
            "[2024-04-02 20:32:17] \u001b[32mTrain: [  3/50] Step 440/520 Loss 3.979 Prec@(1,5) (27.7%, 58.5%)\u001b[0m\n",
            "[2024-04-02 20:32:18] \u001b[32mTrain: [  3/50] Step 460/520 Loss 3.971 Prec@(1,5) (27.8%, 58.7%)\u001b[0m\n",
            "[2024-04-02 20:32:18] \u001b[32mTrain: [  3/50] Step 480/520 Loss 3.968 Prec@(1,5) (27.8%, 58.7%)\u001b[0m\n",
            "[2024-04-02 20:32:19] \u001b[32mTrain: [  3/50] Step 500/520 Loss 3.961 Prec@(1,5) (27.9%, 58.9%)\u001b[0m\n",
            "[2024-04-02 20:32:19] \u001b[32mTrain: [  3/50] Step 520/520 Loss 3.955 Prec@(1,5) (27.9%, 59.0%)\u001b[0m\n",
            "[2024-04-02 20:32:20] \u001b[32mTrain: [  3/50] Final Prec@1 27.9240%\u001b[0m\n",
            "[2024-04-02 20:32:23] \u001b[32mValid: [  3/50] Step 000/104 Loss 4.031 Prec@(1,5) (31.2%, 55.2%)\u001b[0m\n",
            "[2024-04-02 20:32:23] \u001b[32mValid: [  3/50] Step 020/104 Loss 3.822 Prec@(1,5) (28.7%, 59.8%)\u001b[0m\n",
            "[2024-04-02 20:32:23] \u001b[32mValid: [  3/50] Step 040/104 Loss 3.798 Prec@(1,5) (28.1%, 59.1%)\u001b[0m\n",
            "[2024-04-02 20:32:24] \u001b[32mValid: [  3/50] Step 060/104 Loss 3.784 Prec@(1,5) (28.7%, 58.7%)\u001b[0m\n",
            "[2024-04-02 20:32:24] \u001b[32mValid: [  3/50] Step 080/104 Loss 3.811 Prec@(1,5) (28.1%, 58.6%)\u001b[0m\n",
            "[2024-04-02 20:32:24] \u001b[32mValid: [  3/50] Step 100/104 Loss 3.816 Prec@(1,5) (28.2%, 58.7%)\u001b[0m\n",
            "[2024-04-02 20:32:24] \u001b[32mValid: [  3/50] Step 104/104 Loss 3.814 Prec@(1,5) (28.1%, 58.7%)\u001b[0m\n",
            "[2024-04-02 20:32:24] \u001b[32mValid: [  3/50] Final Prec@1 28.1200%\u001b[0m\n",
            "[2024-04-02 20:32:24] \u001b[32mEpoch 3 LR 0.024779\u001b[0m\n",
            "[2024-04-02 20:32:29] \u001b[32mTrain: [  4/50] Step 000/520 Loss 3.630 Prec@(1,5) (34.4%, 63.5%)\u001b[0m\n",
            "[2024-04-02 20:32:29] \u001b[32mTrain: [  4/50] Step 020/520 Loss 3.743 Prec@(1,5) (32.5%, 63.2%)\u001b[0m\n",
            "[2024-04-02 20:32:30] \u001b[32mTrain: [  4/50] Step 040/520 Loss 3.745 Prec@(1,5) (31.3%, 63.4%)\u001b[0m\n",
            "[2024-04-02 20:32:30] \u001b[32mTrain: [  4/50] Step 060/520 Loss 3.760 Prec@(1,5) (30.6%, 63.4%)\u001b[0m\n",
            "[2024-04-02 20:32:31] \u001b[32mTrain: [  4/50] Step 080/520 Loss 3.766 Prec@(1,5) (30.6%, 63.2%)\u001b[0m\n",
            "[2024-04-02 20:32:31] \u001b[32mTrain: [  4/50] Step 100/520 Loss 3.754 Prec@(1,5) (30.6%, 63.4%)\u001b[0m\n",
            "[2024-04-02 20:32:32] \u001b[32mTrain: [  4/50] Step 120/520 Loss 3.743 Prec@(1,5) (30.7%, 63.4%)\u001b[0m\n",
            "[2024-04-02 20:32:32] \u001b[32mTrain: [  4/50] Step 140/520 Loss 3.732 Prec@(1,5) (30.9%, 63.4%)\u001b[0m\n",
            "[2024-04-02 20:32:33] \u001b[32mTrain: [  4/50] Step 160/520 Loss 3.738 Prec@(1,5) (30.9%, 63.3%)\u001b[0m\n",
            "[2024-04-02 20:32:33] \u001b[32mTrain: [  4/50] Step 180/520 Loss 3.732 Prec@(1,5) (31.1%, 63.3%)\u001b[0m\n",
            "[2024-04-02 20:32:34] \u001b[32mTrain: [  4/50] Step 200/520 Loss 3.728 Prec@(1,5) (31.1%, 63.2%)\u001b[0m\n",
            "[2024-04-02 20:32:34] \u001b[32mTrain: [  4/50] Step 220/520 Loss 3.733 Prec@(1,5) (31.0%, 63.1%)\u001b[0m\n",
            "[2024-04-02 20:32:35] \u001b[32mTrain: [  4/50] Step 240/520 Loss 3.726 Prec@(1,5) (31.1%, 63.1%)\u001b[0m\n",
            "[2024-04-02 20:32:35] \u001b[32mTrain: [  4/50] Step 260/520 Loss 3.721 Prec@(1,5) (31.2%, 63.2%)\u001b[0m\n",
            "[2024-04-02 20:32:36] \u001b[32mTrain: [  4/50] Step 280/520 Loss 3.719 Prec@(1,5) (31.1%, 63.2%)\u001b[0m\n",
            "[2024-04-02 20:32:36] \u001b[32mTrain: [  4/50] Step 300/520 Loss 3.715 Prec@(1,5) (31.1%, 63.2%)\u001b[0m\n",
            "[2024-04-02 20:32:37] \u001b[32mTrain: [  4/50] Step 320/520 Loss 3.711 Prec@(1,5) (31.2%, 63.2%)\u001b[0m\n",
            "[2024-04-02 20:32:37] \u001b[32mTrain: [  4/50] Step 340/520 Loss 3.703 Prec@(1,5) (31.2%, 63.4%)\u001b[0m\n",
            "[2024-04-02 20:32:38] \u001b[32mTrain: [  4/50] Step 360/520 Loss 3.695 Prec@(1,5) (31.3%, 63.5%)\u001b[0m\n",
            "[2024-04-02 20:32:38] \u001b[32mTrain: [  4/50] Step 380/520 Loss 3.691 Prec@(1,5) (31.4%, 63.5%)\u001b[0m\n",
            "[2024-04-02 20:32:39] \u001b[32mTrain: [  4/50] Step 400/520 Loss 3.688 Prec@(1,5) (31.4%, 63.6%)\u001b[0m\n",
            "[2024-04-02 20:32:39] \u001b[32mTrain: [  4/50] Step 420/520 Loss 3.690 Prec@(1,5) (31.4%, 63.5%)\u001b[0m\n",
            "[2024-04-02 20:32:40] \u001b[32mTrain: [  4/50] Step 440/520 Loss 3.686 Prec@(1,5) (31.5%, 63.6%)\u001b[0m\n",
            "[2024-04-02 20:32:40] \u001b[32mTrain: [  4/50] Step 460/520 Loss 3.682 Prec@(1,5) (31.5%, 63.6%)\u001b[0m\n",
            "[2024-04-02 20:32:41] \u001b[32mTrain: [  4/50] Step 480/520 Loss 3.677 Prec@(1,5) (31.6%, 63.7%)\u001b[0m\n",
            "[2024-04-02 20:32:41] \u001b[32mTrain: [  4/50] Step 500/520 Loss 3.668 Prec@(1,5) (31.7%, 63.9%)\u001b[0m\n",
            "[2024-04-02 20:32:42] \u001b[32mTrain: [  4/50] Step 520/520 Loss 3.665 Prec@(1,5) (31.8%, 63.9%)\u001b[0m\n",
            "[2024-04-02 20:32:42] \u001b[32mTrain: [  4/50] Final Prec@1 31.7560%\u001b[0m\n",
            "[2024-04-02 20:32:46] \u001b[32mValid: [  4/50] Step 000/104 Loss 3.819 Prec@(1,5) (26.0%, 63.5%)\u001b[0m\n",
            "[2024-04-02 20:32:46] \u001b[32mValid: [  4/50] Step 020/104 Loss 3.788 Prec@(1,5) (29.4%, 63.0%)\u001b[0m\n",
            "[2024-04-02 20:32:46] \u001b[32mValid: [  4/50] Step 040/104 Loss 3.709 Prec@(1,5) (29.8%, 62.8%)\u001b[0m\n",
            "[2024-04-02 20:32:46] \u001b[32mValid: [  4/50] Step 060/104 Loss 3.643 Prec@(1,5) (30.5%, 63.0%)\u001b[0m\n",
            "[2024-04-02 20:32:46] \u001b[32mValid: [  4/50] Step 080/104 Loss 3.675 Prec@(1,5) (30.2%, 62.8%)\u001b[0m\n",
            "[2024-04-02 20:32:47] \u001b[32mValid: [  4/50] Step 100/104 Loss 3.674 Prec@(1,5) (30.4%, 62.9%)\u001b[0m\n",
            "[2024-04-02 20:32:47] \u001b[32mValid: [  4/50] Step 104/104 Loss 3.673 Prec@(1,5) (30.3%, 62.9%)\u001b[0m\n",
            "[2024-04-02 20:32:47] \u001b[32mValid: [  4/50] Final Prec@1 30.3300%\u001b[0m\n",
            "[2024-04-02 20:32:47] \u001b[32mEpoch 4 LR 0.024607\u001b[0m\n",
            "[2024-04-02 20:32:51] \u001b[32mTrain: [  5/50] Step 000/520 Loss 3.445 Prec@(1,5) (41.7%, 63.5%)\u001b[0m\n",
            "[2024-04-02 20:32:52] \u001b[32mTrain: [  5/50] Step 020/520 Loss 3.480 Prec@(1,5) (36.1%, 67.3%)\u001b[0m\n",
            "[2024-04-02 20:32:52] \u001b[32mTrain: [  5/50] Step 040/520 Loss 3.455 Prec@(1,5) (35.6%, 67.6%)\u001b[0m\n",
            "[2024-04-02 20:32:53] \u001b[32mTrain: [  5/50] Step 060/520 Loss 3.463 Prec@(1,5) (35.1%, 67.3%)\u001b[0m\n",
            "[2024-04-02 20:32:53] \u001b[32mTrain: [  5/50] Step 080/520 Loss 3.486 Prec@(1,5) (34.7%, 67.0%)\u001b[0m\n",
            "[2024-04-02 20:32:54] \u001b[32mTrain: [  5/50] Step 100/520 Loss 3.481 Prec@(1,5) (35.0%, 67.1%)\u001b[0m\n",
            "[2024-04-02 20:32:54] \u001b[32mTrain: [  5/50] Step 120/520 Loss 3.460 Prec@(1,5) (35.3%, 67.4%)\u001b[0m\n",
            "[2024-04-02 20:32:55] \u001b[32mTrain: [  5/50] Step 140/520 Loss 3.471 Prec@(1,5) (34.9%, 67.3%)\u001b[0m\n",
            "[2024-04-02 20:32:55] \u001b[32mTrain: [  5/50] Step 160/520 Loss 3.477 Prec@(1,5) (34.7%, 67.1%)\u001b[0m\n",
            "[2024-04-02 20:32:56] \u001b[32mTrain: [  5/50] Step 180/520 Loss 3.473 Prec@(1,5) (34.7%, 67.1%)\u001b[0m\n",
            "[2024-04-02 20:32:57] \u001b[32mTrain: [  5/50] Step 200/520 Loss 3.464 Prec@(1,5) (34.8%, 67.2%)\u001b[0m\n",
            "[2024-04-02 20:32:57] \u001b[32mTrain: [  5/50] Step 220/520 Loss 3.464 Prec@(1,5) (34.9%, 67.2%)\u001b[0m\n",
            "[2024-04-02 20:32:58] \u001b[32mTrain: [  5/50] Step 240/520 Loss 3.463 Prec@(1,5) (34.9%, 67.1%)\u001b[0m\n",
            "[2024-04-02 20:32:58] \u001b[32mTrain: [  5/50] Step 260/520 Loss 3.457 Prec@(1,5) (35.0%, 67.2%)\u001b[0m\n",
            "[2024-04-02 20:32:59] \u001b[32mTrain: [  5/50] Step 280/520 Loss 3.451 Prec@(1,5) (35.2%, 67.3%)\u001b[0m\n",
            "[2024-04-02 20:32:59] \u001b[32mTrain: [  5/50] Step 300/520 Loss 3.450 Prec@(1,5) (35.3%, 67.3%)\u001b[0m\n",
            "[2024-04-02 20:33:00] \u001b[32mTrain: [  5/50] Step 320/520 Loss 3.444 Prec@(1,5) (35.4%, 67.4%)\u001b[0m\n",
            "[2024-04-02 20:33:00] \u001b[32mTrain: [  5/50] Step 340/520 Loss 3.443 Prec@(1,5) (35.4%, 67.4%)\u001b[0m\n",
            "[2024-04-02 20:33:01] \u001b[32mTrain: [  5/50] Step 360/520 Loss 3.446 Prec@(1,5) (35.4%, 67.3%)\u001b[0m\n",
            "[2024-04-02 20:33:01] \u001b[32mTrain: [  5/50] Step 380/520 Loss 3.448 Prec@(1,5) (35.4%, 67.2%)\u001b[0m\n",
            "[2024-04-02 20:33:02] \u001b[32mTrain: [  5/50] Step 400/520 Loss 3.447 Prec@(1,5) (35.4%, 67.2%)\u001b[0m\n",
            "[2024-04-02 20:33:02] \u001b[32mTrain: [  5/50] Step 420/520 Loss 3.443 Prec@(1,5) (35.4%, 67.3%)\u001b[0m\n",
            "[2024-04-02 20:33:03] \u001b[32mTrain: [  5/50] Step 440/520 Loss 3.441 Prec@(1,5) (35.5%, 67.3%)\u001b[0m\n",
            "[2024-04-02 20:33:03] \u001b[32mTrain: [  5/50] Step 460/520 Loss 3.438 Prec@(1,5) (35.5%, 67.3%)\u001b[0m\n",
            "[2024-04-02 20:33:04] \u001b[32mTrain: [  5/50] Step 480/520 Loss 3.440 Prec@(1,5) (35.4%, 67.3%)\u001b[0m\n",
            "[2024-04-02 20:33:04] \u001b[32mTrain: [  5/50] Step 500/520 Loss 3.440 Prec@(1,5) (35.5%, 67.3%)\u001b[0m\n",
            "[2024-04-02 20:33:05] \u001b[32mTrain: [  5/50] Step 520/520 Loss 3.436 Prec@(1,5) (35.5%, 67.4%)\u001b[0m\n",
            "[2024-04-02 20:33:05] \u001b[32mTrain: [  5/50] Final Prec@1 35.5020%\u001b[0m\n",
            "[2024-04-02 20:33:08] \u001b[32mValid: [  5/50] Step 000/104 Loss 3.521 Prec@(1,5) (32.3%, 61.5%)\u001b[0m\n",
            "[2024-04-02 20:33:09] \u001b[32mValid: [  5/50] Step 020/104 Loss 3.501 Prec@(1,5) (33.6%, 67.1%)\u001b[0m\n",
            "[2024-04-02 20:33:09] \u001b[32mValid: [  5/50] Step 040/104 Loss 3.466 Prec@(1,5) (33.0%, 66.2%)\u001b[0m\n",
            "[2024-04-02 20:33:09] \u001b[32mValid: [  5/50] Step 060/104 Loss 3.430 Prec@(1,5) (33.6%, 66.8%)\u001b[0m\n",
            "[2024-04-02 20:33:09] \u001b[32mValid: [  5/50] Step 080/104 Loss 3.452 Prec@(1,5) (32.8%, 66.6%)\u001b[0m\n",
            "[2024-04-02 20:33:09] \u001b[32mValid: [  5/50] Step 100/104 Loss 3.447 Prec@(1,5) (32.9%, 66.5%)\u001b[0m\n",
            "[2024-04-02 20:33:09] \u001b[32mValid: [  5/50] Step 104/104 Loss 3.442 Prec@(1,5) (32.8%, 66.5%)\u001b[0m\n",
            "[2024-04-02 20:33:09] \u001b[32mValid: [  5/50] Final Prec@1 32.8200%\u001b[0m\n",
            "[2024-04-02 20:33:09] \u001b[32mEpoch 5 LR 0.024388\u001b[0m\n",
            "[2024-04-02 20:33:14] \u001b[32mTrain: [  6/50] Step 000/520 Loss 3.182 Prec@(1,5) (44.8%, 69.8%)\u001b[0m\n",
            "[2024-04-02 20:33:15] \u001b[32mTrain: [  6/50] Step 020/520 Loss 3.257 Prec@(1,5) (38.7%, 70.3%)\u001b[0m\n",
            "[2024-04-02 20:33:15] \u001b[32mTrain: [  6/50] Step 040/520 Loss 3.280 Prec@(1,5) (38.2%, 69.0%)\u001b[0m\n",
            "[2024-04-02 20:33:16] \u001b[32mTrain: [  6/50] Step 060/520 Loss 3.291 Prec@(1,5) (37.9%, 69.4%)\u001b[0m\n",
            "[2024-04-02 20:33:16] \u001b[32mTrain: [  6/50] Step 080/520 Loss 3.303 Prec@(1,5) (37.4%, 69.6%)\u001b[0m\n",
            "[2024-04-02 20:33:17] \u001b[32mTrain: [  6/50] Step 100/520 Loss 3.295 Prec@(1,5) (37.8%, 69.8%)\u001b[0m\n",
            "[2024-04-02 20:33:17] \u001b[32mTrain: [  6/50] Step 120/520 Loss 3.283 Prec@(1,5) (37.9%, 70.1%)\u001b[0m\n",
            "[2024-04-02 20:33:18] \u001b[32mTrain: [  6/50] Step 140/520 Loss 3.281 Prec@(1,5) (37.9%, 70.2%)\u001b[0m\n",
            "[2024-04-02 20:33:18] \u001b[32mTrain: [  6/50] Step 160/520 Loss 3.288 Prec@(1,5) (37.8%, 70.0%)\u001b[0m\n",
            "[2024-04-02 20:33:19] \u001b[32mTrain: [  6/50] Step 180/520 Loss 3.284 Prec@(1,5) (37.9%, 70.0%)\u001b[0m\n",
            "[2024-04-02 20:33:19] \u001b[32mTrain: [  6/50] Step 200/520 Loss 3.278 Prec@(1,5) (38.1%, 70.0%)\u001b[0m\n",
            "[2024-04-02 20:33:20] \u001b[32mTrain: [  6/50] Step 220/520 Loss 3.275 Prec@(1,5) (38.1%, 70.1%)\u001b[0m\n",
            "[2024-04-02 20:33:20] \u001b[32mTrain: [  6/50] Step 240/520 Loss 3.278 Prec@(1,5) (38.1%, 70.1%)\u001b[0m\n",
            "[2024-04-02 20:33:21] \u001b[32mTrain: [  6/50] Step 260/520 Loss 3.278 Prec@(1,5) (38.1%, 70.2%)\u001b[0m\n",
            "[2024-04-02 20:33:21] \u001b[32mTrain: [  6/50] Step 280/520 Loss 3.277 Prec@(1,5) (38.2%, 70.2%)\u001b[0m\n",
            "[2024-04-02 20:33:21] \u001b[32mTrain: [  6/50] Step 300/520 Loss 3.274 Prec@(1,5) (38.3%, 70.3%)\u001b[0m\n",
            "[2024-04-02 20:33:22] \u001b[32mTrain: [  6/50] Step 320/520 Loss 3.276 Prec@(1,5) (38.2%, 70.2%)\u001b[0m\n",
            "[2024-04-02 20:33:22] \u001b[32mTrain: [  6/50] Step 340/520 Loss 3.274 Prec@(1,5) (38.2%, 70.2%)\u001b[0m\n",
            "[2024-04-02 20:33:23] \u001b[32mTrain: [  6/50] Step 360/520 Loss 3.270 Prec@(1,5) (38.3%, 70.2%)\u001b[0m\n",
            "[2024-04-02 20:33:23] \u001b[32mTrain: [  6/50] Step 380/520 Loss 3.268 Prec@(1,5) (38.3%, 70.2%)\u001b[0m\n",
            "[2024-04-02 20:33:24] \u001b[32mTrain: [  6/50] Step 400/520 Loss 3.272 Prec@(1,5) (38.2%, 70.2%)\u001b[0m\n",
            "[2024-04-02 20:33:24] \u001b[32mTrain: [  6/50] Step 420/520 Loss 3.270 Prec@(1,5) (38.2%, 70.2%)\u001b[0m\n",
            "[2024-04-02 20:33:25] \u001b[32mTrain: [  6/50] Step 440/520 Loss 3.271 Prec@(1,5) (38.2%, 70.2%)\u001b[0m\n",
            "[2024-04-02 20:33:25] \u001b[32mTrain: [  6/50] Step 460/520 Loss 3.268 Prec@(1,5) (38.3%, 70.2%)\u001b[0m\n",
            "[2024-04-02 20:33:26] \u001b[32mTrain: [  6/50] Step 480/520 Loss 3.267 Prec@(1,5) (38.3%, 70.2%)\u001b[0m\n",
            "[2024-04-02 20:33:26] \u001b[32mTrain: [  6/50] Step 500/520 Loss 3.265 Prec@(1,5) (38.3%, 70.3%)\u001b[0m\n",
            "[2024-04-02 20:33:27] \u001b[32mTrain: [  6/50] Step 520/520 Loss 3.264 Prec@(1,5) (38.3%, 70.3%)\u001b[0m\n",
            "[2024-04-02 20:33:27] \u001b[32mTrain: [  6/50] Final Prec@1 38.2940%\u001b[0m\n",
            "[2024-04-02 20:33:31] \u001b[32mValid: [  6/50] Step 000/104 Loss 3.186 Prec@(1,5) (45.8%, 70.8%)\u001b[0m\n",
            "[2024-04-02 20:33:31] \u001b[32mValid: [  6/50] Step 020/104 Loss 3.361 Prec@(1,5) (36.7%, 68.8%)\u001b[0m\n",
            "[2024-04-02 20:33:31] \u001b[32mValid: [  6/50] Step 040/104 Loss 3.332 Prec@(1,5) (36.0%, 68.3%)\u001b[0m\n",
            "[2024-04-02 20:33:31] \u001b[32mValid: [  6/50] Step 060/104 Loss 3.311 Prec@(1,5) (36.2%, 68.0%)\u001b[0m\n",
            "[2024-04-02 20:33:31] \u001b[32mValid: [  6/50] Step 080/104 Loss 3.325 Prec@(1,5) (35.8%, 68.0%)\u001b[0m\n",
            "[2024-04-02 20:33:31] \u001b[32mValid: [  6/50] Step 100/104 Loss 3.326 Prec@(1,5) (35.8%, 68.1%)\u001b[0m\n",
            "[2024-04-02 20:33:31] \u001b[32mValid: [  6/50] Step 104/104 Loss 3.322 Prec@(1,5) (35.8%, 68.1%)\u001b[0m\n",
            "[2024-04-02 20:33:32] \u001b[32mValid: [  6/50] Final Prec@1 35.8400%\u001b[0m\n",
            "[2024-04-02 20:33:32] \u001b[32mEpoch 6 LR 0.024122\u001b[0m\n",
            "[2024-04-02 20:33:36] \u001b[32mTrain: [  7/50] Step 000/520 Loss 3.146 Prec@(1,5) (47.9%, 69.8%)\u001b[0m\n",
            "[2024-04-02 20:33:37] \u001b[32mTrain: [  7/50] Step 020/520 Loss 3.120 Prec@(1,5) (40.5%, 72.0%)\u001b[0m\n",
            "[2024-04-02 20:33:37] \u001b[32mTrain: [  7/50] Step 040/520 Loss 3.141 Prec@(1,5) (40.5%, 72.0%)\u001b[0m\n",
            "[2024-04-02 20:33:38] \u001b[32mTrain: [  7/50] Step 060/520 Loss 3.157 Prec@(1,5) (39.6%, 71.9%)\u001b[0m\n",
            "[2024-04-02 20:33:38] \u001b[32mTrain: [  7/50] Step 080/520 Loss 3.149 Prec@(1,5) (39.9%, 71.5%)\u001b[0m\n",
            "[2024-04-02 20:33:39] \u001b[32mTrain: [  7/50] Step 100/520 Loss 3.139 Prec@(1,5) (39.8%, 71.6%)\u001b[0m\n",
            "[2024-04-02 20:33:39] \u001b[32mTrain: [  7/50] Step 120/520 Loss 3.135 Prec@(1,5) (40.0%, 71.7%)\u001b[0m\n",
            "[2024-04-02 20:33:40] \u001b[32mTrain: [  7/50] Step 140/520 Loss 3.132 Prec@(1,5) (40.1%, 71.9%)\u001b[0m\n",
            "[2024-04-02 20:33:40] \u001b[32mTrain: [  7/50] Step 160/520 Loss 3.130 Prec@(1,5) (40.1%, 71.9%)\u001b[0m\n",
            "[2024-04-02 20:33:41] \u001b[32mTrain: [  7/50] Step 180/520 Loss 3.128 Prec@(1,5) (40.1%, 72.0%)\u001b[0m\n",
            "[2024-04-02 20:33:41] \u001b[32mTrain: [  7/50] Step 200/520 Loss 3.135 Prec@(1,5) (40.1%, 71.8%)\u001b[0m\n",
            "[2024-04-02 20:33:42] \u001b[32mTrain: [  7/50] Step 220/520 Loss 3.137 Prec@(1,5) (40.1%, 71.8%)\u001b[0m\n",
            "[2024-04-02 20:33:42] \u001b[32mTrain: [  7/50] Step 240/520 Loss 3.141 Prec@(1,5) (40.0%, 71.7%)\u001b[0m\n",
            "[2024-04-02 20:33:43] \u001b[32mTrain: [  7/50] Step 260/520 Loss 3.148 Prec@(1,5) (39.9%, 71.6%)\u001b[0m\n",
            "[2024-04-02 20:33:43] \u001b[32mTrain: [  7/50] Step 280/520 Loss 3.149 Prec@(1,5) (39.9%, 71.6%)\u001b[0m\n",
            "[2024-04-02 20:33:44] \u001b[32mTrain: [  7/50] Step 300/520 Loss 3.141 Prec@(1,5) (40.0%, 71.7%)\u001b[0m\n",
            "[2024-04-02 20:33:44] \u001b[32mTrain: [  7/50] Step 320/520 Loss 3.141 Prec@(1,5) (40.1%, 71.7%)\u001b[0m\n",
            "[2024-04-02 20:33:45] \u001b[32mTrain: [  7/50] Step 340/520 Loss 3.138 Prec@(1,5) (40.2%, 71.8%)\u001b[0m\n",
            "[2024-04-02 20:33:45] \u001b[32mTrain: [  7/50] Step 360/520 Loss 3.140 Prec@(1,5) (40.2%, 71.8%)\u001b[0m\n",
            "[2024-04-02 20:33:46] \u001b[32mTrain: [  7/50] Step 380/520 Loss 3.135 Prec@(1,5) (40.3%, 71.8%)\u001b[0m\n",
            "[2024-04-02 20:33:46] \u001b[32mTrain: [  7/50] Step 400/520 Loss 3.131 Prec@(1,5) (40.3%, 71.9%)\u001b[0m\n",
            "[2024-04-02 20:33:47] \u001b[32mTrain: [  7/50] Step 420/520 Loss 3.128 Prec@(1,5) (40.4%, 72.0%)\u001b[0m\n",
            "[2024-04-02 20:33:47] \u001b[32mTrain: [  7/50] Step 440/520 Loss 3.131 Prec@(1,5) (40.4%, 72.0%)\u001b[0m\n",
            "[2024-04-02 20:33:48] \u001b[32mTrain: [  7/50] Step 460/520 Loss 3.132 Prec@(1,5) (40.3%, 72.0%)\u001b[0m\n",
            "[2024-04-02 20:33:48] \u001b[32mTrain: [  7/50] Step 480/520 Loss 3.130 Prec@(1,5) (40.4%, 72.0%)\u001b[0m\n",
            "[2024-04-02 20:33:49] \u001b[32mTrain: [  7/50] Step 500/520 Loss 3.130 Prec@(1,5) (40.4%, 72.0%)\u001b[0m\n",
            "[2024-04-02 20:33:49] \u001b[32mTrain: [  7/50] Step 520/520 Loss 3.127 Prec@(1,5) (40.4%, 72.0%)\u001b[0m\n",
            "[2024-04-02 20:33:50] \u001b[32mTrain: [  7/50] Final Prec@1 40.4120%\u001b[0m\n",
            "[2024-04-02 20:33:53] \u001b[32mValid: [  7/50] Step 000/104 Loss 3.511 Prec@(1,5) (34.4%, 68.8%)\u001b[0m\n",
            "[2024-04-02 20:33:53] \u001b[32mValid: [  7/50] Step 020/104 Loss 3.518 Prec@(1,5) (37.1%, 68.4%)\u001b[0m\n",
            "[2024-04-02 20:33:54] \u001b[32mValid: [  7/50] Step 040/104 Loss 3.503 Prec@(1,5) (36.4%, 68.5%)\u001b[0m\n",
            "[2024-04-02 20:33:54] \u001b[32mValid: [  7/50] Step 060/104 Loss 3.464 Prec@(1,5) (36.7%, 68.6%)\u001b[0m\n",
            "[2024-04-02 20:33:54] \u001b[32mValid: [  7/50] Step 080/104 Loss 3.487 Prec@(1,5) (35.9%, 68.3%)\u001b[0m\n",
            "[2024-04-02 20:33:54] \u001b[32mValid: [  7/50] Step 100/104 Loss 3.501 Prec@(1,5) (35.9%, 68.2%)\u001b[0m\n",
            "[2024-04-02 20:33:54] \u001b[32mValid: [  7/50] Step 104/104 Loss 3.496 Prec@(1,5) (36.0%, 68.1%)\u001b[0m\n",
            "[2024-04-02 20:33:54] \u001b[32mValid: [  7/50] Final Prec@1 36.0200%\u001b[0m\n",
            "[2024-04-02 20:33:54] \u001b[32mEpoch 7 LR 0.023810\u001b[0m\n",
            "[2024-04-02 20:33:59] \u001b[32mTrain: [  8/50] Step 000/520 Loss 3.038 Prec@(1,5) (35.4%, 78.1%)\u001b[0m\n",
            "[2024-04-02 20:33:59] \u001b[32mTrain: [  8/50] Step 020/520 Loss 2.962 Prec@(1,5) (42.6%, 75.1%)\u001b[0m\n",
            "[2024-04-02 20:34:00] \u001b[32mTrain: [  8/50] Step 040/520 Loss 2.978 Prec@(1,5) (43.1%, 74.7%)\u001b[0m\n",
            "[2024-04-02 20:34:00] \u001b[32mTrain: [  8/50] Step 060/520 Loss 2.985 Prec@(1,5) (42.8%, 74.1%)\u001b[0m\n",
            "[2024-04-02 20:34:01] \u001b[32mTrain: [  8/50] Step 080/520 Loss 2.988 Prec@(1,5) (42.5%, 74.3%)\u001b[0m\n",
            "[2024-04-02 20:34:01] \u001b[32mTrain: [  8/50] Step 100/520 Loss 2.982 Prec@(1,5) (42.7%, 74.3%)\u001b[0m\n",
            "[2024-04-02 20:34:02] \u001b[32mTrain: [  8/50] Step 120/520 Loss 2.976 Prec@(1,5) (42.9%, 74.4%)\u001b[0m\n",
            "[2024-04-02 20:34:02] \u001b[32mTrain: [  8/50] Step 140/520 Loss 2.988 Prec@(1,5) (42.8%, 74.2%)\u001b[0m\n",
            "[2024-04-02 20:34:03] \u001b[32mTrain: [  8/50] Step 160/520 Loss 2.995 Prec@(1,5) (42.5%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:34:03] \u001b[32mTrain: [  8/50] Step 180/520 Loss 2.995 Prec@(1,5) (42.6%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:34:04] \u001b[32mTrain: [  8/50] Step 200/520 Loss 2.996 Prec@(1,5) (42.6%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:34:05] \u001b[32mTrain: [  8/50] Step 220/520 Loss 3.002 Prec@(1,5) (42.6%, 73.9%)\u001b[0m\n",
            "[2024-04-02 20:34:05] \u001b[32mTrain: [  8/50] Step 240/520 Loss 3.001 Prec@(1,5) (42.5%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:34:06] \u001b[32mTrain: [  8/50] Step 260/520 Loss 3.005 Prec@(1,5) (42.4%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:34:06] \u001b[32mTrain: [  8/50] Step 280/520 Loss 3.011 Prec@(1,5) (42.3%, 73.9%)\u001b[0m\n",
            "[2024-04-02 20:34:07] \u001b[32mTrain: [  8/50] Step 300/520 Loss 3.009 Prec@(1,5) (42.4%, 73.9%)\u001b[0m\n",
            "[2024-04-02 20:34:07] \u001b[32mTrain: [  8/50] Step 320/520 Loss 3.008 Prec@(1,5) (42.4%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:34:08] \u001b[32mTrain: [  8/50] Step 340/520 Loss 3.007 Prec@(1,5) (42.3%, 73.9%)\u001b[0m\n",
            "[2024-04-02 20:34:08] \u001b[32mTrain: [  8/50] Step 360/520 Loss 3.004 Prec@(1,5) (42.4%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:34:08] \u001b[32mTrain: [  8/50] Step 380/520 Loss 3.006 Prec@(1,5) (42.3%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:34:09] \u001b[32mTrain: [  8/50] Step 400/520 Loss 3.007 Prec@(1,5) (42.3%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:34:09] \u001b[32mTrain: [  8/50] Step 420/520 Loss 3.007 Prec@(1,5) (42.3%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:34:10] \u001b[32mTrain: [  8/50] Step 440/520 Loss 3.010 Prec@(1,5) (42.2%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:34:10] \u001b[32mTrain: [  8/50] Step 460/520 Loss 3.009 Prec@(1,5) (42.3%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:34:11] \u001b[32mTrain: [  8/50] Step 480/520 Loss 3.009 Prec@(1,5) (42.2%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:34:11] \u001b[32mTrain: [  8/50] Step 500/520 Loss 3.010 Prec@(1,5) (42.2%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:34:12] \u001b[32mTrain: [  8/50] Step 520/520 Loss 3.013 Prec@(1,5) (42.2%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:34:12] \u001b[32mTrain: [  8/50] Final Prec@1 42.1800%\u001b[0m\n",
            "[2024-04-02 20:34:16] \u001b[32mValid: [  8/50] Step 000/104 Loss 3.180 Prec@(1,5) (38.5%, 70.8%)\u001b[0m\n",
            "[2024-04-02 20:34:16] \u001b[32mValid: [  8/50] Step 020/104 Loss 3.171 Prec@(1,5) (39.1%, 71.8%)\u001b[0m\n",
            "[2024-04-02 20:34:16] \u001b[32mValid: [  8/50] Step 040/104 Loss 3.153 Prec@(1,5) (39.2%, 71.1%)\u001b[0m\n",
            "[2024-04-02 20:34:16] \u001b[32mValid: [  8/50] Step 060/104 Loss 3.099 Prec@(1,5) (39.7%, 71.5%)\u001b[0m\n",
            "[2024-04-02 20:34:16] \u001b[32mValid: [  8/50] Step 080/104 Loss 3.099 Prec@(1,5) (39.2%, 71.7%)\u001b[0m\n",
            "[2024-04-02 20:34:16] \u001b[32mValid: [  8/50] Step 100/104 Loss 3.107 Prec@(1,5) (39.3%, 71.7%)\u001b[0m\n",
            "[2024-04-02 20:34:16] \u001b[32mValid: [  8/50] Step 104/104 Loss 3.104 Prec@(1,5) (39.2%, 71.7%)\u001b[0m\n",
            "[2024-04-02 20:34:17] \u001b[32mValid: [  8/50] Final Prec@1 39.1600%\u001b[0m\n",
            "[2024-04-02 20:34:17] \u001b[32mEpoch 8 LR 0.023454\u001b[0m\n",
            "[2024-04-02 20:34:21] \u001b[32mTrain: [  9/50] Step 000/520 Loss 3.083 Prec@(1,5) (41.7%, 68.8%)\u001b[0m\n",
            "[2024-04-02 20:34:22] \u001b[32mTrain: [  9/50] Step 020/520 Loss 2.954 Prec@(1,5) (43.3%, 74.7%)\u001b[0m\n",
            "[2024-04-02 20:34:22] \u001b[32mTrain: [  9/50] Step 040/520 Loss 2.912 Prec@(1,5) (44.5%, 75.2%)\u001b[0m\n",
            "[2024-04-02 20:34:23] \u001b[32mTrain: [  9/50] Step 060/520 Loss 2.893 Prec@(1,5) (44.3%, 75.4%)\u001b[0m\n",
            "[2024-04-02 20:34:23] \u001b[32mTrain: [  9/50] Step 080/520 Loss 2.884 Prec@(1,5) (44.6%, 75.7%)\u001b[0m\n",
            "[2024-04-02 20:34:24] \u001b[32mTrain: [  9/50] Step 100/520 Loss 2.878 Prec@(1,5) (44.7%, 75.6%)\u001b[0m\n",
            "[2024-04-02 20:34:24] \u001b[32mTrain: [  9/50] Step 120/520 Loss 2.896 Prec@(1,5) (44.2%, 75.4%)\u001b[0m\n",
            "[2024-04-02 20:34:25] \u001b[32mTrain: [  9/50] Step 140/520 Loss 2.909 Prec@(1,5) (43.8%, 75.2%)\u001b[0m\n",
            "[2024-04-02 20:34:25] \u001b[32mTrain: [  9/50] Step 160/520 Loss 2.900 Prec@(1,5) (43.8%, 75.5%)\u001b[0m\n",
            "[2024-04-02 20:34:26] \u001b[32mTrain: [  9/50] Step 180/520 Loss 2.903 Prec@(1,5) (43.8%, 75.5%)\u001b[0m\n",
            "[2024-04-02 20:34:26] \u001b[32mTrain: [  9/50] Step 200/520 Loss 2.914 Prec@(1,5) (43.6%, 75.3%)\u001b[0m\n",
            "[2024-04-02 20:34:27] \u001b[32mTrain: [  9/50] Step 220/520 Loss 2.924 Prec@(1,5) (43.4%, 75.2%)\u001b[0m\n",
            "[2024-04-02 20:34:27] \u001b[32mTrain: [  9/50] Step 240/520 Loss 2.917 Prec@(1,5) (43.6%, 75.3%)\u001b[0m\n",
            "[2024-04-02 20:34:28] \u001b[32mTrain: [  9/50] Step 260/520 Loss 2.914 Prec@(1,5) (43.6%, 75.3%)\u001b[0m\n",
            "[2024-04-02 20:34:28] \u001b[32mTrain: [  9/50] Step 280/520 Loss 2.912 Prec@(1,5) (43.7%, 75.4%)\u001b[0m\n",
            "[2024-04-02 20:34:29] \u001b[32mTrain: [  9/50] Step 300/520 Loss 2.909 Prec@(1,5) (43.6%, 75.4%)\u001b[0m\n",
            "[2024-04-02 20:34:29] \u001b[32mTrain: [  9/50] Step 320/520 Loss 2.913 Prec@(1,5) (43.6%, 75.4%)\u001b[0m\n",
            "[2024-04-02 20:34:30] \u001b[32mTrain: [  9/50] Step 340/520 Loss 2.912 Prec@(1,5) (43.6%, 75.4%)\u001b[0m\n",
            "[2024-04-02 20:34:30] \u001b[32mTrain: [  9/50] Step 360/520 Loss 2.909 Prec@(1,5) (43.7%, 75.4%)\u001b[0m\n",
            "[2024-04-02 20:34:31] \u001b[32mTrain: [  9/50] Step 380/520 Loss 2.909 Prec@(1,5) (43.7%, 75.4%)\u001b[0m\n",
            "[2024-04-02 20:34:31] \u001b[32mTrain: [  9/50] Step 400/520 Loss 2.907 Prec@(1,5) (43.7%, 75.5%)\u001b[0m\n",
            "[2024-04-02 20:34:32] \u001b[32mTrain: [  9/50] Step 420/520 Loss 2.907 Prec@(1,5) (43.8%, 75.5%)\u001b[0m\n",
            "[2024-04-02 20:34:32] \u001b[32mTrain: [  9/50] Step 440/520 Loss 2.909 Prec@(1,5) (43.7%, 75.5%)\u001b[0m\n",
            "[2024-04-02 20:34:32] \u001b[32mTrain: [  9/50] Step 460/520 Loss 2.910 Prec@(1,5) (43.7%, 75.5%)\u001b[0m\n",
            "[2024-04-02 20:34:33] \u001b[32mTrain: [  9/50] Step 480/520 Loss 2.913 Prec@(1,5) (43.7%, 75.4%)\u001b[0m\n",
            "[2024-04-02 20:34:33] \u001b[32mTrain: [  9/50] Step 500/520 Loss 2.916 Prec@(1,5) (43.6%, 75.4%)\u001b[0m\n",
            "[2024-04-02 20:34:34] \u001b[32mTrain: [  9/50] Step 520/520 Loss 2.916 Prec@(1,5) (43.6%, 75.4%)\u001b[0m\n",
            "[2024-04-02 20:34:34] \u001b[32mTrain: [  9/50] Final Prec@1 43.6340%\u001b[0m\n",
            "[2024-04-02 20:34:38] \u001b[32mValid: [  9/50] Step 000/104 Loss 2.912 Prec@(1,5) (50.0%, 72.9%)\u001b[0m\n",
            "[2024-04-02 20:34:38] \u001b[32mValid: [  9/50] Step 020/104 Loss 3.181 Prec@(1,5) (39.7%, 71.2%)\u001b[0m\n",
            "[2024-04-02 20:34:38] \u001b[32mValid: [  9/50] Step 040/104 Loss 3.161 Prec@(1,5) (39.7%, 71.3%)\u001b[0m\n",
            "[2024-04-02 20:34:38] \u001b[32mValid: [  9/50] Step 060/104 Loss 3.125 Prec@(1,5) (40.0%, 71.6%)\u001b[0m\n",
            "[2024-04-02 20:34:38] \u001b[32mValid: [  9/50] Step 080/104 Loss 3.145 Prec@(1,5) (39.5%, 71.3%)\u001b[0m\n",
            "[2024-04-02 20:34:39] \u001b[32mValid: [  9/50] Step 100/104 Loss 3.138 Prec@(1,5) (39.5%, 71.5%)\u001b[0m\n",
            "[2024-04-02 20:34:39] \u001b[32mValid: [  9/50] Step 104/104 Loss 3.140 Prec@(1,5) (39.5%, 71.4%)\u001b[0m\n",
            "[2024-04-02 20:34:39] \u001b[32mValid: [  9/50] Final Prec@1 39.5300%\u001b[0m\n",
            "[2024-04-02 20:34:39] \u001b[32mEpoch 9 LR 0.023054\u001b[0m\n",
            "[2024-04-02 20:34:43] \u001b[32mTrain: [ 10/50] Step 000/520 Loss 2.716 Prec@(1,5) (44.8%, 79.2%)\u001b[0m\n",
            "[2024-04-02 20:34:44] \u001b[32mTrain: [ 10/50] Step 020/520 Loss 2.895 Prec@(1,5) (43.7%, 76.2%)\u001b[0m\n",
            "[2024-04-02 20:34:44] \u001b[32mTrain: [ 10/50] Step 040/520 Loss 2.914 Prec@(1,5) (43.3%, 75.3%)\u001b[0m\n",
            "[2024-04-02 20:34:45] \u001b[32mTrain: [ 10/50] Step 060/520 Loss 2.889 Prec@(1,5) (43.7%, 75.8%)\u001b[0m\n",
            "[2024-04-02 20:34:45] \u001b[32mTrain: [ 10/50] Step 080/520 Loss 2.854 Prec@(1,5) (44.5%, 75.8%)\u001b[0m\n",
            "[2024-04-02 20:34:46] \u001b[32mTrain: [ 10/50] Step 100/520 Loss 2.847 Prec@(1,5) (44.6%, 75.7%)\u001b[0m\n",
            "[2024-04-02 20:34:46] \u001b[32mTrain: [ 10/50] Step 120/520 Loss 2.861 Prec@(1,5) (44.6%, 75.5%)\u001b[0m\n",
            "[2024-04-02 20:34:47] \u001b[32mTrain: [ 10/50] Step 140/520 Loss 2.853 Prec@(1,5) (44.9%, 75.6%)\u001b[0m\n",
            "[2024-04-02 20:34:47] \u001b[32mTrain: [ 10/50] Step 160/520 Loss 2.861 Prec@(1,5) (44.7%, 75.6%)\u001b[0m\n",
            "[2024-04-02 20:34:48] \u001b[32mTrain: [ 10/50] Step 180/520 Loss 2.847 Prec@(1,5) (45.0%, 75.9%)\u001b[0m\n",
            "[2024-04-02 20:34:48] \u001b[32mTrain: [ 10/50] Step 200/520 Loss 2.845 Prec@(1,5) (44.8%, 76.0%)\u001b[0m\n",
            "[2024-04-02 20:34:49] \u001b[32mTrain: [ 10/50] Step 220/520 Loss 2.855 Prec@(1,5) (44.7%, 75.9%)\u001b[0m\n",
            "[2024-04-02 20:34:49] \u001b[32mTrain: [ 10/50] Step 240/520 Loss 2.858 Prec@(1,5) (44.6%, 76.0%)\u001b[0m\n",
            "[2024-04-02 20:34:50] \u001b[32mTrain: [ 10/50] Step 260/520 Loss 2.858 Prec@(1,5) (44.6%, 76.0%)\u001b[0m\n",
            "[2024-04-02 20:34:50] \u001b[32mTrain: [ 10/50] Step 280/520 Loss 2.860 Prec@(1,5) (44.7%, 75.9%)\u001b[0m\n",
            "[2024-04-02 20:34:51] \u001b[32mTrain: [ 10/50] Step 300/520 Loss 2.855 Prec@(1,5) (44.7%, 75.9%)\u001b[0m\n",
            "[2024-04-02 20:34:51] \u001b[32mTrain: [ 10/50] Step 320/520 Loss 2.848 Prec@(1,5) (44.9%, 75.9%)\u001b[0m\n",
            "[2024-04-02 20:34:52] \u001b[32mTrain: [ 10/50] Step 340/520 Loss 2.843 Prec@(1,5) (45.0%, 76.0%)\u001b[0m\n",
            "[2024-04-02 20:34:52] \u001b[32mTrain: [ 10/50] Step 360/520 Loss 2.845 Prec@(1,5) (45.0%, 76.0%)\u001b[0m\n",
            "[2024-04-02 20:34:53] \u001b[32mTrain: [ 10/50] Step 380/520 Loss 2.845 Prec@(1,5) (44.9%, 76.0%)\u001b[0m\n",
            "[2024-04-02 20:34:54] \u001b[32mTrain: [ 10/50] Step 400/520 Loss 2.841 Prec@(1,5) (45.0%, 76.1%)\u001b[0m\n",
            "[2024-04-02 20:34:54] \u001b[32mTrain: [ 10/50] Step 420/520 Loss 2.843 Prec@(1,5) (45.0%, 76.1%)\u001b[0m\n",
            "[2024-04-02 20:34:55] \u001b[32mTrain: [ 10/50] Step 440/520 Loss 2.842 Prec@(1,5) (45.0%, 76.1%)\u001b[0m\n",
            "[2024-04-02 20:34:55] \u001b[32mTrain: [ 10/50] Step 460/520 Loss 2.844 Prec@(1,5) (45.0%, 76.1%)\u001b[0m\n",
            "[2024-04-02 20:34:56] \u001b[32mTrain: [ 10/50] Step 480/520 Loss 2.835 Prec@(1,5) (45.1%, 76.2%)\u001b[0m\n",
            "[2024-04-02 20:34:56] \u001b[32mTrain: [ 10/50] Step 500/520 Loss 2.832 Prec@(1,5) (45.2%, 76.3%)\u001b[0m\n",
            "[2024-04-02 20:34:57] \u001b[32mTrain: [ 10/50] Step 520/520 Loss 2.832 Prec@(1,5) (45.2%, 76.3%)\u001b[0m\n",
            "[2024-04-02 20:34:57] \u001b[32mTrain: [ 10/50] Final Prec@1 45.2300%\u001b[0m\n",
            "[2024-04-02 20:35:00] \u001b[32mValid: [ 10/50] Step 000/104 Loss 2.694 Prec@(1,5) (49.0%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:35:00] \u001b[32mValid: [ 10/50] Step 020/104 Loss 3.082 Prec@(1,5) (41.3%, 73.5%)\u001b[0m\n",
            "[2024-04-02 20:35:01] \u001b[32mValid: [ 10/50] Step 040/104 Loss 3.076 Prec@(1,5) (40.9%, 72.5%)\u001b[0m\n",
            "[2024-04-02 20:35:01] \u001b[32mValid: [ 10/50] Step 060/104 Loss 3.032 Prec@(1,5) (41.3%, 73.2%)\u001b[0m\n",
            "[2024-04-02 20:35:01] \u001b[32mValid: [ 10/50] Step 080/104 Loss 3.042 Prec@(1,5) (40.8%, 72.9%)\u001b[0m\n",
            "[2024-04-02 20:35:01] \u001b[32mValid: [ 10/50] Step 100/104 Loss 3.046 Prec@(1,5) (40.9%, 73.1%)\u001b[0m\n",
            "[2024-04-02 20:35:01] \u001b[32mValid: [ 10/50] Step 104/104 Loss 3.046 Prec@(1,5) (40.9%, 73.1%)\u001b[0m\n",
            "[2024-04-02 20:35:01] \u001b[32mValid: [ 10/50] Final Prec@1 40.9000%\u001b[0m\n",
            "[2024-04-02 20:35:01] \u001b[32mEpoch 10 LR 0.022613\u001b[0m\n",
            "[2024-04-02 20:35:06] \u001b[32mTrain: [ 11/50] Step 000/520 Loss 2.722 Prec@(1,5) (46.9%, 77.1%)\u001b[0m\n",
            "[2024-04-02 20:35:06] \u001b[32mTrain: [ 11/50] Step 020/520 Loss 2.739 Prec@(1,5) (47.4%, 76.8%)\u001b[0m\n",
            "[2024-04-02 20:35:07] \u001b[32mTrain: [ 11/50] Step 040/520 Loss 2.696 Prec@(1,5) (47.6%, 77.2%)\u001b[0m\n",
            "[2024-04-02 20:35:07] \u001b[32mTrain: [ 11/50] Step 060/520 Loss 2.699 Prec@(1,5) (47.7%, 77.5%)\u001b[0m\n",
            "[2024-04-02 20:35:08] \u001b[32mTrain: [ 11/50] Step 080/520 Loss 2.716 Prec@(1,5) (47.3%, 77.7%)\u001b[0m\n",
            "[2024-04-02 20:35:08] \u001b[32mTrain: [ 11/50] Step 100/520 Loss 2.706 Prec@(1,5) (47.5%, 77.8%)\u001b[0m\n",
            "[2024-04-02 20:35:09] \u001b[32mTrain: [ 11/50] Step 120/520 Loss 2.720 Prec@(1,5) (47.3%, 77.7%)\u001b[0m\n",
            "[2024-04-02 20:35:09] \u001b[32mTrain: [ 11/50] Step 140/520 Loss 2.726 Prec@(1,5) (47.1%, 77.7%)\u001b[0m\n",
            "[2024-04-02 20:35:10] \u001b[32mTrain: [ 11/50] Step 160/520 Loss 2.725 Prec@(1,5) (47.0%, 77.9%)\u001b[0m\n",
            "[2024-04-02 20:35:11] \u001b[32mTrain: [ 11/50] Step 180/520 Loss 2.723 Prec@(1,5) (46.8%, 78.0%)\u001b[0m\n",
            "[2024-04-02 20:35:11] \u001b[32mTrain: [ 11/50] Step 200/520 Loss 2.725 Prec@(1,5) (46.8%, 77.9%)\u001b[0m\n",
            "[2024-04-02 20:35:12] \u001b[32mTrain: [ 11/50] Step 220/520 Loss 2.730 Prec@(1,5) (46.7%, 77.9%)\u001b[0m\n",
            "[2024-04-02 20:35:12] \u001b[32mTrain: [ 11/50] Step 240/520 Loss 2.735 Prec@(1,5) (46.7%, 77.8%)\u001b[0m\n",
            "[2024-04-02 20:35:13] \u001b[32mTrain: [ 11/50] Step 260/520 Loss 2.744 Prec@(1,5) (46.5%, 77.7%)\u001b[0m\n",
            "[2024-04-02 20:35:13] \u001b[32mTrain: [ 11/50] Step 280/520 Loss 2.746 Prec@(1,5) (46.4%, 77.6%)\u001b[0m\n",
            "[2024-04-02 20:35:14] \u001b[32mTrain: [ 11/50] Step 300/520 Loss 2.746 Prec@(1,5) (46.4%, 77.7%)\u001b[0m\n",
            "[2024-04-02 20:35:14] \u001b[32mTrain: [ 11/50] Step 320/520 Loss 2.747 Prec@(1,5) (46.4%, 77.7%)\u001b[0m\n",
            "[2024-04-02 20:35:15] \u001b[32mTrain: [ 11/50] Step 340/520 Loss 2.749 Prec@(1,5) (46.5%, 77.7%)\u001b[0m\n",
            "[2024-04-02 20:35:15] \u001b[32mTrain: [ 11/50] Step 360/520 Loss 2.745 Prec@(1,5) (46.6%, 77.7%)\u001b[0m\n",
            "[2024-04-02 20:35:16] \u001b[32mTrain: [ 11/50] Step 380/520 Loss 2.748 Prec@(1,5) (46.5%, 77.6%)\u001b[0m\n",
            "[2024-04-02 20:35:16] \u001b[32mTrain: [ 11/50] Step 400/520 Loss 2.746 Prec@(1,5) (46.5%, 77.7%)\u001b[0m\n",
            "[2024-04-02 20:35:17] \u001b[32mTrain: [ 11/50] Step 420/520 Loss 2.747 Prec@(1,5) (46.5%, 77.6%)\u001b[0m\n",
            "[2024-04-02 20:35:17] \u001b[32mTrain: [ 11/50] Step 440/520 Loss 2.743 Prec@(1,5) (46.6%, 77.7%)\u001b[0m\n",
            "[2024-04-02 20:35:18] \u001b[32mTrain: [ 11/50] Step 460/520 Loss 2.745 Prec@(1,5) (46.5%, 77.7%)\u001b[0m\n",
            "[2024-04-02 20:35:18] \u001b[32mTrain: [ 11/50] Step 480/520 Loss 2.746 Prec@(1,5) (46.6%, 77.6%)\u001b[0m\n",
            "[2024-04-02 20:35:19] \u001b[32mTrain: [ 11/50] Step 500/520 Loss 2.746 Prec@(1,5) (46.6%, 77.6%)\u001b[0m\n",
            "[2024-04-02 20:35:19] \u001b[32mTrain: [ 11/50] Step 520/520 Loss 2.746 Prec@(1,5) (46.6%, 77.6%)\u001b[0m\n",
            "[2024-04-02 20:35:19] \u001b[32mTrain: [ 11/50] Final Prec@1 46.5960%\u001b[0m\n",
            "[2024-04-02 20:35:23] \u001b[32mValid: [ 11/50] Step 000/104 Loss 3.023 Prec@(1,5) (43.8%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:35:23] \u001b[32mValid: [ 11/50] Step 020/104 Loss 2.875 Prec@(1,5) (44.0%, 75.7%)\u001b[0m\n",
            "[2024-04-02 20:35:23] \u001b[32mValid: [ 11/50] Step 040/104 Loss 2.851 Prec@(1,5) (43.3%, 75.5%)\u001b[0m\n",
            "[2024-04-02 20:35:23] \u001b[32mValid: [ 11/50] Step 060/104 Loss 2.788 Prec@(1,5) (44.0%, 75.8%)\u001b[0m\n",
            "[2024-04-02 20:35:24] \u001b[32mValid: [ 11/50] Step 080/104 Loss 2.806 Prec@(1,5) (43.7%, 75.8%)\u001b[0m\n",
            "[2024-04-02 20:35:24] \u001b[32mValid: [ 11/50] Step 100/104 Loss 2.793 Prec@(1,5) (43.9%, 75.8%)\u001b[0m\n",
            "[2024-04-02 20:35:24] \u001b[32mValid: [ 11/50] Step 104/104 Loss 2.793 Prec@(1,5) (43.9%, 75.8%)\u001b[0m\n",
            "[2024-04-02 20:35:24] \u001b[32mValid: [ 11/50] Final Prec@1 43.8600%\u001b[0m\n",
            "[2024-04-02 20:35:24] \u001b[32mEpoch 11 LR 0.022132\u001b[0m\n",
            "[2024-04-02 20:35:29] \u001b[32mTrain: [ 12/50] Step 000/520 Loss 2.456 Prec@(1,5) (53.1%, 78.1%)\u001b[0m\n",
            "[2024-04-02 20:35:29] \u001b[32mTrain: [ 12/50] Step 020/520 Loss 2.705 Prec@(1,5) (46.3%, 78.0%)\u001b[0m\n",
            "[2024-04-02 20:35:30] \u001b[32mTrain: [ 12/50] Step 040/520 Loss 2.680 Prec@(1,5) (46.6%, 77.9%)\u001b[0m\n",
            "[2024-04-02 20:35:30] \u001b[32mTrain: [ 12/50] Step 060/520 Loss 2.679 Prec@(1,5) (47.0%, 78.2%)\u001b[0m\n",
            "[2024-04-02 20:35:31] \u001b[32mTrain: [ 12/50] Step 080/520 Loss 2.669 Prec@(1,5) (47.3%, 78.4%)\u001b[0m\n",
            "[2024-04-02 20:35:31] \u001b[32mTrain: [ 12/50] Step 100/520 Loss 2.657 Prec@(1,5) (47.8%, 78.3%)\u001b[0m\n",
            "[2024-04-02 20:35:32] \u001b[32mTrain: [ 12/50] Step 120/520 Loss 2.663 Prec@(1,5) (47.6%, 78.3%)\u001b[0m\n",
            "[2024-04-02 20:35:32] \u001b[32mTrain: [ 12/50] Step 140/520 Loss 2.654 Prec@(1,5) (47.8%, 78.4%)\u001b[0m\n",
            "[2024-04-02 20:35:33] \u001b[32mTrain: [ 12/50] Step 160/520 Loss 2.658 Prec@(1,5) (47.8%, 78.4%)\u001b[0m\n",
            "[2024-04-02 20:35:33] \u001b[32mTrain: [ 12/50] Step 180/520 Loss 2.661 Prec@(1,5) (47.6%, 78.3%)\u001b[0m\n",
            "[2024-04-02 20:35:34] \u001b[32mTrain: [ 12/50] Step 200/520 Loss 2.656 Prec@(1,5) (47.6%, 78.5%)\u001b[0m\n",
            "[2024-04-02 20:35:34] \u001b[32mTrain: [ 12/50] Step 220/520 Loss 2.648 Prec@(1,5) (47.7%, 78.7%)\u001b[0m\n",
            "[2024-04-02 20:35:35] \u001b[32mTrain: [ 12/50] Step 240/520 Loss 2.645 Prec@(1,5) (47.9%, 78.7%)\u001b[0m\n",
            "[2024-04-02 20:35:35] \u001b[32mTrain: [ 12/50] Step 260/520 Loss 2.646 Prec@(1,5) (47.9%, 78.7%)\u001b[0m\n",
            "[2024-04-02 20:35:36] \u001b[32mTrain: [ 12/50] Step 280/520 Loss 2.657 Prec@(1,5) (47.7%, 78.6%)\u001b[0m\n",
            "[2024-04-02 20:35:36] \u001b[32mTrain: [ 12/50] Step 300/520 Loss 2.664 Prec@(1,5) (47.7%, 78.5%)\u001b[0m\n",
            "[2024-04-02 20:35:37] \u001b[32mTrain: [ 12/50] Step 320/520 Loss 2.666 Prec@(1,5) (47.7%, 78.4%)\u001b[0m\n",
            "[2024-04-02 20:35:37] \u001b[32mTrain: [ 12/50] Step 340/520 Loss 2.669 Prec@(1,5) (47.8%, 78.4%)\u001b[0m\n",
            "[2024-04-02 20:35:38] \u001b[32mTrain: [ 12/50] Step 360/520 Loss 2.667 Prec@(1,5) (47.9%, 78.5%)\u001b[0m\n",
            "[2024-04-02 20:35:38] \u001b[32mTrain: [ 12/50] Step 380/520 Loss 2.669 Prec@(1,5) (47.8%, 78.5%)\u001b[0m\n",
            "[2024-04-02 20:35:39] \u001b[32mTrain: [ 12/50] Step 400/520 Loss 2.664 Prec@(1,5) (47.9%, 78.5%)\u001b[0m\n",
            "[2024-04-02 20:35:39] \u001b[32mTrain: [ 12/50] Step 420/520 Loss 2.663 Prec@(1,5) (47.8%, 78.5%)\u001b[0m\n",
            "[2024-04-02 20:35:39] \u001b[32mTrain: [ 12/50] Step 440/520 Loss 2.664 Prec@(1,5) (47.8%, 78.6%)\u001b[0m\n",
            "[2024-04-02 20:35:40] \u001b[32mTrain: [ 12/50] Step 460/520 Loss 2.668 Prec@(1,5) (47.8%, 78.5%)\u001b[0m\n",
            "[2024-04-02 20:35:40] \u001b[32mTrain: [ 12/50] Step 480/520 Loss 2.669 Prec@(1,5) (47.7%, 78.5%)\u001b[0m\n",
            "[2024-04-02 20:35:41] \u001b[32mTrain: [ 12/50] Step 500/520 Loss 2.672 Prec@(1,5) (47.7%, 78.5%)\u001b[0m\n",
            "[2024-04-02 20:35:41] \u001b[32mTrain: [ 12/50] Step 520/520 Loss 2.671 Prec@(1,5) (47.7%, 78.5%)\u001b[0m\n",
            "[2024-04-02 20:35:42] \u001b[32mTrain: [ 12/50] Final Prec@1 47.7240%\u001b[0m\n",
            "[2024-04-02 20:35:45] \u001b[32mValid: [ 12/50] Step 000/104 Loss 3.212 Prec@(1,5) (46.9%, 71.9%)\u001b[0m\n",
            "[2024-04-02 20:35:45] \u001b[32mValid: [ 12/50] Step 020/104 Loss 3.383 Prec@(1,5) (42.0%, 72.4%)\u001b[0m\n",
            "[2024-04-02 20:35:45] \u001b[32mValid: [ 12/50] Step 040/104 Loss 3.356 Prec@(1,5) (41.3%, 71.8%)\u001b[0m\n",
            "[2024-04-02 20:35:46] \u001b[32mValid: [ 12/50] Step 060/104 Loss 3.289 Prec@(1,5) (41.9%, 71.9%)\u001b[0m\n",
            "[2024-04-02 20:35:46] \u001b[32mValid: [ 12/50] Step 080/104 Loss 3.307 Prec@(1,5) (41.3%, 71.6%)\u001b[0m\n",
            "[2024-04-02 20:35:46] \u001b[32mValid: [ 12/50] Step 100/104 Loss 3.295 Prec@(1,5) (41.2%, 71.9%)\u001b[0m\n",
            "[2024-04-02 20:35:46] \u001b[32mValid: [ 12/50] Step 104/104 Loss 3.292 Prec@(1,5) (41.3%, 71.8%)\u001b[0m\n",
            "[2024-04-02 20:35:46] \u001b[32mValid: [ 12/50] Final Prec@1 41.2500%\u001b[0m\n",
            "[2024-04-02 20:35:46] \u001b[32mEpoch 12 LR 0.021612\u001b[0m\n",
            "[2024-04-02 20:35:51] \u001b[32mTrain: [ 13/50] Step 000/520 Loss 2.837 Prec@(1,5) (45.8%, 76.0%)\u001b[0m\n",
            "[2024-04-02 20:35:51] \u001b[32mTrain: [ 13/50] Step 020/520 Loss 2.625 Prec@(1,5) (49.0%, 79.2%)\u001b[0m\n",
            "[2024-04-02 20:35:52] \u001b[32mTrain: [ 13/50] Step 040/520 Loss 2.587 Prec@(1,5) (50.0%, 79.3%)\u001b[0m\n",
            "[2024-04-02 20:35:52] \u001b[32mTrain: [ 13/50] Step 060/520 Loss 2.596 Prec@(1,5) (49.3%, 79.0%)\u001b[0m\n",
            "[2024-04-02 20:35:53] \u001b[32mTrain: [ 13/50] Step 080/520 Loss 2.601 Prec@(1,5) (49.2%, 78.9%)\u001b[0m\n",
            "[2024-04-02 20:35:53] \u001b[32mTrain: [ 13/50] Step 100/520 Loss 2.625 Prec@(1,5) (48.7%, 78.7%)\u001b[0m\n",
            "[2024-04-02 20:35:54] \u001b[32mTrain: [ 13/50] Step 120/520 Loss 2.620 Prec@(1,5) (48.8%, 78.9%)\u001b[0m\n",
            "[2024-04-02 20:35:54] \u001b[32mTrain: [ 13/50] Step 140/520 Loss 2.616 Prec@(1,5) (48.8%, 78.7%)\u001b[0m\n",
            "[2024-04-02 20:35:55] \u001b[32mTrain: [ 13/50] Step 160/520 Loss 2.629 Prec@(1,5) (48.7%, 78.6%)\u001b[0m\n",
            "[2024-04-02 20:35:55] \u001b[32mTrain: [ 13/50] Step 180/520 Loss 2.629 Prec@(1,5) (48.7%, 78.6%)\u001b[0m\n",
            "[2024-04-02 20:35:56] \u001b[32mTrain: [ 13/50] Step 200/520 Loss 2.628 Prec@(1,5) (48.7%, 78.7%)\u001b[0m\n",
            "[2024-04-02 20:35:56] \u001b[32mTrain: [ 13/50] Step 220/520 Loss 2.629 Prec@(1,5) (48.6%, 78.7%)\u001b[0m\n",
            "[2024-04-02 20:35:57] \u001b[32mTrain: [ 13/50] Step 240/520 Loss 2.628 Prec@(1,5) (48.5%, 78.7%)\u001b[0m\n",
            "[2024-04-02 20:35:57] \u001b[32mTrain: [ 13/50] Step 260/520 Loss 2.625 Prec@(1,5) (48.4%, 78.8%)\u001b[0m\n",
            "[2024-04-02 20:35:58] \u001b[32mTrain: [ 13/50] Step 280/520 Loss 2.633 Prec@(1,5) (48.4%, 78.8%)\u001b[0m\n",
            "[2024-04-02 20:35:58] \u001b[32mTrain: [ 13/50] Step 300/520 Loss 2.632 Prec@(1,5) (48.4%, 78.8%)\u001b[0m\n",
            "[2024-04-02 20:35:59] \u001b[32mTrain: [ 13/50] Step 320/520 Loss 2.629 Prec@(1,5) (48.5%, 78.9%)\u001b[0m\n",
            "[2024-04-02 20:35:59] \u001b[32mTrain: [ 13/50] Step 340/520 Loss 2.628 Prec@(1,5) (48.5%, 79.0%)\u001b[0m\n",
            "[2024-04-02 20:36:00] \u001b[32mTrain: [ 13/50] Step 360/520 Loss 2.629 Prec@(1,5) (48.4%, 79.0%)\u001b[0m\n",
            "[2024-04-02 20:36:00] \u001b[32mTrain: [ 13/50] Step 380/520 Loss 2.629 Prec@(1,5) (48.4%, 79.0%)\u001b[0m\n",
            "[2024-04-02 20:36:01] \u001b[32mTrain: [ 13/50] Step 400/520 Loss 2.629 Prec@(1,5) (48.4%, 79.0%)\u001b[0m\n",
            "[2024-04-02 20:36:01] \u001b[32mTrain: [ 13/50] Step 420/520 Loss 2.628 Prec@(1,5) (48.5%, 78.9%)\u001b[0m\n",
            "[2024-04-02 20:36:02] \u001b[32mTrain: [ 13/50] Step 440/520 Loss 2.628 Prec@(1,5) (48.4%, 79.0%)\u001b[0m\n",
            "[2024-04-02 20:36:02] \u001b[32mTrain: [ 13/50] Step 460/520 Loss 2.628 Prec@(1,5) (48.5%, 79.0%)\u001b[0m\n",
            "[2024-04-02 20:36:03] \u001b[32mTrain: [ 13/50] Step 480/520 Loss 2.632 Prec@(1,5) (48.3%, 78.9%)\u001b[0m\n",
            "[2024-04-02 20:36:03] \u001b[32mTrain: [ 13/50] Step 500/520 Loss 2.629 Prec@(1,5) (48.4%, 78.9%)\u001b[0m\n",
            "[2024-04-02 20:36:04] \u001b[32mTrain: [ 13/50] Step 520/520 Loss 2.628 Prec@(1,5) (48.4%, 78.9%)\u001b[0m\n",
            "[2024-04-02 20:36:04] \u001b[32mTrain: [ 13/50] Final Prec@1 48.4080%\u001b[0m\n",
            "[2024-04-02 20:36:07] \u001b[32mValid: [ 13/50] Step 000/104 Loss 2.888 Prec@(1,5) (49.0%, 76.0%)\u001b[0m\n",
            "[2024-04-02 20:36:07] \u001b[32mValid: [ 13/50] Step 020/104 Loss 2.766 Prec@(1,5) (44.9%, 76.8%)\u001b[0m\n",
            "[2024-04-02 20:36:08] \u001b[32mValid: [ 13/50] Step 040/104 Loss 2.761 Prec@(1,5) (44.9%, 76.4%)\u001b[0m\n",
            "[2024-04-02 20:36:08] \u001b[32mValid: [ 13/50] Step 060/104 Loss 2.714 Prec@(1,5) (45.5%, 76.5%)\u001b[0m\n",
            "[2024-04-02 20:36:08] \u001b[32mValid: [ 13/50] Step 080/104 Loss 2.716 Prec@(1,5) (45.2%, 76.4%)\u001b[0m\n",
            "[2024-04-02 20:36:08] \u001b[32mValid: [ 13/50] Step 100/104 Loss 2.707 Prec@(1,5) (45.1%, 76.5%)\u001b[0m\n",
            "[2024-04-02 20:36:08] \u001b[32mValid: [ 13/50] Step 104/104 Loss 2.703 Prec@(1,5) (45.2%, 76.5%)\u001b[0m\n",
            "[2024-04-02 20:36:08] \u001b[32mValid: [ 13/50] Final Prec@1 45.1800%\u001b[0m\n",
            "[2024-04-02 20:36:08] \u001b[32mEpoch 13 LR 0.021057\u001b[0m\n",
            "[2024-04-02 20:36:13] \u001b[32mTrain: [ 14/50] Step 000/520 Loss 2.708 Prec@(1,5) (49.0%, 76.0%)\u001b[0m\n",
            "[2024-04-02 20:36:13] \u001b[32mTrain: [ 14/50] Step 020/520 Loss 2.509 Prec@(1,5) (50.8%, 80.6%)\u001b[0m\n",
            "[2024-04-02 20:36:14] \u001b[32mTrain: [ 14/50] Step 040/520 Loss 2.542 Prec@(1,5) (50.1%, 80.3%)\u001b[0m\n",
            "[2024-04-02 20:36:14] \u001b[32mTrain: [ 14/50] Step 060/520 Loss 2.542 Prec@(1,5) (50.0%, 80.4%)\u001b[0m\n",
            "[2024-04-02 20:36:15] \u001b[32mTrain: [ 14/50] Step 080/520 Loss 2.548 Prec@(1,5) (50.1%, 80.0%)\u001b[0m\n",
            "[2024-04-02 20:36:15] \u001b[32mTrain: [ 14/50] Step 100/520 Loss 2.546 Prec@(1,5) (50.0%, 80.0%)\u001b[0m\n",
            "[2024-04-02 20:36:16] \u001b[32mTrain: [ 14/50] Step 120/520 Loss 2.552 Prec@(1,5) (49.8%, 80.0%)\u001b[0m\n",
            "[2024-04-02 20:36:16] \u001b[32mTrain: [ 14/50] Step 140/520 Loss 2.549 Prec@(1,5) (49.8%, 80.1%)\u001b[0m\n",
            "[2024-04-02 20:36:17] \u001b[32mTrain: [ 14/50] Step 160/520 Loss 2.548 Prec@(1,5) (49.9%, 80.2%)\u001b[0m\n",
            "[2024-04-02 20:36:17] \u001b[32mTrain: [ 14/50] Step 180/520 Loss 2.551 Prec@(1,5) (49.8%, 80.1%)\u001b[0m\n",
            "[2024-04-02 20:36:18] \u001b[32mTrain: [ 14/50] Step 200/520 Loss 2.559 Prec@(1,5) (49.7%, 79.9%)\u001b[0m\n",
            "[2024-04-02 20:36:18] \u001b[32mTrain: [ 14/50] Step 220/520 Loss 2.563 Prec@(1,5) (49.6%, 79.9%)\u001b[0m\n",
            "[2024-04-02 20:36:19] \u001b[32mTrain: [ 14/50] Step 240/520 Loss 2.561 Prec@(1,5) (49.6%, 80.0%)\u001b[0m\n",
            "[2024-04-02 20:36:19] \u001b[32mTrain: [ 14/50] Step 260/520 Loss 2.564 Prec@(1,5) (49.5%, 79.9%)\u001b[0m\n",
            "[2024-04-02 20:36:20] \u001b[32mTrain: [ 14/50] Step 280/520 Loss 2.567 Prec@(1,5) (49.5%, 79.8%)\u001b[0m\n",
            "[2024-04-02 20:36:20] \u001b[32mTrain: [ 14/50] Step 300/520 Loss 2.574 Prec@(1,5) (49.3%, 79.7%)\u001b[0m\n",
            "[2024-04-02 20:36:21] \u001b[32mTrain: [ 14/50] Step 320/520 Loss 2.568 Prec@(1,5) (49.4%, 79.8%)\u001b[0m\n",
            "[2024-04-02 20:36:21] \u001b[32mTrain: [ 14/50] Step 340/520 Loss 2.566 Prec@(1,5) (49.5%, 79.8%)\u001b[0m\n",
            "[2024-04-02 20:36:22] \u001b[32mTrain: [ 14/50] Step 360/520 Loss 2.565 Prec@(1,5) (49.6%, 79.8%)\u001b[0m\n",
            "[2024-04-02 20:36:22] \u001b[32mTrain: [ 14/50] Step 380/520 Loss 2.562 Prec@(1,5) (49.7%, 79.9%)\u001b[0m\n",
            "[2024-04-02 20:36:23] \u001b[32mTrain: [ 14/50] Step 400/520 Loss 2.556 Prec@(1,5) (49.8%, 79.9%)\u001b[0m\n",
            "[2024-04-02 20:36:23] \u001b[32mTrain: [ 14/50] Step 420/520 Loss 2.556 Prec@(1,5) (49.9%, 79.9%)\u001b[0m\n",
            "[2024-04-02 20:36:24] \u001b[32mTrain: [ 14/50] Step 440/520 Loss 2.554 Prec@(1,5) (49.8%, 79.9%)\u001b[0m\n",
            "[2024-04-02 20:36:24] \u001b[32mTrain: [ 14/50] Step 460/520 Loss 2.554 Prec@(1,5) (49.9%, 79.9%)\u001b[0m\n",
            "[2024-04-02 20:36:25] \u001b[32mTrain: [ 14/50] Step 480/520 Loss 2.555 Prec@(1,5) (49.9%, 79.9%)\u001b[0m\n",
            "[2024-04-02 20:36:25] \u001b[32mTrain: [ 14/50] Step 500/520 Loss 2.559 Prec@(1,5) (49.8%, 79.8%)\u001b[0m\n",
            "[2024-04-02 20:36:26] \u001b[32mTrain: [ 14/50] Step 520/520 Loss 2.559 Prec@(1,5) (49.8%, 79.8%)\u001b[0m\n",
            "[2024-04-02 20:36:26] \u001b[32mTrain: [ 14/50] Final Prec@1 49.7920%\u001b[0m\n",
            "[2024-04-02 20:36:29] \u001b[32mValid: [ 14/50] Step 000/104 Loss 2.648 Prec@(1,5) (47.9%, 76.0%)\u001b[0m\n",
            "[2024-04-02 20:36:29] \u001b[32mValid: [ 14/50] Step 020/104 Loss 2.700 Prec@(1,5) (46.6%, 76.8%)\u001b[0m\n",
            "[2024-04-02 20:36:30] \u001b[32mValid: [ 14/50] Step 040/104 Loss 2.671 Prec@(1,5) (45.6%, 76.9%)\u001b[0m\n",
            "[2024-04-02 20:36:30] \u001b[32mValid: [ 14/50] Step 060/104 Loss 2.611 Prec@(1,5) (46.1%, 77.5%)\u001b[0m\n",
            "[2024-04-02 20:36:30] \u001b[32mValid: [ 14/50] Step 080/104 Loss 2.630 Prec@(1,5) (45.9%, 77.2%)\u001b[0m\n",
            "[2024-04-02 20:36:30] \u001b[32mValid: [ 14/50] Step 100/104 Loss 2.617 Prec@(1,5) (46.0%, 77.2%)\u001b[0m\n",
            "[2024-04-02 20:36:30] \u001b[32mValid: [ 14/50] Step 104/104 Loss 2.611 Prec@(1,5) (46.1%, 77.2%)\u001b[0m\n",
            "[2024-04-02 20:36:30] \u001b[32mValid: [ 14/50] Final Prec@1 46.1100%\u001b[0m\n",
            "[2024-04-02 20:36:30] \u001b[32mEpoch 14 LR 0.020468\u001b[0m\n",
            "[2024-04-02 20:36:35] \u001b[32mTrain: [ 15/50] Step 000/520 Loss 2.551 Prec@(1,5) (49.0%, 76.0%)\u001b[0m\n",
            "[2024-04-02 20:36:35] \u001b[32mTrain: [ 15/50] Step 020/520 Loss 2.574 Prec@(1,5) (50.0%, 78.7%)\u001b[0m\n",
            "[2024-04-02 20:36:36] \u001b[32mTrain: [ 15/50] Step 040/520 Loss 2.536 Prec@(1,5) (50.1%, 79.8%)\u001b[0m\n",
            "[2024-04-02 20:36:36] \u001b[32mTrain: [ 15/50] Step 060/520 Loss 2.515 Prec@(1,5) (50.4%, 80.1%)\u001b[0m\n",
            "[2024-04-02 20:36:37] \u001b[32mTrain: [ 15/50] Step 080/520 Loss 2.493 Prec@(1,5) (50.9%, 80.7%)\u001b[0m\n",
            "[2024-04-02 20:36:37] \u001b[32mTrain: [ 15/50] Step 100/520 Loss 2.504 Prec@(1,5) (50.5%, 80.4%)\u001b[0m\n",
            "[2024-04-02 20:36:38] \u001b[32mTrain: [ 15/50] Step 120/520 Loss 2.503 Prec@(1,5) (50.5%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:36:38] \u001b[32mTrain: [ 15/50] Step 140/520 Loss 2.498 Prec@(1,5) (50.6%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:36:39] \u001b[32mTrain: [ 15/50] Step 160/520 Loss 2.505 Prec@(1,5) (50.3%, 80.4%)\u001b[0m\n",
            "[2024-04-02 20:36:39] \u001b[32mTrain: [ 15/50] Step 180/520 Loss 2.519 Prec@(1,5) (50.0%, 80.3%)\u001b[0m\n",
            "[2024-04-02 20:36:40] \u001b[32mTrain: [ 15/50] Step 200/520 Loss 2.519 Prec@(1,5) (50.1%, 80.3%)\u001b[0m\n",
            "[2024-04-02 20:36:40] \u001b[32mTrain: [ 15/50] Step 220/520 Loss 2.515 Prec@(1,5) (50.2%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:36:41] \u001b[32mTrain: [ 15/50] Step 240/520 Loss 2.513 Prec@(1,5) (50.4%, 80.4%)\u001b[0m\n",
            "[2024-04-02 20:36:41] \u001b[32mTrain: [ 15/50] Step 260/520 Loss 2.511 Prec@(1,5) (50.5%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:36:42] \u001b[32mTrain: [ 15/50] Step 280/520 Loss 2.510 Prec@(1,5) (50.5%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:36:42] \u001b[32mTrain: [ 15/50] Step 300/520 Loss 2.512 Prec@(1,5) (50.5%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:36:43] \u001b[32mTrain: [ 15/50] Step 320/520 Loss 2.516 Prec@(1,5) (50.5%, 80.4%)\u001b[0m\n",
            "[2024-04-02 20:36:43] \u001b[32mTrain: [ 15/50] Step 340/520 Loss 2.512 Prec@(1,5) (50.6%, 80.4%)\u001b[0m\n",
            "[2024-04-02 20:36:44] \u001b[32mTrain: [ 15/50] Step 360/520 Loss 2.513 Prec@(1,5) (50.6%, 80.4%)\u001b[0m\n",
            "[2024-04-02 20:36:44] \u001b[32mTrain: [ 15/50] Step 380/520 Loss 2.516 Prec@(1,5) (50.5%, 80.3%)\u001b[0m\n",
            "[2024-04-02 20:36:45] \u001b[32mTrain: [ 15/50] Step 400/520 Loss 2.514 Prec@(1,5) (50.5%, 80.4%)\u001b[0m\n",
            "[2024-04-02 20:36:45] \u001b[32mTrain: [ 15/50] Step 420/520 Loss 2.509 Prec@(1,5) (50.6%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:36:46] \u001b[32mTrain: [ 15/50] Step 440/520 Loss 2.512 Prec@(1,5) (50.6%, 80.4%)\u001b[0m\n",
            "[2024-04-02 20:36:47] \u001b[32mTrain: [ 15/50] Step 460/520 Loss 2.508 Prec@(1,5) (50.7%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:36:47] \u001b[32mTrain: [ 15/50] Step 480/520 Loss 2.507 Prec@(1,5) (50.7%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:36:48] \u001b[32mTrain: [ 15/50] Step 500/520 Loss 2.508 Prec@(1,5) (50.7%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:36:48] \u001b[32mTrain: [ 15/50] Step 520/520 Loss 2.507 Prec@(1,5) (50.7%, 80.6%)\u001b[0m\n",
            "[2024-04-02 20:36:48] \u001b[32mTrain: [ 15/50] Final Prec@1 50.6860%\u001b[0m\n",
            "[2024-04-02 20:36:52] \u001b[32mValid: [ 15/50] Step 000/104 Loss 2.667 Prec@(1,5) (52.1%, 75.0%)\u001b[0m\n",
            "[2024-04-02 20:36:52] \u001b[32mValid: [ 15/50] Step 020/104 Loss 2.594 Prec@(1,5) (48.6%, 78.0%)\u001b[0m\n",
            "[2024-04-02 20:36:52] \u001b[32mValid: [ 15/50] Step 040/104 Loss 2.581 Prec@(1,5) (47.0%, 77.8%)\u001b[0m\n",
            "[2024-04-02 20:36:52] \u001b[32mValid: [ 15/50] Step 060/104 Loss 2.535 Prec@(1,5) (47.5%, 77.9%)\u001b[0m\n",
            "[2024-04-02 20:36:52] \u001b[32mValid: [ 15/50] Step 080/104 Loss 2.538 Prec@(1,5) (47.1%, 77.9%)\u001b[0m\n",
            "[2024-04-02 20:36:53] \u001b[32mValid: [ 15/50] Step 100/104 Loss 2.531 Prec@(1,5) (47.1%, 78.1%)\u001b[0m\n",
            "[2024-04-02 20:36:53] \u001b[32mValid: [ 15/50] Step 104/104 Loss 2.526 Prec@(1,5) (47.2%, 78.1%)\u001b[0m\n",
            "[2024-04-02 20:36:53] \u001b[32mValid: [ 15/50] Final Prec@1 47.1800%\u001b[0m\n",
            "[2024-04-02 20:36:53] \u001b[32mEpoch 15 LR 0.019848\u001b[0m\n",
            "[2024-04-02 20:36:57] \u001b[32mTrain: [ 16/50] Step 000/520 Loss 2.156 Prec@(1,5) (57.3%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:36:58] \u001b[32mTrain: [ 16/50] Step 020/520 Loss 2.333 Prec@(1,5) (53.9%, 83.5%)\u001b[0m\n",
            "[2024-04-02 20:36:58] \u001b[32mTrain: [ 16/50] Step 040/520 Loss 2.452 Prec@(1,5) (51.8%, 81.8%)\u001b[0m\n",
            "[2024-04-02 20:36:59] \u001b[32mTrain: [ 16/50] Step 060/520 Loss 2.428 Prec@(1,5) (52.3%, 82.0%)\u001b[0m\n",
            "[2024-04-02 20:36:59] \u001b[32mTrain: [ 16/50] Step 080/520 Loss 2.438 Prec@(1,5) (52.1%, 81.6%)\u001b[0m\n",
            "[2024-04-02 20:37:00] \u001b[32mTrain: [ 16/50] Step 100/520 Loss 2.428 Prec@(1,5) (52.2%, 81.5%)\u001b[0m\n",
            "[2024-04-02 20:37:00] \u001b[32mTrain: [ 16/50] Step 120/520 Loss 2.436 Prec@(1,5) (52.1%, 81.4%)\u001b[0m\n",
            "[2024-04-02 20:37:01] \u001b[32mTrain: [ 16/50] Step 140/520 Loss 2.448 Prec@(1,5) (51.9%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:37:01] \u001b[32mTrain: [ 16/50] Step 160/520 Loss 2.451 Prec@(1,5) (51.7%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:37:02] \u001b[32mTrain: [ 16/50] Step 180/520 Loss 2.442 Prec@(1,5) (51.9%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:37:02] \u001b[32mTrain: [ 16/50] Step 200/520 Loss 2.447 Prec@(1,5) (51.8%, 81.1%)\u001b[0m\n",
            "[2024-04-02 20:37:03] \u001b[32mTrain: [ 16/50] Step 220/520 Loss 2.452 Prec@(1,5) (51.6%, 81.1%)\u001b[0m\n",
            "[2024-04-02 20:37:03] \u001b[32mTrain: [ 16/50] Step 240/520 Loss 2.458 Prec@(1,5) (51.6%, 81.1%)\u001b[0m\n",
            "[2024-04-02 20:37:04] \u001b[32mTrain: [ 16/50] Step 260/520 Loss 2.458 Prec@(1,5) (51.6%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:37:04] \u001b[32mTrain: [ 16/50] Step 280/520 Loss 2.469 Prec@(1,5) (51.4%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:37:05] \u001b[32mTrain: [ 16/50] Step 300/520 Loss 2.473 Prec@(1,5) (51.3%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:37:05] \u001b[32mTrain: [ 16/50] Step 320/520 Loss 2.469 Prec@(1,5) (51.4%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:37:06] \u001b[32mTrain: [ 16/50] Step 340/520 Loss 2.468 Prec@(1,5) (51.4%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:37:06] \u001b[32mTrain: [ 16/50] Step 360/520 Loss 2.471 Prec@(1,5) (51.2%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:37:07] \u001b[32mTrain: [ 16/50] Step 380/520 Loss 2.473 Prec@(1,5) (51.2%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:37:07] \u001b[32mTrain: [ 16/50] Step 400/520 Loss 2.472 Prec@(1,5) (51.3%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:37:08] \u001b[32mTrain: [ 16/50] Step 420/520 Loss 2.469 Prec@(1,5) (51.3%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:37:08] \u001b[32mTrain: [ 16/50] Step 440/520 Loss 2.473 Prec@(1,5) (51.2%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:37:09] \u001b[32mTrain: [ 16/50] Step 460/520 Loss 2.472 Prec@(1,5) (51.2%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:37:09] \u001b[32mTrain: [ 16/50] Step 480/520 Loss 2.470 Prec@(1,5) (51.2%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:37:10] \u001b[32mTrain: [ 16/50] Step 500/520 Loss 2.469 Prec@(1,5) (51.2%, 81.1%)\u001b[0m\n",
            "[2024-04-02 20:37:10] \u001b[32mTrain: [ 16/50] Step 520/520 Loss 2.468 Prec@(1,5) (51.2%, 81.1%)\u001b[0m\n",
            "[2024-04-02 20:37:11] \u001b[32mTrain: [ 16/50] Final Prec@1 51.1860%\u001b[0m\n",
            "[2024-04-02 20:37:14] \u001b[32mValid: [ 16/50] Step 000/104 Loss 2.721 Prec@(1,5) (46.9%, 79.2%)\u001b[0m\n",
            "[2024-04-02 20:37:14] \u001b[32mValid: [ 16/50] Step 020/104 Loss 2.786 Prec@(1,5) (47.1%, 77.5%)\u001b[0m\n",
            "[2024-04-02 20:37:14] \u001b[32mValid: [ 16/50] Step 040/104 Loss 2.769 Prec@(1,5) (47.3%, 76.5%)\u001b[0m\n",
            "[2024-04-02 20:37:15] \u001b[32mValid: [ 16/50] Step 060/104 Loss 2.719 Prec@(1,5) (47.8%, 77.2%)\u001b[0m\n",
            "[2024-04-02 20:37:15] \u001b[32mValid: [ 16/50] Step 080/104 Loss 2.717 Prec@(1,5) (47.2%, 77.0%)\u001b[0m\n",
            "[2024-04-02 20:37:15] \u001b[32mValid: [ 16/50] Step 100/104 Loss 2.696 Prec@(1,5) (47.6%, 77.1%)\u001b[0m\n",
            "[2024-04-02 20:37:15] \u001b[32mValid: [ 16/50] Step 104/104 Loss 2.693 Prec@(1,5) (47.5%, 77.2%)\u001b[0m\n",
            "[2024-04-02 20:37:15] \u001b[32mValid: [ 16/50] Final Prec@1 47.5400%\u001b[0m\n",
            "[2024-04-02 20:37:15] \u001b[32mEpoch 16 LR 0.019198\u001b[0m\n",
            "[2024-04-02 20:37:20] \u001b[32mTrain: [ 17/50] Step 000/520 Loss 2.143 Prec@(1,5) (61.5%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:37:20] \u001b[32mTrain: [ 17/50] Step 020/520 Loss 2.339 Prec@(1,5) (53.9%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:37:21] \u001b[32mTrain: [ 17/50] Step 040/520 Loss 2.382 Prec@(1,5) (52.6%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:37:21] \u001b[32mTrain: [ 17/50] Step 060/520 Loss 2.351 Prec@(1,5) (52.5%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:37:22] \u001b[32mTrain: [ 17/50] Step 080/520 Loss 2.383 Prec@(1,5) (52.3%, 82.2%)\u001b[0m\n",
            "[2024-04-02 20:37:22] \u001b[32mTrain: [ 17/50] Step 100/520 Loss 2.391 Prec@(1,5) (52.3%, 82.1%)\u001b[0m\n",
            "[2024-04-02 20:37:23] \u001b[32mTrain: [ 17/50] Step 120/520 Loss 2.391 Prec@(1,5) (52.3%, 82.2%)\u001b[0m\n",
            "[2024-04-02 20:37:23] \u001b[32mTrain: [ 17/50] Step 140/520 Loss 2.398 Prec@(1,5) (52.1%, 82.1%)\u001b[0m\n",
            "[2024-04-02 20:37:24] \u001b[32mTrain: [ 17/50] Step 160/520 Loss 2.405 Prec@(1,5) (52.0%, 81.9%)\u001b[0m\n",
            "[2024-04-02 20:37:24] \u001b[32mTrain: [ 17/50] Step 180/520 Loss 2.413 Prec@(1,5) (51.9%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:37:25] \u001b[32mTrain: [ 17/50] Step 200/520 Loss 2.399 Prec@(1,5) (52.1%, 81.9%)\u001b[0m\n",
            "[2024-04-02 20:37:25] \u001b[32mTrain: [ 17/50] Step 220/520 Loss 2.403 Prec@(1,5) (52.1%, 81.9%)\u001b[0m\n",
            "[2024-04-02 20:37:26] \u001b[32mTrain: [ 17/50] Step 240/520 Loss 2.397 Prec@(1,5) (52.2%, 82.0%)\u001b[0m\n",
            "[2024-04-02 20:37:26] \u001b[32mTrain: [ 17/50] Step 260/520 Loss 2.405 Prec@(1,5) (52.1%, 81.8%)\u001b[0m\n",
            "[2024-04-02 20:37:27] \u001b[32mTrain: [ 17/50] Step 280/520 Loss 2.411 Prec@(1,5) (52.1%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:37:27] \u001b[32mTrain: [ 17/50] Step 300/520 Loss 2.408 Prec@(1,5) (52.1%, 81.8%)\u001b[0m\n",
            "[2024-04-02 20:37:28] \u001b[32mTrain: [ 17/50] Step 320/520 Loss 2.410 Prec@(1,5) (52.1%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:37:28] \u001b[32mTrain: [ 17/50] Step 340/520 Loss 2.418 Prec@(1,5) (52.0%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:37:29] \u001b[32mTrain: [ 17/50] Step 360/520 Loss 2.419 Prec@(1,5) (52.0%, 81.6%)\u001b[0m\n",
            "[2024-04-02 20:37:29] \u001b[32mTrain: [ 17/50] Step 380/520 Loss 2.421 Prec@(1,5) (51.9%, 81.6%)\u001b[0m\n",
            "[2024-04-02 20:37:30] \u001b[32mTrain: [ 17/50] Step 400/520 Loss 2.424 Prec@(1,5) (51.9%, 81.5%)\u001b[0m\n",
            "[2024-04-02 20:37:30] \u001b[32mTrain: [ 17/50] Step 420/520 Loss 2.427 Prec@(1,5) (51.8%, 81.5%)\u001b[0m\n",
            "[2024-04-02 20:37:31] \u001b[32mTrain: [ 17/50] Step 440/520 Loss 2.429 Prec@(1,5) (51.8%, 81.5%)\u001b[0m\n",
            "[2024-04-02 20:37:31] \u001b[32mTrain: [ 17/50] Step 460/520 Loss 2.432 Prec@(1,5) (51.8%, 81.5%)\u001b[0m\n",
            "[2024-04-02 20:37:32] \u001b[32mTrain: [ 17/50] Step 480/520 Loss 2.429 Prec@(1,5) (51.8%, 81.5%)\u001b[0m\n",
            "[2024-04-02 20:37:32] \u001b[32mTrain: [ 17/50] Step 500/520 Loss 2.426 Prec@(1,5) (51.9%, 81.6%)\u001b[0m\n",
            "[2024-04-02 20:37:33] \u001b[32mTrain: [ 17/50] Step 520/520 Loss 2.425 Prec@(1,5) (51.9%, 81.6%)\u001b[0m\n",
            "[2024-04-02 20:37:33] \u001b[32mTrain: [ 17/50] Final Prec@1 51.9180%\u001b[0m\n",
            "[2024-04-02 20:37:36] \u001b[32mValid: [ 17/50] Step 000/104 Loss 2.527 Prec@(1,5) (54.2%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:37:36] \u001b[32mValid: [ 17/50] Step 020/104 Loss 2.595 Prec@(1,5) (48.9%, 77.8%)\u001b[0m\n",
            "[2024-04-02 20:37:37] \u001b[32mValid: [ 17/50] Step 040/104 Loss 2.556 Prec@(1,5) (49.0%, 78.3%)\u001b[0m\n",
            "[2024-04-02 20:37:37] \u001b[32mValid: [ 17/50] Step 060/104 Loss 2.500 Prec@(1,5) (49.4%, 78.6%)\u001b[0m\n",
            "[2024-04-02 20:37:37] \u001b[32mValid: [ 17/50] Step 080/104 Loss 2.512 Prec@(1,5) (49.1%, 78.5%)\u001b[0m\n",
            "[2024-04-02 20:37:37] \u001b[32mValid: [ 17/50] Step 100/104 Loss 2.504 Prec@(1,5) (49.0%, 78.6%)\u001b[0m\n",
            "[2024-04-02 20:37:37] \u001b[32mValid: [ 17/50] Step 104/104 Loss 2.506 Prec@(1,5) (49.0%, 78.6%)\u001b[0m\n",
            "[2024-04-02 20:37:37] \u001b[32mValid: [ 17/50] Final Prec@1 48.9600%\u001b[0m\n",
            "[2024-04-02 20:37:37] \u001b[32mEpoch 17 LR 0.018522\u001b[0m\n",
            "[2024-04-02 20:37:42] \u001b[32mTrain: [ 18/50] Step 000/520 Loss 1.950 Prec@(1,5) (59.4%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:37:42] \u001b[32mTrain: [ 18/50] Step 020/520 Loss 2.363 Prec@(1,5) (51.8%, 82.2%)\u001b[0m\n",
            "[2024-04-02 20:37:43] \u001b[32mTrain: [ 18/50] Step 040/520 Loss 2.346 Prec@(1,5) (52.5%, 82.2%)\u001b[0m\n",
            "[2024-04-02 20:37:43] \u001b[32mTrain: [ 18/50] Step 060/520 Loss 2.362 Prec@(1,5) (52.6%, 82.1%)\u001b[0m\n",
            "[2024-04-02 20:37:44] \u001b[32mTrain: [ 18/50] Step 080/520 Loss 2.362 Prec@(1,5) (52.7%, 82.2%)\u001b[0m\n",
            "[2024-04-02 20:37:44] \u001b[32mTrain: [ 18/50] Step 100/520 Loss 2.357 Prec@(1,5) (52.8%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:37:45] \u001b[32mTrain: [ 18/50] Step 120/520 Loss 2.351 Prec@(1,5) (53.0%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:37:45] \u001b[32mTrain: [ 18/50] Step 140/520 Loss 2.346 Prec@(1,5) (53.3%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:37:46] \u001b[32mTrain: [ 18/50] Step 160/520 Loss 2.346 Prec@(1,5) (53.2%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:37:46] \u001b[32mTrain: [ 18/50] Step 180/520 Loss 2.344 Prec@(1,5) (53.4%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:37:47] \u001b[32mTrain: [ 18/50] Step 200/520 Loss 2.350 Prec@(1,5) (53.2%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:37:47] \u001b[32mTrain: [ 18/50] Step 220/520 Loss 2.357 Prec@(1,5) (53.1%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:37:48] \u001b[32mTrain: [ 18/50] Step 240/520 Loss 2.368 Prec@(1,5) (53.0%, 82.4%)\u001b[0m\n",
            "[2024-04-02 20:37:48] \u001b[32mTrain: [ 18/50] Step 260/520 Loss 2.370 Prec@(1,5) (53.0%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:37:49] \u001b[32mTrain: [ 18/50] Step 280/520 Loss 2.375 Prec@(1,5) (53.0%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:37:49] \u001b[32mTrain: [ 18/50] Step 300/520 Loss 2.376 Prec@(1,5) (52.9%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:37:50] \u001b[32mTrain: [ 18/50] Step 320/520 Loss 2.375 Prec@(1,5) (53.0%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:37:50] \u001b[32mTrain: [ 18/50] Step 340/520 Loss 2.373 Prec@(1,5) (53.0%, 82.4%)\u001b[0m\n",
            "[2024-04-02 20:37:51] \u001b[32mTrain: [ 18/50] Step 360/520 Loss 2.373 Prec@(1,5) (53.1%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:37:51] \u001b[32mTrain: [ 18/50] Step 380/520 Loss 2.372 Prec@(1,5) (53.1%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:37:52] \u001b[32mTrain: [ 18/50] Step 400/520 Loss 2.372 Prec@(1,5) (53.0%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:37:52] \u001b[32mTrain: [ 18/50] Step 420/520 Loss 2.374 Prec@(1,5) (53.1%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:37:53] \u001b[32mTrain: [ 18/50] Step 440/520 Loss 2.380 Prec@(1,5) (52.9%, 82.2%)\u001b[0m\n",
            "[2024-04-02 20:37:53] \u001b[32mTrain: [ 18/50] Step 460/520 Loss 2.383 Prec@(1,5) (52.9%, 82.1%)\u001b[0m\n",
            "[2024-04-02 20:37:54] \u001b[32mTrain: [ 18/50] Step 480/520 Loss 2.385 Prec@(1,5) (52.9%, 82.1%)\u001b[0m\n",
            "[2024-04-02 20:37:54] \u001b[32mTrain: [ 18/50] Step 500/520 Loss 2.385 Prec@(1,5) (52.9%, 82.1%)\u001b[0m\n",
            "[2024-04-02 20:37:55] \u001b[32mTrain: [ 18/50] Step 520/520 Loss 2.387 Prec@(1,5) (52.8%, 82.1%)\u001b[0m\n",
            "[2024-04-02 20:37:55] \u001b[32mTrain: [ 18/50] Final Prec@1 52.7820%\u001b[0m\n",
            "[2024-04-02 20:37:58] \u001b[32mValid: [ 18/50] Step 000/104 Loss 2.830 Prec@(1,5) (47.9%, 80.2%)\u001b[0m\n",
            "[2024-04-02 20:37:59] \u001b[32mValid: [ 18/50] Step 020/104 Loss 2.933 Prec@(1,5) (44.0%, 77.3%)\u001b[0m\n",
            "[2024-04-02 20:37:59] \u001b[32mValid: [ 18/50] Step 040/104 Loss 2.958 Prec@(1,5) (43.8%, 76.4%)\u001b[0m\n",
            "[2024-04-02 20:37:59] \u001b[32mValid: [ 18/50] Step 060/104 Loss 2.913 Prec@(1,5) (44.3%, 76.7%)\u001b[0m\n",
            "[2024-04-02 20:37:59] \u001b[32mValid: [ 18/50] Step 080/104 Loss 2.914 Prec@(1,5) (44.2%, 76.5%)\u001b[0m\n",
            "[2024-04-02 20:37:59] \u001b[32mValid: [ 18/50] Step 100/104 Loss 2.907 Prec@(1,5) (44.5%, 76.8%)\u001b[0m\n",
            "[2024-04-02 20:37:59] \u001b[32mValid: [ 18/50] Step 104/104 Loss 2.909 Prec@(1,5) (44.5%, 76.7%)\u001b[0m\n",
            "[2024-04-02 20:37:59] \u001b[32mValid: [ 18/50] Final Prec@1 44.4700%\u001b[0m\n",
            "[2024-04-02 20:37:59] \u001b[32mEpoch 18 LR 0.017823\u001b[0m\n",
            "[2024-04-02 20:38:04] \u001b[32mTrain: [ 19/50] Step 000/520 Loss 2.531 Prec@(1,5) (46.9%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:38:05] \u001b[32mTrain: [ 19/50] Step 020/520 Loss 2.350 Prec@(1,5) (53.2%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:38:05] \u001b[32mTrain: [ 19/50] Step 040/520 Loss 2.338 Prec@(1,5) (54.3%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:38:05] \u001b[32mTrain: [ 19/50] Step 060/520 Loss 2.332 Prec@(1,5) (54.4%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:38:06] \u001b[32mTrain: [ 19/50] Step 080/520 Loss 2.311 Prec@(1,5) (54.6%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:38:06] \u001b[32mTrain: [ 19/50] Step 100/520 Loss 2.332 Prec@(1,5) (54.0%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:38:07] \u001b[32mTrain: [ 19/50] Step 120/520 Loss 2.326 Prec@(1,5) (54.2%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:38:07] \u001b[32mTrain: [ 19/50] Step 140/520 Loss 2.330 Prec@(1,5) (54.1%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:38:08] \u001b[32mTrain: [ 19/50] Step 160/520 Loss 2.324 Prec@(1,5) (54.2%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:38:08] \u001b[32mTrain: [ 19/50] Step 180/520 Loss 2.334 Prec@(1,5) (54.1%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:38:09] \u001b[32mTrain: [ 19/50] Step 200/520 Loss 2.336 Prec@(1,5) (54.0%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:38:09] \u001b[32mTrain: [ 19/50] Step 220/520 Loss 2.343 Prec@(1,5) (53.8%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:38:10] \u001b[32mTrain: [ 19/50] Step 240/520 Loss 2.341 Prec@(1,5) (53.8%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:38:10] \u001b[32mTrain: [ 19/50] Step 260/520 Loss 2.346 Prec@(1,5) (53.7%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:38:11] \u001b[32mTrain: [ 19/50] Step 280/520 Loss 2.348 Prec@(1,5) (53.7%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:38:11] \u001b[32mTrain: [ 19/50] Step 300/520 Loss 2.347 Prec@(1,5) (53.7%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:38:12] \u001b[32mTrain: [ 19/50] Step 320/520 Loss 2.348 Prec@(1,5) (53.7%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:38:12] \u001b[32mTrain: [ 19/50] Step 340/520 Loss 2.349 Prec@(1,5) (53.6%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:38:13] \u001b[32mTrain: [ 19/50] Step 360/520 Loss 2.349 Prec@(1,5) (53.5%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:38:13] \u001b[32mTrain: [ 19/50] Step 380/520 Loss 2.350 Prec@(1,5) (53.5%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:38:14] \u001b[32mTrain: [ 19/50] Step 400/520 Loss 2.348 Prec@(1,5) (53.5%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:38:14] \u001b[32mTrain: [ 19/50] Step 420/520 Loss 2.350 Prec@(1,5) (53.4%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:38:15] \u001b[32mTrain: [ 19/50] Step 440/520 Loss 2.350 Prec@(1,5) (53.4%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:38:15] \u001b[32mTrain: [ 19/50] Step 460/520 Loss 2.349 Prec@(1,5) (53.5%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:38:16] \u001b[32mTrain: [ 19/50] Step 480/520 Loss 2.349 Prec@(1,5) (53.5%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:38:16] \u001b[32mTrain: [ 19/50] Step 500/520 Loss 2.348 Prec@(1,5) (53.5%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:38:17] \u001b[32mTrain: [ 19/50] Step 520/520 Loss 2.351 Prec@(1,5) (53.4%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:38:17] \u001b[32mTrain: [ 19/50] Final Prec@1 53.4180%\u001b[0m\n",
            "[2024-04-02 20:38:21] \u001b[32mValid: [ 19/50] Step 000/104 Loss 2.492 Prec@(1,5) (54.2%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:38:21] \u001b[32mValid: [ 19/50] Step 020/104 Loss 2.462 Prec@(1,5) (52.1%, 78.9%)\u001b[0m\n",
            "[2024-04-02 20:38:21] \u001b[32mValid: [ 19/50] Step 040/104 Loss 2.427 Prec@(1,5) (51.7%, 79.0%)\u001b[0m\n",
            "[2024-04-02 20:38:21] \u001b[32mValid: [ 19/50] Step 060/104 Loss 2.371 Prec@(1,5) (51.6%, 79.7%)\u001b[0m\n",
            "[2024-04-02 20:38:21] \u001b[32mValid: [ 19/50] Step 080/104 Loss 2.389 Prec@(1,5) (50.8%, 79.6%)\u001b[0m\n",
            "[2024-04-02 20:38:21] \u001b[32mValid: [ 19/50] Step 100/104 Loss 2.377 Prec@(1,5) (50.9%, 79.6%)\u001b[0m\n",
            "[2024-04-02 20:38:21] \u001b[32mValid: [ 19/50] Step 104/104 Loss 2.381 Prec@(1,5) (50.9%, 79.6%)\u001b[0m\n",
            "[2024-04-02 20:38:22] \u001b[32mValid: [ 19/50] Final Prec@1 50.8500%\u001b[0m\n",
            "[2024-04-02 20:38:22] \u001b[32mEpoch 19 LR 0.017102\u001b[0m\n",
            "[2024-04-02 20:38:26] \u001b[32mTrain: [ 20/50] Step 000/520 Loss 2.040 Prec@(1,5) (56.2%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:38:27] \u001b[32mTrain: [ 20/50] Step 020/520 Loss 2.293 Prec@(1,5) (54.3%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:38:27] \u001b[32mTrain: [ 20/50] Step 040/520 Loss 2.291 Prec@(1,5) (54.4%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:38:28] \u001b[32mTrain: [ 20/50] Step 060/520 Loss 2.304 Prec@(1,5) (54.4%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:38:28] \u001b[32mTrain: [ 20/50] Step 080/520 Loss 2.303 Prec@(1,5) (54.1%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:38:29] \u001b[32mTrain: [ 20/50] Step 100/520 Loss 2.299 Prec@(1,5) (54.4%, 83.5%)\u001b[0m\n",
            "[2024-04-02 20:38:29] \u001b[32mTrain: [ 20/50] Step 120/520 Loss 2.299 Prec@(1,5) (54.3%, 83.4%)\u001b[0m\n",
            "[2024-04-02 20:38:30] \u001b[32mTrain: [ 20/50] Step 140/520 Loss 2.296 Prec@(1,5) (54.3%, 83.4%)\u001b[0m\n",
            "[2024-04-02 20:38:30] \u001b[32mTrain: [ 20/50] Step 160/520 Loss 2.302 Prec@(1,5) (54.2%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:38:31] \u001b[32mTrain: [ 20/50] Step 180/520 Loss 2.298 Prec@(1,5) (54.3%, 83.4%)\u001b[0m\n",
            "[2024-04-02 20:38:31] \u001b[32mTrain: [ 20/50] Step 200/520 Loss 2.310 Prec@(1,5) (54.1%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:38:32] \u001b[32mTrain: [ 20/50] Step 220/520 Loss 2.310 Prec@(1,5) (53.9%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:38:32] \u001b[32mTrain: [ 20/50] Step 240/520 Loss 2.317 Prec@(1,5) (53.8%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:38:33] \u001b[32mTrain: [ 20/50] Step 260/520 Loss 2.314 Prec@(1,5) (53.9%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:38:33] \u001b[32mTrain: [ 20/50] Step 280/520 Loss 2.311 Prec@(1,5) (54.1%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:38:34] \u001b[32mTrain: [ 20/50] Step 300/520 Loss 2.309 Prec@(1,5) (54.1%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:38:34] \u001b[32mTrain: [ 20/50] Step 320/520 Loss 2.311 Prec@(1,5) (54.1%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:38:35] \u001b[32mTrain: [ 20/50] Step 340/520 Loss 2.307 Prec@(1,5) (54.2%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:38:35] \u001b[32mTrain: [ 20/50] Step 360/520 Loss 2.307 Prec@(1,5) (54.2%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:38:36] \u001b[32mTrain: [ 20/50] Step 380/520 Loss 2.308 Prec@(1,5) (54.1%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:38:36] \u001b[32mTrain: [ 20/50] Step 400/520 Loss 2.307 Prec@(1,5) (54.1%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:38:37] \u001b[32mTrain: [ 20/50] Step 420/520 Loss 2.309 Prec@(1,5) (54.1%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:38:37] \u001b[32mTrain: [ 20/50] Step 440/520 Loss 2.312 Prec@(1,5) (54.0%, 83.1%)\u001b[0m\n",
            "[2024-04-02 20:38:38] \u001b[32mTrain: [ 20/50] Step 460/520 Loss 2.310 Prec@(1,5) (54.0%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:38:38] \u001b[32mTrain: [ 20/50] Step 480/520 Loss 2.311 Prec@(1,5) (54.1%, 83.1%)\u001b[0m\n",
            "[2024-04-02 20:38:39] \u001b[32mTrain: [ 20/50] Step 500/520 Loss 2.310 Prec@(1,5) (54.2%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:38:39] \u001b[32mTrain: [ 20/50] Step 520/520 Loss 2.307 Prec@(1,5) (54.2%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:38:39] \u001b[32mTrain: [ 20/50] Final Prec@1 54.2140%\u001b[0m\n",
            "[2024-04-02 20:38:43] \u001b[32mValid: [ 20/50] Step 000/104 Loss 2.182 Prec@(1,5) (54.2%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:38:43] \u001b[32mValid: [ 20/50] Step 020/104 Loss 2.302 Prec@(1,5) (51.8%, 80.6%)\u001b[0m\n",
            "[2024-04-02 20:38:43] \u001b[32mValid: [ 20/50] Step 040/104 Loss 2.265 Prec@(1,5) (51.8%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:38:43] \u001b[32mValid: [ 20/50] Step 060/104 Loss 2.236 Prec@(1,5) (51.9%, 81.3%)\u001b[0m\n",
            "[2024-04-02 20:38:44] \u001b[32mValid: [ 20/50] Step 080/104 Loss 2.248 Prec@(1,5) (51.4%, 81.3%)\u001b[0m\n",
            "[2024-04-02 20:38:44] \u001b[32mValid: [ 20/50] Step 100/104 Loss 2.231 Prec@(1,5) (51.9%, 81.4%)\u001b[0m\n",
            "[2024-04-02 20:38:44] \u001b[32mValid: [ 20/50] Step 104/104 Loss 2.234 Prec@(1,5) (51.8%, 81.4%)\u001b[0m\n",
            "[2024-04-02 20:38:44] \u001b[32mValid: [ 20/50] Final Prec@1 51.8300%\u001b[0m\n",
            "[2024-04-02 20:38:44] \u001b[32mEpoch 20 LR 0.016363\u001b[0m\n",
            "[2024-04-02 20:38:49] \u001b[32mTrain: [ 21/50] Step 000/520 Loss 2.610 Prec@(1,5) (46.9%, 76.0%)\u001b[0m\n",
            "[2024-04-02 20:38:49] \u001b[32mTrain: [ 21/50] Step 020/520 Loss 2.243 Prec@(1,5) (56.5%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:38:50] \u001b[32mTrain: [ 21/50] Step 040/520 Loss 2.245 Prec@(1,5) (56.0%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:38:50] \u001b[32mTrain: [ 21/50] Step 060/520 Loss 2.240 Prec@(1,5) (56.1%, 83.4%)\u001b[0m\n",
            "[2024-04-02 20:38:51] \u001b[32mTrain: [ 21/50] Step 080/520 Loss 2.234 Prec@(1,5) (56.3%, 83.8%)\u001b[0m\n",
            "[2024-04-02 20:38:51] \u001b[32mTrain: [ 21/50] Step 100/520 Loss 2.253 Prec@(1,5) (55.7%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:38:52] \u001b[32mTrain: [ 21/50] Step 120/520 Loss 2.274 Prec@(1,5) (55.6%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:38:52] \u001b[32mTrain: [ 21/50] Step 140/520 Loss 2.275 Prec@(1,5) (55.6%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:38:53] \u001b[32mTrain: [ 21/50] Step 160/520 Loss 2.271 Prec@(1,5) (55.4%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:38:53] \u001b[32mTrain: [ 21/50] Step 180/520 Loss 2.268 Prec@(1,5) (55.4%, 83.4%)\u001b[0m\n",
            "[2024-04-02 20:38:54] \u001b[32mTrain: [ 21/50] Step 200/520 Loss 2.260 Prec@(1,5) (55.4%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:38:54] \u001b[32mTrain: [ 21/50] Step 220/520 Loss 2.260 Prec@(1,5) (55.3%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:38:55] \u001b[32mTrain: [ 21/50] Step 240/520 Loss 2.257 Prec@(1,5) (55.2%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:38:55] \u001b[32mTrain: [ 21/50] Step 260/520 Loss 2.261 Prec@(1,5) (55.1%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:38:56] \u001b[32mTrain: [ 21/50] Step 280/520 Loss 2.264 Prec@(1,5) (55.1%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:38:56] \u001b[32mTrain: [ 21/50] Step 300/520 Loss 2.265 Prec@(1,5) (55.1%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:38:57] \u001b[32mTrain: [ 21/50] Step 320/520 Loss 2.267 Prec@(1,5) (55.0%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:38:57] \u001b[32mTrain: [ 21/50] Step 340/520 Loss 2.267 Prec@(1,5) (54.9%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:38:58] \u001b[32mTrain: [ 21/50] Step 360/520 Loss 2.269 Prec@(1,5) (54.9%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:38:58] \u001b[32mTrain: [ 21/50] Step 380/520 Loss 2.275 Prec@(1,5) (54.8%, 83.5%)\u001b[0m\n",
            "[2024-04-02 20:38:59] \u001b[32mTrain: [ 21/50] Step 400/520 Loss 2.277 Prec@(1,5) (54.8%, 83.5%)\u001b[0m\n",
            "[2024-04-02 20:39:00] \u001b[32mTrain: [ 21/50] Step 420/520 Loss 2.276 Prec@(1,5) (54.8%, 83.5%)\u001b[0m\n",
            "[2024-04-02 20:39:00] \u001b[32mTrain: [ 21/50] Step 440/520 Loss 2.281 Prec@(1,5) (54.7%, 83.4%)\u001b[0m\n",
            "[2024-04-02 20:39:01] \u001b[32mTrain: [ 21/50] Step 460/520 Loss 2.281 Prec@(1,5) (54.7%, 83.5%)\u001b[0m\n",
            "[2024-04-02 20:39:01] \u001b[32mTrain: [ 21/50] Step 480/520 Loss 2.282 Prec@(1,5) (54.7%, 83.5%)\u001b[0m\n",
            "[2024-04-02 20:39:02] \u001b[32mTrain: [ 21/50] Step 500/520 Loss 2.285 Prec@(1,5) (54.6%, 83.4%)\u001b[0m\n",
            "[2024-04-02 20:39:02] \u001b[32mTrain: [ 21/50] Step 520/520 Loss 2.287 Prec@(1,5) (54.6%, 83.4%)\u001b[0m\n",
            "[2024-04-02 20:39:02] \u001b[32mTrain: [ 21/50] Final Prec@1 54.5500%\u001b[0m\n",
            "[2024-04-02 20:39:06] \u001b[32mValid: [ 21/50] Step 000/104 Loss 2.247 Prec@(1,5) (61.5%, 80.2%)\u001b[0m\n",
            "[2024-04-02 20:39:06] \u001b[32mValid: [ 21/50] Step 020/104 Loss 2.459 Prec@(1,5) (51.0%, 80.6%)\u001b[0m\n",
            "[2024-04-02 20:39:06] \u001b[32mValid: [ 21/50] Step 040/104 Loss 2.489 Prec@(1,5) (50.0%, 80.1%)\u001b[0m\n",
            "[2024-04-02 20:39:06] \u001b[32mValid: [ 21/50] Step 060/104 Loss 2.440 Prec@(1,5) (50.4%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:39:06] \u001b[32mValid: [ 21/50] Step 080/104 Loss 2.451 Prec@(1,5) (49.8%, 80.2%)\u001b[0m\n",
            "[2024-04-02 20:39:07] \u001b[32mValid: [ 21/50] Step 100/104 Loss 2.442 Prec@(1,5) (49.9%, 80.2%)\u001b[0m\n",
            "[2024-04-02 20:39:07] \u001b[32mValid: [ 21/50] Step 104/104 Loss 2.438 Prec@(1,5) (50.0%, 80.2%)\u001b[0m\n",
            "[2024-04-02 20:39:07] \u001b[32mValid: [ 21/50] Final Prec@1 49.9600%\u001b[0m\n",
            "[2024-04-02 20:39:07] \u001b[32mEpoch 21 LR 0.015609\u001b[0m\n",
            "[2024-04-02 20:39:11] \u001b[32mTrain: [ 22/50] Step 000/520 Loss 2.505 Prec@(1,5) (52.1%, 80.2%)\u001b[0m\n",
            "[2024-04-02 20:39:12] \u001b[32mTrain: [ 22/50] Step 020/520 Loss 2.196 Prec@(1,5) (55.7%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:39:12] \u001b[32mTrain: [ 22/50] Step 040/520 Loss 2.182 Prec@(1,5) (55.9%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:39:13] \u001b[32mTrain: [ 22/50] Step 060/520 Loss 2.219 Prec@(1,5) (55.4%, 84.0%)\u001b[0m\n",
            "[2024-04-02 20:39:13] \u001b[32mTrain: [ 22/50] Step 080/520 Loss 2.208 Prec@(1,5) (55.8%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:39:14] \u001b[32mTrain: [ 22/50] Step 100/520 Loss 2.222 Prec@(1,5) (55.6%, 83.8%)\u001b[0m\n",
            "[2024-04-02 20:39:14] \u001b[32mTrain: [ 22/50] Step 120/520 Loss 2.217 Prec@(1,5) (55.6%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:39:15] \u001b[32mTrain: [ 22/50] Step 140/520 Loss 2.229 Prec@(1,5) (55.5%, 83.9%)\u001b[0m\n",
            "[2024-04-02 20:39:15] \u001b[32mTrain: [ 22/50] Step 160/520 Loss 2.233 Prec@(1,5) (55.4%, 83.8%)\u001b[0m\n",
            "[2024-04-02 20:39:16] \u001b[32mTrain: [ 22/50] Step 180/520 Loss 2.238 Prec@(1,5) (55.4%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:39:16] \u001b[32mTrain: [ 22/50] Step 200/520 Loss 2.234 Prec@(1,5) (55.4%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:39:17] \u001b[32mTrain: [ 22/50] Step 220/520 Loss 2.230 Prec@(1,5) (55.5%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:39:17] \u001b[32mTrain: [ 22/50] Step 240/520 Loss 2.230 Prec@(1,5) (55.5%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:39:18] \u001b[32mTrain: [ 22/50] Step 260/520 Loss 2.229 Prec@(1,5) (55.5%, 83.8%)\u001b[0m\n",
            "[2024-04-02 20:39:18] \u001b[32mTrain: [ 22/50] Step 280/520 Loss 2.239 Prec@(1,5) (55.3%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:39:19] \u001b[32mTrain: [ 22/50] Step 300/520 Loss 2.237 Prec@(1,5) (55.3%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:39:19] \u001b[32mTrain: [ 22/50] Step 320/520 Loss 2.238 Prec@(1,5) (55.3%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:39:20] \u001b[32mTrain: [ 22/50] Step 340/520 Loss 2.239 Prec@(1,5) (55.3%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:39:20] \u001b[32mTrain: [ 22/50] Step 360/520 Loss 2.239 Prec@(1,5) (55.2%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:39:21] \u001b[32mTrain: [ 22/50] Step 380/520 Loss 2.240 Prec@(1,5) (55.2%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:39:21] \u001b[32mTrain: [ 22/50] Step 400/520 Loss 2.243 Prec@(1,5) (55.3%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:39:22] \u001b[32mTrain: [ 22/50] Step 420/520 Loss 2.247 Prec@(1,5) (55.3%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:39:22] \u001b[32mTrain: [ 22/50] Step 440/520 Loss 2.248 Prec@(1,5) (55.3%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:39:23] \u001b[32mTrain: [ 22/50] Step 460/520 Loss 2.250 Prec@(1,5) (55.2%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:39:23] \u001b[32mTrain: [ 22/50] Step 480/520 Loss 2.251 Prec@(1,5) (55.2%, 83.5%)\u001b[0m\n",
            "[2024-04-02 20:39:24] \u001b[32mTrain: [ 22/50] Step 500/520 Loss 2.249 Prec@(1,5) (55.2%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:39:24] \u001b[32mTrain: [ 22/50] Step 520/520 Loss 2.248 Prec@(1,5) (55.3%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:39:24] \u001b[32mTrain: [ 22/50] Final Prec@1 55.2660%\u001b[0m\n",
            "[2024-04-02 20:39:28] \u001b[32mValid: [ 22/50] Step 000/104 Loss 2.407 Prec@(1,5) (51.0%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:39:28] \u001b[32mValid: [ 22/50] Step 020/104 Loss 2.466 Prec@(1,5) (50.0%, 81.3%)\u001b[0m\n",
            "[2024-04-02 20:39:28] \u001b[32mValid: [ 22/50] Step 040/104 Loss 2.460 Prec@(1,5) (49.6%, 81.1%)\u001b[0m\n",
            "[2024-04-02 20:39:28] \u001b[32mValid: [ 22/50] Step 060/104 Loss 2.421 Prec@(1,5) (50.0%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:39:29] \u001b[32mValid: [ 22/50] Step 080/104 Loss 2.430 Prec@(1,5) (49.5%, 80.8%)\u001b[0m\n",
            "[2024-04-02 20:39:29] \u001b[32mValid: [ 22/50] Step 100/104 Loss 2.431 Prec@(1,5) (49.6%, 80.8%)\u001b[0m\n",
            "[2024-04-02 20:39:29] \u001b[32mValid: [ 22/50] Step 104/104 Loss 2.436 Prec@(1,5) (49.6%, 80.7%)\u001b[0m\n",
            "[2024-04-02 20:39:29] \u001b[32mValid: [ 22/50] Final Prec@1 49.6000%\u001b[0m\n",
            "[2024-04-02 20:39:29] \u001b[32mEpoch 22 LR 0.014843\u001b[0m\n",
            "[2024-04-02 20:39:34] \u001b[32mTrain: [ 23/50] Step 000/520 Loss 2.227 Prec@(1,5) (53.1%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:39:34] \u001b[32mTrain: [ 23/50] Step 020/520 Loss 2.180 Prec@(1,5) (56.2%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:39:35] \u001b[32mTrain: [ 23/50] Step 040/520 Loss 2.139 Prec@(1,5) (56.8%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:39:35] \u001b[32mTrain: [ 23/50] Step 060/520 Loss 2.186 Prec@(1,5) (56.2%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:39:36] \u001b[32mTrain: [ 23/50] Step 080/520 Loss 2.181 Prec@(1,5) (56.0%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:39:36] \u001b[32mTrain: [ 23/50] Step 100/520 Loss 2.186 Prec@(1,5) (56.1%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:39:37] \u001b[32mTrain: [ 23/50] Step 120/520 Loss 2.189 Prec@(1,5) (56.1%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:39:37] \u001b[32mTrain: [ 23/50] Step 140/520 Loss 2.195 Prec@(1,5) (56.2%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:39:38] \u001b[32mTrain: [ 23/50] Step 160/520 Loss 2.195 Prec@(1,5) (56.3%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:39:38] \u001b[32mTrain: [ 23/50] Step 180/520 Loss 2.206 Prec@(1,5) (56.2%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:39:39] \u001b[32mTrain: [ 23/50] Step 200/520 Loss 2.206 Prec@(1,5) (56.3%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:39:39] \u001b[32mTrain: [ 23/50] Step 220/520 Loss 2.205 Prec@(1,5) (56.3%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:39:40] \u001b[32mTrain: [ 23/50] Step 240/520 Loss 2.208 Prec@(1,5) (56.3%, 84.0%)\u001b[0m\n",
            "[2024-04-02 20:39:40] \u001b[32mTrain: [ 23/50] Step 260/520 Loss 2.210 Prec@(1,5) (56.3%, 84.0%)\u001b[0m\n",
            "[2024-04-02 20:39:41] \u001b[32mTrain: [ 23/50] Step 280/520 Loss 2.214 Prec@(1,5) (56.2%, 84.0%)\u001b[0m\n",
            "[2024-04-02 20:39:41] \u001b[32mTrain: [ 23/50] Step 300/520 Loss 2.216 Prec@(1,5) (56.1%, 84.0%)\u001b[0m\n",
            "[2024-04-02 20:39:42] \u001b[32mTrain: [ 23/50] Step 320/520 Loss 2.211 Prec@(1,5) (56.2%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:39:42] \u001b[32mTrain: [ 23/50] Step 340/520 Loss 2.208 Prec@(1,5) (56.2%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:39:43] \u001b[32mTrain: [ 23/50] Step 360/520 Loss 2.205 Prec@(1,5) (56.3%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:39:43] \u001b[32mTrain: [ 23/50] Step 380/520 Loss 2.204 Prec@(1,5) (56.3%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:39:44] \u001b[32mTrain: [ 23/50] Step 400/520 Loss 2.207 Prec@(1,5) (56.3%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:39:44] \u001b[32mTrain: [ 23/50] Step 420/520 Loss 2.208 Prec@(1,5) (56.3%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:39:45] \u001b[32mTrain: [ 23/50] Step 440/520 Loss 2.210 Prec@(1,5) (56.2%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:39:45] \u001b[32mTrain: [ 23/50] Step 460/520 Loss 2.212 Prec@(1,5) (56.1%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:39:46] \u001b[32mTrain: [ 23/50] Step 480/520 Loss 2.211 Prec@(1,5) (56.1%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:39:46] \u001b[32mTrain: [ 23/50] Step 500/520 Loss 2.212 Prec@(1,5) (56.1%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:39:47] \u001b[32mTrain: [ 23/50] Step 520/520 Loss 2.214 Prec@(1,5) (56.0%, 84.0%)\u001b[0m\n",
            "[2024-04-02 20:39:47] \u001b[32mTrain: [ 23/50] Final Prec@1 56.0380%\u001b[0m\n",
            "[2024-04-02 20:39:50] \u001b[32mValid: [ 23/50] Step 000/104 Loss 2.558 Prec@(1,5) (58.3%, 77.1%)\u001b[0m\n",
            "[2024-04-02 20:39:51] \u001b[32mValid: [ 23/50] Step 020/104 Loss 2.625 Prec@(1,5) (50.2%, 79.4%)\u001b[0m\n",
            "[2024-04-02 20:39:51] \u001b[32mValid: [ 23/50] Step 040/104 Loss 2.600 Prec@(1,5) (49.7%, 79.8%)\u001b[0m\n",
            "[2024-04-02 20:39:51] \u001b[32mValid: [ 23/50] Step 060/104 Loss 2.552 Prec@(1,5) (50.1%, 80.2%)\u001b[0m\n",
            "[2024-04-02 20:39:51] \u001b[32mValid: [ 23/50] Step 080/104 Loss 2.577 Prec@(1,5) (49.5%, 80.2%)\u001b[0m\n",
            "[2024-04-02 20:39:51] \u001b[32mValid: [ 23/50] Step 100/104 Loss 2.579 Prec@(1,5) (49.5%, 80.3%)\u001b[0m\n",
            "[2024-04-02 20:39:51] \u001b[32mValid: [ 23/50] Step 104/104 Loss 2.578 Prec@(1,5) (49.5%, 80.2%)\u001b[0m\n",
            "[2024-04-02 20:39:51] \u001b[32mValid: [ 23/50] Final Prec@1 49.5400%\u001b[0m\n",
            "[2024-04-02 20:39:51] \u001b[32mEpoch 23 LR 0.014067\u001b[0m\n",
            "[2024-04-02 20:39:56] \u001b[32mTrain: [ 24/50] Step 000/520 Loss 2.131 Prec@(1,5) (55.2%, 79.2%)\u001b[0m\n",
            "[2024-04-02 20:39:57] \u001b[32mTrain: [ 24/50] Step 020/520 Loss 2.222 Prec@(1,5) (56.4%, 83.9%)\u001b[0m\n",
            "[2024-04-02 20:39:57] \u001b[32mTrain: [ 24/50] Step 040/520 Loss 2.233 Prec@(1,5) (56.8%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:39:58] \u001b[32mTrain: [ 24/50] Step 060/520 Loss 2.205 Prec@(1,5) (57.0%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:39:58] \u001b[32mTrain: [ 24/50] Step 080/520 Loss 2.200 Prec@(1,5) (56.6%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:39:59] \u001b[32mTrain: [ 24/50] Step 100/520 Loss 2.192 Prec@(1,5) (56.7%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:39:59] \u001b[32mTrain: [ 24/50] Step 120/520 Loss 2.194 Prec@(1,5) (56.5%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:40:00] \u001b[32mTrain: [ 24/50] Step 140/520 Loss 2.189 Prec@(1,5) (56.5%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:40:00] \u001b[32mTrain: [ 24/50] Step 160/520 Loss 2.190 Prec@(1,5) (56.5%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:40:01] \u001b[32mTrain: [ 24/50] Step 180/520 Loss 2.187 Prec@(1,5) (56.6%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:40:01] \u001b[32mTrain: [ 24/50] Step 200/520 Loss 2.184 Prec@(1,5) (56.6%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:40:02] \u001b[32mTrain: [ 24/50] Step 220/520 Loss 2.183 Prec@(1,5) (56.6%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:40:02] \u001b[32mTrain: [ 24/50] Step 240/520 Loss 2.184 Prec@(1,5) (56.6%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:40:03] \u001b[32mTrain: [ 24/50] Step 260/520 Loss 2.184 Prec@(1,5) (56.5%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:40:03] \u001b[32mTrain: [ 24/50] Step 280/520 Loss 2.194 Prec@(1,5) (56.2%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:40:04] \u001b[32mTrain: [ 24/50] Step 300/520 Loss 2.194 Prec@(1,5) (56.3%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:40:04] \u001b[32mTrain: [ 24/50] Step 320/520 Loss 2.197 Prec@(1,5) (56.2%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:40:05] \u001b[32mTrain: [ 24/50] Step 340/520 Loss 2.195 Prec@(1,5) (56.2%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:40:05] \u001b[32mTrain: [ 24/50] Step 360/520 Loss 2.193 Prec@(1,5) (56.2%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:40:06] \u001b[32mTrain: [ 24/50] Step 380/520 Loss 2.192 Prec@(1,5) (56.3%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:40:06] \u001b[32mTrain: [ 24/50] Step 400/520 Loss 2.187 Prec@(1,5) (56.4%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:40:07] \u001b[32mTrain: [ 24/50] Step 420/520 Loss 2.186 Prec@(1,5) (56.4%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:40:07] \u001b[32mTrain: [ 24/50] Step 440/520 Loss 2.187 Prec@(1,5) (56.3%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:40:08] \u001b[32mTrain: [ 24/50] Step 460/520 Loss 2.190 Prec@(1,5) (56.2%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:40:08] \u001b[32mTrain: [ 24/50] Step 480/520 Loss 2.189 Prec@(1,5) (56.2%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:40:09] \u001b[32mTrain: [ 24/50] Step 500/520 Loss 2.191 Prec@(1,5) (56.1%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:40:09] \u001b[32mTrain: [ 24/50] Step 520/520 Loss 2.193 Prec@(1,5) (56.1%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:40:10] \u001b[32mTrain: [ 24/50] Final Prec@1 56.1220%\u001b[0m\n",
            "[2024-04-02 20:40:13] \u001b[32mValid: [ 24/50] Step 000/104 Loss 2.305 Prec@(1,5) (57.3%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:40:13] \u001b[32mValid: [ 24/50] Step 020/104 Loss 2.411 Prec@(1,5) (52.1%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:40:13] \u001b[32mValid: [ 24/50] Step 040/104 Loss 2.413 Prec@(1,5) (51.5%, 81.4%)\u001b[0m\n",
            "[2024-04-02 20:40:14] \u001b[32mValid: [ 24/50] Step 060/104 Loss 2.369 Prec@(1,5) (52.0%, 81.9%)\u001b[0m\n",
            "[2024-04-02 20:40:14] \u001b[32mValid: [ 24/50] Step 080/104 Loss 2.378 Prec@(1,5) (51.7%, 81.5%)\u001b[0m\n",
            "[2024-04-02 20:40:14] \u001b[32mValid: [ 24/50] Step 100/104 Loss 2.368 Prec@(1,5) (52.0%, 81.3%)\u001b[0m\n",
            "[2024-04-02 20:40:14] \u001b[32mValid: [ 24/50] Step 104/104 Loss 2.365 Prec@(1,5) (51.9%, 81.3%)\u001b[0m\n",
            "[2024-04-02 20:40:14] \u001b[32mValid: [ 24/50] Final Prec@1 51.9100%\u001b[0m\n",
            "[2024-04-02 20:40:14] \u001b[32mEpoch 24 LR 0.013285\u001b[0m\n",
            "[2024-04-02 20:40:19] \u001b[32mTrain: [ 25/50] Step 000/520 Loss 2.313 Prec@(1,5) (56.2%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:40:19] \u001b[32mTrain: [ 25/50] Step 020/520 Loss 2.109 Prec@(1,5) (57.1%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:40:20] \u001b[32mTrain: [ 25/50] Step 040/520 Loss 2.123 Prec@(1,5) (57.5%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:40:20] \u001b[32mTrain: [ 25/50] Step 060/520 Loss 2.106 Prec@(1,5) (57.7%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:40:21] \u001b[32mTrain: [ 25/50] Step 080/520 Loss 2.115 Prec@(1,5) (57.3%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:40:21] \u001b[32mTrain: [ 25/50] Step 100/520 Loss 2.138 Prec@(1,5) (56.8%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:40:22] \u001b[32mTrain: [ 25/50] Step 120/520 Loss 2.137 Prec@(1,5) (57.1%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:40:22] \u001b[32mTrain: [ 25/50] Step 140/520 Loss 2.133 Prec@(1,5) (57.2%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:40:23] \u001b[32mTrain: [ 25/50] Step 160/520 Loss 2.139 Prec@(1,5) (57.2%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:40:23] \u001b[32mTrain: [ 25/50] Step 180/520 Loss 2.139 Prec@(1,5) (57.1%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:40:24] \u001b[32mTrain: [ 25/50] Step 200/520 Loss 2.141 Prec@(1,5) (57.0%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:40:24] \u001b[32mTrain: [ 25/50] Step 220/520 Loss 2.148 Prec@(1,5) (57.0%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:40:25] \u001b[32mTrain: [ 25/50] Step 240/520 Loss 2.147 Prec@(1,5) (57.0%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:40:25] \u001b[32mTrain: [ 25/50] Step 260/520 Loss 2.142 Prec@(1,5) (57.2%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:40:26] \u001b[32mTrain: [ 25/50] Step 280/520 Loss 2.139 Prec@(1,5) (57.3%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:40:26] \u001b[32mTrain: [ 25/50] Step 300/520 Loss 2.142 Prec@(1,5) (57.3%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:40:27] \u001b[32mTrain: [ 25/50] Step 320/520 Loss 2.143 Prec@(1,5) (57.2%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:40:27] \u001b[32mTrain: [ 25/50] Step 340/520 Loss 2.146 Prec@(1,5) (57.2%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:40:28] \u001b[32mTrain: [ 25/50] Step 360/520 Loss 2.148 Prec@(1,5) (57.1%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:40:28] \u001b[32mTrain: [ 25/50] Step 380/520 Loss 2.150 Prec@(1,5) (57.1%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:40:29] \u001b[32mTrain: [ 25/50] Step 400/520 Loss 2.156 Prec@(1,5) (57.0%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:40:29] \u001b[32mTrain: [ 25/50] Step 420/520 Loss 2.155 Prec@(1,5) (57.0%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:40:30] \u001b[32mTrain: [ 25/50] Step 440/520 Loss 2.156 Prec@(1,5) (56.9%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:40:30] \u001b[32mTrain: [ 25/50] Step 460/520 Loss 2.154 Prec@(1,5) (57.0%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:40:30] \u001b[32mTrain: [ 25/50] Step 480/520 Loss 2.152 Prec@(1,5) (57.1%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:40:31] \u001b[32mTrain: [ 25/50] Step 500/520 Loss 2.152 Prec@(1,5) (57.1%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:40:31] \u001b[32mTrain: [ 25/50] Step 520/520 Loss 2.155 Prec@(1,5) (57.1%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:40:32] \u001b[32mTrain: [ 25/50] Final Prec@1 57.0660%\u001b[0m\n",
            "[2024-04-02 20:40:35] \u001b[32mValid: [ 25/50] Step 000/104 Loss 2.416 Prec@(1,5) (52.1%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:40:35] \u001b[32mValid: [ 25/50] Step 020/104 Loss 2.424 Prec@(1,5) (52.2%, 81.9%)\u001b[0m\n",
            "[2024-04-02 20:40:36] \u001b[32mValid: [ 25/50] Step 040/104 Loss 2.401 Prec@(1,5) (52.1%, 81.8%)\u001b[0m\n",
            "[2024-04-02 20:40:36] \u001b[32mValid: [ 25/50] Step 060/104 Loss 2.361 Prec@(1,5) (52.2%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:40:36] \u001b[32mValid: [ 25/50] Step 080/104 Loss 2.381 Prec@(1,5) (51.8%, 81.4%)\u001b[0m\n",
            "[2024-04-02 20:40:36] \u001b[32mValid: [ 25/50] Step 100/104 Loss 2.382 Prec@(1,5) (52.0%, 81.4%)\u001b[0m\n",
            "[2024-04-02 20:40:36] \u001b[32mValid: [ 25/50] Step 104/104 Loss 2.382 Prec@(1,5) (52.0%, 81.4%)\u001b[0m\n",
            "[2024-04-02 20:40:36] \u001b[32mValid: [ 25/50] Final Prec@1 51.9900%\u001b[0m\n",
            "[2024-04-02 20:40:36] \u001b[32mEpoch 25 LR 0.012500\u001b[0m\n",
            "[2024-04-02 20:40:41] \u001b[32mTrain: [ 26/50] Step 000/520 Loss 1.830 Prec@(1,5) (61.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:40:41] \u001b[32mTrain: [ 26/50] Step 020/520 Loss 2.254 Prec@(1,5) (54.8%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:40:42] \u001b[32mTrain: [ 26/50] Step 040/520 Loss 2.142 Prec@(1,5) (57.2%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:40:42] \u001b[32mTrain: [ 26/50] Step 060/520 Loss 2.130 Prec@(1,5) (57.4%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:40:43] \u001b[32mTrain: [ 26/50] Step 080/520 Loss 2.126 Prec@(1,5) (57.5%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:40:43] \u001b[32mTrain: [ 26/50] Step 100/520 Loss 2.113 Prec@(1,5) (57.6%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:40:44] \u001b[32mTrain: [ 26/50] Step 120/520 Loss 2.106 Prec@(1,5) (57.7%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:40:44] \u001b[32mTrain: [ 26/50] Step 140/520 Loss 2.105 Prec@(1,5) (57.8%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:40:45] \u001b[32mTrain: [ 26/50] Step 160/520 Loss 2.107 Prec@(1,5) (57.7%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:40:45] \u001b[32mTrain: [ 26/50] Step 180/520 Loss 2.116 Prec@(1,5) (57.5%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:40:46] \u001b[32mTrain: [ 26/50] Step 200/520 Loss 2.114 Prec@(1,5) (57.5%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:40:47] \u001b[32mTrain: [ 26/50] Step 220/520 Loss 2.115 Prec@(1,5) (57.4%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:40:47] \u001b[32mTrain: [ 26/50] Step 240/520 Loss 2.117 Prec@(1,5) (57.3%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:40:48] \u001b[32mTrain: [ 26/50] Step 260/520 Loss 2.114 Prec@(1,5) (57.4%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:40:48] \u001b[32mTrain: [ 26/50] Step 280/520 Loss 2.115 Prec@(1,5) (57.4%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:40:49] \u001b[32mTrain: [ 26/50] Step 300/520 Loss 2.118 Prec@(1,5) (57.4%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:40:49] \u001b[32mTrain: [ 26/50] Step 320/520 Loss 2.122 Prec@(1,5) (57.4%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:40:50] \u001b[32mTrain: [ 26/50] Step 340/520 Loss 2.123 Prec@(1,5) (57.4%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:40:50] \u001b[32mTrain: [ 26/50] Step 360/520 Loss 2.120 Prec@(1,5) (57.4%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:40:51] \u001b[32mTrain: [ 26/50] Step 380/520 Loss 2.120 Prec@(1,5) (57.4%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:40:51] \u001b[32mTrain: [ 26/50] Step 400/520 Loss 2.125 Prec@(1,5) (57.4%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:40:52] \u001b[32mTrain: [ 26/50] Step 420/520 Loss 2.127 Prec@(1,5) (57.3%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:40:52] \u001b[32mTrain: [ 26/50] Step 440/520 Loss 2.130 Prec@(1,5) (57.3%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:40:53] \u001b[32mTrain: [ 26/50] Step 460/520 Loss 2.132 Prec@(1,5) (57.2%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:40:53] \u001b[32mTrain: [ 26/50] Step 480/520 Loss 2.137 Prec@(1,5) (57.0%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:40:54] \u001b[32mTrain: [ 26/50] Step 500/520 Loss 2.135 Prec@(1,5) (57.1%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:40:54] \u001b[32mTrain: [ 26/50] Step 520/520 Loss 2.134 Prec@(1,5) (57.1%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:40:54] \u001b[32mTrain: [ 26/50] Final Prec@1 57.1000%\u001b[0m\n",
            "[2024-04-02 20:40:58] \u001b[32mValid: [ 26/50] Step 000/104 Loss 2.163 Prec@(1,5) (58.3%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:40:58] \u001b[32mValid: [ 26/50] Step 020/104 Loss 2.188 Prec@(1,5) (53.9%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:40:58] \u001b[32mValid: [ 26/50] Step 040/104 Loss 2.187 Prec@(1,5) (53.5%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:40:58] \u001b[32mValid: [ 26/50] Step 060/104 Loss 2.150 Prec@(1,5) (53.6%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:40:59] \u001b[32mValid: [ 26/50] Step 080/104 Loss 2.151 Prec@(1,5) (53.4%, 83.1%)\u001b[0m\n",
            "[2024-04-02 20:40:59] \u001b[32mValid: [ 26/50] Step 100/104 Loss 2.143 Prec@(1,5) (53.7%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:40:59] \u001b[32mValid: [ 26/50] Step 104/104 Loss 2.147 Prec@(1,5) (53.7%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:40:59] \u001b[32mValid: [ 26/50] Final Prec@1 53.6600%\u001b[0m\n",
            "[2024-04-02 20:40:59] \u001b[32mEpoch 26 LR 0.011716\u001b[0m\n",
            "[2024-04-02 20:41:04] \u001b[32mTrain: [ 27/50] Step 000/520 Loss 2.012 Prec@(1,5) (54.2%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:41:04] \u001b[32mTrain: [ 27/50] Step 020/520 Loss 2.177 Prec@(1,5) (56.5%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:41:05] \u001b[32mTrain: [ 27/50] Step 040/520 Loss 2.088 Prec@(1,5) (58.0%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:41:05] \u001b[32mTrain: [ 27/50] Step 060/520 Loss 2.110 Prec@(1,5) (57.5%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:41:06] \u001b[32mTrain: [ 27/50] Step 080/520 Loss 2.103 Prec@(1,5) (57.5%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:41:06] \u001b[32mTrain: [ 27/50] Step 100/520 Loss 2.116 Prec@(1,5) (57.3%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:41:07] \u001b[32mTrain: [ 27/50] Step 120/520 Loss 2.112 Prec@(1,5) (57.4%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:41:07] \u001b[32mTrain: [ 27/50] Step 140/520 Loss 2.105 Prec@(1,5) (57.5%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:41:08] \u001b[32mTrain: [ 27/50] Step 160/520 Loss 2.101 Prec@(1,5) (57.6%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:41:08] \u001b[32mTrain: [ 27/50] Step 180/520 Loss 2.104 Prec@(1,5) (57.6%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:41:09] \u001b[32mTrain: [ 27/50] Step 200/520 Loss 2.103 Prec@(1,5) (57.6%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:41:09] \u001b[32mTrain: [ 27/50] Step 220/520 Loss 2.102 Prec@(1,5) (57.7%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:41:10] \u001b[32mTrain: [ 27/50] Step 240/520 Loss 2.100 Prec@(1,5) (57.8%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:41:10] \u001b[32mTrain: [ 27/50] Step 260/520 Loss 2.100 Prec@(1,5) (57.8%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:41:11] \u001b[32mTrain: [ 27/50] Step 280/520 Loss 2.099 Prec@(1,5) (57.7%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:41:11] \u001b[32mTrain: [ 27/50] Step 300/520 Loss 2.097 Prec@(1,5) (57.8%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:41:12] \u001b[32mTrain: [ 27/50] Step 320/520 Loss 2.098 Prec@(1,5) (57.8%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:41:12] \u001b[32mTrain: [ 27/50] Step 340/520 Loss 2.099 Prec@(1,5) (57.9%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:41:13] \u001b[32mTrain: [ 27/50] Step 360/520 Loss 2.099 Prec@(1,5) (57.8%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:41:13] \u001b[32mTrain: [ 27/50] Step 380/520 Loss 2.101 Prec@(1,5) (57.8%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:41:14] \u001b[32mTrain: [ 27/50] Step 400/520 Loss 2.102 Prec@(1,5) (57.8%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:41:14] \u001b[32mTrain: [ 27/50] Step 420/520 Loss 2.103 Prec@(1,5) (57.7%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:41:15] \u001b[32mTrain: [ 27/50] Step 440/520 Loss 2.102 Prec@(1,5) (57.8%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:41:15] \u001b[32mTrain: [ 27/50] Step 460/520 Loss 2.106 Prec@(1,5) (57.7%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:41:16] \u001b[32mTrain: [ 27/50] Step 480/520 Loss 2.101 Prec@(1,5) (57.8%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:41:16] \u001b[32mTrain: [ 27/50] Step 500/520 Loss 2.103 Prec@(1,5) (57.7%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:41:17] \u001b[32mTrain: [ 27/50] Step 520/520 Loss 2.107 Prec@(1,5) (57.7%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:41:17] \u001b[32mTrain: [ 27/50] Final Prec@1 57.6920%\u001b[0m\n",
            "[2024-04-02 20:41:20] \u001b[32mValid: [ 27/50] Step 000/104 Loss 2.365 Prec@(1,5) (57.3%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:41:21] \u001b[32mValid: [ 27/50] Step 020/104 Loss 2.458 Prec@(1,5) (52.6%, 81.6%)\u001b[0m\n",
            "[2024-04-02 20:41:21] \u001b[32mValid: [ 27/50] Step 040/104 Loss 2.427 Prec@(1,5) (52.1%, 81.8%)\u001b[0m\n",
            "[2024-04-02 20:41:21] \u001b[32mValid: [ 27/50] Step 060/104 Loss 2.393 Prec@(1,5) (52.4%, 81.8%)\u001b[0m\n",
            "[2024-04-02 20:41:21] \u001b[32mValid: [ 27/50] Step 080/104 Loss 2.400 Prec@(1,5) (52.1%, 81.6%)\u001b[0m\n",
            "[2024-04-02 20:41:21] \u001b[32mValid: [ 27/50] Step 100/104 Loss 2.385 Prec@(1,5) (52.4%, 81.6%)\u001b[0m\n",
            "[2024-04-02 20:41:21] \u001b[32mValid: [ 27/50] Step 104/104 Loss 2.386 Prec@(1,5) (52.4%, 81.5%)\u001b[0m\n",
            "[2024-04-02 20:41:22] \u001b[32mValid: [ 27/50] Final Prec@1 52.4000%\u001b[0m\n",
            "[2024-04-02 20:41:22] \u001b[32mEpoch 27 LR 0.010934\u001b[0m\n",
            "[2024-04-02 20:41:26] \u001b[32mTrain: [ 28/50] Step 000/520 Loss 1.903 Prec@(1,5) (62.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:41:27] \u001b[32mTrain: [ 28/50] Step 020/520 Loss 2.046 Prec@(1,5) (59.1%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:41:27] \u001b[32mTrain: [ 28/50] Step 040/520 Loss 2.033 Prec@(1,5) (58.9%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:41:28] \u001b[32mTrain: [ 28/50] Step 060/520 Loss 2.015 Prec@(1,5) (59.2%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:41:28] \u001b[32mTrain: [ 28/50] Step 080/520 Loss 2.034 Prec@(1,5) (59.1%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:41:29] \u001b[32mTrain: [ 28/50] Step 100/520 Loss 2.037 Prec@(1,5) (59.2%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:41:29] \u001b[32mTrain: [ 28/50] Step 120/520 Loss 2.043 Prec@(1,5) (59.3%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:41:30] \u001b[32mTrain: [ 28/50] Step 140/520 Loss 2.059 Prec@(1,5) (59.1%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:41:30] \u001b[32mTrain: [ 28/50] Step 160/520 Loss 2.061 Prec@(1,5) (59.1%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:41:31] \u001b[32mTrain: [ 28/50] Step 180/520 Loss 2.056 Prec@(1,5) (59.1%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:41:31] \u001b[32mTrain: [ 28/50] Step 200/520 Loss 2.062 Prec@(1,5) (59.0%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:41:32] \u001b[32mTrain: [ 28/50] Step 220/520 Loss 2.065 Prec@(1,5) (58.9%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:41:32] \u001b[32mTrain: [ 28/50] Step 240/520 Loss 2.067 Prec@(1,5) (58.8%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:41:33] \u001b[32mTrain: [ 28/50] Step 260/520 Loss 2.067 Prec@(1,5) (58.7%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:41:33] \u001b[32mTrain: [ 28/50] Step 280/520 Loss 2.068 Prec@(1,5) (58.7%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:41:34] \u001b[32mTrain: [ 28/50] Step 300/520 Loss 2.073 Prec@(1,5) (58.7%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:41:34] \u001b[32mTrain: [ 28/50] Step 320/520 Loss 2.073 Prec@(1,5) (58.7%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:41:35] \u001b[32mTrain: [ 28/50] Step 340/520 Loss 2.073 Prec@(1,5) (58.6%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:41:35] \u001b[32mTrain: [ 28/50] Step 360/520 Loss 2.067 Prec@(1,5) (58.6%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:41:36] \u001b[32mTrain: [ 28/50] Step 380/520 Loss 2.069 Prec@(1,5) (58.6%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:41:36] \u001b[32mTrain: [ 28/50] Step 400/520 Loss 2.071 Prec@(1,5) (58.6%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:41:37] \u001b[32mTrain: [ 28/50] Step 420/520 Loss 2.072 Prec@(1,5) (58.6%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:41:37] \u001b[32mTrain: [ 28/50] Step 440/520 Loss 2.069 Prec@(1,5) (58.7%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:41:38] \u001b[32mTrain: [ 28/50] Step 460/520 Loss 2.068 Prec@(1,5) (58.6%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:41:38] \u001b[32mTrain: [ 28/50] Step 480/520 Loss 2.068 Prec@(1,5) (58.7%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:41:39] \u001b[32mTrain: [ 28/50] Step 500/520 Loss 2.068 Prec@(1,5) (58.7%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:41:39] \u001b[32mTrain: [ 28/50] Step 520/520 Loss 2.070 Prec@(1,5) (58.6%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:41:39] \u001b[32mTrain: [ 28/50] Final Prec@1 58.5800%\u001b[0m\n",
            "[2024-04-02 20:41:43] \u001b[32mValid: [ 28/50] Step 000/104 Loss 2.066 Prec@(1,5) (59.4%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:41:43] \u001b[32mValid: [ 28/50] Step 020/104 Loss 2.259 Prec@(1,5) (55.4%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:41:43] \u001b[32mValid: [ 28/50] Step 040/104 Loss 2.209 Prec@(1,5) (55.1%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:41:43] \u001b[32mValid: [ 28/50] Step 060/104 Loss 2.161 Prec@(1,5) (55.1%, 83.1%)\u001b[0m\n",
            "[2024-04-02 20:41:44] \u001b[32mValid: [ 28/50] Step 080/104 Loss 2.150 Prec@(1,5) (55.0%, 83.4%)\u001b[0m\n",
            "[2024-04-02 20:41:44] \u001b[32mValid: [ 28/50] Step 100/104 Loss 2.146 Prec@(1,5) (55.0%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:41:44] \u001b[32mValid: [ 28/50] Step 104/104 Loss 2.145 Prec@(1,5) (55.0%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:41:44] \u001b[32mValid: [ 28/50] Final Prec@1 55.0300%\u001b[0m\n",
            "[2024-04-02 20:41:44] \u001b[32mEpoch 28 LR 0.010158\u001b[0m\n",
            "[2024-04-02 20:41:49] \u001b[32mTrain: [ 29/50] Step 000/520 Loss 2.087 Prec@(1,5) (61.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:41:49] \u001b[32mTrain: [ 29/50] Step 020/520 Loss 2.044 Prec@(1,5) (59.4%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:41:50] \u001b[32mTrain: [ 29/50] Step 040/520 Loss 2.033 Prec@(1,5) (59.4%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:41:50] \u001b[32mTrain: [ 29/50] Step 060/520 Loss 2.029 Prec@(1,5) (59.8%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:41:51] \u001b[32mTrain: [ 29/50] Step 080/520 Loss 2.033 Prec@(1,5) (59.5%, 86.1%)\u001b[0m\n",
            "[2024-04-02 20:41:51] \u001b[32mTrain: [ 29/50] Step 100/520 Loss 2.033 Prec@(1,5) (59.4%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:41:52] \u001b[32mTrain: [ 29/50] Step 120/520 Loss 2.013 Prec@(1,5) (59.7%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:41:52] \u001b[32mTrain: [ 29/50] Step 140/520 Loss 2.024 Prec@(1,5) (59.7%, 86.1%)\u001b[0m\n",
            "[2024-04-02 20:41:53] \u001b[32mTrain: [ 29/50] Step 160/520 Loss 2.034 Prec@(1,5) (59.5%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:41:53] \u001b[32mTrain: [ 29/50] Step 180/520 Loss 2.045 Prec@(1,5) (59.3%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:41:54] \u001b[32mTrain: [ 29/50] Step 200/520 Loss 2.055 Prec@(1,5) (59.1%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:41:54] \u001b[32mTrain: [ 29/50] Step 220/520 Loss 2.046 Prec@(1,5) (59.3%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:41:55] \u001b[32mTrain: [ 29/50] Step 240/520 Loss 2.044 Prec@(1,5) (59.2%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:41:55] \u001b[32mTrain: [ 29/50] Step 260/520 Loss 2.047 Prec@(1,5) (59.2%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:41:55] \u001b[32mTrain: [ 29/50] Step 280/520 Loss 2.046 Prec@(1,5) (59.2%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:41:56] \u001b[32mTrain: [ 29/50] Step 300/520 Loss 2.046 Prec@(1,5) (59.1%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:41:56] \u001b[32mTrain: [ 29/50] Step 320/520 Loss 2.046 Prec@(1,5) (59.2%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:41:57] \u001b[32mTrain: [ 29/50] Step 340/520 Loss 2.050 Prec@(1,5) (59.1%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:41:57] \u001b[32mTrain: [ 29/50] Step 360/520 Loss 2.049 Prec@(1,5) (59.0%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:41:58] \u001b[32mTrain: [ 29/50] Step 380/520 Loss 2.050 Prec@(1,5) (59.0%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:41:58] \u001b[32mTrain: [ 29/50] Step 400/520 Loss 2.054 Prec@(1,5) (58.9%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:41:59] \u001b[32mTrain: [ 29/50] Step 420/520 Loss 2.053 Prec@(1,5) (59.0%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:41:59] \u001b[32mTrain: [ 29/50] Step 440/520 Loss 2.054 Prec@(1,5) (58.9%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:42:00] \u001b[32mTrain: [ 29/50] Step 460/520 Loss 2.055 Prec@(1,5) (58.8%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:42:00] \u001b[32mTrain: [ 29/50] Step 480/520 Loss 2.055 Prec@(1,5) (58.8%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:42:01] \u001b[32mTrain: [ 29/50] Step 500/520 Loss 2.055 Prec@(1,5) (58.8%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:42:01] \u001b[32mTrain: [ 29/50] Step 520/520 Loss 2.056 Prec@(1,5) (58.8%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:42:02] \u001b[32mTrain: [ 29/50] Final Prec@1 58.7600%\u001b[0m\n",
            "[2024-04-02 20:42:05] \u001b[32mValid: [ 29/50] Step 000/104 Loss 2.113 Prec@(1,5) (53.1%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:42:05] \u001b[32mValid: [ 29/50] Step 020/104 Loss 2.233 Prec@(1,5) (54.7%, 83.4%)\u001b[0m\n",
            "[2024-04-02 20:42:05] \u001b[32mValid: [ 29/50] Step 040/104 Loss 2.237 Prec@(1,5) (53.7%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:42:06] \u001b[32mValid: [ 29/50] Step 060/104 Loss 2.211 Prec@(1,5) (54.2%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:42:06] \u001b[32mValid: [ 29/50] Step 080/104 Loss 2.228 Prec@(1,5) (53.9%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:42:06] \u001b[32mValid: [ 29/50] Step 100/104 Loss 2.215 Prec@(1,5) (54.0%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:42:06] \u001b[32mValid: [ 29/50] Step 104/104 Loss 2.214 Prec@(1,5) (53.9%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:42:06] \u001b[32mValid: [ 29/50] Final Prec@1 53.9400%\u001b[0m\n",
            "[2024-04-02 20:42:06] \u001b[32mEpoch 29 LR 0.009392\u001b[0m\n",
            "[2024-04-02 20:42:11] \u001b[32mTrain: [ 30/50] Step 000/520 Loss 2.155 Prec@(1,5) (57.3%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:42:11] \u001b[32mTrain: [ 30/50] Step 020/520 Loss 2.027 Prec@(1,5) (58.3%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:42:12] \u001b[32mTrain: [ 30/50] Step 040/520 Loss 2.021 Prec@(1,5) (59.1%, 86.1%)\u001b[0m\n",
            "[2024-04-02 20:42:12] \u001b[32mTrain: [ 30/50] Step 060/520 Loss 2.039 Prec@(1,5) (59.1%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:42:13] \u001b[32mTrain: [ 30/50] Step 080/520 Loss 2.037 Prec@(1,5) (59.1%, 86.1%)\u001b[0m\n",
            "[2024-04-02 20:42:13] \u001b[32mTrain: [ 30/50] Step 100/520 Loss 2.003 Prec@(1,5) (59.9%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:42:14] \u001b[32mTrain: [ 30/50] Step 120/520 Loss 1.998 Prec@(1,5) (59.8%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:42:14] \u001b[32mTrain: [ 30/50] Step 140/520 Loss 2.010 Prec@(1,5) (59.6%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:42:15] \u001b[32mTrain: [ 30/50] Step 160/520 Loss 2.008 Prec@(1,5) (59.6%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:42:15] \u001b[32mTrain: [ 30/50] Step 180/520 Loss 2.009 Prec@(1,5) (59.6%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:42:16] \u001b[32mTrain: [ 30/50] Step 200/520 Loss 2.010 Prec@(1,5) (59.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:42:16] \u001b[32mTrain: [ 30/50] Step 220/520 Loss 2.009 Prec@(1,5) (59.6%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:42:17] \u001b[32mTrain: [ 30/50] Step 240/520 Loss 2.007 Prec@(1,5) (59.6%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:42:17] \u001b[32mTrain: [ 30/50] Step 260/520 Loss 2.012 Prec@(1,5) (59.5%, 86.4%)\u001b[0m\n",
            "[2024-04-02 20:42:18] \u001b[32mTrain: [ 30/50] Step 280/520 Loss 2.017 Prec@(1,5) (59.4%, 86.4%)\u001b[0m\n",
            "[2024-04-02 20:42:18] \u001b[32mTrain: [ 30/50] Step 300/520 Loss 2.017 Prec@(1,5) (59.3%, 86.4%)\u001b[0m\n",
            "[2024-04-02 20:42:19] \u001b[32mTrain: [ 30/50] Step 320/520 Loss 2.018 Prec@(1,5) (59.3%, 86.4%)\u001b[0m\n",
            "[2024-04-02 20:42:19] \u001b[32mTrain: [ 30/50] Step 340/520 Loss 2.017 Prec@(1,5) (59.4%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:42:20] \u001b[32mTrain: [ 30/50] Step 360/520 Loss 2.017 Prec@(1,5) (59.4%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:42:20] \u001b[32mTrain: [ 30/50] Step 380/520 Loss 2.019 Prec@(1,5) (59.3%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:42:21] \u001b[32mTrain: [ 30/50] Step 400/520 Loss 2.019 Prec@(1,5) (59.3%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:42:21] \u001b[32mTrain: [ 30/50] Step 420/520 Loss 2.023 Prec@(1,5) (59.3%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:42:22] \u001b[32mTrain: [ 30/50] Step 440/520 Loss 2.023 Prec@(1,5) (59.2%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:42:22] \u001b[32mTrain: [ 30/50] Step 460/520 Loss 2.021 Prec@(1,5) (59.3%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:42:23] \u001b[32mTrain: [ 30/50] Step 480/520 Loss 2.019 Prec@(1,5) (59.3%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:42:23] \u001b[32mTrain: [ 30/50] Step 500/520 Loss 2.021 Prec@(1,5) (59.3%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:42:24] \u001b[32mTrain: [ 30/50] Step 520/520 Loss 2.023 Prec@(1,5) (59.2%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:42:24] \u001b[32mTrain: [ 30/50] Final Prec@1 59.2180%\u001b[0m\n",
            "[2024-04-02 20:42:27] \u001b[32mValid: [ 30/50] Step 000/104 Loss 2.014 Prec@(1,5) (59.4%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:42:27] \u001b[32mValid: [ 30/50] Step 020/104 Loss 2.064 Prec@(1,5) (57.0%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:42:28] \u001b[32mValid: [ 30/50] Step 040/104 Loss 2.069 Prec@(1,5) (56.4%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:42:28] \u001b[32mValid: [ 30/50] Step 060/104 Loss 2.033 Prec@(1,5) (56.5%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:42:28] \u001b[32mValid: [ 30/50] Step 080/104 Loss 2.039 Prec@(1,5) (56.2%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:42:28] \u001b[32mValid: [ 30/50] Step 100/104 Loss 2.032 Prec@(1,5) (56.3%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:42:28] \u001b[32mValid: [ 30/50] Step 104/104 Loss 2.029 Prec@(1,5) (56.3%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:42:28] \u001b[32mValid: [ 30/50] Final Prec@1 56.3400%\u001b[0m\n",
            "[2024-04-02 20:42:28] \u001b[32mEpoch 30 LR 0.008638\u001b[0m\n",
            "[2024-04-02 20:42:33] \u001b[32mTrain: [ 31/50] Step 000/520 Loss 2.038 Prec@(1,5) (59.4%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:42:33] \u001b[32mTrain: [ 31/50] Step 020/520 Loss 1.953 Prec@(1,5) (60.6%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:42:34] \u001b[32mTrain: [ 31/50] Step 040/520 Loss 1.983 Prec@(1,5) (60.0%, 86.8%)\u001b[0m\n",
            "[2024-04-02 20:42:34] \u001b[32mTrain: [ 31/50] Step 060/520 Loss 1.964 Prec@(1,5) (59.9%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:42:35] \u001b[32mTrain: [ 31/50] Step 080/520 Loss 1.974 Prec@(1,5) (60.0%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:42:35] \u001b[32mTrain: [ 31/50] Step 100/520 Loss 1.978 Prec@(1,5) (60.0%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:42:36] \u001b[32mTrain: [ 31/50] Step 120/520 Loss 1.977 Prec@(1,5) (59.9%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:42:36] \u001b[32mTrain: [ 31/50] Step 140/520 Loss 1.975 Prec@(1,5) (60.0%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:42:37] \u001b[32mTrain: [ 31/50] Step 160/520 Loss 1.971 Prec@(1,5) (60.1%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:42:37] \u001b[32mTrain: [ 31/50] Step 180/520 Loss 1.987 Prec@(1,5) (59.8%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:42:38] \u001b[32mTrain: [ 31/50] Step 200/520 Loss 1.991 Prec@(1,5) (59.7%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:42:38] \u001b[32mTrain: [ 31/50] Step 220/520 Loss 1.990 Prec@(1,5) (59.8%, 86.8%)\u001b[0m\n",
            "[2024-04-02 20:42:39] \u001b[32mTrain: [ 31/50] Step 240/520 Loss 1.994 Prec@(1,5) (59.8%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:42:39] \u001b[32mTrain: [ 31/50] Step 260/520 Loss 1.995 Prec@(1,5) (59.8%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:42:40] \u001b[32mTrain: [ 31/50] Step 280/520 Loss 1.999 Prec@(1,5) (59.8%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:42:40] \u001b[32mTrain: [ 31/50] Step 300/520 Loss 2.003 Prec@(1,5) (59.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:42:41] \u001b[32mTrain: [ 31/50] Step 320/520 Loss 2.000 Prec@(1,5) (59.8%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:42:41] \u001b[32mTrain: [ 31/50] Step 340/520 Loss 2.002 Prec@(1,5) (59.8%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:42:42] \u001b[32mTrain: [ 31/50] Step 360/520 Loss 2.002 Prec@(1,5) (59.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:42:42] \u001b[32mTrain: [ 31/50] Step 380/520 Loss 2.003 Prec@(1,5) (59.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:42:43] \u001b[32mTrain: [ 31/50] Step 400/520 Loss 2.003 Prec@(1,5) (59.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:42:43] \u001b[32mTrain: [ 31/50] Step 420/520 Loss 2.000 Prec@(1,5) (59.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:42:44] \u001b[32mTrain: [ 31/50] Step 440/520 Loss 2.001 Prec@(1,5) (59.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:42:44] \u001b[32mTrain: [ 31/50] Step 460/520 Loss 2.002 Prec@(1,5) (59.6%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:42:45] \u001b[32mTrain: [ 31/50] Step 480/520 Loss 2.000 Prec@(1,5) (59.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:42:45] \u001b[32mTrain: [ 31/50] Step 500/520 Loss 2.003 Prec@(1,5) (59.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:42:46] \u001b[32mTrain: [ 31/50] Step 520/520 Loss 2.007 Prec@(1,5) (59.6%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:42:46] \u001b[32mTrain: [ 31/50] Final Prec@1 59.6360%\u001b[0m\n",
            "[2024-04-02 20:42:50] \u001b[32mValid: [ 31/50] Step 000/104 Loss 2.243 Prec@(1,5) (56.2%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:42:50] \u001b[32mValid: [ 31/50] Step 020/104 Loss 2.111 Prec@(1,5) (56.8%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:42:50] \u001b[32mValid: [ 31/50] Step 040/104 Loss 2.104 Prec@(1,5) (56.2%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:42:50] \u001b[32mValid: [ 31/50] Step 060/104 Loss 2.058 Prec@(1,5) (56.5%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:42:50] \u001b[32mValid: [ 31/50] Step 080/104 Loss 2.057 Prec@(1,5) (56.3%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:42:50] \u001b[32mValid: [ 31/50] Step 100/104 Loss 2.048 Prec@(1,5) (56.4%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:42:50] \u001b[32mValid: [ 31/50] Step 104/104 Loss 2.045 Prec@(1,5) (56.5%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:42:51] \u001b[32mValid: [ 31/50] Final Prec@1 56.4500%\u001b[0m\n",
            "[2024-04-02 20:42:51] \u001b[32mEpoch 31 LR 0.007899\u001b[0m\n",
            "[2024-04-02 20:42:55] \u001b[32mTrain: [ 32/50] Step 000/520 Loss 2.087 Prec@(1,5) (58.3%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:42:56] \u001b[32mTrain: [ 32/50] Step 020/520 Loss 1.984 Prec@(1,5) (59.4%, 86.8%)\u001b[0m\n",
            "[2024-04-02 20:42:56] \u001b[32mTrain: [ 32/50] Step 040/520 Loss 1.971 Prec@(1,5) (60.0%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:42:57] \u001b[32mTrain: [ 32/50] Step 060/520 Loss 1.973 Prec@(1,5) (60.0%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:42:57] \u001b[32mTrain: [ 32/50] Step 080/520 Loss 1.967 Prec@(1,5) (60.2%, 86.8%)\u001b[0m\n",
            "[2024-04-02 20:42:58] \u001b[32mTrain: [ 32/50] Step 100/520 Loss 1.962 Prec@(1,5) (60.3%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:42:58] \u001b[32mTrain: [ 32/50] Step 120/520 Loss 1.964 Prec@(1,5) (60.4%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:42:59] \u001b[32mTrain: [ 32/50] Step 140/520 Loss 1.965 Prec@(1,5) (60.2%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:42:59] \u001b[32mTrain: [ 32/50] Step 160/520 Loss 1.974 Prec@(1,5) (60.0%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:43:00] \u001b[32mTrain: [ 32/50] Step 180/520 Loss 1.969 Prec@(1,5) (60.0%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:43:00] \u001b[32mTrain: [ 32/50] Step 200/520 Loss 1.971 Prec@(1,5) (60.0%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:43:01] \u001b[32mTrain: [ 32/50] Step 220/520 Loss 1.967 Prec@(1,5) (60.1%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:43:01] \u001b[32mTrain: [ 32/50] Step 240/520 Loss 1.969 Prec@(1,5) (60.1%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:43:02] \u001b[32mTrain: [ 32/50] Step 260/520 Loss 1.964 Prec@(1,5) (60.1%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:43:02] \u001b[32mTrain: [ 32/50] Step 280/520 Loss 1.967 Prec@(1,5) (60.2%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:43:03] \u001b[32mTrain: [ 32/50] Step 300/520 Loss 1.966 Prec@(1,5) (60.2%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:43:03] \u001b[32mTrain: [ 32/50] Step 320/520 Loss 1.964 Prec@(1,5) (60.2%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:43:04] \u001b[32mTrain: [ 32/50] Step 340/520 Loss 1.958 Prec@(1,5) (60.3%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:43:04] \u001b[32mTrain: [ 32/50] Step 360/520 Loss 1.961 Prec@(1,5) (60.3%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:43:05] \u001b[32mTrain: [ 32/50] Step 380/520 Loss 1.966 Prec@(1,5) (60.2%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:43:05] \u001b[32mTrain: [ 32/50] Step 400/520 Loss 1.969 Prec@(1,5) (60.2%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:43:06] \u001b[32mTrain: [ 32/50] Step 420/520 Loss 1.971 Prec@(1,5) (60.2%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:43:06] \u001b[32mTrain: [ 32/50] Step 440/520 Loss 1.972 Prec@(1,5) (60.2%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:43:07] \u001b[32mTrain: [ 32/50] Step 460/520 Loss 1.975 Prec@(1,5) (60.2%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:43:07] \u001b[32mTrain: [ 32/50] Step 480/520 Loss 1.975 Prec@(1,5) (60.2%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:43:08] \u001b[32mTrain: [ 32/50] Step 500/520 Loss 1.978 Prec@(1,5) (60.1%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:43:08] \u001b[32mTrain: [ 32/50] Step 520/520 Loss 1.979 Prec@(1,5) (60.1%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:43:09] \u001b[32mTrain: [ 32/50] Final Prec@1 60.1120%\u001b[0m\n",
            "[2024-04-02 20:43:12] \u001b[32mValid: [ 32/50] Step 000/104 Loss 2.107 Prec@(1,5) (57.3%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:43:12] \u001b[32mValid: [ 32/50] Step 020/104 Loss 2.121 Prec@(1,5) (55.9%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:43:12] \u001b[32mValid: [ 32/50] Step 040/104 Loss 2.098 Prec@(1,5) (55.6%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:43:13] \u001b[32mValid: [ 32/50] Step 060/104 Loss 2.071 Prec@(1,5) (56.1%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:43:13] \u001b[32mValid: [ 32/50] Step 080/104 Loss 2.072 Prec@(1,5) (55.7%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:43:13] \u001b[32mValid: [ 32/50] Step 100/104 Loss 2.061 Prec@(1,5) (56.0%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:43:13] \u001b[32mValid: [ 32/50] Step 104/104 Loss 2.064 Prec@(1,5) (55.9%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:43:13] \u001b[32mValid: [ 32/50] Final Prec@1 55.9400%\u001b[0m\n",
            "[2024-04-02 20:43:13] \u001b[32mEpoch 32 LR 0.007178\u001b[0m\n",
            "[2024-04-02 20:43:18] \u001b[32mTrain: [ 33/50] Step 000/520 Loss 1.944 Prec@(1,5) (60.4%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:43:18] \u001b[32mTrain: [ 33/50] Step 020/520 Loss 1.919 Prec@(1,5) (61.8%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:43:19] \u001b[32mTrain: [ 33/50] Step 040/520 Loss 1.956 Prec@(1,5) (61.4%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:43:19] \u001b[32mTrain: [ 33/50] Step 060/520 Loss 1.956 Prec@(1,5) (60.8%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:43:20] \u001b[32mTrain: [ 33/50] Step 080/520 Loss 1.960 Prec@(1,5) (60.7%, 86.8%)\u001b[0m\n",
            "[2024-04-02 20:43:20] \u001b[32mTrain: [ 33/50] Step 100/520 Loss 1.957 Prec@(1,5) (60.7%, 86.7%)\u001b[0m\n",
            "[2024-04-02 20:43:21] \u001b[32mTrain: [ 33/50] Step 120/520 Loss 1.950 Prec@(1,5) (61.1%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:43:21] \u001b[32mTrain: [ 33/50] Step 140/520 Loss 1.952 Prec@(1,5) (61.0%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:43:22] \u001b[32mTrain: [ 33/50] Step 160/520 Loss 1.946 Prec@(1,5) (60.9%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:43:22] \u001b[32mTrain: [ 33/50] Step 180/520 Loss 1.951 Prec@(1,5) (60.9%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:43:23] \u001b[32mTrain: [ 33/50] Step 200/520 Loss 1.953 Prec@(1,5) (60.9%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:43:23] \u001b[32mTrain: [ 33/50] Step 220/520 Loss 1.957 Prec@(1,5) (60.8%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:43:24] \u001b[32mTrain: [ 33/50] Step 240/520 Loss 1.958 Prec@(1,5) (60.7%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:43:24] \u001b[32mTrain: [ 33/50] Step 260/520 Loss 1.955 Prec@(1,5) (60.7%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:43:25] \u001b[32mTrain: [ 33/50] Step 280/520 Loss 1.957 Prec@(1,5) (60.7%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:43:25] \u001b[32mTrain: [ 33/50] Step 300/520 Loss 1.957 Prec@(1,5) (60.6%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:43:26] \u001b[32mTrain: [ 33/50] Step 320/520 Loss 1.952 Prec@(1,5) (60.7%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:43:26] \u001b[32mTrain: [ 33/50] Step 340/520 Loss 1.950 Prec@(1,5) (60.6%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:43:27] \u001b[32mTrain: [ 33/50] Step 360/520 Loss 1.952 Prec@(1,5) (60.6%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:43:27] \u001b[32mTrain: [ 33/50] Step 380/520 Loss 1.955 Prec@(1,5) (60.5%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:43:28] \u001b[32mTrain: [ 33/50] Step 400/520 Loss 1.952 Prec@(1,5) (60.5%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:43:28] \u001b[32mTrain: [ 33/50] Step 420/520 Loss 1.955 Prec@(1,5) (60.5%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:43:28] \u001b[32mTrain: [ 33/50] Step 440/520 Loss 1.954 Prec@(1,5) (60.5%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:43:29] \u001b[32mTrain: [ 33/50] Step 460/520 Loss 1.952 Prec@(1,5) (60.6%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:43:29] \u001b[32mTrain: [ 33/50] Step 480/520 Loss 1.953 Prec@(1,5) (60.6%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:43:30] \u001b[32mTrain: [ 33/50] Step 500/520 Loss 1.956 Prec@(1,5) (60.5%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:43:30] \u001b[32mTrain: [ 33/50] Step 520/520 Loss 1.956 Prec@(1,5) (60.5%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:43:31] \u001b[32mTrain: [ 33/50] Final Prec@1 60.5220%\u001b[0m\n",
            "[2024-04-02 20:43:34] \u001b[32mValid: [ 33/50] Step 000/104 Loss 2.205 Prec@(1,5) (57.3%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:43:34] \u001b[32mValid: [ 33/50] Step 020/104 Loss 2.169 Prec@(1,5) (56.7%, 83.8%)\u001b[0m\n",
            "[2024-04-02 20:43:34] \u001b[32mValid: [ 33/50] Step 040/104 Loss 2.140 Prec@(1,5) (56.6%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:43:35] \u001b[32mValid: [ 33/50] Step 060/104 Loss 2.098 Prec@(1,5) (56.6%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:43:35] \u001b[32mValid: [ 33/50] Step 080/104 Loss 2.101 Prec@(1,5) (56.0%, 83.5%)\u001b[0m\n",
            "[2024-04-02 20:43:35] \u001b[32mValid: [ 33/50] Step 100/104 Loss 2.085 Prec@(1,5) (56.4%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:43:35] \u001b[32mValid: [ 33/50] Step 104/104 Loss 2.083 Prec@(1,5) (56.4%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:43:35] \u001b[32mValid: [ 33/50] Final Prec@1 56.3800%\u001b[0m\n",
            "[2024-04-02 20:43:35] \u001b[32mEpoch 33 LR 0.006479\u001b[0m\n",
            "[2024-04-02 20:43:40] \u001b[32mTrain: [ 34/50] Step 000/520 Loss 1.945 Prec@(1,5) (57.3%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:43:40] \u001b[32mTrain: [ 34/50] Step 020/520 Loss 1.948 Prec@(1,5) (60.4%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:43:41] \u001b[32mTrain: [ 34/50] Step 040/520 Loss 1.913 Prec@(1,5) (62.0%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:43:41] \u001b[32mTrain: [ 34/50] Step 060/520 Loss 1.931 Prec@(1,5) (61.1%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:43:42] \u001b[32mTrain: [ 34/50] Step 080/520 Loss 1.926 Prec@(1,5) (61.0%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:43:42] \u001b[32mTrain: [ 34/50] Step 100/520 Loss 1.912 Prec@(1,5) (61.3%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:43:43] \u001b[32mTrain: [ 34/50] Step 120/520 Loss 1.914 Prec@(1,5) (61.1%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:43:43] \u001b[32mTrain: [ 34/50] Step 140/520 Loss 1.913 Prec@(1,5) (61.3%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:43:44] \u001b[32mTrain: [ 34/50] Step 160/520 Loss 1.916 Prec@(1,5) (61.3%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:43:44] \u001b[32mTrain: [ 34/50] Step 180/520 Loss 1.917 Prec@(1,5) (61.3%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:43:45] \u001b[32mTrain: [ 34/50] Step 200/520 Loss 1.923 Prec@(1,5) (61.2%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:43:45] \u001b[32mTrain: [ 34/50] Step 220/520 Loss 1.922 Prec@(1,5) (61.2%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:43:46] \u001b[32mTrain: [ 34/50] Step 240/520 Loss 1.926 Prec@(1,5) (61.1%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:43:46] \u001b[32mTrain: [ 34/50] Step 260/520 Loss 1.928 Prec@(1,5) (61.1%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:43:47] \u001b[32mTrain: [ 34/50] Step 280/520 Loss 1.934 Prec@(1,5) (61.0%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:43:47] \u001b[32mTrain: [ 34/50] Step 300/520 Loss 1.930 Prec@(1,5) (61.1%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:43:48] \u001b[32mTrain: [ 34/50] Step 320/520 Loss 1.933 Prec@(1,5) (61.0%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:43:48] \u001b[32mTrain: [ 34/50] Step 340/520 Loss 1.927 Prec@(1,5) (61.1%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:43:49] \u001b[32mTrain: [ 34/50] Step 360/520 Loss 1.929 Prec@(1,5) (61.0%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:43:49] \u001b[32mTrain: [ 34/50] Step 380/520 Loss 1.927 Prec@(1,5) (61.0%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:43:50] \u001b[32mTrain: [ 34/50] Step 400/520 Loss 1.931 Prec@(1,5) (61.0%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:43:50] \u001b[32mTrain: [ 34/50] Step 420/520 Loss 1.930 Prec@(1,5) (61.0%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:43:51] \u001b[32mTrain: [ 34/50] Step 440/520 Loss 1.928 Prec@(1,5) (61.1%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:43:51] \u001b[32mTrain: [ 34/50] Step 460/520 Loss 1.930 Prec@(1,5) (61.0%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:43:52] \u001b[32mTrain: [ 34/50] Step 480/520 Loss 1.930 Prec@(1,5) (61.0%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:43:52] \u001b[32mTrain: [ 34/50] Step 500/520 Loss 1.929 Prec@(1,5) (61.1%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:43:53] \u001b[32mTrain: [ 34/50] Step 520/520 Loss 1.929 Prec@(1,5) (61.0%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:43:53] \u001b[32mTrain: [ 34/50] Final Prec@1 61.0340%\u001b[0m\n",
            "[2024-04-02 20:43:56] \u001b[32mValid: [ 34/50] Step 000/104 Loss 1.998 Prec@(1,5) (59.4%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:43:56] \u001b[32mValid: [ 34/50] Step 020/104 Loss 1.985 Prec@(1,5) (57.8%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:43:57] \u001b[32mValid: [ 34/50] Step 040/104 Loss 2.003 Prec@(1,5) (57.2%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:43:57] \u001b[32mValid: [ 34/50] Step 060/104 Loss 1.968 Prec@(1,5) (57.8%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:43:57] \u001b[32mValid: [ 34/50] Step 080/104 Loss 1.965 Prec@(1,5) (57.5%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:43:57] \u001b[32mValid: [ 34/50] Step 100/104 Loss 1.954 Prec@(1,5) (57.7%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:43:57] \u001b[32mValid: [ 34/50] Step 104/104 Loss 1.954 Prec@(1,5) (57.7%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:43:57] \u001b[32mValid: [ 34/50] Final Prec@1 57.7200%\u001b[0m\n",
            "[2024-04-02 20:43:57] \u001b[32mEpoch 34 LR 0.005803\u001b[0m\n",
            "[2024-04-02 20:44:02] \u001b[32mTrain: [ 35/50] Step 000/520 Loss 1.857 Prec@(1,5) (60.4%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:44:02] \u001b[32mTrain: [ 35/50] Step 020/520 Loss 1.928 Prec@(1,5) (62.0%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:44:03] \u001b[32mTrain: [ 35/50] Step 040/520 Loss 1.931 Prec@(1,5) (61.9%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:44:03] \u001b[32mTrain: [ 35/50] Step 060/520 Loss 1.920 Prec@(1,5) (62.0%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:44:04] \u001b[32mTrain: [ 35/50] Step 080/520 Loss 1.921 Prec@(1,5) (61.8%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:44:04] \u001b[32mTrain: [ 35/50] Step 100/520 Loss 1.906 Prec@(1,5) (61.8%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:44:05] \u001b[32mTrain: [ 35/50] Step 120/520 Loss 1.893 Prec@(1,5) (62.1%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:44:05] \u001b[32mTrain: [ 35/50] Step 140/520 Loss 1.898 Prec@(1,5) (62.0%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:44:06] \u001b[32mTrain: [ 35/50] Step 160/520 Loss 1.890 Prec@(1,5) (62.1%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:44:06] \u001b[32mTrain: [ 35/50] Step 180/520 Loss 1.884 Prec@(1,5) (62.0%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:44:07] \u001b[32mTrain: [ 35/50] Step 200/520 Loss 1.888 Prec@(1,5) (62.0%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:44:07] \u001b[32mTrain: [ 35/50] Step 220/520 Loss 1.893 Prec@(1,5) (61.9%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:44:08] \u001b[32mTrain: [ 35/50] Step 240/520 Loss 1.892 Prec@(1,5) (62.0%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:44:08] \u001b[32mTrain: [ 35/50] Step 260/520 Loss 1.897 Prec@(1,5) (61.9%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:44:09] \u001b[32mTrain: [ 35/50] Step 280/520 Loss 1.895 Prec@(1,5) (61.9%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:44:09] \u001b[32mTrain: [ 35/50] Step 300/520 Loss 1.898 Prec@(1,5) (61.9%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:44:10] \u001b[32mTrain: [ 35/50] Step 320/520 Loss 1.897 Prec@(1,5) (61.9%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:44:10] \u001b[32mTrain: [ 35/50] Step 340/520 Loss 1.895 Prec@(1,5) (61.9%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:44:11] \u001b[32mTrain: [ 35/50] Step 360/520 Loss 1.893 Prec@(1,5) (62.0%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:44:11] \u001b[32mTrain: [ 35/50] Step 380/520 Loss 1.897 Prec@(1,5) (61.8%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:44:12] \u001b[32mTrain: [ 35/50] Step 400/520 Loss 1.899 Prec@(1,5) (61.9%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:44:12] \u001b[32mTrain: [ 35/50] Step 420/520 Loss 1.900 Prec@(1,5) (61.8%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:44:13] \u001b[32mTrain: [ 35/50] Step 440/520 Loss 1.904 Prec@(1,5) (61.7%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:44:13] \u001b[32mTrain: [ 35/50] Step 460/520 Loss 1.905 Prec@(1,5) (61.6%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:44:14] \u001b[32mTrain: [ 35/50] Step 480/520 Loss 1.906 Prec@(1,5) (61.6%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:44:14] \u001b[32mTrain: [ 35/50] Step 500/520 Loss 1.908 Prec@(1,5) (61.6%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:44:15] \u001b[32mTrain: [ 35/50] Step 520/520 Loss 1.907 Prec@(1,5) (61.6%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:44:15] \u001b[32mTrain: [ 35/50] Final Prec@1 61.5840%\u001b[0m\n",
            "[2024-04-02 20:44:18] \u001b[32mValid: [ 35/50] Step 000/104 Loss 1.927 Prec@(1,5) (61.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:44:19] \u001b[32mValid: [ 35/50] Step 020/104 Loss 1.947 Prec@(1,5) (57.6%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:44:19] \u001b[32mValid: [ 35/50] Step 040/104 Loss 1.963 Prec@(1,5) (57.6%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:44:19] \u001b[32mValid: [ 35/50] Step 060/104 Loss 1.933 Prec@(1,5) (57.9%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:44:19] \u001b[32mValid: [ 35/50] Step 080/104 Loss 1.928 Prec@(1,5) (57.6%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:44:19] \u001b[32mValid: [ 35/50] Step 100/104 Loss 1.921 Prec@(1,5) (57.9%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:44:19] \u001b[32mValid: [ 35/50] Step 104/104 Loss 1.921 Prec@(1,5) (58.0%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:44:20] \u001b[32mValid: [ 35/50] Final Prec@1 57.9700%\u001b[0m\n",
            "[2024-04-02 20:44:20] \u001b[32mEpoch 35 LR 0.005153\u001b[0m\n",
            "[2024-04-02 20:44:24] \u001b[32mTrain: [ 36/50] Step 000/520 Loss 1.864 Prec@(1,5) (62.5%, 90.6%)\u001b[0m\n",
            "[2024-04-02 20:44:25] \u001b[32mTrain: [ 36/50] Step 020/520 Loss 1.903 Prec@(1,5) (61.9%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:44:25] \u001b[32mTrain: [ 36/50] Step 040/520 Loss 1.881 Prec@(1,5) (61.9%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:44:26] \u001b[32mTrain: [ 36/50] Step 060/520 Loss 1.868 Prec@(1,5) (62.3%, 88.1%)\u001b[0m\n",
            "[2024-04-02 20:44:26] \u001b[32mTrain: [ 36/50] Step 080/520 Loss 1.872 Prec@(1,5) (62.4%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:44:27] \u001b[32mTrain: [ 36/50] Step 100/520 Loss 1.877 Prec@(1,5) (62.4%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:44:27] \u001b[32mTrain: [ 36/50] Step 120/520 Loss 1.897 Prec@(1,5) (62.1%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:44:28] \u001b[32mTrain: [ 36/50] Step 140/520 Loss 1.884 Prec@(1,5) (62.1%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:44:28] \u001b[32mTrain: [ 36/50] Step 160/520 Loss 1.891 Prec@(1,5) (62.0%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:44:29] \u001b[32mTrain: [ 36/50] Step 180/520 Loss 1.888 Prec@(1,5) (62.0%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:44:29] \u001b[32mTrain: [ 36/50] Step 200/520 Loss 1.887 Prec@(1,5) (62.0%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:44:30] \u001b[32mTrain: [ 36/50] Step 220/520 Loss 1.889 Prec@(1,5) (61.9%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:44:30] \u001b[32mTrain: [ 36/50] Step 240/520 Loss 1.884 Prec@(1,5) (62.0%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:44:31] \u001b[32mTrain: [ 36/50] Step 260/520 Loss 1.877 Prec@(1,5) (62.1%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:44:31] \u001b[32mTrain: [ 36/50] Step 280/520 Loss 1.876 Prec@(1,5) (62.1%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:44:32] \u001b[32mTrain: [ 36/50] Step 300/520 Loss 1.876 Prec@(1,5) (62.2%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:44:32] \u001b[32mTrain: [ 36/50] Step 320/520 Loss 1.879 Prec@(1,5) (62.1%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:44:33] \u001b[32mTrain: [ 36/50] Step 340/520 Loss 1.882 Prec@(1,5) (62.0%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:44:33] \u001b[32mTrain: [ 36/50] Step 360/520 Loss 1.884 Prec@(1,5) (61.9%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:44:34] \u001b[32mTrain: [ 36/50] Step 380/520 Loss 1.887 Prec@(1,5) (62.0%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:44:34] \u001b[32mTrain: [ 36/50] Step 400/520 Loss 1.886 Prec@(1,5) (62.0%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:44:35] \u001b[32mTrain: [ 36/50] Step 420/520 Loss 1.885 Prec@(1,5) (62.0%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:44:35] \u001b[32mTrain: [ 36/50] Step 440/520 Loss 1.886 Prec@(1,5) (62.0%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:44:36] \u001b[32mTrain: [ 36/50] Step 460/520 Loss 1.890 Prec@(1,5) (61.9%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:44:36] \u001b[32mTrain: [ 36/50] Step 480/520 Loss 1.890 Prec@(1,5) (61.9%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:44:37] \u001b[32mTrain: [ 36/50] Step 500/520 Loss 1.888 Prec@(1,5) (62.0%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:44:37] \u001b[32mTrain: [ 36/50] Step 520/520 Loss 1.889 Prec@(1,5) (62.0%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:44:37] \u001b[32mTrain: [ 36/50] Final Prec@1 61.9740%\u001b[0m\n",
            "[2024-04-02 20:44:41] \u001b[32mValid: [ 36/50] Step 000/104 Loss 2.133 Prec@(1,5) (62.5%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:44:41] \u001b[32mValid: [ 36/50] Step 020/104 Loss 2.011 Prec@(1,5) (59.0%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:44:41] \u001b[32mValid: [ 36/50] Step 040/104 Loss 2.012 Prec@(1,5) (58.1%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:44:41] \u001b[32mValid: [ 36/50] Step 060/104 Loss 1.971 Prec@(1,5) (58.8%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:44:41] \u001b[32mValid: [ 36/50] Step 080/104 Loss 1.977 Prec@(1,5) (58.2%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:44:42] \u001b[32mValid: [ 36/50] Step 100/104 Loss 1.969 Prec@(1,5) (58.2%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:44:42] \u001b[32mValid: [ 36/50] Step 104/104 Loss 1.972 Prec@(1,5) (58.2%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:44:42] \u001b[32mValid: [ 36/50] Final Prec@1 58.1700%\u001b[0m\n",
            "[2024-04-02 20:44:42] \u001b[32mEpoch 36 LR 0.004533\u001b[0m\n",
            "[2024-04-02 20:44:46] \u001b[32mTrain: [ 37/50] Step 000/520 Loss 1.683 Prec@(1,5) (69.8%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:44:47] \u001b[32mTrain: [ 37/50] Step 020/520 Loss 1.769 Prec@(1,5) (64.1%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:44:47] \u001b[32mTrain: [ 37/50] Step 040/520 Loss 1.828 Prec@(1,5) (62.7%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:44:48] \u001b[32mTrain: [ 37/50] Step 060/520 Loss 1.825 Prec@(1,5) (62.8%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:44:49] \u001b[32mTrain: [ 37/50] Step 080/520 Loss 1.844 Prec@(1,5) (62.5%, 88.1%)\u001b[0m\n",
            "[2024-04-02 20:44:49] \u001b[32mTrain: [ 37/50] Step 100/520 Loss 1.849 Prec@(1,5) (62.6%, 88.1%)\u001b[0m\n",
            "[2024-04-02 20:44:50] \u001b[32mTrain: [ 37/50] Step 120/520 Loss 1.843 Prec@(1,5) (62.7%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:44:50] \u001b[32mTrain: [ 37/50] Step 140/520 Loss 1.844 Prec@(1,5) (62.7%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:44:51] \u001b[32mTrain: [ 37/50] Step 160/520 Loss 1.847 Prec@(1,5) (62.6%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:44:51] \u001b[32mTrain: [ 37/50] Step 180/520 Loss 1.848 Prec@(1,5) (62.6%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:44:52] \u001b[32mTrain: [ 37/50] Step 200/520 Loss 1.848 Prec@(1,5) (62.6%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:44:52] \u001b[32mTrain: [ 37/50] Step 220/520 Loss 1.848 Prec@(1,5) (62.4%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:44:53] \u001b[32mTrain: [ 37/50] Step 240/520 Loss 1.852 Prec@(1,5) (62.4%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:44:53] \u001b[32mTrain: [ 37/50] Step 260/520 Loss 1.851 Prec@(1,5) (62.4%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:44:54] \u001b[32mTrain: [ 37/50] Step 280/520 Loss 1.850 Prec@(1,5) (62.5%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:44:54] \u001b[32mTrain: [ 37/50] Step 300/520 Loss 1.850 Prec@(1,5) (62.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:44:55] \u001b[32mTrain: [ 37/50] Step 320/520 Loss 1.849 Prec@(1,5) (62.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:44:55] \u001b[32mTrain: [ 37/50] Step 340/520 Loss 1.846 Prec@(1,5) (62.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:44:56] \u001b[32mTrain: [ 37/50] Step 360/520 Loss 1.848 Prec@(1,5) (62.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:44:56] \u001b[32mTrain: [ 37/50] Step 380/520 Loss 1.846 Prec@(1,5) (62.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:44:57] \u001b[32mTrain: [ 37/50] Step 400/520 Loss 1.847 Prec@(1,5) (62.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:44:57] \u001b[32mTrain: [ 37/50] Step 420/520 Loss 1.853 Prec@(1,5) (62.6%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:44:58] \u001b[32mTrain: [ 37/50] Step 440/520 Loss 1.856 Prec@(1,5) (62.6%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:44:58] \u001b[32mTrain: [ 37/50] Step 460/520 Loss 1.858 Prec@(1,5) (62.5%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:44:59] \u001b[32mTrain: [ 37/50] Step 480/520 Loss 1.857 Prec@(1,5) (62.5%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:44:59] \u001b[32mTrain: [ 37/50] Step 500/520 Loss 1.859 Prec@(1,5) (62.5%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:45:00] \u001b[32mTrain: [ 37/50] Step 520/520 Loss 1.862 Prec@(1,5) (62.5%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:45:00] \u001b[32mTrain: [ 37/50] Final Prec@1 62.4520%\u001b[0m\n",
            "[2024-04-02 20:45:03] \u001b[32mValid: [ 37/50] Step 000/104 Loss 2.040 Prec@(1,5) (61.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:45:04] \u001b[32mValid: [ 37/50] Step 020/104 Loss 1.999 Prec@(1,5) (58.4%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:45:04] \u001b[32mValid: [ 37/50] Step 040/104 Loss 2.001 Prec@(1,5) (57.5%, 86.4%)\u001b[0m\n",
            "[2024-04-02 20:45:04] \u001b[32mValid: [ 37/50] Step 060/104 Loss 1.970 Prec@(1,5) (58.1%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:45:04] \u001b[32mValid: [ 37/50] Step 080/104 Loss 1.971 Prec@(1,5) (57.8%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:45:04] \u001b[32mValid: [ 37/50] Step 100/104 Loss 1.964 Prec@(1,5) (57.9%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:45:04] \u001b[32mValid: [ 37/50] Step 104/104 Loss 1.962 Prec@(1,5) (57.9%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:45:05] \u001b[32mValid: [ 37/50] Final Prec@1 57.8900%\u001b[0m\n",
            "[2024-04-02 20:45:05] \u001b[32mEpoch 37 LR 0.003944\u001b[0m\n",
            "[2024-04-02 20:45:09] \u001b[32mTrain: [ 38/50] Step 000/520 Loss 1.774 Prec@(1,5) (63.5%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:45:10] \u001b[32mTrain: [ 38/50] Step 020/520 Loss 1.870 Prec@(1,5) (61.9%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:45:10] \u001b[32mTrain: [ 38/50] Step 040/520 Loss 1.851 Prec@(1,5) (62.0%, 87.9%)\u001b[0m\n",
            "[2024-04-02 20:45:11] \u001b[32mTrain: [ 38/50] Step 060/520 Loss 1.836 Prec@(1,5) (62.2%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:45:11] \u001b[32mTrain: [ 38/50] Step 080/520 Loss 1.836 Prec@(1,5) (62.3%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:45:12] \u001b[32mTrain: [ 38/50] Step 100/520 Loss 1.832 Prec@(1,5) (62.2%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:45:12] \u001b[32mTrain: [ 38/50] Step 120/520 Loss 1.824 Prec@(1,5) (62.9%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:45:13] \u001b[32mTrain: [ 38/50] Step 140/520 Loss 1.831 Prec@(1,5) (62.9%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:45:13] \u001b[32mTrain: [ 38/50] Step 160/520 Loss 1.826 Prec@(1,5) (63.0%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:45:14] \u001b[32mTrain: [ 38/50] Step 180/520 Loss 1.836 Prec@(1,5) (62.8%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:45:14] \u001b[32mTrain: [ 38/50] Step 200/520 Loss 1.836 Prec@(1,5) (62.7%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:45:15] \u001b[32mTrain: [ 38/50] Step 220/520 Loss 1.830 Prec@(1,5) (62.9%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:45:15] \u001b[32mTrain: [ 38/50] Step 240/520 Loss 1.832 Prec@(1,5) (62.7%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:45:16] \u001b[32mTrain: [ 38/50] Step 260/520 Loss 1.838 Prec@(1,5) (62.6%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:45:16] \u001b[32mTrain: [ 38/50] Step 280/520 Loss 1.834 Prec@(1,5) (62.6%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:45:17] \u001b[32mTrain: [ 38/50] Step 300/520 Loss 1.829 Prec@(1,5) (62.8%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:45:17] \u001b[32mTrain: [ 38/50] Step 320/520 Loss 1.831 Prec@(1,5) (62.8%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:45:17] \u001b[32mTrain: [ 38/50] Step 340/520 Loss 1.834 Prec@(1,5) (62.8%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:45:18] \u001b[32mTrain: [ 38/50] Step 360/520 Loss 1.835 Prec@(1,5) (62.7%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:45:18] \u001b[32mTrain: [ 38/50] Step 380/520 Loss 1.838 Prec@(1,5) (62.7%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:45:19] \u001b[32mTrain: [ 38/50] Step 400/520 Loss 1.838 Prec@(1,5) (62.7%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:45:19] \u001b[32mTrain: [ 38/50] Step 420/520 Loss 1.841 Prec@(1,5) (62.7%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:45:20] \u001b[32mTrain: [ 38/50] Step 440/520 Loss 1.839 Prec@(1,5) (62.8%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:45:20] \u001b[32mTrain: [ 38/50] Step 460/520 Loss 1.839 Prec@(1,5) (62.8%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:45:21] \u001b[32mTrain: [ 38/50] Step 480/520 Loss 1.844 Prec@(1,5) (62.7%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:45:21] \u001b[32mTrain: [ 38/50] Step 500/520 Loss 1.843 Prec@(1,5) (62.7%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:45:22] \u001b[32mTrain: [ 38/50] Step 520/520 Loss 1.843 Prec@(1,5) (62.7%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:45:22] \u001b[32mTrain: [ 38/50] Final Prec@1 62.7140%\u001b[0m\n",
            "[2024-04-02 20:45:26] \u001b[32mValid: [ 38/50] Step 000/104 Loss 1.911 Prec@(1,5) (60.4%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:45:26] \u001b[32mValid: [ 38/50] Step 020/104 Loss 1.919 Prec@(1,5) (58.8%, 86.4%)\u001b[0m\n",
            "[2024-04-02 20:45:26] \u001b[32mValid: [ 38/50] Step 040/104 Loss 1.922 Prec@(1,5) (58.7%, 86.1%)\u001b[0m\n",
            "[2024-04-02 20:45:26] \u001b[32mValid: [ 38/50] Step 060/104 Loss 1.892 Prec@(1,5) (59.3%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:45:26] \u001b[32mValid: [ 38/50] Step 080/104 Loss 1.894 Prec@(1,5) (58.8%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:45:26] \u001b[32mValid: [ 38/50] Step 100/104 Loss 1.885 Prec@(1,5) (58.7%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:45:26] \u001b[32mValid: [ 38/50] Step 104/104 Loss 1.884 Prec@(1,5) (58.7%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:45:27] \u001b[32mValid: [ 38/50] Final Prec@1 58.7200%\u001b[0m\n",
            "[2024-04-02 20:45:27] \u001b[32mEpoch 38 LR 0.003389\u001b[0m\n",
            "[2024-04-02 20:45:31] \u001b[32mTrain: [ 39/50] Step 000/520 Loss 1.809 Prec@(1,5) (62.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:45:32] \u001b[32mTrain: [ 39/50] Step 020/520 Loss 1.818 Prec@(1,5) (62.0%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:45:32] \u001b[32mTrain: [ 39/50] Step 040/520 Loss 1.825 Prec@(1,5) (62.8%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:45:33] \u001b[32mTrain: [ 39/50] Step 060/520 Loss 1.814 Prec@(1,5) (63.2%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:45:33] \u001b[32mTrain: [ 39/50] Step 080/520 Loss 1.814 Prec@(1,5) (63.2%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:45:34] \u001b[32mTrain: [ 39/50] Step 100/520 Loss 1.821 Prec@(1,5) (63.1%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:45:34] \u001b[32mTrain: [ 39/50] Step 120/520 Loss 1.813 Prec@(1,5) (63.5%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:45:35] \u001b[32mTrain: [ 39/50] Step 140/520 Loss 1.810 Prec@(1,5) (63.4%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:45:35] \u001b[32mTrain: [ 39/50] Step 160/520 Loss 1.814 Prec@(1,5) (63.4%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:45:36] \u001b[32mTrain: [ 39/50] Step 180/520 Loss 1.815 Prec@(1,5) (63.3%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:45:36] \u001b[32mTrain: [ 39/50] Step 200/520 Loss 1.812 Prec@(1,5) (63.3%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:45:37] \u001b[32mTrain: [ 39/50] Step 220/520 Loss 1.809 Prec@(1,5) (63.4%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:45:37] \u001b[32mTrain: [ 39/50] Step 240/520 Loss 1.811 Prec@(1,5) (63.4%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:45:38] \u001b[32mTrain: [ 39/50] Step 260/520 Loss 1.810 Prec@(1,5) (63.5%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:45:38] \u001b[32mTrain: [ 39/50] Step 280/520 Loss 1.813 Prec@(1,5) (63.4%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:45:39] \u001b[32mTrain: [ 39/50] Step 300/520 Loss 1.814 Prec@(1,5) (63.3%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:45:39] \u001b[32mTrain: [ 39/50] Step 320/520 Loss 1.811 Prec@(1,5) (63.4%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:45:40] \u001b[32mTrain: [ 39/50] Step 340/520 Loss 1.811 Prec@(1,5) (63.3%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:45:40] \u001b[32mTrain: [ 39/50] Step 360/520 Loss 1.812 Prec@(1,5) (63.2%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:45:41] \u001b[32mTrain: [ 39/50] Step 380/520 Loss 1.814 Prec@(1,5) (63.2%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:45:41] \u001b[32mTrain: [ 39/50] Step 400/520 Loss 1.815 Prec@(1,5) (63.2%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:45:42] \u001b[32mTrain: [ 39/50] Step 420/520 Loss 1.814 Prec@(1,5) (63.2%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:45:42] \u001b[32mTrain: [ 39/50] Step 440/520 Loss 1.814 Prec@(1,5) (63.2%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:45:43] \u001b[32mTrain: [ 39/50] Step 460/520 Loss 1.817 Prec@(1,5) (63.2%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:45:43] \u001b[32mTrain: [ 39/50] Step 480/520 Loss 1.819 Prec@(1,5) (63.1%, 88.3%)\u001b[0m\n",
            "[2024-04-02 20:45:44] \u001b[32mTrain: [ 39/50] Step 500/520 Loss 1.818 Prec@(1,5) (63.2%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:45:44] \u001b[32mTrain: [ 39/50] Step 520/520 Loss 1.820 Prec@(1,5) (63.1%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:45:45] \u001b[32mTrain: [ 39/50] Final Prec@1 63.0960%\u001b[0m\n",
            "[2024-04-02 20:45:48] \u001b[32mValid: [ 39/50] Step 000/104 Loss 1.890 Prec@(1,5) (63.5%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:45:48] \u001b[32mValid: [ 39/50] Step 020/104 Loss 1.902 Prec@(1,5) (60.1%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:45:48] \u001b[32mValid: [ 39/50] Step 040/104 Loss 1.907 Prec@(1,5) (59.5%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:45:49] \u001b[32mValid: [ 39/50] Step 060/104 Loss 1.877 Prec@(1,5) (59.8%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:45:49] \u001b[32mValid: [ 39/50] Step 080/104 Loss 1.875 Prec@(1,5) (59.2%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:45:49] \u001b[32mValid: [ 39/50] Step 100/104 Loss 1.866 Prec@(1,5) (59.4%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:45:49] \u001b[32mValid: [ 39/50] Step 104/104 Loss 1.869 Prec@(1,5) (59.3%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:45:49] \u001b[32mValid: [ 39/50] Final Prec@1 59.3400%\u001b[0m\n",
            "[2024-04-02 20:45:49] \u001b[32mEpoch 39 LR 0.002869\u001b[0m\n",
            "[2024-04-02 20:45:54] \u001b[32mTrain: [ 40/50] Step 000/520 Loss 2.141 Prec@(1,5) (55.2%, 80.2%)\u001b[0m\n",
            "[2024-04-02 20:45:54] \u001b[32mTrain: [ 40/50] Step 020/520 Loss 1.804 Prec@(1,5) (63.4%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:45:55] \u001b[32mTrain: [ 40/50] Step 040/520 Loss 1.786 Prec@(1,5) (64.0%, 88.1%)\u001b[0m\n",
            "[2024-04-02 20:45:55] \u001b[32mTrain: [ 40/50] Step 060/520 Loss 1.784 Prec@(1,5) (63.8%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:45:56] \u001b[32mTrain: [ 40/50] Step 080/520 Loss 1.798 Prec@(1,5) (63.6%, 88.0%)\u001b[0m\n",
            "[2024-04-02 20:45:56] \u001b[32mTrain: [ 40/50] Step 100/520 Loss 1.796 Prec@(1,5) (63.8%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:45:57] \u001b[32mTrain: [ 40/50] Step 120/520 Loss 1.796 Prec@(1,5) (63.8%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:45:57] \u001b[32mTrain: [ 40/50] Step 140/520 Loss 1.786 Prec@(1,5) (63.8%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:45:58] \u001b[32mTrain: [ 40/50] Step 160/520 Loss 1.787 Prec@(1,5) (63.8%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:45:58] \u001b[32mTrain: [ 40/50] Step 180/520 Loss 1.782 Prec@(1,5) (63.9%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:45:59] \u001b[32mTrain: [ 40/50] Step 200/520 Loss 1.783 Prec@(1,5) (63.9%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:45:59] \u001b[32mTrain: [ 40/50] Step 220/520 Loss 1.781 Prec@(1,5) (63.9%, 88.7%)\u001b[0m\n",
            "[2024-04-02 20:46:00] \u001b[32mTrain: [ 40/50] Step 240/520 Loss 1.787 Prec@(1,5) (63.7%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:46:00] \u001b[32mTrain: [ 40/50] Step 260/520 Loss 1.788 Prec@(1,5) (63.6%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:46:01] \u001b[32mTrain: [ 40/50] Step 280/520 Loss 1.788 Prec@(1,5) (63.5%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:46:01] \u001b[32mTrain: [ 40/50] Step 300/520 Loss 1.793 Prec@(1,5) (63.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:46:02] \u001b[32mTrain: [ 40/50] Step 320/520 Loss 1.795 Prec@(1,5) (63.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:46:02] \u001b[32mTrain: [ 40/50] Step 340/520 Loss 1.795 Prec@(1,5) (63.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:46:03] \u001b[32mTrain: [ 40/50] Step 360/520 Loss 1.795 Prec@(1,5) (63.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:46:03] \u001b[32mTrain: [ 40/50] Step 380/520 Loss 1.796 Prec@(1,5) (63.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:46:04] \u001b[32mTrain: [ 40/50] Step 400/520 Loss 1.798 Prec@(1,5) (63.4%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:46:04] \u001b[32mTrain: [ 40/50] Step 420/520 Loss 1.799 Prec@(1,5) (63.4%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:46:05] \u001b[32mTrain: [ 40/50] Step 440/520 Loss 1.800 Prec@(1,5) (63.4%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:46:05] \u001b[32mTrain: [ 40/50] Step 460/520 Loss 1.802 Prec@(1,5) (63.3%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:46:06] \u001b[32mTrain: [ 40/50] Step 480/520 Loss 1.802 Prec@(1,5) (63.4%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:46:06] \u001b[32mTrain: [ 40/50] Step 500/520 Loss 1.802 Prec@(1,5) (63.4%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:46:07] \u001b[32mTrain: [ 40/50] Step 520/520 Loss 1.803 Prec@(1,5) (63.4%, 88.4%)\u001b[0m\n",
            "[2024-04-02 20:46:07] \u001b[32mTrain: [ 40/50] Final Prec@1 63.4260%\u001b[0m\n",
            "[2024-04-02 20:46:11] \u001b[32mValid: [ 40/50] Step 000/104 Loss 1.849 Prec@(1,5) (61.5%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:46:11] \u001b[32mValid: [ 40/50] Step 020/104 Loss 1.901 Prec@(1,5) (59.1%, 86.4%)\u001b[0m\n",
            "[2024-04-02 20:46:11] \u001b[32mValid: [ 40/50] Step 040/104 Loss 1.889 Prec@(1,5) (59.4%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:46:11] \u001b[32mValid: [ 40/50] Step 060/104 Loss 1.860 Prec@(1,5) (59.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:46:11] \u001b[32mValid: [ 40/50] Step 080/104 Loss 1.853 Prec@(1,5) (59.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:46:11] \u001b[32mValid: [ 40/50] Step 100/104 Loss 1.843 Prec@(1,5) (59.6%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:46:11] \u001b[32mValid: [ 40/50] Step 104/104 Loss 1.845 Prec@(1,5) (59.6%, 86.6%)\u001b[0m\n",
            "[2024-04-02 20:46:12] \u001b[32mValid: [ 40/50] Final Prec@1 59.6100%\u001b[0m\n",
            "[2024-04-02 20:46:12] \u001b[32mEpoch 40 LR 0.002388\u001b[0m\n",
            "[2024-04-02 20:46:16] \u001b[32mTrain: [ 41/50] Step 000/520 Loss 1.543 Prec@(1,5) (64.6%, 91.7%)\u001b[0m\n",
            "[2024-04-02 20:46:17] \u001b[32mTrain: [ 41/50] Step 020/520 Loss 1.790 Prec@(1,5) (64.1%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:46:17] \u001b[32mTrain: [ 41/50] Step 040/520 Loss 1.777 Prec@(1,5) (64.1%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:46:18] \u001b[32mTrain: [ 41/50] Step 060/520 Loss 1.785 Prec@(1,5) (64.0%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:46:18] \u001b[32mTrain: [ 41/50] Step 080/520 Loss 1.786 Prec@(1,5) (63.8%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:46:19] \u001b[32mTrain: [ 41/50] Step 100/520 Loss 1.768 Prec@(1,5) (64.0%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:46:19] \u001b[32mTrain: [ 41/50] Step 120/520 Loss 1.773 Prec@(1,5) (63.9%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:46:20] \u001b[32mTrain: [ 41/50] Step 140/520 Loss 1.770 Prec@(1,5) (64.0%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:46:20] \u001b[32mTrain: [ 41/50] Step 160/520 Loss 1.760 Prec@(1,5) (64.3%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:46:21] \u001b[32mTrain: [ 41/50] Step 180/520 Loss 1.755 Prec@(1,5) (64.4%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:46:21] \u001b[32mTrain: [ 41/50] Step 200/520 Loss 1.759 Prec@(1,5) (64.4%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:46:22] \u001b[32mTrain: [ 41/50] Step 220/520 Loss 1.758 Prec@(1,5) (64.3%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:46:22] \u001b[32mTrain: [ 41/50] Step 240/520 Loss 1.760 Prec@(1,5) (64.3%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:46:23] \u001b[32mTrain: [ 41/50] Step 260/520 Loss 1.761 Prec@(1,5) (64.2%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:46:23] \u001b[32mTrain: [ 41/50] Step 280/520 Loss 1.762 Prec@(1,5) (64.1%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:46:24] \u001b[32mTrain: [ 41/50] Step 300/520 Loss 1.764 Prec@(1,5) (64.1%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:46:24] \u001b[32mTrain: [ 41/50] Step 320/520 Loss 1.772 Prec@(1,5) (64.0%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:46:25] \u001b[32mTrain: [ 41/50] Step 340/520 Loss 1.771 Prec@(1,5) (64.0%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:46:25] \u001b[32mTrain: [ 41/50] Step 360/520 Loss 1.770 Prec@(1,5) (64.0%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:46:26] \u001b[32mTrain: [ 41/50] Step 380/520 Loss 1.773 Prec@(1,5) (63.9%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:46:26] \u001b[32mTrain: [ 41/50] Step 400/520 Loss 1.775 Prec@(1,5) (63.9%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:46:27] \u001b[32mTrain: [ 41/50] Step 420/520 Loss 1.779 Prec@(1,5) (63.8%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:46:27] \u001b[32mTrain: [ 41/50] Step 440/520 Loss 1.781 Prec@(1,5) (63.8%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:46:27] \u001b[32mTrain: [ 41/50] Step 460/520 Loss 1.782 Prec@(1,5) (63.8%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:46:28] \u001b[32mTrain: [ 41/50] Step 480/520 Loss 1.782 Prec@(1,5) (63.8%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:46:28] \u001b[32mTrain: [ 41/50] Step 500/520 Loss 1.784 Prec@(1,5) (63.8%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:46:29] \u001b[32mTrain: [ 41/50] Step 520/520 Loss 1.786 Prec@(1,5) (63.7%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:46:29] \u001b[32mTrain: [ 41/50] Final Prec@1 63.7320%\u001b[0m\n",
            "[2024-04-02 20:46:33] \u001b[32mValid: [ 41/50] Step 000/104 Loss 1.827 Prec@(1,5) (63.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:46:33] \u001b[32mValid: [ 41/50] Step 020/104 Loss 1.922 Prec@(1,5) (60.0%, 86.4%)\u001b[0m\n",
            "[2024-04-02 20:46:33] \u001b[32mValid: [ 41/50] Step 040/104 Loss 1.910 Prec@(1,5) (59.7%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:46:33] \u001b[32mValid: [ 41/50] Step 060/104 Loss 1.875 Prec@(1,5) (60.0%, 86.4%)\u001b[0m\n",
            "[2024-04-02 20:46:33] \u001b[32mValid: [ 41/50] Step 080/104 Loss 1.872 Prec@(1,5) (59.9%, 86.1%)\u001b[0m\n",
            "[2024-04-02 20:46:33] \u001b[32mValid: [ 41/50] Step 100/104 Loss 1.859 Prec@(1,5) (59.9%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:46:34] \u001b[32mValid: [ 41/50] Step 104/104 Loss 1.860 Prec@(1,5) (59.9%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:46:34] \u001b[32mValid: [ 41/50] Final Prec@1 59.8800%\u001b[0m\n",
            "[2024-04-02 20:46:34] \u001b[32mEpoch 41 LR 0.001947\u001b[0m\n",
            "[2024-04-02 20:46:38] \u001b[32mTrain: [ 42/50] Step 000/520 Loss 2.008 Prec@(1,5) (61.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:46:39] \u001b[32mTrain: [ 42/50] Step 020/520 Loss 1.821 Prec@(1,5) (63.5%, 88.2%)\u001b[0m\n",
            "[2024-04-02 20:46:39] \u001b[32mTrain: [ 42/50] Step 040/520 Loss 1.796 Prec@(1,5) (63.4%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:46:40] \u001b[32mTrain: [ 42/50] Step 060/520 Loss 1.763 Prec@(1,5) (64.0%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:46:40] \u001b[32mTrain: [ 42/50] Step 080/520 Loss 1.754 Prec@(1,5) (63.9%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:46:41] \u001b[32mTrain: [ 42/50] Step 100/520 Loss 1.754 Prec@(1,5) (63.7%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:46:41] \u001b[32mTrain: [ 42/50] Step 120/520 Loss 1.753 Prec@(1,5) (63.9%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:46:42] \u001b[32mTrain: [ 42/50] Step 140/520 Loss 1.761 Prec@(1,5) (63.9%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:46:42] \u001b[32mTrain: [ 42/50] Step 160/520 Loss 1.761 Prec@(1,5) (63.8%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:46:43] \u001b[32mTrain: [ 42/50] Step 180/520 Loss 1.754 Prec@(1,5) (63.9%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:46:43] \u001b[32mTrain: [ 42/50] Step 200/520 Loss 1.766 Prec@(1,5) (63.7%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:46:44] \u001b[32mTrain: [ 42/50] Step 220/520 Loss 1.768 Prec@(1,5) (63.8%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:46:44] \u001b[32mTrain: [ 42/50] Step 240/520 Loss 1.767 Prec@(1,5) (63.8%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:46:45] \u001b[32mTrain: [ 42/50] Step 260/520 Loss 1.769 Prec@(1,5) (63.8%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:46:45] \u001b[32mTrain: [ 42/50] Step 280/520 Loss 1.767 Prec@(1,5) (63.9%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:46:46] \u001b[32mTrain: [ 42/50] Step 300/520 Loss 1.767 Prec@(1,5) (63.9%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:46:46] \u001b[32mTrain: [ 42/50] Step 320/520 Loss 1.766 Prec@(1,5) (63.9%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:46:47] \u001b[32mTrain: [ 42/50] Step 340/520 Loss 1.765 Prec@(1,5) (64.0%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:46:47] \u001b[32mTrain: [ 42/50] Step 360/520 Loss 1.769 Prec@(1,5) (63.9%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:46:48] \u001b[32mTrain: [ 42/50] Step 380/520 Loss 1.769 Prec@(1,5) (63.9%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:46:48] \u001b[32mTrain: [ 42/50] Step 400/520 Loss 1.767 Prec@(1,5) (63.9%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:46:49] \u001b[32mTrain: [ 42/50] Step 420/520 Loss 1.765 Prec@(1,5) (63.9%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:46:49] \u001b[32mTrain: [ 42/50] Step 440/520 Loss 1.764 Prec@(1,5) (64.0%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:46:50] \u001b[32mTrain: [ 42/50] Step 460/520 Loss 1.765 Prec@(1,5) (64.0%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:46:50] \u001b[32mTrain: [ 42/50] Step 480/520 Loss 1.763 Prec@(1,5) (64.1%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:46:51] \u001b[32mTrain: [ 42/50] Step 500/520 Loss 1.764 Prec@(1,5) (64.1%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:46:51] \u001b[32mTrain: [ 42/50] Step 520/520 Loss 1.767 Prec@(1,5) (64.0%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:46:52] \u001b[32mTrain: [ 42/50] Final Prec@1 64.0140%\u001b[0m\n",
            "[2024-04-02 20:46:55] \u001b[32mValid: [ 42/50] Step 000/104 Loss 1.965 Prec@(1,5) (59.4%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:46:55] \u001b[32mValid: [ 42/50] Step 020/104 Loss 1.942 Prec@(1,5) (59.9%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:46:55] \u001b[32mValid: [ 42/50] Step 040/104 Loss 1.928 Prec@(1,5) (59.0%, 86.4%)\u001b[0m\n",
            "[2024-04-02 20:46:56] \u001b[32mValid: [ 42/50] Step 060/104 Loss 1.891 Prec@(1,5) (59.3%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:46:56] \u001b[32mValid: [ 42/50] Step 080/104 Loss 1.885 Prec@(1,5) (59.1%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:46:56] \u001b[32mValid: [ 42/50] Step 100/104 Loss 1.874 Prec@(1,5) (59.4%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:46:56] \u001b[32mValid: [ 42/50] Step 104/104 Loss 1.874 Prec@(1,5) (59.4%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:46:56] \u001b[32mValid: [ 42/50] Final Prec@1 59.4300%\u001b[0m\n",
            "[2024-04-02 20:46:56] \u001b[32mEpoch 42 LR 0.001547\u001b[0m\n",
            "[2024-04-02 20:47:01] \u001b[32mTrain: [ 43/50] Step 000/520 Loss 2.012 Prec@(1,5) (58.3%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:47:01] \u001b[32mTrain: [ 43/50] Step 020/520 Loss 1.734 Prec@(1,5) (65.5%, 88.7%)\u001b[0m\n",
            "[2024-04-02 20:47:02] \u001b[32mTrain: [ 43/50] Step 040/520 Loss 1.740 Prec@(1,5) (65.0%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:47:02] \u001b[32mTrain: [ 43/50] Step 060/520 Loss 1.743 Prec@(1,5) (65.5%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:47:03] \u001b[32mTrain: [ 43/50] Step 080/520 Loss 1.755 Prec@(1,5) (65.0%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:47:03] \u001b[32mTrain: [ 43/50] Step 100/520 Loss 1.762 Prec@(1,5) (64.7%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:47:04] \u001b[32mTrain: [ 43/50] Step 120/520 Loss 1.762 Prec@(1,5) (64.5%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:47:04] \u001b[32mTrain: [ 43/50] Step 140/520 Loss 1.762 Prec@(1,5) (64.5%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:47:05] \u001b[32mTrain: [ 43/50] Step 160/520 Loss 1.764 Prec@(1,5) (64.4%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:47:05] \u001b[32mTrain: [ 43/50] Step 180/520 Loss 1.760 Prec@(1,5) (64.5%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:47:06] \u001b[32mTrain: [ 43/50] Step 200/520 Loss 1.750 Prec@(1,5) (64.6%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:47:06] \u001b[32mTrain: [ 43/50] Step 220/520 Loss 1.749 Prec@(1,5) (64.6%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:47:07] \u001b[32mTrain: [ 43/50] Step 240/520 Loss 1.752 Prec@(1,5) (64.6%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:47:07] \u001b[32mTrain: [ 43/50] Step 260/520 Loss 1.748 Prec@(1,5) (64.6%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:47:08] \u001b[32mTrain: [ 43/50] Step 280/520 Loss 1.744 Prec@(1,5) (64.6%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:47:08] \u001b[32mTrain: [ 43/50] Step 300/520 Loss 1.745 Prec@(1,5) (64.5%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:47:09] \u001b[32mTrain: [ 43/50] Step 320/520 Loss 1.744 Prec@(1,5) (64.5%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:47:09] \u001b[32mTrain: [ 43/50] Step 340/520 Loss 1.746 Prec@(1,5) (64.5%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:47:10] \u001b[32mTrain: [ 43/50] Step 360/520 Loss 1.748 Prec@(1,5) (64.5%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:47:10] \u001b[32mTrain: [ 43/50] Step 380/520 Loss 1.748 Prec@(1,5) (64.5%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:47:11] \u001b[32mTrain: [ 43/50] Step 400/520 Loss 1.748 Prec@(1,5) (64.4%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:47:11] \u001b[32mTrain: [ 43/50] Step 420/520 Loss 1.748 Prec@(1,5) (64.5%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:47:12] \u001b[32mTrain: [ 43/50] Step 440/520 Loss 1.748 Prec@(1,5) (64.5%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:47:12] \u001b[32mTrain: [ 43/50] Step 460/520 Loss 1.746 Prec@(1,5) (64.5%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:47:13] \u001b[32mTrain: [ 43/50] Step 480/520 Loss 1.747 Prec@(1,5) (64.5%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:47:13] \u001b[32mTrain: [ 43/50] Step 500/520 Loss 1.746 Prec@(1,5) (64.5%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:47:14] \u001b[32mTrain: [ 43/50] Step 520/520 Loss 1.744 Prec@(1,5) (64.5%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:47:14] \u001b[32mTrain: [ 43/50] Final Prec@1 64.4980%\u001b[0m\n",
            "[2024-04-02 20:47:18] \u001b[32mValid: [ 43/50] Step 000/104 Loss 1.942 Prec@(1,5) (64.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:47:18] \u001b[32mValid: [ 43/50] Step 020/104 Loss 1.855 Prec@(1,5) (60.4%, 87.8%)\u001b[0m\n",
            "[2024-04-02 20:47:18] \u001b[32mValid: [ 43/50] Step 040/104 Loss 1.849 Prec@(1,5) (60.1%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:47:18] \u001b[32mValid: [ 43/50] Step 060/104 Loss 1.820 Prec@(1,5) (60.4%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:47:18] \u001b[32mValid: [ 43/50] Step 080/104 Loss 1.815 Prec@(1,5) (60.1%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:47:18] \u001b[32mValid: [ 43/50] Step 100/104 Loss 1.803 Prec@(1,5) (60.2%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:47:18] \u001b[32mValid: [ 43/50] Step 104/104 Loss 1.803 Prec@(1,5) (60.3%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:47:19] \u001b[32mValid: [ 43/50] Final Prec@1 60.2600%\u001b[0m\n",
            "[2024-04-02 20:47:19] \u001b[32mEpoch 43 LR 0.001191\u001b[0m\n",
            "[2024-04-02 20:47:23] \u001b[32mTrain: [ 44/50] Step 000/520 Loss 1.603 Prec@(1,5) (69.8%, 90.6%)\u001b[0m\n",
            "[2024-04-02 20:47:24] \u001b[32mTrain: [ 44/50] Step 020/520 Loss 1.770 Prec@(1,5) (64.2%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:47:24] \u001b[32mTrain: [ 44/50] Step 040/520 Loss 1.752 Prec@(1,5) (64.2%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:47:25] \u001b[32mTrain: [ 44/50] Step 060/520 Loss 1.729 Prec@(1,5) (64.7%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:47:25] \u001b[32mTrain: [ 44/50] Step 080/520 Loss 1.726 Prec@(1,5) (65.1%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:47:26] \u001b[32mTrain: [ 44/50] Step 100/520 Loss 1.737 Prec@(1,5) (64.8%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:47:26] \u001b[32mTrain: [ 44/50] Step 120/520 Loss 1.739 Prec@(1,5) (64.9%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:47:27] \u001b[32mTrain: [ 44/50] Step 140/520 Loss 1.749 Prec@(1,5) (64.7%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:47:27] \u001b[32mTrain: [ 44/50] Step 160/520 Loss 1.755 Prec@(1,5) (64.6%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:47:28] \u001b[32mTrain: [ 44/50] Step 180/520 Loss 1.751 Prec@(1,5) (64.6%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:47:28] \u001b[32mTrain: [ 44/50] Step 200/520 Loss 1.748 Prec@(1,5) (64.5%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:47:29] \u001b[32mTrain: [ 44/50] Step 220/520 Loss 1.750 Prec@(1,5) (64.4%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:47:29] \u001b[32mTrain: [ 44/50] Step 240/520 Loss 1.744 Prec@(1,5) (64.5%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:47:30] \u001b[32mTrain: [ 44/50] Step 260/520 Loss 1.752 Prec@(1,5) (64.4%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:47:30] \u001b[32mTrain: [ 44/50] Step 280/520 Loss 1.755 Prec@(1,5) (64.3%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:47:31] \u001b[32mTrain: [ 44/50] Step 300/520 Loss 1.756 Prec@(1,5) (64.3%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:47:31] \u001b[32mTrain: [ 44/50] Step 320/520 Loss 1.752 Prec@(1,5) (64.4%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:47:32] \u001b[32mTrain: [ 44/50] Step 340/520 Loss 1.753 Prec@(1,5) (64.4%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:47:32] \u001b[32mTrain: [ 44/50] Step 360/520 Loss 1.755 Prec@(1,5) (64.4%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:47:33] \u001b[32mTrain: [ 44/50] Step 380/520 Loss 1.755 Prec@(1,5) (64.5%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:47:33] \u001b[32mTrain: [ 44/50] Step 400/520 Loss 1.758 Prec@(1,5) (64.4%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:47:34] \u001b[32mTrain: [ 44/50] Step 420/520 Loss 1.758 Prec@(1,5) (64.4%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:47:34] \u001b[32mTrain: [ 44/50] Step 440/520 Loss 1.756 Prec@(1,5) (64.5%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:47:35] \u001b[32mTrain: [ 44/50] Step 460/520 Loss 1.752 Prec@(1,5) (64.6%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:47:35] \u001b[32mTrain: [ 44/50] Step 480/520 Loss 1.749 Prec@(1,5) (64.6%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:47:36] \u001b[32mTrain: [ 44/50] Step 500/520 Loss 1.748 Prec@(1,5) (64.6%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:47:36] \u001b[32mTrain: [ 44/50] Step 520/520 Loss 1.749 Prec@(1,5) (64.6%, 89.0%)\u001b[0m\n",
            "[2024-04-02 20:47:36] \u001b[32mTrain: [ 44/50] Final Prec@1 64.6140%\u001b[0m\n",
            "[2024-04-02 20:47:40] \u001b[32mValid: [ 44/50] Step 000/104 Loss 1.868 Prec@(1,5) (61.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:47:40] \u001b[32mValid: [ 44/50] Step 020/104 Loss 1.875 Prec@(1,5) (60.8%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:47:40] \u001b[32mValid: [ 44/50] Step 040/104 Loss 1.866 Prec@(1,5) (59.9%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:47:40] \u001b[32mValid: [ 44/50] Step 060/104 Loss 1.832 Prec@(1,5) (60.3%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:47:41] \u001b[32mValid: [ 44/50] Step 080/104 Loss 1.829 Prec@(1,5) (60.2%, 86.9%)\u001b[0m\n",
            "[2024-04-02 20:47:41] \u001b[32mValid: [ 44/50] Step 100/104 Loss 1.815 Prec@(1,5) (60.5%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:47:41] \u001b[32mValid: [ 44/50] Step 104/104 Loss 1.814 Prec@(1,5) (60.5%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:47:41] \u001b[32mValid: [ 44/50] Final Prec@1 60.5300%\u001b[0m\n",
            "[2024-04-02 20:47:41] \u001b[32mEpoch 44 LR 0.000879\u001b[0m\n",
            "[2024-04-02 20:47:46] \u001b[32mTrain: [ 45/50] Step 000/520 Loss 1.933 Prec@(1,5) (62.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:47:46] \u001b[32mTrain: [ 45/50] Step 020/520 Loss 1.707 Prec@(1,5) (63.9%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:47:47] \u001b[32mTrain: [ 45/50] Step 040/520 Loss 1.715 Prec@(1,5) (64.4%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:47:47] \u001b[32mTrain: [ 45/50] Step 060/520 Loss 1.696 Prec@(1,5) (65.0%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:47:48] \u001b[32mTrain: [ 45/50] Step 080/520 Loss 1.704 Prec@(1,5) (64.8%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:47:48] \u001b[32mTrain: [ 45/50] Step 100/520 Loss 1.709 Prec@(1,5) (64.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:47:49] \u001b[32mTrain: [ 45/50] Step 120/520 Loss 1.696 Prec@(1,5) (65.1%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:47:49] \u001b[32mTrain: [ 45/50] Step 140/520 Loss 1.693 Prec@(1,5) (65.1%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:47:50] \u001b[32mTrain: [ 45/50] Step 160/520 Loss 1.702 Prec@(1,5) (65.1%, 89.7%)\u001b[0m\n",
            "[2024-04-02 20:47:50] \u001b[32mTrain: [ 45/50] Step 180/520 Loss 1.706 Prec@(1,5) (65.1%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:47:51] \u001b[32mTrain: [ 45/50] Step 200/520 Loss 1.710 Prec@(1,5) (65.0%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:47:51] \u001b[32mTrain: [ 45/50] Step 220/520 Loss 1.710 Prec@(1,5) (65.1%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:47:52] \u001b[32mTrain: [ 45/50] Step 240/520 Loss 1.716 Prec@(1,5) (64.9%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:47:52] \u001b[32mTrain: [ 45/50] Step 260/520 Loss 1.718 Prec@(1,5) (64.9%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:47:53] \u001b[32mTrain: [ 45/50] Step 280/520 Loss 1.716 Prec@(1,5) (65.0%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:47:53] \u001b[32mTrain: [ 45/50] Step 300/520 Loss 1.718 Prec@(1,5) (65.0%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:47:54] \u001b[32mTrain: [ 45/50] Step 320/520 Loss 1.717 Prec@(1,5) (65.1%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:47:54] \u001b[32mTrain: [ 45/50] Step 340/520 Loss 1.714 Prec@(1,5) (65.1%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:47:54] \u001b[32mTrain: [ 45/50] Step 360/520 Loss 1.713 Prec@(1,5) (65.1%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:47:55] \u001b[32mTrain: [ 45/50] Step 380/520 Loss 1.714 Prec@(1,5) (65.1%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:47:55] \u001b[32mTrain: [ 45/50] Step 400/520 Loss 1.712 Prec@(1,5) (65.1%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:47:56] \u001b[32mTrain: [ 45/50] Step 420/520 Loss 1.714 Prec@(1,5) (65.1%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:47:56] \u001b[32mTrain: [ 45/50] Step 440/520 Loss 1.713 Prec@(1,5) (65.1%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:47:57] \u001b[32mTrain: [ 45/50] Step 460/520 Loss 1.718 Prec@(1,5) (64.9%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:47:57] \u001b[32mTrain: [ 45/50] Step 480/520 Loss 1.719 Prec@(1,5) (64.9%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:47:58] \u001b[32mTrain: [ 45/50] Step 500/520 Loss 1.721 Prec@(1,5) (64.9%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:47:58] \u001b[32mTrain: [ 45/50] Step 520/520 Loss 1.722 Prec@(1,5) (64.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:47:59] \u001b[32mTrain: [ 45/50] Final Prec@1 64.9160%\u001b[0m\n",
            "[2024-04-02 20:48:02] \u001b[32mValid: [ 45/50] Step 000/104 Loss 1.859 Prec@(1,5) (62.5%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:48:02] \u001b[32mValid: [ 45/50] Step 020/104 Loss 1.854 Prec@(1,5) (60.5%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:48:02] \u001b[32mValid: [ 45/50] Step 040/104 Loss 1.849 Prec@(1,5) (60.1%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:48:03] \u001b[32mValid: [ 45/50] Step 060/104 Loss 1.818 Prec@(1,5) (60.8%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:48:03] \u001b[32mValid: [ 45/50] Step 080/104 Loss 1.813 Prec@(1,5) (60.3%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:48:03] \u001b[32mValid: [ 45/50] Step 100/104 Loss 1.802 Prec@(1,5) (60.5%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:48:03] \u001b[32mValid: [ 45/50] Step 104/104 Loss 1.803 Prec@(1,5) (60.5%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:48:03] \u001b[32mValid: [ 45/50] Final Prec@1 60.4500%\u001b[0m\n",
            "[2024-04-02 20:48:03] \u001b[32mEpoch 45 LR 0.000613\u001b[0m\n",
            "[2024-04-02 20:48:08] \u001b[32mTrain: [ 46/50] Step 000/520 Loss 1.849 Prec@(1,5) (57.3%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:48:08] \u001b[32mTrain: [ 46/50] Step 020/520 Loss 1.627 Prec@(1,5) (66.4%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:48:09] \u001b[32mTrain: [ 46/50] Step 040/520 Loss 1.643 Prec@(1,5) (66.2%, 89.8%)\u001b[0m\n",
            "[2024-04-02 20:48:09] \u001b[32mTrain: [ 46/50] Step 060/520 Loss 1.680 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:48:10] \u001b[32mTrain: [ 46/50] Step 080/520 Loss 1.699 Prec@(1,5) (65.3%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:48:10] \u001b[32mTrain: [ 46/50] Step 100/520 Loss 1.702 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:48:11] \u001b[32mTrain: [ 46/50] Step 120/520 Loss 1.700 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:48:11] \u001b[32mTrain: [ 46/50] Step 140/520 Loss 1.705 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:48:12] \u001b[32mTrain: [ 46/50] Step 160/520 Loss 1.712 Prec@(1,5) (65.1%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:48:12] \u001b[32mTrain: [ 46/50] Step 180/520 Loss 1.710 Prec@(1,5) (65.3%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:48:13] \u001b[32mTrain: [ 46/50] Step 200/520 Loss 1.714 Prec@(1,5) (65.3%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:48:13] \u001b[32mTrain: [ 46/50] Step 220/520 Loss 1.712 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:48:14] \u001b[32mTrain: [ 46/50] Step 240/520 Loss 1.722 Prec@(1,5) (65.3%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:48:14] \u001b[32mTrain: [ 46/50] Step 260/520 Loss 1.721 Prec@(1,5) (65.3%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:48:15] \u001b[32mTrain: [ 46/50] Step 280/520 Loss 1.722 Prec@(1,5) (65.2%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:48:15] \u001b[32mTrain: [ 46/50] Step 300/520 Loss 1.724 Prec@(1,5) (65.1%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:48:16] \u001b[32mTrain: [ 46/50] Step 320/520 Loss 1.727 Prec@(1,5) (65.0%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:48:16] \u001b[32mTrain: [ 46/50] Step 340/520 Loss 1.726 Prec@(1,5) (65.1%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:48:17] \u001b[32mTrain: [ 46/50] Step 360/520 Loss 1.729 Prec@(1,5) (65.0%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:48:17] \u001b[32mTrain: [ 46/50] Step 380/520 Loss 1.730 Prec@(1,5) (64.9%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:48:18] \u001b[32mTrain: [ 46/50] Step 400/520 Loss 1.728 Prec@(1,5) (64.9%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:48:18] \u001b[32mTrain: [ 46/50] Step 420/520 Loss 1.727 Prec@(1,5) (65.0%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:48:19] \u001b[32mTrain: [ 46/50] Step 440/520 Loss 1.728 Prec@(1,5) (65.0%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:48:19] \u001b[32mTrain: [ 46/50] Step 460/520 Loss 1.725 Prec@(1,5) (65.1%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:48:20] \u001b[32mTrain: [ 46/50] Step 480/520 Loss 1.721 Prec@(1,5) (65.2%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:48:20] \u001b[32mTrain: [ 46/50] Step 500/520 Loss 1.722 Prec@(1,5) (65.2%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:48:20] \u001b[32mTrain: [ 46/50] Step 520/520 Loss 1.723 Prec@(1,5) (65.1%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:48:21] \u001b[32mTrain: [ 46/50] Final Prec@1 65.1180%\u001b[0m\n",
            "[2024-04-02 20:48:24] \u001b[32mValid: [ 46/50] Step 000/104 Loss 1.770 Prec@(1,5) (64.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:48:24] \u001b[32mValid: [ 46/50] Step 020/104 Loss 1.833 Prec@(1,5) (60.7%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:48:24] \u001b[32mValid: [ 46/50] Step 040/104 Loss 1.825 Prec@(1,5) (60.2%, 87.0%)\u001b[0m\n",
            "[2024-04-02 20:48:25] \u001b[32mValid: [ 46/50] Step 060/104 Loss 1.792 Prec@(1,5) (60.7%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:48:25] \u001b[32mValid: [ 46/50] Step 080/104 Loss 1.787 Prec@(1,5) (60.5%, 87.1%)\u001b[0m\n",
            "[2024-04-02 20:48:25] \u001b[32mValid: [ 46/50] Step 100/104 Loss 1.774 Prec@(1,5) (60.7%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:48:25] \u001b[32mValid: [ 46/50] Step 104/104 Loss 1.774 Prec@(1,5) (60.7%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:48:25] \u001b[32mValid: [ 46/50] Final Prec@1 60.6700%\u001b[0m\n",
            "[2024-04-02 20:48:25] \u001b[32mEpoch 46 LR 0.000394\u001b[0m\n",
            "[2024-04-02 20:48:30] \u001b[32mTrain: [ 47/50] Step 000/520 Loss 1.815 Prec@(1,5) (67.7%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:48:30] \u001b[32mTrain: [ 47/50] Step 020/520 Loss 1.774 Prec@(1,5) (63.9%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:48:31] \u001b[32mTrain: [ 47/50] Step 040/520 Loss 1.749 Prec@(1,5) (64.6%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:48:31] \u001b[32mTrain: [ 47/50] Step 060/520 Loss 1.743 Prec@(1,5) (64.3%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:48:32] \u001b[32mTrain: [ 47/50] Step 080/520 Loss 1.731 Prec@(1,5) (64.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:48:32] \u001b[32mTrain: [ 47/50] Step 100/520 Loss 1.728 Prec@(1,5) (64.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:48:33] \u001b[32mTrain: [ 47/50] Step 120/520 Loss 1.720 Prec@(1,5) (64.8%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:48:33] \u001b[32mTrain: [ 47/50] Step 140/520 Loss 1.724 Prec@(1,5) (64.8%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:48:34] \u001b[32mTrain: [ 47/50] Step 160/520 Loss 1.721 Prec@(1,5) (64.9%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:48:34] \u001b[32mTrain: [ 47/50] Step 180/520 Loss 1.714 Prec@(1,5) (65.3%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:48:35] \u001b[32mTrain: [ 47/50] Step 200/520 Loss 1.711 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:48:35] \u001b[32mTrain: [ 47/50] Step 220/520 Loss 1.714 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:48:36] \u001b[32mTrain: [ 47/50] Step 240/520 Loss 1.719 Prec@(1,5) (65.2%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:48:36] \u001b[32mTrain: [ 47/50] Step 260/520 Loss 1.716 Prec@(1,5) (65.2%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:48:37] \u001b[32mTrain: [ 47/50] Step 280/520 Loss 1.723 Prec@(1,5) (65.0%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:48:37] \u001b[32mTrain: [ 47/50] Step 300/520 Loss 1.722 Prec@(1,5) (65.1%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:48:38] \u001b[32mTrain: [ 47/50] Step 320/520 Loss 1.722 Prec@(1,5) (65.0%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:48:38] \u001b[32mTrain: [ 47/50] Step 340/520 Loss 1.720 Prec@(1,5) (65.0%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:48:39] \u001b[32mTrain: [ 47/50] Step 360/520 Loss 1.721 Prec@(1,5) (65.1%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:48:39] \u001b[32mTrain: [ 47/50] Step 380/520 Loss 1.723 Prec@(1,5) (65.0%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:48:40] \u001b[32mTrain: [ 47/50] Step 400/520 Loss 1.721 Prec@(1,5) (65.0%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:48:40] \u001b[32mTrain: [ 47/50] Step 420/520 Loss 1.722 Prec@(1,5) (64.9%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:48:41] \u001b[32mTrain: [ 47/50] Step 440/520 Loss 1.722 Prec@(1,5) (64.9%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:48:41] \u001b[32mTrain: [ 47/50] Step 460/520 Loss 1.720 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:48:42] \u001b[32mTrain: [ 47/50] Step 480/520 Loss 1.722 Prec@(1,5) (65.0%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:48:42] \u001b[32mTrain: [ 47/50] Step 500/520 Loss 1.722 Prec@(1,5) (65.0%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:48:43] \u001b[32mTrain: [ 47/50] Step 520/520 Loss 1.722 Prec@(1,5) (65.0%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:48:43] \u001b[32mTrain: [ 47/50] Final Prec@1 65.0160%\u001b[0m\n",
            "[2024-04-02 20:48:46] \u001b[32mValid: [ 47/50] Step 000/104 Loss 1.800 Prec@(1,5) (63.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:48:47] \u001b[32mValid: [ 47/50] Step 020/104 Loss 1.827 Prec@(1,5) (60.7%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:48:47] \u001b[32mValid: [ 47/50] Step 040/104 Loss 1.821 Prec@(1,5) (60.3%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:48:47] \u001b[32mValid: [ 47/50] Step 060/104 Loss 1.788 Prec@(1,5) (60.8%, 87.2%)\u001b[0m\n",
            "[2024-04-02 20:48:47] \u001b[32mValid: [ 47/50] Step 080/104 Loss 1.783 Prec@(1,5) (60.5%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:48:47] \u001b[32mValid: [ 47/50] Step 100/104 Loss 1.770 Prec@(1,5) (60.7%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:48:47] \u001b[32mValid: [ 47/50] Step 104/104 Loss 1.769 Prec@(1,5) (60.7%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:48:47] \u001b[32mValid: [ 47/50] Final Prec@1 60.7100%\u001b[0m\n",
            "[2024-04-02 20:48:47] \u001b[32mEpoch 47 LR 0.000222\u001b[0m\n",
            "[2024-04-02 20:48:52] \u001b[32mTrain: [ 48/50] Step 000/520 Loss 1.621 Prec@(1,5) (67.7%, 90.6%)\u001b[0m\n",
            "[2024-04-02 20:48:53] \u001b[32mTrain: [ 48/50] Step 020/520 Loss 1.739 Prec@(1,5) (65.5%, 88.8%)\u001b[0m\n",
            "[2024-04-02 20:48:53] \u001b[32mTrain: [ 48/50] Step 040/520 Loss 1.714 Prec@(1,5) (66.0%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:48:54] \u001b[32mTrain: [ 48/50] Step 060/520 Loss 1.703 Prec@(1,5) (66.0%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:48:54] \u001b[32mTrain: [ 48/50] Step 080/520 Loss 1.708 Prec@(1,5) (65.7%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:48:55] \u001b[32mTrain: [ 48/50] Step 100/520 Loss 1.709 Prec@(1,5) (65.7%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:48:55] \u001b[32mTrain: [ 48/50] Step 120/520 Loss 1.709 Prec@(1,5) (65.8%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:48:56] \u001b[32mTrain: [ 48/50] Step 140/520 Loss 1.706 Prec@(1,5) (65.6%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:48:56] \u001b[32mTrain: [ 48/50] Step 160/520 Loss 1.708 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:48:57] \u001b[32mTrain: [ 48/50] Step 180/520 Loss 1.713 Prec@(1,5) (65.3%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:48:57] \u001b[32mTrain: [ 48/50] Step 200/520 Loss 1.717 Prec@(1,5) (65.1%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:48:58] \u001b[32mTrain: [ 48/50] Step 220/520 Loss 1.718 Prec@(1,5) (65.2%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:48:58] \u001b[32mTrain: [ 48/50] Step 240/520 Loss 1.714 Prec@(1,5) (65.3%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:48:59] \u001b[32mTrain: [ 48/50] Step 260/520 Loss 1.722 Prec@(1,5) (65.0%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:48:59] \u001b[32mTrain: [ 48/50] Step 280/520 Loss 1.722 Prec@(1,5) (65.0%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:49:00] \u001b[32mTrain: [ 48/50] Step 300/520 Loss 1.724 Prec@(1,5) (64.9%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:49:00] \u001b[32mTrain: [ 48/50] Step 320/520 Loss 1.722 Prec@(1,5) (65.0%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:49:01] \u001b[32mTrain: [ 48/50] Step 340/520 Loss 1.717 Prec@(1,5) (65.1%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:49:01] \u001b[32mTrain: [ 48/50] Step 360/520 Loss 1.716 Prec@(1,5) (65.1%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:49:02] \u001b[32mTrain: [ 48/50] Step 380/520 Loss 1.711 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:02] \u001b[32mTrain: [ 48/50] Step 400/520 Loss 1.715 Prec@(1,5) (65.1%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:49:03] \u001b[32mTrain: [ 48/50] Step 420/520 Loss 1.714 Prec@(1,5) (65.2%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:49:03] \u001b[32mTrain: [ 48/50] Step 440/520 Loss 1.712 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:04] \u001b[32mTrain: [ 48/50] Step 460/520 Loss 1.710 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:04] \u001b[32mTrain: [ 48/50] Step 480/520 Loss 1.711 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:05] \u001b[32mTrain: [ 48/50] Step 500/520 Loss 1.713 Prec@(1,5) (65.1%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:05] \u001b[32mTrain: [ 48/50] Step 520/520 Loss 1.713 Prec@(1,5) (65.1%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:49:05] \u001b[32mTrain: [ 48/50] Final Prec@1 65.1000%\u001b[0m\n",
            "[2024-04-02 20:49:09] \u001b[32mValid: [ 48/50] Step 000/104 Loss 1.782 Prec@(1,5) (64.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:49:09] \u001b[32mValid: [ 48/50] Step 020/104 Loss 1.827 Prec@(1,5) (61.1%, 87.7%)\u001b[0m\n",
            "[2024-04-02 20:49:09] \u001b[32mValid: [ 48/50] Step 040/104 Loss 1.823 Prec@(1,5) (60.6%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:49:09] \u001b[32mValid: [ 48/50] Step 060/104 Loss 1.788 Prec@(1,5) (61.0%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:49:09] \u001b[32mValid: [ 48/50] Step 080/104 Loss 1.782 Prec@(1,5) (60.8%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:49:10] \u001b[32mValid: [ 48/50] Step 100/104 Loss 1.770 Prec@(1,5) (61.0%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:49:10] \u001b[32mValid: [ 48/50] Step 104/104 Loss 1.769 Prec@(1,5) (61.0%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:49:10] \u001b[32mValid: [ 48/50] Final Prec@1 60.9700%\u001b[0m\n",
            "[2024-04-02 20:49:10] \u001b[32mEpoch 48 LR 0.000100\u001b[0m\n",
            "[2024-04-02 20:49:14] \u001b[32mTrain: [ 49/50] Step 000/520 Loss 1.812 Prec@(1,5) (62.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 20:49:15] \u001b[32mTrain: [ 49/50] Step 020/520 Loss 1.731 Prec@(1,5) (65.0%, 88.6%)\u001b[0m\n",
            "[2024-04-02 20:49:15] \u001b[32mTrain: [ 49/50] Step 040/520 Loss 1.718 Prec@(1,5) (65.1%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:16] \u001b[32mTrain: [ 49/50] Step 060/520 Loss 1.714 Prec@(1,5) (65.6%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:16] \u001b[32mTrain: [ 49/50] Step 080/520 Loss 1.716 Prec@(1,5) (65.6%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:17] \u001b[32mTrain: [ 49/50] Step 100/520 Loss 1.712 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:49:17] \u001b[32mTrain: [ 49/50] Step 120/520 Loss 1.711 Prec@(1,5) (65.7%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:18] \u001b[32mTrain: [ 49/50] Step 140/520 Loss 1.727 Prec@(1,5) (65.4%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:49:18] \u001b[32mTrain: [ 49/50] Step 160/520 Loss 1.716 Prec@(1,5) (65.5%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:49:19] \u001b[32mTrain: [ 49/50] Step 180/520 Loss 1.717 Prec@(1,5) (65.4%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:49:19] \u001b[32mTrain: [ 49/50] Step 200/520 Loss 1.709 Prec@(1,5) (65.7%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:20] \u001b[32mTrain: [ 49/50] Step 220/520 Loss 1.709 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:49:20] \u001b[32mTrain: [ 49/50] Step 240/520 Loss 1.709 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:49:21] \u001b[32mTrain: [ 49/50] Step 260/520 Loss 1.712 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:49:21] \u001b[32mTrain: [ 49/50] Step 280/520 Loss 1.712 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:22] \u001b[32mTrain: [ 49/50] Step 300/520 Loss 1.714 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:22] \u001b[32mTrain: [ 49/50] Step 320/520 Loss 1.717 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:23] \u001b[32mTrain: [ 49/50] Step 340/520 Loss 1.718 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:23] \u001b[32mTrain: [ 49/50] Step 360/520 Loss 1.716 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:24] \u001b[32mTrain: [ 49/50] Step 380/520 Loss 1.717 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:24] \u001b[32mTrain: [ 49/50] Step 400/520 Loss 1.718 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:25] \u001b[32mTrain: [ 49/50] Step 420/520 Loss 1.716 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:25] \u001b[32mTrain: [ 49/50] Step 440/520 Loss 1.717 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:26] \u001b[32mTrain: [ 49/50] Step 460/520 Loss 1.715 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:26] \u001b[32mTrain: [ 49/50] Step 480/520 Loss 1.716 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:27] \u001b[32mTrain: [ 49/50] Step 500/520 Loss 1.715 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:27] \u001b[32mTrain: [ 49/50] Step 520/520 Loss 1.716 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:27] \u001b[32mTrain: [ 49/50] Final Prec@1 65.4200%\u001b[0m\n",
            "[2024-04-02 20:49:31] \u001b[32mValid: [ 49/50] Step 000/104 Loss 1.782 Prec@(1,5) (64.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:49:31] \u001b[32mValid: [ 49/50] Step 020/104 Loss 1.838 Prec@(1,5) (61.0%, 87.6%)\u001b[0m\n",
            "[2024-04-02 20:49:31] \u001b[32mValid: [ 49/50] Step 040/104 Loss 1.836 Prec@(1,5) (60.5%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:49:31] \u001b[32mValid: [ 49/50] Step 060/104 Loss 1.800 Prec@(1,5) (61.0%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:49:32] \u001b[32mValid: [ 49/50] Step 080/104 Loss 1.794 Prec@(1,5) (60.7%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:49:32] \u001b[32mValid: [ 49/50] Step 100/104 Loss 1.781 Prec@(1,5) (60.9%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:49:32] \u001b[32mValid: [ 49/50] Step 104/104 Loss 1.780 Prec@(1,5) (60.9%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:49:32] \u001b[32mValid: [ 49/50] Final Prec@1 60.9000%\u001b[0m\n",
            "[2024-04-02 20:49:32] \u001b[32mEpoch 49 LR 0.000026\u001b[0m\n",
            "[2024-04-02 20:49:37] \u001b[32mTrain: [ 50/50] Step 000/520 Loss 1.730 Prec@(1,5) (62.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:49:37] \u001b[32mTrain: [ 50/50] Step 020/520 Loss 1.698 Prec@(1,5) (64.5%, 88.7%)\u001b[0m\n",
            "[2024-04-02 20:49:38] \u001b[32mTrain: [ 50/50] Step 040/520 Loss 1.700 Prec@(1,5) (65.1%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:49:38] \u001b[32mTrain: [ 50/50] Step 060/520 Loss 1.727 Prec@(1,5) (64.9%, 88.9%)\u001b[0m\n",
            "[2024-04-02 20:49:39] \u001b[32mTrain: [ 50/50] Step 080/520 Loss 1.721 Prec@(1,5) (64.7%, 89.1%)\u001b[0m\n",
            "[2024-04-02 20:49:39] \u001b[32mTrain: [ 50/50] Step 100/520 Loss 1.713 Prec@(1,5) (65.1%, 89.2%)\u001b[0m\n",
            "[2024-04-02 20:49:40] \u001b[32mTrain: [ 50/50] Step 120/520 Loss 1.702 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:40] \u001b[32mTrain: [ 50/50] Step 140/520 Loss 1.706 Prec@(1,5) (65.5%, 89.3%)\u001b[0m\n",
            "[2024-04-02 20:49:41] \u001b[32mTrain: [ 50/50] Step 160/520 Loss 1.707 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:41] \u001b[32mTrain: [ 50/50] Step 180/520 Loss 1.704 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:49:42] \u001b[32mTrain: [ 50/50] Step 200/520 Loss 1.703 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:49:42] \u001b[32mTrain: [ 50/50] Step 220/520 Loss 1.711 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:43] \u001b[32mTrain: [ 50/50] Step 240/520 Loss 1.706 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:49:43] \u001b[32mTrain: [ 50/50] Step 260/520 Loss 1.707 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:49:44] \u001b[32mTrain: [ 50/50] Step 280/520 Loss 1.706 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:49:44] \u001b[32mTrain: [ 50/50] Step 300/520 Loss 1.708 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:49:45] \u001b[32mTrain: [ 50/50] Step 320/520 Loss 1.706 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:49:45] \u001b[32mTrain: [ 50/50] Step 340/520 Loss 1.710 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:49:46] \u001b[32mTrain: [ 50/50] Step 360/520 Loss 1.711 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:49:46] \u001b[32mTrain: [ 50/50] Step 380/520 Loss 1.708 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:49:47] \u001b[32mTrain: [ 50/50] Step 400/520 Loss 1.707 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:49:47] \u001b[32mTrain: [ 50/50] Step 420/520 Loss 1.710 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:49:47] \u001b[32mTrain: [ 50/50] Step 440/520 Loss 1.713 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:49:48] \u001b[32mTrain: [ 50/50] Step 460/520 Loss 1.710 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:49:48] \u001b[32mTrain: [ 50/50] Step 480/520 Loss 1.710 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 20:49:49] \u001b[32mTrain: [ 50/50] Step 500/520 Loss 1.714 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:49] \u001b[32mTrain: [ 50/50] Step 520/520 Loss 1.714 Prec@(1,5) (65.3%, 89.4%)\u001b[0m\n",
            "[2024-04-02 20:49:50] \u001b[32mTrain: [ 50/50] Final Prec@1 65.2640%\u001b[0m\n",
            "[2024-04-02 20:49:53] \u001b[32mValid: [ 50/50] Step 000/104 Loss 1.792 Prec@(1,5) (64.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:49:53] \u001b[32mValid: [ 50/50] Step 020/104 Loss 1.827 Prec@(1,5) (61.0%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:49:54] \u001b[32mValid: [ 50/50] Step 040/104 Loss 1.820 Prec@(1,5) (60.6%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:49:54] \u001b[32mValid: [ 50/50] Step 060/104 Loss 1.786 Prec@(1,5) (61.2%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:49:54] \u001b[32mValid: [ 50/50] Step 080/104 Loss 1.780 Prec@(1,5) (60.9%, 87.3%)\u001b[0m\n",
            "[2024-04-02 20:49:54] \u001b[32mValid: [ 50/50] Step 100/104 Loss 1.768 Prec@(1,5) (61.1%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:49:54] \u001b[32mValid: [ 50/50] Step 104/104 Loss 1.768 Prec@(1,5) (61.1%, 87.4%)\u001b[0m\n",
            "[2024-04-02 20:49:54] \u001b[32mValid: [ 50/50] Final Prec@1 61.0900%\u001b[0m\n",
            "Final best Prec@1 = 61.0900%\n",
            "{'lambd=1.263157894736842': 0.6138000170707703, 'lambd=1.6842105263157894': 0.6144000166893006, 'lambd=2.1052631578947367': 0.6146000204086304, 'lambd=2.526315789473684': 0.6115000175476074, 'lambd=2.9473684210526314': 0.6235000196456909, 'lambd=3.3684210526315788': 0.6109000211715698}\n",
            "random_edges/lambd=3.789473684210526/\n",
            "[2024-04-02 20:49:54] \u001b[32mFixed architecture: {'reduce_n2_p0': 'sepconv5x5', 'reduce_n2_p1': 'sepconv5x5', 'reduce_n3_p0': 'dilconv5x5', 'reduce_n3_p1': 'sepconv5x5', 'reduce_n3_p2': 'sepconv5x5', 'reduce_n4_p0': 'sepconv3x3', 'reduce_n4_p1': 'sepconv5x5', 'reduce_n4_p2': 'sepconv5x5', 'reduce_n4_p3': 'sepconv5x5', 'reduce_n5_p0': 'maxpool', 'reduce_n5_p1': 'sepconv3x3', 'reduce_n5_p2': 'sepconv5x5', 'reduce_n5_p3': 'sepconv5x5', 'reduce_n5_p4': 'maxpool', 'reduce_n2_switch': [1], 'reduce_n3_switch': [1], 'reduce_n4_switch': [0], 'reduce_n5_switch': [4]}\u001b[0m\n",
            "[2024-04-02 20:49:54] \u001b[32mEpoch 0 LR 0.025000\u001b[0m\n",
            "[2024-04-02 20:49:59] \u001b[32mTrain: [  1/50] Step 000/520 Loss 6.458 Prec@(1,5) (0.0%, 8.3%)\u001b[0m\n",
            "[2024-04-02 20:49:59] \u001b[32mTrain: [  1/50] Step 020/520 Loss 6.393 Prec@(1,5) (2.6%, 9.2%)\u001b[0m\n",
            "[2024-04-02 20:50:00] \u001b[32mTrain: [  1/50] Step 040/520 Loss 6.248 Prec@(1,5) (3.9%, 13.2%)\u001b[0m\n",
            "[2024-04-02 20:50:00] \u001b[32mTrain: [  1/50] Step 060/520 Loss 6.123 Prec@(1,5) (4.6%, 15.7%)\u001b[0m\n",
            "[2024-04-02 20:50:01] \u001b[32mTrain: [  1/50] Step 080/520 Loss 6.041 Prec@(1,5) (5.2%, 17.5%)\u001b[0m\n",
            "[2024-04-02 20:50:01] \u001b[32mTrain: [  1/50] Step 100/520 Loss 5.986 Prec@(1,5) (5.4%, 18.7%)\u001b[0m\n",
            "[2024-04-02 20:50:02] \u001b[32mTrain: [  1/50] Step 120/520 Loss 5.935 Prec@(1,5) (5.9%, 19.8%)\u001b[0m\n",
            "[2024-04-02 20:50:02] \u001b[32mTrain: [  1/50] Step 140/520 Loss 5.876 Prec@(1,5) (6.3%, 21.0%)\u001b[0m\n",
            "[2024-04-02 20:50:03] \u001b[32mTrain: [  1/50] Step 160/520 Loss 5.831 Prec@(1,5) (6.7%, 21.9%)\u001b[0m\n",
            "[2024-04-02 20:50:03] \u001b[32mTrain: [  1/50] Step 180/520 Loss 5.780 Prec@(1,5) (7.1%, 22.8%)\u001b[0m\n",
            "[2024-04-02 20:50:04] \u001b[32mTrain: [  1/50] Step 200/520 Loss 5.733 Prec@(1,5) (7.5%, 23.8%)\u001b[0m\n",
            "[2024-04-02 20:50:04] \u001b[32mTrain: [  1/50] Step 220/520 Loss 5.691 Prec@(1,5) (7.9%, 24.7%)\u001b[0m\n",
            "[2024-04-02 20:50:05] \u001b[32mTrain: [  1/50] Step 240/520 Loss 5.657 Prec@(1,5) (8.2%, 25.4%)\u001b[0m\n",
            "[2024-04-02 20:50:05] \u001b[32mTrain: [  1/50] Step 260/520 Loss 5.624 Prec@(1,5) (8.4%, 26.1%)\u001b[0m\n",
            "[2024-04-02 20:50:05] \u001b[32mTrain: [  1/50] Step 280/520 Loss 5.586 Prec@(1,5) (8.7%, 26.9%)\u001b[0m\n",
            "[2024-04-02 20:50:06] \u001b[32mTrain: [  1/50] Step 300/520 Loss 5.558 Prec@(1,5) (8.9%, 27.5%)\u001b[0m\n",
            "[2024-04-02 20:50:06] \u001b[32mTrain: [  1/50] Step 320/520 Loss 5.532 Prec@(1,5) (9.1%, 28.0%)\u001b[0m\n",
            "[2024-04-02 20:50:07] \u001b[32mTrain: [  1/50] Step 340/520 Loss 5.506 Prec@(1,5) (9.3%, 28.5%)\u001b[0m\n",
            "[2024-04-02 20:50:07] \u001b[32mTrain: [  1/50] Step 360/520 Loss 5.478 Prec@(1,5) (9.6%, 29.1%)\u001b[0m\n",
            "[2024-04-02 20:50:08] \u001b[32mTrain: [  1/50] Step 380/520 Loss 5.453 Prec@(1,5) (9.9%, 29.7%)\u001b[0m\n",
            "[2024-04-02 20:50:08] \u001b[32mTrain: [  1/50] Step 400/520 Loss 5.431 Prec@(1,5) (10.1%, 30.2%)\u001b[0m\n",
            "[2024-04-02 20:50:09] \u001b[32mTrain: [  1/50] Step 420/520 Loss 5.399 Prec@(1,5) (10.5%, 30.9%)\u001b[0m\n",
            "[2024-04-02 20:50:09] \u001b[32mTrain: [  1/50] Step 440/520 Loss 5.375 Prec@(1,5) (10.8%, 31.4%)\u001b[0m\n",
            "[2024-04-02 20:50:10] \u001b[32mTrain: [  1/50] Step 460/520 Loss 5.353 Prec@(1,5) (11.0%, 31.9%)\u001b[0m\n",
            "[2024-04-02 20:50:10] \u001b[32mTrain: [  1/50] Step 480/520 Loss 5.331 Prec@(1,5) (11.2%, 32.4%)\u001b[0m\n",
            "[2024-04-02 20:50:11] \u001b[32mTrain: [  1/50] Step 500/520 Loss 5.307 Prec@(1,5) (11.4%, 32.9%)\u001b[0m\n",
            "[2024-04-02 20:50:11] \u001b[32mTrain: [  1/50] Step 520/520 Loss 5.284 Prec@(1,5) (11.7%, 33.4%)\u001b[0m\n",
            "[2024-04-02 20:50:11] \u001b[32mTrain: [  1/50] Final Prec@1 11.7220%\u001b[0m\n",
            "[2024-04-02 20:50:15] \u001b[32mValid: [  1/50] Step 000/104 Loss 4.436 Prec@(1,5) (17.7%, 42.7%)\u001b[0m\n",
            "[2024-04-02 20:50:15] \u001b[32mValid: [  1/50] Step 020/104 Loss 4.314 Prec@(1,5) (17.4%, 43.7%)\u001b[0m\n",
            "[2024-04-02 20:50:15] \u001b[32mValid: [  1/50] Step 040/104 Loss 4.300 Prec@(1,5) (17.0%, 44.0%)\u001b[0m\n",
            "[2024-04-02 20:50:15] \u001b[32mValid: [  1/50] Step 060/104 Loss 4.242 Prec@(1,5) (17.5%, 44.8%)\u001b[0m\n",
            "[2024-04-02 20:50:15] \u001b[32mValid: [  1/50] Step 080/104 Loss 4.254 Prec@(1,5) (17.3%, 44.7%)\u001b[0m\n",
            "[2024-04-02 20:50:16] \u001b[32mValid: [  1/50] Step 100/104 Loss 4.264 Prec@(1,5) (17.1%, 44.8%)\u001b[0m\n",
            "[2024-04-02 20:50:16] \u001b[32mValid: [  1/50] Step 104/104 Loss 4.266 Prec@(1,5) (17.0%, 44.8%)\u001b[0m\n",
            "[2024-04-02 20:50:16] \u001b[32mValid: [  1/50] Final Prec@1 17.0400%\u001b[0m\n",
            "[2024-04-02 20:50:16] \u001b[32mEpoch 1 LR 0.024975\u001b[0m\n",
            "[2024-04-02 20:50:20] \u001b[32mTrain: [  2/50] Step 000/520 Loss 4.609 Prec@(1,5) (13.5%, 47.9%)\u001b[0m\n",
            "[2024-04-02 20:50:21] \u001b[32mTrain: [  2/50] Step 020/520 Loss 4.636 Prec@(1,5) (17.9%, 45.7%)\u001b[0m\n",
            "[2024-04-02 20:50:21] \u001b[32mTrain: [  2/50] Step 040/520 Loss 4.642 Prec@(1,5) (18.9%, 47.0%)\u001b[0m\n",
            "[2024-04-02 20:50:22] \u001b[32mTrain: [  2/50] Step 060/520 Loss 4.632 Prec@(1,5) (18.8%, 47.1%)\u001b[0m\n",
            "[2024-04-02 20:50:22] \u001b[32mTrain: [  2/50] Step 080/520 Loss 4.631 Prec@(1,5) (19.1%, 47.2%)\u001b[0m\n",
            "[2024-04-02 20:50:23] \u001b[32mTrain: [  2/50] Step 100/520 Loss 4.610 Prec@(1,5) (19.3%, 47.6%)\u001b[0m\n",
            "[2024-04-02 20:50:23] \u001b[32mTrain: [  2/50] Step 120/520 Loss 4.595 Prec@(1,5) (19.4%, 47.8%)\u001b[0m\n",
            "[2024-04-02 20:50:24] \u001b[32mTrain: [  2/50] Step 140/520 Loss 4.578 Prec@(1,5) (19.6%, 48.0%)\u001b[0m\n",
            "[2024-04-02 20:50:24] \u001b[32mTrain: [  2/50] Step 160/520 Loss 4.563 Prec@(1,5) (19.7%, 48.2%)\u001b[0m\n",
            "[2024-04-02 20:50:25] \u001b[32mTrain: [  2/50] Step 180/520 Loss 4.543 Prec@(1,5) (19.8%, 48.5%)\u001b[0m\n",
            "[2024-04-02 20:50:25] \u001b[32mTrain: [  2/50] Step 200/520 Loss 4.524 Prec@(1,5) (20.2%, 48.8%)\u001b[0m\n",
            "[2024-04-02 20:50:26] \u001b[32mTrain: [  2/50] Step 220/520 Loss 4.518 Prec@(1,5) (20.4%, 48.9%)\u001b[0m\n",
            "[2024-04-02 20:50:26] \u001b[32mTrain: [  2/50] Step 240/520 Loss 4.508 Prec@(1,5) (20.5%, 49.2%)\u001b[0m\n",
            "[2024-04-02 20:50:27] \u001b[32mTrain: [  2/50] Step 260/520 Loss 4.494 Prec@(1,5) (20.8%, 49.4%)\u001b[0m\n",
            "[2024-04-02 20:50:27] \u001b[32mTrain: [  2/50] Step 280/520 Loss 4.486 Prec@(1,5) (20.8%, 49.6%)\u001b[0m\n",
            "[2024-04-02 20:50:28] \u001b[32mTrain: [  2/50] Step 300/520 Loss 4.479 Prec@(1,5) (21.0%, 49.7%)\u001b[0m\n",
            "[2024-04-02 20:50:28] \u001b[32mTrain: [  2/50] Step 320/520 Loss 4.469 Prec@(1,5) (21.0%, 49.8%)\u001b[0m\n",
            "[2024-04-02 20:50:29] \u001b[32mTrain: [  2/50] Step 340/520 Loss 4.460 Prec@(1,5) (21.1%, 49.9%)\u001b[0m\n",
            "[2024-04-02 20:50:29] \u001b[32mTrain: [  2/50] Step 360/520 Loss 4.445 Prec@(1,5) (21.3%, 50.2%)\u001b[0m\n",
            "[2024-04-02 20:50:30] \u001b[32mTrain: [  2/50] Step 380/520 Loss 4.433 Prec@(1,5) (21.5%, 50.4%)\u001b[0m\n",
            "[2024-04-02 20:50:30] \u001b[32mTrain: [  2/50] Step 400/520 Loss 4.425 Prec@(1,5) (21.6%, 50.5%)\u001b[0m\n",
            "[2024-04-02 20:50:31] \u001b[32mTrain: [  2/50] Step 420/520 Loss 4.417 Prec@(1,5) (21.7%, 50.7%)\u001b[0m\n",
            "[2024-04-02 20:50:31] \u001b[32mTrain: [  2/50] Step 440/520 Loss 4.406 Prec@(1,5) (21.9%, 50.9%)\u001b[0m\n",
            "[2024-04-02 20:50:32] \u001b[32mTrain: [  2/50] Step 460/520 Loss 4.398 Prec@(1,5) (21.9%, 51.0%)\u001b[0m\n",
            "[2024-04-02 20:50:32] \u001b[32mTrain: [  2/50] Step 480/520 Loss 4.391 Prec@(1,5) (22.0%, 51.2%)\u001b[0m\n",
            "[2024-04-02 20:50:33] \u001b[32mTrain: [  2/50] Step 500/520 Loss 4.380 Prec@(1,5) (22.2%, 51.4%)\u001b[0m\n",
            "[2024-04-02 20:50:33] \u001b[32mTrain: [  2/50] Step 520/520 Loss 4.370 Prec@(1,5) (22.2%, 51.5%)\u001b[0m\n",
            "[2024-04-02 20:50:34] \u001b[32mTrain: [  2/50] Final Prec@1 22.2440%\u001b[0m\n",
            "[2024-04-02 20:50:37] \u001b[32mValid: [  2/50] Step 000/104 Loss 4.616 Prec@(1,5) (21.9%, 52.1%)\u001b[0m\n",
            "[2024-04-02 20:50:37] \u001b[32mValid: [  2/50] Step 020/104 Loss 4.277 Prec@(1,5) (22.5%, 53.4%)\u001b[0m\n",
            "[2024-04-02 20:50:37] \u001b[32mValid: [  2/50] Step 040/104 Loss 4.207 Prec@(1,5) (22.8%, 52.9%)\u001b[0m\n",
            "[2024-04-02 20:50:38] \u001b[32mValid: [  2/50] Step 060/104 Loss 4.171 Prec@(1,5) (23.1%, 53.2%)\u001b[0m\n",
            "[2024-04-02 20:50:38] \u001b[32mValid: [  2/50] Step 080/104 Loss 4.176 Prec@(1,5) (23.1%, 52.9%)\u001b[0m\n",
            "[2024-04-02 20:50:38] \u001b[32mValid: [  2/50] Step 100/104 Loss 4.181 Prec@(1,5) (22.8%, 53.0%)\u001b[0m\n",
            "[2024-04-02 20:50:38] \u001b[32mValid: [  2/50] Step 104/104 Loss 4.179 Prec@(1,5) (22.8%, 52.9%)\u001b[0m\n",
            "[2024-04-02 20:50:38] \u001b[32mValid: [  2/50] Final Prec@1 22.7600%\u001b[0m\n",
            "[2024-04-02 20:50:38] \u001b[32mEpoch 2 LR 0.024901\u001b[0m\n",
            "[2024-04-02 20:50:43] \u001b[32mTrain: [  3/50] Step 000/520 Loss 4.226 Prec@(1,5) (19.8%, 60.4%)\u001b[0m\n",
            "[2024-04-02 20:50:43] \u001b[32mTrain: [  3/50] Step 020/520 Loss 4.080 Prec@(1,5) (25.5%, 56.3%)\u001b[0m\n",
            "[2024-04-02 20:50:44] \u001b[32mTrain: [  3/50] Step 040/520 Loss 4.049 Prec@(1,5) (26.3%, 56.7%)\u001b[0m\n",
            "[2024-04-02 20:50:44] \u001b[32mTrain: [  3/50] Step 060/520 Loss 4.047 Prec@(1,5) (26.2%, 56.8%)\u001b[0m\n",
            "[2024-04-02 20:50:45] \u001b[32mTrain: [  3/50] Step 080/520 Loss 4.050 Prec@(1,5) (26.0%, 57.0%)\u001b[0m\n",
            "[2024-04-02 20:50:45] \u001b[32mTrain: [  3/50] Step 100/520 Loss 4.041 Prec@(1,5) (26.5%, 57.1%)\u001b[0m\n",
            "[2024-04-02 20:50:46] \u001b[32mTrain: [  3/50] Step 120/520 Loss 4.046 Prec@(1,5) (26.4%, 57.0%)\u001b[0m\n",
            "[2024-04-02 20:50:46] \u001b[32mTrain: [  3/50] Step 140/520 Loss 4.043 Prec@(1,5) (26.5%, 56.9%)\u001b[0m\n",
            "[2024-04-02 20:50:47] \u001b[32mTrain: [  3/50] Step 160/520 Loss 4.045 Prec@(1,5) (26.5%, 57.0%)\u001b[0m\n",
            "[2024-04-02 20:50:47] \u001b[32mTrain: [  3/50] Step 180/520 Loss 4.035 Prec@(1,5) (26.7%, 57.1%)\u001b[0m\n",
            "[2024-04-02 20:50:48] \u001b[32mTrain: [  3/50] Step 200/520 Loss 4.037 Prec@(1,5) (26.7%, 57.1%)\u001b[0m\n",
            "[2024-04-02 20:50:48] \u001b[32mTrain: [  3/50] Step 220/520 Loss 4.033 Prec@(1,5) (26.6%, 57.3%)\u001b[0m\n",
            "[2024-04-02 20:50:49] \u001b[32mTrain: [  3/50] Step 240/520 Loss 4.021 Prec@(1,5) (26.8%, 57.5%)\u001b[0m\n",
            "[2024-04-02 20:50:49] \u001b[32mTrain: [  3/50] Step 260/520 Loss 4.014 Prec@(1,5) (26.9%, 57.7%)\u001b[0m\n",
            "[2024-04-02 20:50:50] \u001b[32mTrain: [  3/50] Step 280/520 Loss 4.003 Prec@(1,5) (27.0%, 58.0%)\u001b[0m\n",
            "[2024-04-02 20:50:50] \u001b[32mTrain: [  3/50] Step 300/520 Loss 3.995 Prec@(1,5) (27.2%, 58.1%)\u001b[0m\n",
            "[2024-04-02 20:50:51] \u001b[32mTrain: [  3/50] Step 320/520 Loss 3.989 Prec@(1,5) (27.3%, 58.3%)\u001b[0m\n",
            "[2024-04-02 20:50:51] \u001b[32mTrain: [  3/50] Step 340/520 Loss 3.981 Prec@(1,5) (27.4%, 58.4%)\u001b[0m\n",
            "[2024-04-02 20:50:52] \u001b[32mTrain: [  3/50] Step 360/520 Loss 3.971 Prec@(1,5) (27.5%, 58.6%)\u001b[0m\n",
            "[2024-04-02 20:50:52] \u001b[32mTrain: [  3/50] Step 380/520 Loss 3.968 Prec@(1,5) (27.6%, 58.6%)\u001b[0m\n",
            "[2024-04-02 20:50:53] \u001b[32mTrain: [  3/50] Step 400/520 Loss 3.965 Prec@(1,5) (27.6%, 58.7%)\u001b[0m\n",
            "[2024-04-02 20:50:53] \u001b[32mTrain: [  3/50] Step 420/520 Loss 3.960 Prec@(1,5) (27.7%, 58.7%)\u001b[0m\n",
            "[2024-04-02 20:50:54] \u001b[32mTrain: [  3/50] Step 440/520 Loss 3.955 Prec@(1,5) (27.7%, 58.8%)\u001b[0m\n",
            "[2024-04-02 20:50:54] \u001b[32mTrain: [  3/50] Step 460/520 Loss 3.947 Prec@(1,5) (27.9%, 58.9%)\u001b[0m\n",
            "[2024-04-02 20:50:55] \u001b[32mTrain: [  3/50] Step 480/520 Loss 3.944 Prec@(1,5) (27.9%, 59.0%)\u001b[0m\n",
            "[2024-04-02 20:50:55] \u001b[32mTrain: [  3/50] Step 500/520 Loss 3.938 Prec@(1,5) (28.0%, 59.0%)\u001b[0m\n",
            "[2024-04-02 20:50:56] \u001b[32mTrain: [  3/50] Step 520/520 Loss 3.927 Prec@(1,5) (28.1%, 59.3%)\u001b[0m\n",
            "[2024-04-02 20:50:56] \u001b[32mTrain: [  3/50] Final Prec@1 28.1480%\u001b[0m\n",
            "[2024-04-02 20:51:00] \u001b[32mValid: [  3/50] Step 000/104 Loss 4.032 Prec@(1,5) (25.0%, 60.4%)\u001b[0m\n",
            "[2024-04-02 20:51:00] \u001b[32mValid: [  3/50] Step 020/104 Loss 3.945 Prec@(1,5) (27.2%, 58.9%)\u001b[0m\n",
            "[2024-04-02 20:51:00] \u001b[32mValid: [  3/50] Step 040/104 Loss 3.900 Prec@(1,5) (27.7%, 59.3%)\u001b[0m\n",
            "[2024-04-02 20:51:00] \u001b[32mValid: [  3/50] Step 060/104 Loss 3.864 Prec@(1,5) (28.3%, 59.7%)\u001b[0m\n",
            "[2024-04-02 20:51:00] \u001b[32mValid: [  3/50] Step 080/104 Loss 3.885 Prec@(1,5) (27.7%, 59.7%)\u001b[0m\n",
            "[2024-04-02 20:51:01] \u001b[32mValid: [  3/50] Step 100/104 Loss 3.876 Prec@(1,5) (27.8%, 59.8%)\u001b[0m\n",
            "[2024-04-02 20:51:01] \u001b[32mValid: [  3/50] Step 104/104 Loss 3.879 Prec@(1,5) (27.8%, 59.7%)\u001b[0m\n",
            "[2024-04-02 20:51:01] \u001b[32mValid: [  3/50] Final Prec@1 27.8100%\u001b[0m\n",
            "[2024-04-02 20:51:01] \u001b[32mEpoch 3 LR 0.024779\u001b[0m\n",
            "[2024-04-02 20:51:05] \u001b[32mTrain: [  4/50] Step 000/520 Loss 4.102 Prec@(1,5) (21.9%, 61.5%)\u001b[0m\n",
            "[2024-04-02 20:51:06] \u001b[32mTrain: [  4/50] Step 020/520 Loss 3.708 Prec@(1,5) (30.8%, 62.1%)\u001b[0m\n",
            "[2024-04-02 20:51:06] \u001b[32mTrain: [  4/50] Step 040/520 Loss 3.698 Prec@(1,5) (30.4%, 63.4%)\u001b[0m\n",
            "[2024-04-02 20:51:07] \u001b[32mTrain: [  4/50] Step 060/520 Loss 3.695 Prec@(1,5) (30.7%, 63.9%)\u001b[0m\n",
            "[2024-04-02 20:51:07] \u001b[32mTrain: [  4/50] Step 080/520 Loss 3.691 Prec@(1,5) (31.1%, 63.7%)\u001b[0m\n",
            "[2024-04-02 20:51:08] \u001b[32mTrain: [  4/50] Step 100/520 Loss 3.689 Prec@(1,5) (31.2%, 63.7%)\u001b[0m\n",
            "[2024-04-02 20:51:08] \u001b[32mTrain: [  4/50] Step 120/520 Loss 3.693 Prec@(1,5) (31.1%, 63.8%)\u001b[0m\n",
            "[2024-04-02 20:51:09] \u001b[32mTrain: [  4/50] Step 140/520 Loss 3.702 Prec@(1,5) (31.2%, 63.5%)\u001b[0m\n",
            "[2024-04-02 20:51:09] \u001b[32mTrain: [  4/50] Step 160/520 Loss 3.710 Prec@(1,5) (30.9%, 63.3%)\u001b[0m\n",
            "[2024-04-02 20:51:10] \u001b[32mTrain: [  4/50] Step 180/520 Loss 3.719 Prec@(1,5) (31.0%, 63.0%)\u001b[0m\n",
            "[2024-04-02 20:51:10] \u001b[32mTrain: [  4/50] Step 200/520 Loss 3.712 Prec@(1,5) (31.1%, 63.1%)\u001b[0m\n",
            "[2024-04-02 20:51:11] \u001b[32mTrain: [  4/50] Step 220/520 Loss 3.704 Prec@(1,5) (31.3%, 63.3%)\u001b[0m\n",
            "[2024-04-02 20:51:11] \u001b[32mTrain: [  4/50] Step 240/520 Loss 3.701 Prec@(1,5) (31.3%, 63.3%)\u001b[0m\n",
            "[2024-04-02 20:51:12] \u001b[32mTrain: [  4/50] Step 260/520 Loss 3.701 Prec@(1,5) (31.1%, 63.3%)\u001b[0m\n",
            "[2024-04-02 20:51:12] \u001b[32mTrain: [  4/50] Step 280/520 Loss 3.690 Prec@(1,5) (31.2%, 63.5%)\u001b[0m\n",
            "[2024-04-02 20:51:13] \u001b[32mTrain: [  4/50] Step 300/520 Loss 3.680 Prec@(1,5) (31.5%, 63.7%)\u001b[0m\n",
            "[2024-04-02 20:51:13] \u001b[32mTrain: [  4/50] Step 320/520 Loss 3.676 Prec@(1,5) (31.6%, 63.8%)\u001b[0m\n",
            "[2024-04-02 20:51:14] \u001b[32mTrain: [  4/50] Step 340/520 Loss 3.671 Prec@(1,5) (31.7%, 63.9%)\u001b[0m\n",
            "[2024-04-02 20:51:14] \u001b[32mTrain: [  4/50] Step 360/520 Loss 3.669 Prec@(1,5) (31.8%, 63.8%)\u001b[0m\n",
            "[2024-04-02 20:51:15] \u001b[32mTrain: [  4/50] Step 380/520 Loss 3.667 Prec@(1,5) (31.8%, 63.9%)\u001b[0m\n",
            "[2024-04-02 20:51:15] \u001b[32mTrain: [  4/50] Step 400/520 Loss 3.658 Prec@(1,5) (31.9%, 64.0%)\u001b[0m\n",
            "[2024-04-02 20:51:16] \u001b[32mTrain: [  4/50] Step 420/520 Loss 3.654 Prec@(1,5) (31.9%, 64.1%)\u001b[0m\n",
            "[2024-04-02 20:51:16] \u001b[32mTrain: [  4/50] Step 440/520 Loss 3.651 Prec@(1,5) (32.0%, 64.1%)\u001b[0m\n",
            "[2024-04-02 20:51:17] \u001b[32mTrain: [  4/50] Step 460/520 Loss 3.648 Prec@(1,5) (32.1%, 64.1%)\u001b[0m\n",
            "[2024-04-02 20:51:17] \u001b[32mTrain: [  4/50] Step 480/520 Loss 3.645 Prec@(1,5) (32.2%, 64.1%)\u001b[0m\n",
            "[2024-04-02 20:51:18] \u001b[32mTrain: [  4/50] Step 500/520 Loss 3.642 Prec@(1,5) (32.2%, 64.2%)\u001b[0m\n",
            "[2024-04-02 20:51:18] \u001b[32mTrain: [  4/50] Step 520/520 Loss 3.636 Prec@(1,5) (32.3%, 64.3%)\u001b[0m\n",
            "[2024-04-02 20:51:18] \u001b[32mTrain: [  4/50] Final Prec@1 32.3260%\u001b[0m\n",
            "[2024-04-02 20:51:22] \u001b[32mValid: [  4/50] Step 000/104 Loss 3.655 Prec@(1,5) (31.2%, 58.3%)\u001b[0m\n",
            "[2024-04-02 20:51:22] \u001b[32mValid: [  4/50] Step 020/104 Loss 3.638 Prec@(1,5) (31.8%, 64.6%)\u001b[0m\n",
            "[2024-04-02 20:51:22] \u001b[32mValid: [  4/50] Step 040/104 Loss 3.586 Prec@(1,5) (31.5%, 64.2%)\u001b[0m\n",
            "[2024-04-02 20:51:22] \u001b[32mValid: [  4/50] Step 060/104 Loss 3.575 Prec@(1,5) (31.6%, 64.0%)\u001b[0m\n",
            "[2024-04-02 20:51:22] \u001b[32mValid: [  4/50] Step 080/104 Loss 3.591 Prec@(1,5) (31.1%, 63.7%)\u001b[0m\n",
            "[2024-04-02 20:51:23] \u001b[32mValid: [  4/50] Step 100/104 Loss 3.599 Prec@(1,5) (31.2%, 63.6%)\u001b[0m\n",
            "[2024-04-02 20:51:23] \u001b[32mValid: [  4/50] Step 104/104 Loss 3.598 Prec@(1,5) (31.2%, 63.6%)\u001b[0m\n",
            "[2024-04-02 20:51:23] \u001b[32mValid: [  4/50] Final Prec@1 31.2200%\u001b[0m\n",
            "[2024-04-02 20:51:23] \u001b[32mEpoch 4 LR 0.024607\u001b[0m\n",
            "[2024-04-02 20:51:27] \u001b[32mTrain: [  5/50] Step 000/520 Loss 3.588 Prec@(1,5) (30.2%, 63.5%)\u001b[0m\n",
            "[2024-04-02 20:51:28] \u001b[32mTrain: [  5/50] Step 020/520 Loss 3.435 Prec@(1,5) (36.3%, 67.4%)\u001b[0m\n",
            "[2024-04-02 20:51:28] \u001b[32mTrain: [  5/50] Step 040/520 Loss 3.459 Prec@(1,5) (35.5%, 66.8%)\u001b[0m\n",
            "[2024-04-02 20:51:29] \u001b[32mTrain: [  5/50] Step 060/520 Loss 3.444 Prec@(1,5) (35.7%, 67.1%)\u001b[0m\n",
            "[2024-04-02 20:51:29] \u001b[32mTrain: [  5/50] Step 080/520 Loss 3.431 Prec@(1,5) (35.8%, 67.5%)\u001b[0m\n",
            "[2024-04-02 20:51:30] \u001b[32mTrain: [  5/50] Step 100/520 Loss 3.433 Prec@(1,5) (35.7%, 67.5%)\u001b[0m\n",
            "[2024-04-02 20:51:30] \u001b[32mTrain: [  5/50] Step 120/520 Loss 3.436 Prec@(1,5) (35.6%, 67.5%)\u001b[0m\n",
            "[2024-04-02 20:51:31] \u001b[32mTrain: [  5/50] Step 140/520 Loss 3.437 Prec@(1,5) (35.5%, 67.5%)\u001b[0m\n",
            "[2024-04-02 20:51:31] \u001b[32mTrain: [  5/50] Step 160/520 Loss 3.445 Prec@(1,5) (35.3%, 67.3%)\u001b[0m\n",
            "[2024-04-02 20:51:32] \u001b[32mTrain: [  5/50] Step 180/520 Loss 3.431 Prec@(1,5) (35.3%, 67.6%)\u001b[0m\n",
            "[2024-04-02 20:51:32] \u001b[32mTrain: [  5/50] Step 200/520 Loss 3.436 Prec@(1,5) (35.2%, 67.6%)\u001b[0m\n",
            "[2024-04-02 20:51:33] \u001b[32mTrain: [  5/50] Step 220/520 Loss 3.432 Prec@(1,5) (35.3%, 67.6%)\u001b[0m\n",
            "[2024-04-02 20:51:33] \u001b[32mTrain: [  5/50] Step 240/520 Loss 3.433 Prec@(1,5) (35.4%, 67.5%)\u001b[0m\n",
            "[2024-04-02 20:51:34] \u001b[32mTrain: [  5/50] Step 260/520 Loss 3.434 Prec@(1,5) (35.4%, 67.5%)\u001b[0m\n",
            "[2024-04-02 20:51:34] \u001b[32mTrain: [  5/50] Step 280/520 Loss 3.427 Prec@(1,5) (35.6%, 67.6%)\u001b[0m\n",
            "[2024-04-02 20:51:35] \u001b[32mTrain: [  5/50] Step 300/520 Loss 3.423 Prec@(1,5) (35.6%, 67.7%)\u001b[0m\n",
            "[2024-04-02 20:51:35] \u001b[32mTrain: [  5/50] Step 320/520 Loss 3.419 Prec@(1,5) (35.6%, 67.8%)\u001b[0m\n",
            "[2024-04-02 20:51:36] \u001b[32mTrain: [  5/50] Step 340/520 Loss 3.414 Prec@(1,5) (35.7%, 67.9%)\u001b[0m\n",
            "[2024-04-02 20:51:36] \u001b[32mTrain: [  5/50] Step 360/520 Loss 3.416 Prec@(1,5) (35.7%, 67.9%)\u001b[0m\n",
            "[2024-04-02 20:51:37] \u001b[32mTrain: [  5/50] Step 380/520 Loss 3.415 Prec@(1,5) (35.7%, 67.8%)\u001b[0m\n",
            "[2024-04-02 20:51:37] \u001b[32mTrain: [  5/50] Step 400/520 Loss 3.412 Prec@(1,5) (35.8%, 67.9%)\u001b[0m\n",
            "[2024-04-02 20:51:38] \u001b[32mTrain: [  5/50] Step 420/520 Loss 3.412 Prec@(1,5) (35.8%, 67.9%)\u001b[0m\n",
            "[2024-04-02 20:51:38] \u001b[32mTrain: [  5/50] Step 440/520 Loss 3.415 Prec@(1,5) (35.8%, 67.8%)\u001b[0m\n",
            "[2024-04-02 20:51:39] \u001b[32mTrain: [  5/50] Step 460/520 Loss 3.416 Prec@(1,5) (35.8%, 67.8%)\u001b[0m\n",
            "[2024-04-02 20:51:39] \u001b[32mTrain: [  5/50] Step 480/520 Loss 3.412 Prec@(1,5) (35.9%, 67.9%)\u001b[0m\n",
            "[2024-04-02 20:51:40] \u001b[32mTrain: [  5/50] Step 500/520 Loss 3.410 Prec@(1,5) (35.9%, 67.9%)\u001b[0m\n",
            "[2024-04-02 20:51:40] \u001b[32mTrain: [  5/50] Step 520/520 Loss 3.408 Prec@(1,5) (36.0%, 68.0%)\u001b[0m\n",
            "[2024-04-02 20:51:41] \u001b[32mTrain: [  5/50] Final Prec@1 35.9780%\u001b[0m\n",
            "[2024-04-02 20:51:44] \u001b[32mValid: [  5/50] Step 000/104 Loss 3.513 Prec@(1,5) (33.3%, 70.8%)\u001b[0m\n",
            "[2024-04-02 20:51:44] \u001b[32mValid: [  5/50] Step 020/104 Loss 3.488 Prec@(1,5) (33.9%, 66.6%)\u001b[0m\n",
            "[2024-04-02 20:51:44] \u001b[32mValid: [  5/50] Step 040/104 Loss 3.476 Prec@(1,5) (33.6%, 66.3%)\u001b[0m\n",
            "[2024-04-02 20:51:45] \u001b[32mValid: [  5/50] Step 060/104 Loss 3.455 Prec@(1,5) (34.0%, 66.6%)\u001b[0m\n",
            "[2024-04-02 20:51:45] \u001b[32mValid: [  5/50] Step 080/104 Loss 3.487 Prec@(1,5) (33.1%, 66.2%)\u001b[0m\n",
            "[2024-04-02 20:51:45] \u001b[32mValid: [  5/50] Step 100/104 Loss 3.497 Prec@(1,5) (33.0%, 66.1%)\u001b[0m\n",
            "[2024-04-02 20:51:45] \u001b[32mValid: [  5/50] Step 104/104 Loss 3.502 Prec@(1,5) (33.0%, 66.0%)\u001b[0m\n",
            "[2024-04-02 20:51:45] \u001b[32mValid: [  5/50] Final Prec@1 32.9500%\u001b[0m\n",
            "[2024-04-02 20:51:45] \u001b[32mEpoch 5 LR 0.024388\u001b[0m\n",
            "[2024-04-02 20:51:50] \u001b[32mTrain: [  6/50] Step 000/520 Loss 3.142 Prec@(1,5) (38.5%, 70.8%)\u001b[0m\n",
            "[2024-04-02 20:51:50] \u001b[32mTrain: [  6/50] Step 020/520 Loss 3.258 Prec@(1,5) (37.0%, 70.3%)\u001b[0m\n",
            "[2024-04-02 20:51:51] \u001b[32mTrain: [  6/50] Step 040/520 Loss 3.278 Prec@(1,5) (37.0%, 69.5%)\u001b[0m\n",
            "[2024-04-02 20:51:51] \u001b[32mTrain: [  6/50] Step 060/520 Loss 3.276 Prec@(1,5) (37.1%, 69.6%)\u001b[0m\n",
            "[2024-04-02 20:51:52] \u001b[32mTrain: [  6/50] Step 080/520 Loss 3.287 Prec@(1,5) (37.0%, 69.6%)\u001b[0m\n",
            "[2024-04-02 20:51:52] \u001b[32mTrain: [  6/50] Step 100/520 Loss 3.275 Prec@(1,5) (37.4%, 69.9%)\u001b[0m\n",
            "[2024-04-02 20:51:53] \u001b[32mTrain: [  6/50] Step 120/520 Loss 3.278 Prec@(1,5) (37.4%, 69.8%)\u001b[0m\n",
            "[2024-04-02 20:51:53] \u001b[32mTrain: [  6/50] Step 140/520 Loss 3.266 Prec@(1,5) (37.6%, 69.9%)\u001b[0m\n",
            "[2024-04-02 20:51:54] \u001b[32mTrain: [  6/50] Step 160/520 Loss 3.274 Prec@(1,5) (37.5%, 69.9%)\u001b[0m\n",
            "[2024-04-02 20:51:54] \u001b[32mTrain: [  6/50] Step 180/520 Loss 3.274 Prec@(1,5) (37.7%, 69.8%)\u001b[0m\n",
            "[2024-04-02 20:51:55] \u001b[32mTrain: [  6/50] Step 200/520 Loss 3.275 Prec@(1,5) (37.7%, 69.7%)\u001b[0m\n",
            "[2024-04-02 20:51:55] \u001b[32mTrain: [  6/50] Step 220/520 Loss 3.276 Prec@(1,5) (37.7%, 69.8%)\u001b[0m\n",
            "[2024-04-02 20:51:56] \u001b[32mTrain: [  6/50] Step 240/520 Loss 3.276 Prec@(1,5) (37.5%, 69.8%)\u001b[0m\n",
            "[2024-04-02 20:51:56] \u001b[32mTrain: [  6/50] Step 260/520 Loss 3.278 Prec@(1,5) (37.6%, 69.9%)\u001b[0m\n",
            "[2024-04-02 20:51:57] \u001b[32mTrain: [  6/50] Step 280/520 Loss 3.277 Prec@(1,5) (37.6%, 69.9%)\u001b[0m\n",
            "[2024-04-02 20:51:57] \u001b[32mTrain: [  6/50] Step 300/520 Loss 3.277 Prec@(1,5) (37.7%, 69.8%)\u001b[0m\n",
            "[2024-04-02 20:51:58] \u001b[32mTrain: [  6/50] Step 320/520 Loss 3.266 Prec@(1,5) (37.9%, 70.0%)\u001b[0m\n",
            "[2024-04-02 20:51:58] \u001b[32mTrain: [  6/50] Step 340/520 Loss 3.267 Prec@(1,5) (38.0%, 70.0%)\u001b[0m\n",
            "[2024-04-02 20:51:59] \u001b[32mTrain: [  6/50] Step 360/520 Loss 3.266 Prec@(1,5) (38.0%, 70.0%)\u001b[0m\n",
            "[2024-04-02 20:51:59] \u001b[32mTrain: [  6/50] Step 380/520 Loss 3.261 Prec@(1,5) (38.2%, 70.0%)\u001b[0m\n",
            "[2024-04-02 20:52:00] \u001b[32mTrain: [  6/50] Step 400/520 Loss 3.257 Prec@(1,5) (38.3%, 70.1%)\u001b[0m\n",
            "[2024-04-02 20:52:00] \u001b[32mTrain: [  6/50] Step 420/520 Loss 3.261 Prec@(1,5) (38.2%, 70.0%)\u001b[0m\n",
            "[2024-04-02 20:52:01] \u001b[32mTrain: [  6/50] Step 440/520 Loss 3.260 Prec@(1,5) (38.3%, 70.0%)\u001b[0m\n",
            "[2024-04-02 20:52:01] \u001b[32mTrain: [  6/50] Step 460/520 Loss 3.261 Prec@(1,5) (38.3%, 70.1%)\u001b[0m\n",
            "[2024-04-02 20:52:02] \u001b[32mTrain: [  6/50] Step 480/520 Loss 3.260 Prec@(1,5) (38.3%, 70.1%)\u001b[0m\n",
            "[2024-04-02 20:52:02] \u001b[32mTrain: [  6/50] Step 500/520 Loss 3.255 Prec@(1,5) (38.4%, 70.2%)\u001b[0m\n",
            "[2024-04-02 20:52:03] \u001b[32mTrain: [  6/50] Step 520/520 Loss 3.250 Prec@(1,5) (38.4%, 70.3%)\u001b[0m\n",
            "[2024-04-02 20:52:03] \u001b[32mTrain: [  6/50] Final Prec@1 38.3780%\u001b[0m\n",
            "[2024-04-02 20:52:06] \u001b[32mValid: [  6/50] Step 000/104 Loss 3.212 Prec@(1,5) (35.4%, 71.9%)\u001b[0m\n",
            "[2024-04-02 20:52:07] \u001b[32mValid: [  6/50] Step 020/104 Loss 3.226 Prec@(1,5) (36.4%, 69.6%)\u001b[0m\n",
            "[2024-04-02 20:52:07] \u001b[32mValid: [  6/50] Step 040/104 Loss 3.184 Prec@(1,5) (36.9%, 69.6%)\u001b[0m\n",
            "[2024-04-02 20:52:07] \u001b[32mValid: [  6/50] Step 060/104 Loss 3.128 Prec@(1,5) (37.8%, 70.2%)\u001b[0m\n",
            "[2024-04-02 20:52:07] \u001b[32mValid: [  6/50] Step 080/104 Loss 3.140 Prec@(1,5) (37.3%, 69.8%)\u001b[0m\n",
            "[2024-04-02 20:52:07] \u001b[32mValid: [  6/50] Step 100/104 Loss 3.123 Prec@(1,5) (37.6%, 70.2%)\u001b[0m\n",
            "[2024-04-02 20:52:07] \u001b[32mValid: [  6/50] Step 104/104 Loss 3.125 Prec@(1,5) (37.6%, 70.1%)\u001b[0m\n",
            "[2024-04-02 20:52:07] \u001b[32mValid: [  6/50] Final Prec@1 37.5500%\u001b[0m\n",
            "[2024-04-02 20:52:07] \u001b[32mEpoch 6 LR 0.024122\u001b[0m\n",
            "[2024-04-02 20:52:12] \u001b[32mTrain: [  7/50] Step 000/520 Loss 3.474 Prec@(1,5) (38.5%, 64.6%)\u001b[0m\n",
            "[2024-04-02 20:52:13] \u001b[32mTrain: [  7/50] Step 020/520 Loss 3.165 Prec@(1,5) (40.4%, 71.6%)\u001b[0m\n",
            "[2024-04-02 20:52:13] \u001b[32mTrain: [  7/50] Step 040/520 Loss 3.132 Prec@(1,5) (40.5%, 71.8%)\u001b[0m\n",
            "[2024-04-02 20:52:14] \u001b[32mTrain: [  7/50] Step 060/520 Loss 3.085 Prec@(1,5) (41.2%, 72.8%)\u001b[0m\n",
            "[2024-04-02 20:52:14] \u001b[32mTrain: [  7/50] Step 080/520 Loss 3.100 Prec@(1,5) (41.0%, 72.6%)\u001b[0m\n",
            "[2024-04-02 20:52:15] \u001b[32mTrain: [  7/50] Step 100/520 Loss 3.099 Prec@(1,5) (41.0%, 72.5%)\u001b[0m\n",
            "[2024-04-02 20:52:15] \u001b[32mTrain: [  7/50] Step 120/520 Loss 3.112 Prec@(1,5) (40.6%, 72.4%)\u001b[0m\n",
            "[2024-04-02 20:52:16] \u001b[32mTrain: [  7/50] Step 140/520 Loss 3.121 Prec@(1,5) (40.4%, 72.3%)\u001b[0m\n",
            "[2024-04-02 20:52:16] \u001b[32mTrain: [  7/50] Step 160/520 Loss 3.135 Prec@(1,5) (40.3%, 72.1%)\u001b[0m\n",
            "[2024-04-02 20:52:17] \u001b[32mTrain: [  7/50] Step 180/520 Loss 3.140 Prec@(1,5) (40.2%, 71.9%)\u001b[0m\n",
            "[2024-04-02 20:52:17] \u001b[32mTrain: [  7/50] Step 200/520 Loss 3.134 Prec@(1,5) (40.1%, 72.1%)\u001b[0m\n",
            "[2024-04-02 20:52:17] \u001b[32mTrain: [  7/50] Step 220/520 Loss 3.128 Prec@(1,5) (40.3%, 72.1%)\u001b[0m\n",
            "[2024-04-02 20:52:18] \u001b[32mTrain: [  7/50] Step 240/520 Loss 3.129 Prec@(1,5) (40.3%, 72.1%)\u001b[0m\n",
            "[2024-04-02 20:52:18] \u001b[32mTrain: [  7/50] Step 260/520 Loss 3.126 Prec@(1,5) (40.3%, 72.3%)\u001b[0m\n",
            "[2024-04-02 20:52:19] \u001b[32mTrain: [  7/50] Step 280/520 Loss 3.121 Prec@(1,5) (40.3%, 72.4%)\u001b[0m\n",
            "[2024-04-02 20:52:19] \u001b[32mTrain: [  7/50] Step 300/520 Loss 3.118 Prec@(1,5) (40.4%, 72.3%)\u001b[0m\n",
            "[2024-04-02 20:52:20] \u001b[32mTrain: [  7/50] Step 320/520 Loss 3.121 Prec@(1,5) (40.4%, 72.3%)\u001b[0m\n",
            "[2024-04-02 20:52:20] \u001b[32mTrain: [  7/50] Step 340/520 Loss 3.121 Prec@(1,5) (40.5%, 72.3%)\u001b[0m\n",
            "[2024-04-02 20:52:21] \u001b[32mTrain: [  7/50] Step 360/520 Loss 3.119 Prec@(1,5) (40.5%, 72.3%)\u001b[0m\n",
            "[2024-04-02 20:52:21] \u001b[32mTrain: [  7/50] Step 380/520 Loss 3.109 Prec@(1,5) (40.6%, 72.4%)\u001b[0m\n",
            "[2024-04-02 20:52:22] \u001b[32mTrain: [  7/50] Step 400/520 Loss 3.108 Prec@(1,5) (40.7%, 72.5%)\u001b[0m\n",
            "[2024-04-02 20:52:22] \u001b[32mTrain: [  7/50] Step 420/520 Loss 3.106 Prec@(1,5) (40.7%, 72.5%)\u001b[0m\n",
            "[2024-04-02 20:52:23] \u001b[32mTrain: [  7/50] Step 440/520 Loss 3.105 Prec@(1,5) (40.8%, 72.6%)\u001b[0m\n",
            "[2024-04-02 20:52:23] \u001b[32mTrain: [  7/50] Step 460/520 Loss 3.103 Prec@(1,5) (40.8%, 72.6%)\u001b[0m\n",
            "[2024-04-02 20:52:24] \u001b[32mTrain: [  7/50] Step 480/520 Loss 3.102 Prec@(1,5) (40.8%, 72.6%)\u001b[0m\n",
            "[2024-04-02 20:52:24] \u001b[32mTrain: [  7/50] Step 500/520 Loss 3.102 Prec@(1,5) (40.8%, 72.6%)\u001b[0m\n",
            "[2024-04-02 20:52:25] \u001b[32mTrain: [  7/50] Step 520/520 Loss 3.098 Prec@(1,5) (40.9%, 72.7%)\u001b[0m\n",
            "[2024-04-02 20:52:25] \u001b[32mTrain: [  7/50] Final Prec@1 40.8800%\u001b[0m\n",
            "[2024-04-02 20:52:28] \u001b[32mValid: [  7/50] Step 000/104 Loss 3.291 Prec@(1,5) (41.7%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:52:29] \u001b[32mValid: [  7/50] Step 020/104 Loss 3.495 Prec@(1,5) (37.7%, 68.2%)\u001b[0m\n",
            "[2024-04-02 20:52:29] \u001b[32mValid: [  7/50] Step 040/104 Loss 3.419 Prec@(1,5) (37.3%, 67.8%)\u001b[0m\n",
            "[2024-04-02 20:52:29] \u001b[32mValid: [  7/50] Step 060/104 Loss 3.369 Prec@(1,5) (37.8%, 68.1%)\u001b[0m\n",
            "[2024-04-02 20:52:29] \u001b[32mValid: [  7/50] Step 080/104 Loss 3.364 Prec@(1,5) (37.6%, 68.2%)\u001b[0m\n",
            "[2024-04-02 20:52:29] \u001b[32mValid: [  7/50] Step 100/104 Loss 3.349 Prec@(1,5) (37.7%, 68.3%)\u001b[0m\n",
            "[2024-04-02 20:52:29] \u001b[32mValid: [  7/50] Step 104/104 Loss 3.347 Prec@(1,5) (37.6%, 68.4%)\u001b[0m\n",
            "[2024-04-02 20:52:30] \u001b[32mValid: [  7/50] Final Prec@1 37.6200%\u001b[0m\n",
            "[2024-04-02 20:52:30] \u001b[32mEpoch 7 LR 0.023810\u001b[0m\n",
            "[2024-04-02 20:52:34] \u001b[32mTrain: [  8/50] Step 000/520 Loss 3.025 Prec@(1,5) (43.8%, 67.7%)\u001b[0m\n",
            "[2024-04-02 20:52:35] \u001b[32mTrain: [  8/50] Step 020/520 Loss 2.931 Prec@(1,5) (43.6%, 75.0%)\u001b[0m\n",
            "[2024-04-02 20:52:35] \u001b[32mTrain: [  8/50] Step 040/520 Loss 2.992 Prec@(1,5) (42.6%, 73.9%)\u001b[0m\n",
            "[2024-04-02 20:52:36] \u001b[32mTrain: [  8/50] Step 060/520 Loss 3.008 Prec@(1,5) (42.7%, 73.5%)\u001b[0m\n",
            "[2024-04-02 20:52:36] \u001b[32mTrain: [  8/50] Step 080/520 Loss 2.997 Prec@(1,5) (42.4%, 73.8%)\u001b[0m\n",
            "[2024-04-02 20:52:37] \u001b[32mTrain: [  8/50] Step 100/520 Loss 3.008 Prec@(1,5) (42.2%, 73.8%)\u001b[0m\n",
            "[2024-04-02 20:52:37] \u001b[32mTrain: [  8/50] Step 120/520 Loss 3.011 Prec@(1,5) (42.0%, 73.7%)\u001b[0m\n",
            "[2024-04-02 20:52:38] \u001b[32mTrain: [  8/50] Step 140/520 Loss 3.007 Prec@(1,5) (42.2%, 73.9%)\u001b[0m\n",
            "[2024-04-02 20:52:38] \u001b[32mTrain: [  8/50] Step 160/520 Loss 3.003 Prec@(1,5) (42.2%, 74.1%)\u001b[0m\n",
            "[2024-04-02 20:52:39] \u001b[32mTrain: [  8/50] Step 180/520 Loss 3.004 Prec@(1,5) (42.3%, 74.1%)\u001b[0m\n",
            "[2024-04-02 20:52:39] \u001b[32mTrain: [  8/50] Step 200/520 Loss 2.997 Prec@(1,5) (42.3%, 74.2%)\u001b[0m\n",
            "[2024-04-02 20:52:40] \u001b[32mTrain: [  8/50] Step 220/520 Loss 3.002 Prec@(1,5) (42.3%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:52:40] \u001b[32mTrain: [  8/50] Step 240/520 Loss 3.004 Prec@(1,5) (42.2%, 73.9%)\u001b[0m\n",
            "[2024-04-02 20:52:41] \u001b[32mTrain: [  8/50] Step 260/520 Loss 3.003 Prec@(1,5) (42.2%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:52:41] \u001b[32mTrain: [  8/50] Step 280/520 Loss 3.002 Prec@(1,5) (42.2%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:52:42] \u001b[32mTrain: [  8/50] Step 300/520 Loss 3.001 Prec@(1,5) (42.2%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:52:42] \u001b[32mTrain: [  8/50] Step 320/520 Loss 2.995 Prec@(1,5) (42.4%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:52:43] \u001b[32mTrain: [  8/50] Step 340/520 Loss 2.991 Prec@(1,5) (42.5%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:52:43] \u001b[32mTrain: [  8/50] Step 360/520 Loss 2.992 Prec@(1,5) (42.5%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:52:44] \u001b[32mTrain: [  8/50] Step 380/520 Loss 2.988 Prec@(1,5) (42.6%, 74.1%)\u001b[0m\n",
            "[2024-04-02 20:52:44] \u001b[32mTrain: [  8/50] Step 400/520 Loss 2.980 Prec@(1,5) (42.8%, 74.2%)\u001b[0m\n",
            "[2024-04-02 20:52:45] \u001b[32mTrain: [  8/50] Step 420/520 Loss 2.977 Prec@(1,5) (42.8%, 74.2%)\u001b[0m\n",
            "[2024-04-02 20:52:45] \u001b[32mTrain: [  8/50] Step 440/520 Loss 2.978 Prec@(1,5) (42.8%, 74.2%)\u001b[0m\n",
            "[2024-04-02 20:52:46] \u001b[32mTrain: [  8/50] Step 460/520 Loss 2.981 Prec@(1,5) (42.8%, 74.2%)\u001b[0m\n",
            "[2024-04-02 20:52:46] \u001b[32mTrain: [  8/50] Step 480/520 Loss 2.985 Prec@(1,5) (42.7%, 74.2%)\u001b[0m\n",
            "[2024-04-02 20:52:47] \u001b[32mTrain: [  8/50] Step 500/520 Loss 2.984 Prec@(1,5) (42.7%, 74.2%)\u001b[0m\n",
            "[2024-04-02 20:52:47] \u001b[32mTrain: [  8/50] Step 520/520 Loss 2.985 Prec@(1,5) (42.7%, 74.2%)\u001b[0m\n",
            "[2024-04-02 20:52:47] \u001b[32mTrain: [  8/50] Final Prec@1 42.7020%\u001b[0m\n",
            "[2024-04-02 20:52:51] \u001b[32mValid: [  8/50] Step 000/104 Loss 2.985 Prec@(1,5) (42.7%, 71.9%)\u001b[0m\n",
            "[2024-04-02 20:52:51] \u001b[32mValid: [  8/50] Step 020/104 Loss 3.072 Prec@(1,5) (41.7%, 72.5%)\u001b[0m\n",
            "[2024-04-02 20:52:51] \u001b[32mValid: [  8/50] Step 040/104 Loss 3.032 Prec@(1,5) (41.7%, 72.5%)\u001b[0m\n",
            "[2024-04-02 20:52:52] \u001b[32mValid: [  8/50] Step 060/104 Loss 2.985 Prec@(1,5) (41.7%, 72.6%)\u001b[0m\n",
            "[2024-04-02 20:52:52] \u001b[32mValid: [  8/50] Step 080/104 Loss 2.998 Prec@(1,5) (41.1%, 72.8%)\u001b[0m\n",
            "[2024-04-02 20:52:52] \u001b[32mValid: [  8/50] Step 100/104 Loss 2.974 Prec@(1,5) (41.2%, 73.0%)\u001b[0m\n",
            "[2024-04-02 20:52:52] \u001b[32mValid: [  8/50] Step 104/104 Loss 2.973 Prec@(1,5) (41.1%, 73.0%)\u001b[0m\n",
            "[2024-04-02 20:52:52] \u001b[32mValid: [  8/50] Final Prec@1 41.1000%\u001b[0m\n",
            "[2024-04-02 20:52:52] \u001b[32mEpoch 8 LR 0.023454\u001b[0m\n",
            "[2024-04-02 20:52:57] \u001b[32mTrain: [  9/50] Step 000/520 Loss 2.513 Prec@(1,5) (47.9%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:52:57] \u001b[32mTrain: [  9/50] Step 020/520 Loss 2.907 Prec@(1,5) (43.8%, 75.6%)\u001b[0m\n",
            "[2024-04-02 20:52:58] \u001b[32mTrain: [  9/50] Step 040/520 Loss 2.931 Prec@(1,5) (43.5%, 75.1%)\u001b[0m\n",
            "[2024-04-02 20:52:58] \u001b[32mTrain: [  9/50] Step 060/520 Loss 2.921 Prec@(1,5) (43.5%, 75.2%)\u001b[0m\n",
            "[2024-04-02 20:52:59] \u001b[32mTrain: [  9/50] Step 080/520 Loss 2.915 Prec@(1,5) (43.8%, 75.3%)\u001b[0m\n",
            "[2024-04-02 20:52:59] \u001b[32mTrain: [  9/50] Step 100/520 Loss 2.901 Prec@(1,5) (43.9%, 75.5%)\u001b[0m\n",
            "[2024-04-02 20:53:00] \u001b[32mTrain: [  9/50] Step 120/520 Loss 2.907 Prec@(1,5) (44.1%, 75.3%)\u001b[0m\n",
            "[2024-04-02 20:53:00] \u001b[32mTrain: [  9/50] Step 140/520 Loss 2.898 Prec@(1,5) (44.2%, 75.5%)\u001b[0m\n",
            "[2024-04-02 20:53:01] \u001b[32mTrain: [  9/50] Step 160/520 Loss 2.902 Prec@(1,5) (44.0%, 75.5%)\u001b[0m\n",
            "[2024-04-02 20:53:01] \u001b[32mTrain: [  9/50] Step 180/520 Loss 2.909 Prec@(1,5) (43.9%, 75.5%)\u001b[0m\n",
            "[2024-04-02 20:53:02] \u001b[32mTrain: [  9/50] Step 200/520 Loss 2.908 Prec@(1,5) (43.9%, 75.6%)\u001b[0m\n",
            "[2024-04-02 20:53:02] \u001b[32mTrain: [  9/50] Step 220/520 Loss 2.906 Prec@(1,5) (43.9%, 75.6%)\u001b[0m\n",
            "[2024-04-02 20:53:03] \u001b[32mTrain: [  9/50] Step 240/520 Loss 2.902 Prec@(1,5) (44.0%, 75.7%)\u001b[0m\n",
            "[2024-04-02 20:53:03] \u001b[32mTrain: [  9/50] Step 260/520 Loss 2.902 Prec@(1,5) (44.0%, 75.6%)\u001b[0m\n",
            "[2024-04-02 20:53:04] \u001b[32mTrain: [  9/50] Step 280/520 Loss 2.907 Prec@(1,5) (43.9%, 75.5%)\u001b[0m\n",
            "[2024-04-02 20:53:04] \u001b[32mTrain: [  9/50] Step 300/520 Loss 2.907 Prec@(1,5) (43.9%, 75.6%)\u001b[0m\n",
            "[2024-04-02 20:53:05] \u001b[32mTrain: [  9/50] Step 320/520 Loss 2.905 Prec@(1,5) (44.0%, 75.5%)\u001b[0m\n",
            "[2024-04-02 20:53:05] \u001b[32mTrain: [  9/50] Step 340/520 Loss 2.903 Prec@(1,5) (44.0%, 75.6%)\u001b[0m\n",
            "[2024-04-02 20:53:06] \u001b[32mTrain: [  9/50] Step 360/520 Loss 2.910 Prec@(1,5) (43.9%, 75.4%)\u001b[0m\n",
            "[2024-04-02 20:53:06] \u001b[32mTrain: [  9/50] Step 380/520 Loss 2.909 Prec@(1,5) (43.9%, 75.4%)\u001b[0m\n",
            "[2024-04-02 20:53:07] \u001b[32mTrain: [  9/50] Step 400/520 Loss 2.907 Prec@(1,5) (44.0%, 75.4%)\u001b[0m\n",
            "[2024-04-02 20:53:07] \u001b[32mTrain: [  9/50] Step 420/520 Loss 2.905 Prec@(1,5) (44.0%, 75.4%)\u001b[0m\n",
            "[2024-04-02 20:53:08] \u001b[32mTrain: [  9/50] Step 440/520 Loss 2.905 Prec@(1,5) (44.0%, 75.4%)\u001b[0m\n",
            "[2024-04-02 20:53:08] \u001b[32mTrain: [  9/50] Step 460/520 Loss 2.908 Prec@(1,5) (44.0%, 75.3%)\u001b[0m\n",
            "[2024-04-02 20:53:09] \u001b[32mTrain: [  9/50] Step 480/520 Loss 2.903 Prec@(1,5) (44.1%, 75.4%)\u001b[0m\n",
            "[2024-04-02 20:53:09] \u001b[32mTrain: [  9/50] Step 500/520 Loss 2.905 Prec@(1,5) (44.1%, 75.4%)\u001b[0m\n",
            "[2024-04-02 20:53:10] \u001b[32mTrain: [  9/50] Step 520/520 Loss 2.904 Prec@(1,5) (44.1%, 75.4%)\u001b[0m\n",
            "[2024-04-02 20:53:10] \u001b[32mTrain: [  9/50] Final Prec@1 44.0920%\u001b[0m\n",
            "[2024-04-02 20:53:13] \u001b[32mValid: [  9/50] Step 000/104 Loss 2.981 Prec@(1,5) (44.8%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:53:14] \u001b[32mValid: [  9/50] Step 020/104 Loss 3.154 Prec@(1,5) (40.5%, 72.7%)\u001b[0m\n",
            "[2024-04-02 20:53:14] \u001b[32mValid: [  9/50] Step 040/104 Loss 3.099 Prec@(1,5) (40.5%, 72.8%)\u001b[0m\n",
            "[2024-04-02 20:53:14] \u001b[32mValid: [  9/50] Step 060/104 Loss 3.058 Prec@(1,5) (40.9%, 73.1%)\u001b[0m\n",
            "[2024-04-02 20:53:14] \u001b[32mValid: [  9/50] Step 080/104 Loss 3.066 Prec@(1,5) (40.4%, 72.9%)\u001b[0m\n",
            "[2024-04-02 20:53:14] \u001b[32mValid: [  9/50] Step 100/104 Loss 3.054 Prec@(1,5) (40.5%, 72.9%)\u001b[0m\n",
            "[2024-04-02 20:53:14] \u001b[32mValid: [  9/50] Step 104/104 Loss 3.056 Prec@(1,5) (40.4%, 72.9%)\u001b[0m\n",
            "[2024-04-02 20:53:15] \u001b[32mValid: [  9/50] Final Prec@1 40.4100%\u001b[0m\n",
            "[2024-04-02 20:53:15] \u001b[32mEpoch 9 LR 0.023054\u001b[0m\n",
            "[2024-04-02 20:53:19] \u001b[32mTrain: [ 10/50] Step 000/520 Loss 2.908 Prec@(1,5) (44.8%, 72.9%)\u001b[0m\n",
            "[2024-04-02 20:53:20] \u001b[32mTrain: [ 10/50] Step 020/520 Loss 2.787 Prec@(1,5) (45.2%, 77.4%)\u001b[0m\n",
            "[2024-04-02 20:53:20] \u001b[32mTrain: [ 10/50] Step 040/520 Loss 2.796 Prec@(1,5) (45.2%, 77.3%)\u001b[0m\n",
            "[2024-04-02 20:53:21] \u001b[32mTrain: [ 10/50] Step 060/520 Loss 2.796 Prec@(1,5) (45.5%, 77.1%)\u001b[0m\n",
            "[2024-04-02 20:53:21] \u001b[32mTrain: [ 10/50] Step 080/520 Loss 2.798 Prec@(1,5) (45.8%, 76.8%)\u001b[0m\n",
            "[2024-04-02 20:53:22] \u001b[32mTrain: [ 10/50] Step 100/520 Loss 2.806 Prec@(1,5) (45.7%, 76.6%)\u001b[0m\n",
            "[2024-04-02 20:53:22] \u001b[32mTrain: [ 10/50] Step 120/520 Loss 2.812 Prec@(1,5) (45.7%, 76.5%)\u001b[0m\n",
            "[2024-04-02 20:53:23] \u001b[32mTrain: [ 10/50] Step 140/520 Loss 2.806 Prec@(1,5) (45.7%, 76.8%)\u001b[0m\n",
            "[2024-04-02 20:53:23] \u001b[32mTrain: [ 10/50] Step 160/520 Loss 2.804 Prec@(1,5) (45.5%, 76.8%)\u001b[0m\n",
            "[2024-04-02 20:53:24] \u001b[32mTrain: [ 10/50] Step 180/520 Loss 2.807 Prec@(1,5) (45.6%, 76.8%)\u001b[0m\n",
            "[2024-04-02 20:53:24] \u001b[32mTrain: [ 10/50] Step 200/520 Loss 2.807 Prec@(1,5) (45.6%, 76.8%)\u001b[0m\n",
            "[2024-04-02 20:53:25] \u001b[32mTrain: [ 10/50] Step 220/520 Loss 2.805 Prec@(1,5) (45.6%, 76.7%)\u001b[0m\n",
            "[2024-04-02 20:53:25] \u001b[32mTrain: [ 10/50] Step 240/520 Loss 2.809 Prec@(1,5) (45.5%, 76.7%)\u001b[0m\n",
            "[2024-04-02 20:53:26] \u001b[32mTrain: [ 10/50] Step 260/520 Loss 2.804 Prec@(1,5) (45.8%, 76.8%)\u001b[0m\n",
            "[2024-04-02 20:53:26] \u001b[32mTrain: [ 10/50] Step 280/520 Loss 2.805 Prec@(1,5) (45.8%, 76.8%)\u001b[0m\n",
            "[2024-04-02 20:53:27] \u001b[32mTrain: [ 10/50] Step 300/520 Loss 2.804 Prec@(1,5) (45.8%, 76.8%)\u001b[0m\n",
            "[2024-04-02 20:53:27] \u001b[32mTrain: [ 10/50] Step 320/520 Loss 2.803 Prec@(1,5) (45.8%, 76.8%)\u001b[0m\n",
            "[2024-04-02 20:53:28] \u001b[32mTrain: [ 10/50] Step 340/520 Loss 2.802 Prec@(1,5) (45.8%, 76.8%)\u001b[0m\n",
            "[2024-04-02 20:53:28] \u001b[32mTrain: [ 10/50] Step 360/520 Loss 2.805 Prec@(1,5) (45.7%, 76.8%)\u001b[0m\n",
            "[2024-04-02 20:53:29] \u001b[32mTrain: [ 10/50] Step 380/520 Loss 2.812 Prec@(1,5) (45.6%, 76.6%)\u001b[0m\n",
            "[2024-04-02 20:53:29] \u001b[32mTrain: [ 10/50] Step 400/520 Loss 2.811 Prec@(1,5) (45.6%, 76.7%)\u001b[0m\n",
            "[2024-04-02 20:53:30] \u001b[32mTrain: [ 10/50] Step 420/520 Loss 2.809 Prec@(1,5) (45.7%, 76.7%)\u001b[0m\n",
            "[2024-04-02 20:53:30] \u001b[32mTrain: [ 10/50] Step 440/520 Loss 2.806 Prec@(1,5) (45.7%, 76.8%)\u001b[0m\n",
            "[2024-04-02 20:53:31] \u001b[32mTrain: [ 10/50] Step 460/520 Loss 2.805 Prec@(1,5) (45.7%, 76.8%)\u001b[0m\n",
            "[2024-04-02 20:53:31] \u001b[32mTrain: [ 10/50] Step 480/520 Loss 2.803 Prec@(1,5) (45.7%, 76.9%)\u001b[0m\n",
            "[2024-04-02 20:53:32] \u001b[32mTrain: [ 10/50] Step 500/520 Loss 2.805 Prec@(1,5) (45.7%, 76.8%)\u001b[0m\n",
            "[2024-04-02 20:53:32] \u001b[32mTrain: [ 10/50] Step 520/520 Loss 2.803 Prec@(1,5) (45.7%, 76.9%)\u001b[0m\n",
            "[2024-04-02 20:53:33] \u001b[32mTrain: [ 10/50] Final Prec@1 45.7300%\u001b[0m\n",
            "[2024-04-02 20:53:36] \u001b[32mValid: [ 10/50] Step 000/104 Loss 2.753 Prec@(1,5) (45.8%, 74.0%)\u001b[0m\n",
            "[2024-04-02 20:53:36] \u001b[32mValid: [ 10/50] Step 020/104 Loss 2.833 Prec@(1,5) (43.2%, 75.3%)\u001b[0m\n",
            "[2024-04-02 20:53:36] \u001b[32mValid: [ 10/50] Step 040/104 Loss 2.817 Prec@(1,5) (43.1%, 75.2%)\u001b[0m\n",
            "[2024-04-02 20:53:37] \u001b[32mValid: [ 10/50] Step 060/104 Loss 2.789 Prec@(1,5) (43.6%, 75.3%)\u001b[0m\n",
            "[2024-04-02 20:53:37] \u001b[32mValid: [ 10/50] Step 080/104 Loss 2.812 Prec@(1,5) (43.2%, 75.1%)\u001b[0m\n",
            "[2024-04-02 20:53:37] \u001b[32mValid: [ 10/50] Step 100/104 Loss 2.794 Prec@(1,5) (43.3%, 75.3%)\u001b[0m\n",
            "[2024-04-02 20:53:37] \u001b[32mValid: [ 10/50] Step 104/104 Loss 2.792 Prec@(1,5) (43.3%, 75.2%)\u001b[0m\n",
            "[2024-04-02 20:53:37] \u001b[32mValid: [ 10/50] Final Prec@1 43.2800%\u001b[0m\n",
            "[2024-04-02 20:53:37] \u001b[32mEpoch 10 LR 0.022613\u001b[0m\n",
            "[2024-04-02 20:53:42] \u001b[32mTrain: [ 11/50] Step 000/520 Loss 2.806 Prec@(1,5) (41.7%, 79.2%)\u001b[0m\n",
            "[2024-04-02 20:53:42] \u001b[32mTrain: [ 11/50] Step 020/520 Loss 2.668 Prec@(1,5) (47.5%, 79.0%)\u001b[0m\n",
            "[2024-04-02 20:53:43] \u001b[32mTrain: [ 11/50] Step 040/520 Loss 2.646 Prec@(1,5) (48.6%, 79.1%)\u001b[0m\n",
            "[2024-04-02 20:53:43] \u001b[32mTrain: [ 11/50] Step 060/520 Loss 2.680 Prec@(1,5) (47.7%, 78.4%)\u001b[0m\n",
            "[2024-04-02 20:53:44] \u001b[32mTrain: [ 11/50] Step 080/520 Loss 2.669 Prec@(1,5) (48.1%, 78.8%)\u001b[0m\n",
            "[2024-04-02 20:53:44] \u001b[32mTrain: [ 11/50] Step 100/520 Loss 2.688 Prec@(1,5) (47.8%, 78.5%)\u001b[0m\n",
            "[2024-04-02 20:53:45] \u001b[32mTrain: [ 11/50] Step 120/520 Loss 2.701 Prec@(1,5) (47.7%, 78.3%)\u001b[0m\n",
            "[2024-04-02 20:53:45] \u001b[32mTrain: [ 11/50] Step 140/520 Loss 2.701 Prec@(1,5) (47.6%, 78.4%)\u001b[0m\n",
            "[2024-04-02 20:53:46] \u001b[32mTrain: [ 11/50] Step 160/520 Loss 2.711 Prec@(1,5) (47.1%, 78.3%)\u001b[0m\n",
            "[2024-04-02 20:53:46] \u001b[32mTrain: [ 11/50] Step 180/520 Loss 2.713 Prec@(1,5) (47.1%, 78.2%)\u001b[0m\n",
            "[2024-04-02 20:53:47] \u001b[32mTrain: [ 11/50] Step 200/520 Loss 2.712 Prec@(1,5) (47.2%, 78.1%)\u001b[0m\n",
            "[2024-04-02 20:53:47] \u001b[32mTrain: [ 11/50] Step 220/520 Loss 2.717 Prec@(1,5) (47.2%, 77.9%)\u001b[0m\n",
            "[2024-04-02 20:53:48] \u001b[32mTrain: [ 11/50] Step 240/520 Loss 2.727 Prec@(1,5) (46.9%, 77.8%)\u001b[0m\n",
            "[2024-04-02 20:53:48] \u001b[32mTrain: [ 11/50] Step 260/520 Loss 2.730 Prec@(1,5) (46.9%, 77.8%)\u001b[0m\n",
            "[2024-04-02 20:53:49] \u001b[32mTrain: [ 11/50] Step 280/520 Loss 2.734 Prec@(1,5) (46.8%, 77.7%)\u001b[0m\n",
            "[2024-04-02 20:53:49] \u001b[32mTrain: [ 11/50] Step 300/520 Loss 2.734 Prec@(1,5) (46.7%, 77.7%)\u001b[0m\n",
            "[2024-04-02 20:53:50] \u001b[32mTrain: [ 11/50] Step 320/520 Loss 2.732 Prec@(1,5) (46.7%, 77.8%)\u001b[0m\n",
            "[2024-04-02 20:53:50] \u001b[32mTrain: [ 11/50] Step 340/520 Loss 2.730 Prec@(1,5) (46.8%, 77.8%)\u001b[0m\n",
            "[2024-04-02 20:53:51] \u001b[32mTrain: [ 11/50] Step 360/520 Loss 2.729 Prec@(1,5) (46.8%, 77.8%)\u001b[0m\n",
            "[2024-04-02 20:53:51] \u001b[32mTrain: [ 11/50] Step 380/520 Loss 2.723 Prec@(1,5) (46.8%, 77.9%)\u001b[0m\n",
            "[2024-04-02 20:53:51] \u001b[32mTrain: [ 11/50] Step 400/520 Loss 2.722 Prec@(1,5) (46.8%, 78.0%)\u001b[0m\n",
            "[2024-04-02 20:53:52] \u001b[32mTrain: [ 11/50] Step 420/520 Loss 2.726 Prec@(1,5) (46.8%, 77.9%)\u001b[0m\n",
            "[2024-04-02 20:53:52] \u001b[32mTrain: [ 11/50] Step 440/520 Loss 2.727 Prec@(1,5) (46.9%, 77.9%)\u001b[0m\n",
            "[2024-04-02 20:53:53] \u001b[32mTrain: [ 11/50] Step 460/520 Loss 2.728 Prec@(1,5) (46.9%, 77.9%)\u001b[0m\n",
            "[2024-04-02 20:53:53] \u001b[32mTrain: [ 11/50] Step 480/520 Loss 2.727 Prec@(1,5) (46.9%, 77.9%)\u001b[0m\n",
            "[2024-04-02 20:53:54] \u001b[32mTrain: [ 11/50] Step 500/520 Loss 2.729 Prec@(1,5) (46.9%, 77.8%)\u001b[0m\n",
            "[2024-04-02 20:53:54] \u001b[32mTrain: [ 11/50] Step 520/520 Loss 2.726 Prec@(1,5) (46.9%, 77.9%)\u001b[0m\n",
            "[2024-04-02 20:53:55] \u001b[32mTrain: [ 11/50] Final Prec@1 46.9460%\u001b[0m\n",
            "[2024-04-02 20:53:58] \u001b[32mValid: [ 11/50] Step 000/104 Loss 2.977 Prec@(1,5) (49.0%, 76.0%)\u001b[0m\n",
            "[2024-04-02 20:53:58] \u001b[32mValid: [ 11/50] Step 020/104 Loss 3.338 Prec@(1,5) (40.5%, 72.4%)\u001b[0m\n",
            "[2024-04-02 20:53:58] \u001b[32mValid: [ 11/50] Step 040/104 Loss 3.287 Prec@(1,5) (40.1%, 72.1%)\u001b[0m\n",
            "[2024-04-02 20:53:59] \u001b[32mValid: [ 11/50] Step 060/104 Loss 3.239 Prec@(1,5) (40.6%, 71.9%)\u001b[0m\n",
            "[2024-04-02 20:53:59] \u001b[32mValid: [ 11/50] Step 080/104 Loss 3.241 Prec@(1,5) (40.1%, 72.0%)\u001b[0m\n",
            "[2024-04-02 20:53:59] \u001b[32mValid: [ 11/50] Step 100/104 Loss 3.231 Prec@(1,5) (40.0%, 72.2%)\u001b[0m\n",
            "[2024-04-02 20:53:59] \u001b[32mValid: [ 11/50] Step 104/104 Loss 3.233 Prec@(1,5) (40.0%, 72.2%)\u001b[0m\n",
            "[2024-04-02 20:53:59] \u001b[32mValid: [ 11/50] Final Prec@1 39.9600%\u001b[0m\n",
            "[2024-04-02 20:53:59] \u001b[32mEpoch 11 LR 0.022132\u001b[0m\n",
            "[2024-04-02 20:54:04] \u001b[32mTrain: [ 12/50] Step 000/520 Loss 2.646 Prec@(1,5) (52.1%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:54:04] \u001b[32mTrain: [ 12/50] Step 020/520 Loss 2.649 Prec@(1,5) (49.0%, 79.5%)\u001b[0m\n",
            "[2024-04-02 20:54:05] \u001b[32mTrain: [ 12/50] Step 040/520 Loss 2.646 Prec@(1,5) (48.1%, 79.7%)\u001b[0m\n",
            "[2024-04-02 20:54:05] \u001b[32mTrain: [ 12/50] Step 060/520 Loss 2.659 Prec@(1,5) (47.4%, 79.0%)\u001b[0m\n",
            "[2024-04-02 20:54:06] \u001b[32mTrain: [ 12/50] Step 080/520 Loss 2.645 Prec@(1,5) (47.9%, 79.2%)\u001b[0m\n",
            "[2024-04-02 20:54:06] \u001b[32mTrain: [ 12/50] Step 100/520 Loss 2.665 Prec@(1,5) (47.5%, 78.8%)\u001b[0m\n",
            "[2024-04-02 20:54:07] \u001b[32mTrain: [ 12/50] Step 120/520 Loss 2.671 Prec@(1,5) (47.5%, 78.8%)\u001b[0m\n",
            "[2024-04-02 20:54:07] \u001b[32mTrain: [ 12/50] Step 140/520 Loss 2.678 Prec@(1,5) (47.6%, 78.6%)\u001b[0m\n",
            "[2024-04-02 20:54:08] \u001b[32mTrain: [ 12/50] Step 160/520 Loss 2.672 Prec@(1,5) (47.6%, 78.7%)\u001b[0m\n",
            "[2024-04-02 20:54:08] \u001b[32mTrain: [ 12/50] Step 180/520 Loss 2.677 Prec@(1,5) (47.5%, 78.6%)\u001b[0m\n",
            "[2024-04-02 20:54:09] \u001b[32mTrain: [ 12/50] Step 200/520 Loss 2.677 Prec@(1,5) (47.5%, 78.6%)\u001b[0m\n",
            "[2024-04-02 20:54:09] \u001b[32mTrain: [ 12/50] Step 220/520 Loss 2.670 Prec@(1,5) (47.7%, 78.7%)\u001b[0m\n",
            "[2024-04-02 20:54:10] \u001b[32mTrain: [ 12/50] Step 240/520 Loss 2.671 Prec@(1,5) (47.7%, 78.7%)\u001b[0m\n",
            "[2024-04-02 20:54:10] \u001b[32mTrain: [ 12/50] Step 260/520 Loss 2.671 Prec@(1,5) (47.8%, 78.6%)\u001b[0m\n",
            "[2024-04-02 20:54:11] \u001b[32mTrain: [ 12/50] Step 280/520 Loss 2.665 Prec@(1,5) (47.8%, 78.7%)\u001b[0m\n",
            "[2024-04-02 20:54:11] \u001b[32mTrain: [ 12/50] Step 300/520 Loss 2.665 Prec@(1,5) (47.8%, 78.8%)\u001b[0m\n",
            "[2024-04-02 20:54:12] \u001b[32mTrain: [ 12/50] Step 320/520 Loss 2.660 Prec@(1,5) (47.9%, 78.9%)\u001b[0m\n",
            "[2024-04-02 20:54:12] \u001b[32mTrain: [ 12/50] Step 340/520 Loss 2.657 Prec@(1,5) (47.9%, 78.9%)\u001b[0m\n",
            "[2024-04-02 20:54:13] \u001b[32mTrain: [ 12/50] Step 360/520 Loss 2.657 Prec@(1,5) (47.9%, 78.9%)\u001b[0m\n",
            "[2024-04-02 20:54:13] \u001b[32mTrain: [ 12/50] Step 380/520 Loss 2.659 Prec@(1,5) (47.8%, 78.8%)\u001b[0m\n",
            "[2024-04-02 20:54:14] \u001b[32mTrain: [ 12/50] Step 400/520 Loss 2.657 Prec@(1,5) (47.9%, 78.8%)\u001b[0m\n",
            "[2024-04-02 20:54:14] \u001b[32mTrain: [ 12/50] Step 420/520 Loss 2.658 Prec@(1,5) (47.8%, 78.8%)\u001b[0m\n",
            "[2024-04-02 20:54:15] \u001b[32mTrain: [ 12/50] Step 440/520 Loss 2.659 Prec@(1,5) (47.8%, 78.7%)\u001b[0m\n",
            "[2024-04-02 20:54:15] \u001b[32mTrain: [ 12/50] Step 460/520 Loss 2.659 Prec@(1,5) (47.9%, 78.7%)\u001b[0m\n",
            "[2024-04-02 20:54:16] \u001b[32mTrain: [ 12/50] Step 480/520 Loss 2.657 Prec@(1,5) (48.0%, 78.8%)\u001b[0m\n",
            "[2024-04-02 20:54:16] \u001b[32mTrain: [ 12/50] Step 500/520 Loss 2.659 Prec@(1,5) (47.9%, 78.8%)\u001b[0m\n",
            "[2024-04-02 20:54:17] \u001b[32mTrain: [ 12/50] Step 520/520 Loss 2.659 Prec@(1,5) (47.9%, 78.8%)\u001b[0m\n",
            "[2024-04-02 20:54:17] \u001b[32mTrain: [ 12/50] Final Prec@1 47.8960%\u001b[0m\n",
            "[2024-04-02 20:54:21] \u001b[32mValid: [ 12/50] Step 000/104 Loss 2.937 Prec@(1,5) (45.8%, 78.1%)\u001b[0m\n",
            "[2024-04-02 20:54:21] \u001b[32mValid: [ 12/50] Step 020/104 Loss 3.120 Prec@(1,5) (42.4%, 73.8%)\u001b[0m\n",
            "[2024-04-02 20:54:21] \u001b[32mValid: [ 12/50] Step 040/104 Loss 3.080 Prec@(1,5) (42.1%, 74.1%)\u001b[0m\n",
            "[2024-04-02 20:54:21] \u001b[32mValid: [ 12/50] Step 060/104 Loss 3.072 Prec@(1,5) (42.0%, 74.2%)\u001b[0m\n",
            "[2024-04-02 20:54:21] \u001b[32mValid: [ 12/50] Step 080/104 Loss 3.090 Prec@(1,5) (41.8%, 74.2%)\u001b[0m\n",
            "[2024-04-02 20:54:22] \u001b[32mValid: [ 12/50] Step 100/104 Loss 3.078 Prec@(1,5) (42.0%, 74.2%)\u001b[0m\n",
            "[2024-04-02 20:54:22] \u001b[32mValid: [ 12/50] Step 104/104 Loss 3.080 Prec@(1,5) (42.0%, 74.2%)\u001b[0m\n",
            "[2024-04-02 20:54:22] \u001b[32mValid: [ 12/50] Final Prec@1 41.9500%\u001b[0m\n",
            "[2024-04-02 20:54:22] \u001b[32mEpoch 12 LR 0.021612\u001b[0m\n",
            "[2024-04-02 20:54:26] \u001b[32mTrain: [ 13/50] Step 000/520 Loss 2.986 Prec@(1,5) (43.8%, 72.9%)\u001b[0m\n",
            "[2024-04-02 20:54:27] \u001b[32mTrain: [ 13/50] Step 020/520 Loss 2.539 Prec@(1,5) (50.0%, 80.1%)\u001b[0m\n",
            "[2024-04-02 20:54:27] \u001b[32mTrain: [ 13/50] Step 040/520 Loss 2.561 Prec@(1,5) (49.9%, 80.3%)\u001b[0m\n",
            "[2024-04-02 20:54:28] \u001b[32mTrain: [ 13/50] Step 060/520 Loss 2.556 Prec@(1,5) (49.8%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:54:28] \u001b[32mTrain: [ 13/50] Step 080/520 Loss 2.546 Prec@(1,5) (50.2%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:54:29] \u001b[32mTrain: [ 13/50] Step 100/520 Loss 2.560 Prec@(1,5) (49.9%, 80.3%)\u001b[0m\n",
            "[2024-04-02 20:54:29] \u001b[32mTrain: [ 13/50] Step 120/520 Loss 2.579 Prec@(1,5) (49.6%, 80.0%)\u001b[0m\n",
            "[2024-04-02 20:54:30] \u001b[32mTrain: [ 13/50] Step 140/520 Loss 2.582 Prec@(1,5) (49.5%, 80.0%)\u001b[0m\n",
            "[2024-04-02 20:54:30] \u001b[32mTrain: [ 13/50] Step 160/520 Loss 2.585 Prec@(1,5) (49.6%, 79.9%)\u001b[0m\n",
            "[2024-04-02 20:54:31] \u001b[32mTrain: [ 13/50] Step 180/520 Loss 2.590 Prec@(1,5) (49.4%, 79.9%)\u001b[0m\n",
            "[2024-04-02 20:54:31] \u001b[32mTrain: [ 13/50] Step 200/520 Loss 2.592 Prec@(1,5) (49.2%, 79.8%)\u001b[0m\n",
            "[2024-04-02 20:54:32] \u001b[32mTrain: [ 13/50] Step 220/520 Loss 2.594 Prec@(1,5) (49.2%, 79.8%)\u001b[0m\n",
            "[2024-04-02 20:54:32] \u001b[32mTrain: [ 13/50] Step 240/520 Loss 2.597 Prec@(1,5) (49.3%, 79.8%)\u001b[0m\n",
            "[2024-04-02 20:54:33] \u001b[32mTrain: [ 13/50] Step 260/520 Loss 2.595 Prec@(1,5) (49.3%, 79.7%)\u001b[0m\n",
            "[2024-04-02 20:54:33] \u001b[32mTrain: [ 13/50] Step 280/520 Loss 2.599 Prec@(1,5) (49.3%, 79.7%)\u001b[0m\n",
            "[2024-04-02 20:54:34] \u001b[32mTrain: [ 13/50] Step 300/520 Loss 2.600 Prec@(1,5) (49.2%, 79.6%)\u001b[0m\n",
            "[2024-04-02 20:54:34] \u001b[32mTrain: [ 13/50] Step 320/520 Loss 2.596 Prec@(1,5) (49.2%, 79.6%)\u001b[0m\n",
            "[2024-04-02 20:54:35] \u001b[32mTrain: [ 13/50] Step 340/520 Loss 2.599 Prec@(1,5) (49.2%, 79.6%)\u001b[0m\n",
            "[2024-04-02 20:54:35] \u001b[32mTrain: [ 13/50] Step 360/520 Loss 2.604 Prec@(1,5) (49.0%, 79.5%)\u001b[0m\n",
            "[2024-04-02 20:54:36] \u001b[32mTrain: [ 13/50] Step 380/520 Loss 2.605 Prec@(1,5) (49.0%, 79.5%)\u001b[0m\n",
            "[2024-04-02 20:54:36] \u001b[32mTrain: [ 13/50] Step 400/520 Loss 2.608 Prec@(1,5) (48.9%, 79.4%)\u001b[0m\n",
            "[2024-04-02 20:54:37] \u001b[32mTrain: [ 13/50] Step 420/520 Loss 2.608 Prec@(1,5) (49.0%, 79.4%)\u001b[0m\n",
            "[2024-04-02 20:54:37] \u001b[32mTrain: [ 13/50] Step 440/520 Loss 2.610 Prec@(1,5) (48.9%, 79.4%)\u001b[0m\n",
            "[2024-04-02 20:54:38] \u001b[32mTrain: [ 13/50] Step 460/520 Loss 2.610 Prec@(1,5) (49.0%, 79.4%)\u001b[0m\n",
            "[2024-04-02 20:54:38] \u001b[32mTrain: [ 13/50] Step 480/520 Loss 2.611 Prec@(1,5) (49.0%, 79.4%)\u001b[0m\n",
            "[2024-04-02 20:54:39] \u001b[32mTrain: [ 13/50] Step 500/520 Loss 2.612 Prec@(1,5) (49.0%, 79.4%)\u001b[0m\n",
            "[2024-04-02 20:54:39] \u001b[32mTrain: [ 13/50] Step 520/520 Loss 2.610 Prec@(1,5) (49.0%, 79.4%)\u001b[0m\n",
            "[2024-04-02 20:54:39] \u001b[32mTrain: [ 13/50] Final Prec@1 49.0220%\u001b[0m\n",
            "[2024-04-02 20:54:43] \u001b[32mValid: [ 13/50] Step 000/104 Loss 2.844 Prec@(1,5) (49.0%, 76.0%)\u001b[0m\n",
            "[2024-04-02 20:54:43] \u001b[32mValid: [ 13/50] Step 020/104 Loss 2.774 Prec@(1,5) (47.2%, 76.7%)\u001b[0m\n",
            "[2024-04-02 20:54:43] \u001b[32mValid: [ 13/50] Step 040/104 Loss 2.753 Prec@(1,5) (45.9%, 76.9%)\u001b[0m\n",
            "[2024-04-02 20:54:43] \u001b[32mValid: [ 13/50] Step 060/104 Loss 2.738 Prec@(1,5) (46.4%, 76.6%)\u001b[0m\n",
            "[2024-04-02 20:54:44] \u001b[32mValid: [ 13/50] Step 080/104 Loss 2.748 Prec@(1,5) (45.9%, 77.0%)\u001b[0m\n",
            "[2024-04-02 20:54:44] \u001b[32mValid: [ 13/50] Step 100/104 Loss 2.731 Prec@(1,5) (45.7%, 76.9%)\u001b[0m\n",
            "[2024-04-02 20:54:44] \u001b[32mValid: [ 13/50] Step 104/104 Loss 2.728 Prec@(1,5) (45.8%, 76.9%)\u001b[0m\n",
            "[2024-04-02 20:54:44] \u001b[32mValid: [ 13/50] Final Prec@1 45.8000%\u001b[0m\n",
            "[2024-04-02 20:54:44] \u001b[32mEpoch 13 LR 0.021057\u001b[0m\n",
            "[2024-04-02 20:54:49] \u001b[32mTrain: [ 14/50] Step 000/520 Loss 2.619 Prec@(1,5) (53.1%, 78.1%)\u001b[0m\n",
            "[2024-04-02 20:54:49] \u001b[32mTrain: [ 14/50] Step 020/520 Loss 2.438 Prec@(1,5) (53.4%, 81.5%)\u001b[0m\n",
            "[2024-04-02 20:54:50] \u001b[32mTrain: [ 14/50] Step 040/520 Loss 2.482 Prec@(1,5) (52.1%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:54:50] \u001b[32mTrain: [ 14/50] Step 060/520 Loss 2.510 Prec@(1,5) (51.1%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:54:51] \u001b[32mTrain: [ 14/50] Step 080/520 Loss 2.499 Prec@(1,5) (51.3%, 80.7%)\u001b[0m\n",
            "[2024-04-02 20:54:51] \u001b[32mTrain: [ 14/50] Step 100/520 Loss 2.503 Prec@(1,5) (51.4%, 80.7%)\u001b[0m\n",
            "[2024-04-02 20:54:52] \u001b[32mTrain: [ 14/50] Step 120/520 Loss 2.511 Prec@(1,5) (51.1%, 80.6%)\u001b[0m\n",
            "[2024-04-02 20:54:52] \u001b[32mTrain: [ 14/50] Step 140/520 Loss 2.514 Prec@(1,5) (50.9%, 80.6%)\u001b[0m\n",
            "[2024-04-02 20:54:52] \u001b[32mTrain: [ 14/50] Step 160/520 Loss 2.524 Prec@(1,5) (50.7%, 80.4%)\u001b[0m\n",
            "[2024-04-02 20:54:53] \u001b[32mTrain: [ 14/50] Step 180/520 Loss 2.531 Prec@(1,5) (50.5%, 80.3%)\u001b[0m\n",
            "[2024-04-02 20:54:53] \u001b[32mTrain: [ 14/50] Step 200/520 Loss 2.534 Prec@(1,5) (50.4%, 80.3%)\u001b[0m\n",
            "[2024-04-02 20:54:54] \u001b[32mTrain: [ 14/50] Step 220/520 Loss 2.537 Prec@(1,5) (50.4%, 80.2%)\u001b[0m\n",
            "[2024-04-02 20:54:54] \u001b[32mTrain: [ 14/50] Step 240/520 Loss 2.536 Prec@(1,5) (50.4%, 80.2%)\u001b[0m\n",
            "[2024-04-02 20:54:55] \u001b[32mTrain: [ 14/50] Step 260/520 Loss 2.539 Prec@(1,5) (50.3%, 80.1%)\u001b[0m\n",
            "[2024-04-02 20:54:55] \u001b[32mTrain: [ 14/50] Step 280/520 Loss 2.543 Prec@(1,5) (50.2%, 80.1%)\u001b[0m\n",
            "[2024-04-02 20:54:56] \u001b[32mTrain: [ 14/50] Step 300/520 Loss 2.541 Prec@(1,5) (50.2%, 80.1%)\u001b[0m\n",
            "[2024-04-02 20:54:56] \u001b[32mTrain: [ 14/50] Step 320/520 Loss 2.543 Prec@(1,5) (50.2%, 80.1%)\u001b[0m\n",
            "[2024-04-02 20:54:57] \u001b[32mTrain: [ 14/50] Step 340/520 Loss 2.544 Prec@(1,5) (50.2%, 80.1%)\u001b[0m\n",
            "[2024-04-02 20:54:57] \u001b[32mTrain: [ 14/50] Step 360/520 Loss 2.543 Prec@(1,5) (50.2%, 80.1%)\u001b[0m\n",
            "[2024-04-02 20:54:58] \u001b[32mTrain: [ 14/50] Step 380/520 Loss 2.549 Prec@(1,5) (50.1%, 80.0%)\u001b[0m\n",
            "[2024-04-02 20:54:58] \u001b[32mTrain: [ 14/50] Step 400/520 Loss 2.550 Prec@(1,5) (50.1%, 79.9%)\u001b[0m\n",
            "[2024-04-02 20:54:59] \u001b[32mTrain: [ 14/50] Step 420/520 Loss 2.549 Prec@(1,5) (50.2%, 80.0%)\u001b[0m\n",
            "[2024-04-02 20:54:59] \u001b[32mTrain: [ 14/50] Step 440/520 Loss 2.553 Prec@(1,5) (50.1%, 79.9%)\u001b[0m\n",
            "[2024-04-02 20:55:00] \u001b[32mTrain: [ 14/50] Step 460/520 Loss 2.551 Prec@(1,5) (50.1%, 80.0%)\u001b[0m\n",
            "[2024-04-02 20:55:00] \u001b[32mTrain: [ 14/50] Step 480/520 Loss 2.551 Prec@(1,5) (50.1%, 80.0%)\u001b[0m\n",
            "[2024-04-02 20:55:01] \u001b[32mTrain: [ 14/50] Step 500/520 Loss 2.552 Prec@(1,5) (50.1%, 79.9%)\u001b[0m\n",
            "[2024-04-02 20:55:01] \u001b[32mTrain: [ 14/50] Step 520/520 Loss 2.552 Prec@(1,5) (50.1%, 80.0%)\u001b[0m\n",
            "[2024-04-02 20:55:02] \u001b[32mTrain: [ 14/50] Final Prec@1 50.0780%\u001b[0m\n",
            "[2024-04-02 20:55:05] \u001b[32mValid: [ 14/50] Step 000/104 Loss 2.706 Prec@(1,5) (50.0%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:55:05] \u001b[32mValid: [ 14/50] Step 020/104 Loss 2.878 Prec@(1,5) (45.9%, 77.0%)\u001b[0m\n",
            "[2024-04-02 20:55:05] \u001b[32mValid: [ 14/50] Step 040/104 Loss 2.841 Prec@(1,5) (45.7%, 77.3%)\u001b[0m\n",
            "[2024-04-02 20:55:06] \u001b[32mValid: [ 14/50] Step 060/104 Loss 2.809 Prec@(1,5) (45.9%, 77.5%)\u001b[0m\n",
            "[2024-04-02 20:55:06] \u001b[32mValid: [ 14/50] Step 080/104 Loss 2.830 Prec@(1,5) (45.4%, 77.4%)\u001b[0m\n",
            "[2024-04-02 20:55:06] \u001b[32mValid: [ 14/50] Step 100/104 Loss 2.827 Prec@(1,5) (45.5%, 77.4%)\u001b[0m\n",
            "[2024-04-02 20:55:06] \u001b[32mValid: [ 14/50] Step 104/104 Loss 2.829 Prec@(1,5) (45.4%, 77.4%)\u001b[0m\n",
            "[2024-04-02 20:55:06] \u001b[32mValid: [ 14/50] Final Prec@1 45.3800%\u001b[0m\n",
            "[2024-04-02 20:55:06] \u001b[32mEpoch 14 LR 0.020468\u001b[0m\n",
            "[2024-04-02 20:55:11] \u001b[32mTrain: [ 15/50] Step 000/520 Loss 2.111 Prec@(1,5) (55.2%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:55:11] \u001b[32mTrain: [ 15/50] Step 020/520 Loss 2.478 Prec@(1,5) (50.8%, 81.1%)\u001b[0m\n",
            "[2024-04-02 20:55:12] \u001b[32mTrain: [ 15/50] Step 040/520 Loss 2.502 Prec@(1,5) (51.2%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:55:12] \u001b[32mTrain: [ 15/50] Step 060/520 Loss 2.496 Prec@(1,5) (51.0%, 80.7%)\u001b[0m\n",
            "[2024-04-02 20:55:13] \u001b[32mTrain: [ 15/50] Step 080/520 Loss 2.493 Prec@(1,5) (51.3%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:55:13] \u001b[32mTrain: [ 15/50] Step 100/520 Loss 2.504 Prec@(1,5) (51.0%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:55:14] \u001b[32mTrain: [ 15/50] Step 120/520 Loss 2.511 Prec@(1,5) (51.0%, 80.7%)\u001b[0m\n",
            "[2024-04-02 20:55:14] \u001b[32mTrain: [ 15/50] Step 140/520 Loss 2.510 Prec@(1,5) (51.0%, 80.7%)\u001b[0m\n",
            "[2024-04-02 20:55:15] \u001b[32mTrain: [ 15/50] Step 160/520 Loss 2.514 Prec@(1,5) (50.8%, 80.6%)\u001b[0m\n",
            "[2024-04-02 20:55:15] \u001b[32mTrain: [ 15/50] Step 180/520 Loss 2.516 Prec@(1,5) (50.9%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:55:16] \u001b[32mTrain: [ 15/50] Step 200/520 Loss 2.517 Prec@(1,5) (50.9%, 80.4%)\u001b[0m\n",
            "[2024-04-02 20:55:16] \u001b[32mTrain: [ 15/50] Step 220/520 Loss 2.519 Prec@(1,5) (50.8%, 80.4%)\u001b[0m\n",
            "[2024-04-02 20:55:17] \u001b[32mTrain: [ 15/50] Step 240/520 Loss 2.522 Prec@(1,5) (50.7%, 80.3%)\u001b[0m\n",
            "[2024-04-02 20:55:17] \u001b[32mTrain: [ 15/50] Step 260/520 Loss 2.525 Prec@(1,5) (50.7%, 80.3%)\u001b[0m\n",
            "[2024-04-02 20:55:18] \u001b[32mTrain: [ 15/50] Step 280/520 Loss 2.527 Prec@(1,5) (50.6%, 80.3%)\u001b[0m\n",
            "[2024-04-02 20:55:18] \u001b[32mTrain: [ 15/50] Step 300/520 Loss 2.525 Prec@(1,5) (50.7%, 80.2%)\u001b[0m\n",
            "[2024-04-02 20:55:19] \u001b[32mTrain: [ 15/50] Step 320/520 Loss 2.526 Prec@(1,5) (50.8%, 80.2%)\u001b[0m\n",
            "[2024-04-02 20:55:19] \u001b[32mTrain: [ 15/50] Step 340/520 Loss 2.524 Prec@(1,5) (50.8%, 80.3%)\u001b[0m\n",
            "[2024-04-02 20:55:20] \u001b[32mTrain: [ 15/50] Step 360/520 Loss 2.521 Prec@(1,5) (50.8%, 80.3%)\u001b[0m\n",
            "[2024-04-02 20:55:20] \u001b[32mTrain: [ 15/50] Step 380/520 Loss 2.519 Prec@(1,5) (50.8%, 80.4%)\u001b[0m\n",
            "[2024-04-02 20:55:21] \u001b[32mTrain: [ 15/50] Step 400/520 Loss 2.518 Prec@(1,5) (50.7%, 80.4%)\u001b[0m\n",
            "[2024-04-02 20:55:21] \u001b[32mTrain: [ 15/50] Step 420/520 Loss 2.518 Prec@(1,5) (50.7%, 80.4%)\u001b[0m\n",
            "[2024-04-02 20:55:22] \u001b[32mTrain: [ 15/50] Step 440/520 Loss 2.516 Prec@(1,5) (50.8%, 80.4%)\u001b[0m\n",
            "[2024-04-02 20:55:22] \u001b[32mTrain: [ 15/50] Step 460/520 Loss 2.512 Prec@(1,5) (50.9%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:55:23] \u001b[32mTrain: [ 15/50] Step 480/520 Loss 2.510 Prec@(1,5) (50.9%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:55:23] \u001b[32mTrain: [ 15/50] Step 500/520 Loss 2.506 Prec@(1,5) (50.9%, 80.6%)\u001b[0m\n",
            "[2024-04-02 20:55:24] \u001b[32mTrain: [ 15/50] Step 520/520 Loss 2.504 Prec@(1,5) (51.0%, 80.7%)\u001b[0m\n",
            "[2024-04-02 20:55:24] \u001b[32mTrain: [ 15/50] Final Prec@1 50.9540%\u001b[0m\n",
            "[2024-04-02 20:55:27] \u001b[32mValid: [ 15/50] Step 000/104 Loss 2.305 Prec@(1,5) (52.1%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:55:27] \u001b[32mValid: [ 15/50] Step 020/104 Loss 2.606 Prec@(1,5) (47.2%, 78.7%)\u001b[0m\n",
            "[2024-04-02 20:55:28] \u001b[32mValid: [ 15/50] Step 040/104 Loss 2.559 Prec@(1,5) (47.5%, 78.6%)\u001b[0m\n",
            "[2024-04-02 20:55:28] \u001b[32mValid: [ 15/50] Step 060/104 Loss 2.530 Prec@(1,5) (47.8%, 78.5%)\u001b[0m\n",
            "[2024-04-02 20:55:28] \u001b[32mValid: [ 15/50] Step 080/104 Loss 2.548 Prec@(1,5) (47.4%, 78.2%)\u001b[0m\n",
            "[2024-04-02 20:55:28] \u001b[32mValid: [ 15/50] Step 100/104 Loss 2.535 Prec@(1,5) (47.4%, 78.2%)\u001b[0m\n",
            "[2024-04-02 20:55:28] \u001b[32mValid: [ 15/50] Step 104/104 Loss 2.532 Prec@(1,5) (47.5%, 78.2%)\u001b[0m\n",
            "[2024-04-02 20:55:28] \u001b[32mValid: [ 15/50] Final Prec@1 47.5300%\u001b[0m\n",
            "[2024-04-02 20:55:28] \u001b[32mEpoch 15 LR 0.019848\u001b[0m\n",
            "[2024-04-02 20:55:33] \u001b[32mTrain: [ 16/50] Step 000/520 Loss 2.995 Prec@(1,5) (49.0%, 69.8%)\u001b[0m\n",
            "[2024-04-02 20:55:34] \u001b[32mTrain: [ 16/50] Step 020/520 Loss 2.558 Prec@(1,5) (50.1%, 79.6%)\u001b[0m\n",
            "[2024-04-02 20:55:34] \u001b[32mTrain: [ 16/50] Step 040/520 Loss 2.489 Prec@(1,5) (50.8%, 80.6%)\u001b[0m\n",
            "[2024-04-02 20:55:35] \u001b[32mTrain: [ 16/50] Step 060/520 Loss 2.467 Prec@(1,5) (51.5%, 80.7%)\u001b[0m\n",
            "[2024-04-02 20:55:35] \u001b[32mTrain: [ 16/50] Step 080/520 Loss 2.463 Prec@(1,5) (51.8%, 80.8%)\u001b[0m\n",
            "[2024-04-02 20:55:35] \u001b[32mTrain: [ 16/50] Step 100/520 Loss 2.466 Prec@(1,5) (51.4%, 80.6%)\u001b[0m\n",
            "[2024-04-02 20:55:36] \u001b[32mTrain: [ 16/50] Step 120/520 Loss 2.457 Prec@(1,5) (51.6%, 80.7%)\u001b[0m\n",
            "[2024-04-02 20:55:36] \u001b[32mTrain: [ 16/50] Step 140/520 Loss 2.474 Prec@(1,5) (51.3%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:55:37] \u001b[32mTrain: [ 16/50] Step 160/520 Loss 2.460 Prec@(1,5) (51.5%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:55:37] \u001b[32mTrain: [ 16/50] Step 180/520 Loss 2.461 Prec@(1,5) (51.5%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:55:38] \u001b[32mTrain: [ 16/50] Step 200/520 Loss 2.452 Prec@(1,5) (51.7%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:55:38] \u001b[32mTrain: [ 16/50] Step 220/520 Loss 2.445 Prec@(1,5) (51.8%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:55:39] \u001b[32mTrain: [ 16/50] Step 240/520 Loss 2.438 Prec@(1,5) (51.9%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:55:39] \u001b[32mTrain: [ 16/50] Step 260/520 Loss 2.443 Prec@(1,5) (51.8%, 81.1%)\u001b[0m\n",
            "[2024-04-02 20:55:40] \u001b[32mTrain: [ 16/50] Step 280/520 Loss 2.445 Prec@(1,5) (51.8%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:55:40] \u001b[32mTrain: [ 16/50] Step 300/520 Loss 2.447 Prec@(1,5) (51.8%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:55:41] \u001b[32mTrain: [ 16/50] Step 320/520 Loss 2.451 Prec@(1,5) (51.8%, 81.1%)\u001b[0m\n",
            "[2024-04-02 20:55:41] \u001b[32mTrain: [ 16/50] Step 340/520 Loss 2.452 Prec@(1,5) (51.7%, 81.1%)\u001b[0m\n",
            "[2024-04-02 20:55:42] \u001b[32mTrain: [ 16/50] Step 360/520 Loss 2.453 Prec@(1,5) (51.7%, 81.1%)\u001b[0m\n",
            "[2024-04-02 20:55:42] \u001b[32mTrain: [ 16/50] Step 380/520 Loss 2.459 Prec@(1,5) (51.6%, 81.1%)\u001b[0m\n",
            "[2024-04-02 20:55:43] \u001b[32mTrain: [ 16/50] Step 400/520 Loss 2.461 Prec@(1,5) (51.6%, 81.1%)\u001b[0m\n",
            "[2024-04-02 20:55:43] \u001b[32mTrain: [ 16/50] Step 420/520 Loss 2.463 Prec@(1,5) (51.5%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:55:44] \u001b[32mTrain: [ 16/50] Step 440/520 Loss 2.465 Prec@(1,5) (51.5%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:55:44] \u001b[32mTrain: [ 16/50] Step 460/520 Loss 2.466 Prec@(1,5) (51.5%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:55:45] \u001b[32mTrain: [ 16/50] Step 480/520 Loss 2.467 Prec@(1,5) (51.5%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:55:45] \u001b[32mTrain: [ 16/50] Step 500/520 Loss 2.470 Prec@(1,5) (51.4%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:55:46] \u001b[32mTrain: [ 16/50] Step 520/520 Loss 2.469 Prec@(1,5) (51.4%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:55:46] \u001b[32mTrain: [ 16/50] Final Prec@1 51.4420%\u001b[0m\n",
            "[2024-04-02 20:55:49] \u001b[32mValid: [ 16/50] Step 000/104 Loss 2.682 Prec@(1,5) (52.1%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:55:50] \u001b[32mValid: [ 16/50] Step 020/104 Loss 2.833 Prec@(1,5) (47.1%, 77.1%)\u001b[0m\n",
            "[2024-04-02 20:55:50] \u001b[32mValid: [ 16/50] Step 040/104 Loss 2.776 Prec@(1,5) (47.2%, 77.1%)\u001b[0m\n",
            "[2024-04-02 20:55:50] \u001b[32mValid: [ 16/50] Step 060/104 Loss 2.723 Prec@(1,5) (47.9%, 77.0%)\u001b[0m\n",
            "[2024-04-02 20:55:50] \u001b[32mValid: [ 16/50] Step 080/104 Loss 2.723 Prec@(1,5) (47.4%, 77.1%)\u001b[0m\n",
            "[2024-04-02 20:55:50] \u001b[32mValid: [ 16/50] Step 100/104 Loss 2.708 Prec@(1,5) (47.6%, 77.3%)\u001b[0m\n",
            "[2024-04-02 20:55:50] \u001b[32mValid: [ 16/50] Step 104/104 Loss 2.706 Prec@(1,5) (47.6%, 77.2%)\u001b[0m\n",
            "[2024-04-02 20:55:51] \u001b[32mValid: [ 16/50] Final Prec@1 47.6000%\u001b[0m\n",
            "[2024-04-02 20:55:51] \u001b[32mEpoch 16 LR 0.019198\u001b[0m\n",
            "[2024-04-02 20:55:55] \u001b[32mTrain: [ 17/50] Step 000/520 Loss 2.759 Prec@(1,5) (45.8%, 75.0%)\u001b[0m\n",
            "[2024-04-02 20:55:56] \u001b[32mTrain: [ 17/50] Step 020/520 Loss 2.407 Prec@(1,5) (52.0%, 81.9%)\u001b[0m\n",
            "[2024-04-02 20:55:56] \u001b[32mTrain: [ 17/50] Step 040/520 Loss 2.423 Prec@(1,5) (52.0%, 81.6%)\u001b[0m\n",
            "[2024-04-02 20:55:57] \u001b[32mTrain: [ 17/50] Step 060/520 Loss 2.428 Prec@(1,5) (51.9%, 81.5%)\u001b[0m\n",
            "[2024-04-02 20:55:57] \u001b[32mTrain: [ 17/50] Step 080/520 Loss 2.415 Prec@(1,5) (52.1%, 81.8%)\u001b[0m\n",
            "[2024-04-02 20:55:58] \u001b[32mTrain: [ 17/50] Step 100/520 Loss 2.415 Prec@(1,5) (52.2%, 81.6%)\u001b[0m\n",
            "[2024-04-02 20:55:58] \u001b[32mTrain: [ 17/50] Step 120/520 Loss 2.420 Prec@(1,5) (52.3%, 81.5%)\u001b[0m\n",
            "[2024-04-02 20:55:59] \u001b[32mTrain: [ 17/50] Step 140/520 Loss 2.406 Prec@(1,5) (52.4%, 81.8%)\u001b[0m\n",
            "[2024-04-02 20:55:59] \u001b[32mTrain: [ 17/50] Step 160/520 Loss 2.408 Prec@(1,5) (52.3%, 81.8%)\u001b[0m\n",
            "[2024-04-02 20:56:00] \u001b[32mTrain: [ 17/50] Step 180/520 Loss 2.420 Prec@(1,5) (52.2%, 81.8%)\u001b[0m\n",
            "[2024-04-02 20:56:00] \u001b[32mTrain: [ 17/50] Step 200/520 Loss 2.419 Prec@(1,5) (52.1%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:56:01] \u001b[32mTrain: [ 17/50] Step 220/520 Loss 2.419 Prec@(1,5) (52.2%, 81.8%)\u001b[0m\n",
            "[2024-04-02 20:56:01] \u001b[32mTrain: [ 17/50] Step 240/520 Loss 2.414 Prec@(1,5) (52.3%, 81.8%)\u001b[0m\n",
            "[2024-04-02 20:56:02] \u001b[32mTrain: [ 17/50] Step 260/520 Loss 2.417 Prec@(1,5) (52.2%, 81.8%)\u001b[0m\n",
            "[2024-04-02 20:56:02] \u001b[32mTrain: [ 17/50] Step 280/520 Loss 2.420 Prec@(1,5) (52.1%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:56:03] \u001b[32mTrain: [ 17/50] Step 300/520 Loss 2.417 Prec@(1,5) (52.2%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:56:03] \u001b[32mTrain: [ 17/50] Step 320/520 Loss 2.422 Prec@(1,5) (52.2%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:56:04] \u001b[32mTrain: [ 17/50] Step 340/520 Loss 2.422 Prec@(1,5) (52.2%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:56:04] \u001b[32mTrain: [ 17/50] Step 360/520 Loss 2.421 Prec@(1,5) (52.2%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:56:05] \u001b[32mTrain: [ 17/50] Step 380/520 Loss 2.424 Prec@(1,5) (52.2%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:56:05] \u001b[32mTrain: [ 17/50] Step 400/520 Loss 2.426 Prec@(1,5) (52.1%, 81.6%)\u001b[0m\n",
            "[2024-04-02 20:56:06] \u001b[32mTrain: [ 17/50] Step 420/520 Loss 2.426 Prec@(1,5) (52.1%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:56:06] \u001b[32mTrain: [ 17/50] Step 440/520 Loss 2.425 Prec@(1,5) (52.1%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:56:07] \u001b[32mTrain: [ 17/50] Step 460/520 Loss 2.424 Prec@(1,5) (52.1%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:56:07] \u001b[32mTrain: [ 17/50] Step 480/520 Loss 2.425 Prec@(1,5) (52.1%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:56:08] \u001b[32mTrain: [ 17/50] Step 500/520 Loss 2.423 Prec@(1,5) (52.1%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:56:08] \u001b[32mTrain: [ 17/50] Step 520/520 Loss 2.424 Prec@(1,5) (52.2%, 81.7%)\u001b[0m\n",
            "[2024-04-02 20:56:08] \u001b[32mTrain: [ 17/50] Final Prec@1 52.1760%\u001b[0m\n",
            "[2024-04-02 20:56:12] \u001b[32mValid: [ 17/50] Step 000/104 Loss 2.639 Prec@(1,5) (57.3%, 78.1%)\u001b[0m\n",
            "[2024-04-02 20:56:12] \u001b[32mValid: [ 17/50] Step 020/104 Loss 2.626 Prec@(1,5) (50.1%, 79.2%)\u001b[0m\n",
            "[2024-04-02 20:56:12] \u001b[32mValid: [ 17/50] Step 040/104 Loss 2.611 Prec@(1,5) (49.5%, 79.0%)\u001b[0m\n",
            "[2024-04-02 20:56:12] \u001b[32mValid: [ 17/50] Step 060/104 Loss 2.554 Prec@(1,5) (49.6%, 79.4%)\u001b[0m\n",
            "[2024-04-02 20:56:12] \u001b[32mValid: [ 17/50] Step 080/104 Loss 2.560 Prec@(1,5) (48.8%, 79.2%)\u001b[0m\n",
            "[2024-04-02 20:56:13] \u001b[32mValid: [ 17/50] Step 100/104 Loss 2.544 Prec@(1,5) (48.9%, 79.5%)\u001b[0m\n",
            "[2024-04-02 20:56:13] \u001b[32mValid: [ 17/50] Step 104/104 Loss 2.544 Prec@(1,5) (48.8%, 79.5%)\u001b[0m\n",
            "[2024-04-02 20:56:13] \u001b[32mValid: [ 17/50] Final Prec@1 48.7900%\u001b[0m\n",
            "[2024-04-02 20:56:13] \u001b[32mEpoch 17 LR 0.018522\u001b[0m\n",
            "[2024-04-02 20:56:17] \u001b[32mTrain: [ 18/50] Step 000/520 Loss 2.243 Prec@(1,5) (56.2%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:56:18] \u001b[32mTrain: [ 18/50] Step 020/520 Loss 2.403 Prec@(1,5) (51.8%, 82.4%)\u001b[0m\n",
            "[2024-04-02 20:56:18] \u001b[32mTrain: [ 18/50] Step 040/520 Loss 2.347 Prec@(1,5) (52.7%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:56:19] \u001b[32mTrain: [ 18/50] Step 060/520 Loss 2.326 Prec@(1,5) (53.0%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:56:19] \u001b[32mTrain: [ 18/50] Step 080/520 Loss 2.345 Prec@(1,5) (53.3%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:56:20] \u001b[32mTrain: [ 18/50] Step 100/520 Loss 2.362 Prec@(1,5) (53.0%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:56:20] \u001b[32mTrain: [ 18/50] Step 120/520 Loss 2.349 Prec@(1,5) (53.2%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:56:21] \u001b[32mTrain: [ 18/50] Step 140/520 Loss 2.339 Prec@(1,5) (53.4%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:56:21] \u001b[32mTrain: [ 18/50] Step 160/520 Loss 2.336 Prec@(1,5) (53.4%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:56:22] \u001b[32mTrain: [ 18/50] Step 180/520 Loss 2.340 Prec@(1,5) (53.2%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:56:22] \u001b[32mTrain: [ 18/50] Step 200/520 Loss 2.352 Prec@(1,5) (53.0%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:56:23] \u001b[32mTrain: [ 18/50] Step 220/520 Loss 2.356 Prec@(1,5) (53.0%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:56:23] \u001b[32mTrain: [ 18/50] Step 240/520 Loss 2.360 Prec@(1,5) (53.0%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:56:24] \u001b[32mTrain: [ 18/50] Step 260/520 Loss 2.364 Prec@(1,5) (52.9%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:56:24] \u001b[32mTrain: [ 18/50] Step 280/520 Loss 2.364 Prec@(1,5) (52.9%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:56:25] \u001b[32mTrain: [ 18/50] Step 300/520 Loss 2.367 Prec@(1,5) (52.9%, 82.4%)\u001b[0m\n",
            "[2024-04-02 20:56:25] \u001b[32mTrain: [ 18/50] Step 320/520 Loss 2.370 Prec@(1,5) (52.9%, 82.4%)\u001b[0m\n",
            "[2024-04-02 20:56:26] \u001b[32mTrain: [ 18/50] Step 340/520 Loss 2.363 Prec@(1,5) (52.9%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:56:26] \u001b[32mTrain: [ 18/50] Step 360/520 Loss 2.360 Prec@(1,5) (53.0%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:56:27] \u001b[32mTrain: [ 18/50] Step 380/520 Loss 2.363 Prec@(1,5) (53.0%, 82.4%)\u001b[0m\n",
            "[2024-04-02 20:56:27] \u001b[32mTrain: [ 18/50] Step 400/520 Loss 2.362 Prec@(1,5) (53.1%, 82.4%)\u001b[0m\n",
            "[2024-04-02 20:56:28] \u001b[32mTrain: [ 18/50] Step 420/520 Loss 2.366 Prec@(1,5) (53.0%, 82.4%)\u001b[0m\n",
            "[2024-04-02 20:56:28] \u001b[32mTrain: [ 18/50] Step 440/520 Loss 2.370 Prec@(1,5) (52.9%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:56:29] \u001b[32mTrain: [ 18/50] Step 460/520 Loss 2.372 Prec@(1,5) (53.0%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:56:29] \u001b[32mTrain: [ 18/50] Step 480/520 Loss 2.373 Prec@(1,5) (52.9%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:56:30] \u001b[32mTrain: [ 18/50] Step 500/520 Loss 2.376 Prec@(1,5) (52.8%, 82.2%)\u001b[0m\n",
            "[2024-04-02 20:56:30] \u001b[32mTrain: [ 18/50] Step 520/520 Loss 2.372 Prec@(1,5) (52.9%, 82.2%)\u001b[0m\n",
            "[2024-04-02 20:56:30] \u001b[32mTrain: [ 18/50] Final Prec@1 52.8820%\u001b[0m\n",
            "[2024-04-02 20:56:34] \u001b[32mValid: [ 18/50] Step 000/104 Loss 2.441 Prec@(1,5) (50.0%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:56:34] \u001b[32mValid: [ 18/50] Step 020/104 Loss 2.510 Prec@(1,5) (50.4%, 80.8%)\u001b[0m\n",
            "[2024-04-02 20:56:34] \u001b[32mValid: [ 18/50] Step 040/104 Loss 2.481 Prec@(1,5) (50.4%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:56:34] \u001b[32mValid: [ 18/50] Step 060/104 Loss 2.434 Prec@(1,5) (50.5%, 80.8%)\u001b[0m\n",
            "[2024-04-02 20:56:35] \u001b[32mValid: [ 18/50] Step 080/104 Loss 2.452 Prec@(1,5) (50.2%, 80.7%)\u001b[0m\n",
            "[2024-04-02 20:56:35] \u001b[32mValid: [ 18/50] Step 100/104 Loss 2.428 Prec@(1,5) (50.1%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:56:35] \u001b[32mValid: [ 18/50] Step 104/104 Loss 2.433 Prec@(1,5) (50.1%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:56:35] \u001b[32mValid: [ 18/50] Final Prec@1 50.0600%\u001b[0m\n",
            "[2024-04-02 20:56:35] \u001b[32mEpoch 18 LR 0.017823\u001b[0m\n",
            "[2024-04-02 20:56:40] \u001b[32mTrain: [ 19/50] Step 000/520 Loss 2.707 Prec@(1,5) (44.8%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:56:40] \u001b[32mTrain: [ 19/50] Step 020/520 Loss 2.312 Prec@(1,5) (54.6%, 83.5%)\u001b[0m\n",
            "[2024-04-02 20:56:41] \u001b[32mTrain: [ 19/50] Step 040/520 Loss 2.355 Prec@(1,5) (53.3%, 82.2%)\u001b[0m\n",
            "[2024-04-02 20:56:41] \u001b[32mTrain: [ 19/50] Step 060/520 Loss 2.315 Prec@(1,5) (53.9%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:56:42] \u001b[32mTrain: [ 19/50] Step 080/520 Loss 2.328 Prec@(1,5) (54.1%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:56:42] \u001b[32mTrain: [ 19/50] Step 100/520 Loss 2.345 Prec@(1,5) (53.7%, 82.4%)\u001b[0m\n",
            "[2024-04-02 20:56:43] \u001b[32mTrain: [ 19/50] Step 120/520 Loss 2.353 Prec@(1,5) (53.7%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:56:43] \u001b[32mTrain: [ 19/50] Step 140/520 Loss 2.351 Prec@(1,5) (53.8%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:56:44] \u001b[32mTrain: [ 19/50] Step 160/520 Loss 2.351 Prec@(1,5) (53.7%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:56:44] \u001b[32mTrain: [ 19/50] Step 180/520 Loss 2.355 Prec@(1,5) (53.7%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:56:45] \u001b[32mTrain: [ 19/50] Step 200/520 Loss 2.348 Prec@(1,5) (53.6%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:56:45] \u001b[32mTrain: [ 19/50] Step 220/520 Loss 2.345 Prec@(1,5) (53.7%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:56:46] \u001b[32mTrain: [ 19/50] Step 240/520 Loss 2.347 Prec@(1,5) (53.8%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:56:46] \u001b[32mTrain: [ 19/50] Step 260/520 Loss 2.342 Prec@(1,5) (53.8%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:56:47] \u001b[32mTrain: [ 19/50] Step 280/520 Loss 2.344 Prec@(1,5) (53.8%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:56:47] \u001b[32mTrain: [ 19/50] Step 300/520 Loss 2.349 Prec@(1,5) (53.6%, 82.7%)\u001b[0m\n",
            "[2024-04-02 20:56:48] \u001b[32mTrain: [ 19/50] Step 320/520 Loss 2.345 Prec@(1,5) (53.6%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:56:48] \u001b[32mTrain: [ 19/50] Step 340/520 Loss 2.343 Prec@(1,5) (53.6%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:56:49] \u001b[32mTrain: [ 19/50] Step 360/520 Loss 2.340 Prec@(1,5) (53.6%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:56:49] \u001b[32mTrain: [ 19/50] Step 380/520 Loss 2.341 Prec@(1,5) (53.6%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:56:50] \u001b[32mTrain: [ 19/50] Step 400/520 Loss 2.338 Prec@(1,5) (53.5%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:56:50] \u001b[32mTrain: [ 19/50] Step 420/520 Loss 2.340 Prec@(1,5) (53.5%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:56:51] \u001b[32mTrain: [ 19/50] Step 440/520 Loss 2.340 Prec@(1,5) (53.5%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:56:51] \u001b[32mTrain: [ 19/50] Step 460/520 Loss 2.342 Prec@(1,5) (53.5%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:56:52] \u001b[32mTrain: [ 19/50] Step 480/520 Loss 2.340 Prec@(1,5) (53.6%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:56:52] \u001b[32mTrain: [ 19/50] Step 500/520 Loss 2.339 Prec@(1,5) (53.6%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:56:53] \u001b[32mTrain: [ 19/50] Step 520/520 Loss 2.338 Prec@(1,5) (53.6%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:56:53] \u001b[32mTrain: [ 19/50] Final Prec@1 53.6260%\u001b[0m\n",
            "[2024-04-02 20:56:57] \u001b[32mValid: [ 19/50] Step 000/104 Loss 2.402 Prec@(1,5) (53.1%, 80.2%)\u001b[0m\n",
            "[2024-04-02 20:56:57] \u001b[32mValid: [ 19/50] Step 020/104 Loss 2.474 Prec@(1,5) (50.5%, 80.3%)\u001b[0m\n",
            "[2024-04-02 20:56:57] \u001b[32mValid: [ 19/50] Step 040/104 Loss 2.450 Prec@(1,5) (51.1%, 80.6%)\u001b[0m\n",
            "[2024-04-02 20:56:57] \u001b[32mValid: [ 19/50] Step 060/104 Loss 2.407 Prec@(1,5) (51.3%, 80.4%)\u001b[0m\n",
            "[2024-04-02 20:56:57] \u001b[32mValid: [ 19/50] Step 080/104 Loss 2.421 Prec@(1,5) (51.0%, 80.4%)\u001b[0m\n",
            "[2024-04-02 20:56:57] \u001b[32mValid: [ 19/50] Step 100/104 Loss 2.408 Prec@(1,5) (50.9%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:56:57] \u001b[32mValid: [ 19/50] Step 104/104 Loss 2.410 Prec@(1,5) (50.8%, 80.5%)\u001b[0m\n",
            "[2024-04-02 20:56:58] \u001b[32mValid: [ 19/50] Final Prec@1 50.8200%\u001b[0m\n",
            "[2024-04-02 20:56:58] \u001b[32mEpoch 19 LR 0.017102\u001b[0m\n",
            "[2024-04-02 20:57:02] \u001b[32mTrain: [ 20/50] Step 000/520 Loss 2.219 Prec@(1,5) (57.3%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:57:03] \u001b[32mTrain: [ 20/50] Step 020/520 Loss 2.273 Prec@(1,5) (54.6%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:57:03] \u001b[32mTrain: [ 20/50] Step 040/520 Loss 2.253 Prec@(1,5) (55.5%, 83.9%)\u001b[0m\n",
            "[2024-04-02 20:57:04] \u001b[32mTrain: [ 20/50] Step 060/520 Loss 2.254 Prec@(1,5) (55.4%, 83.9%)\u001b[0m\n",
            "[2024-04-02 20:57:04] \u001b[32mTrain: [ 20/50] Step 080/520 Loss 2.254 Prec@(1,5) (55.3%, 83.8%)\u001b[0m\n",
            "[2024-04-02 20:57:05] \u001b[32mTrain: [ 20/50] Step 100/520 Loss 2.264 Prec@(1,5) (55.0%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:57:05] \u001b[32mTrain: [ 20/50] Step 120/520 Loss 2.267 Prec@(1,5) (54.8%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:57:06] \u001b[32mTrain: [ 20/50] Step 140/520 Loss 2.283 Prec@(1,5) (54.4%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:57:06] \u001b[32mTrain: [ 20/50] Step 160/520 Loss 2.291 Prec@(1,5) (54.2%, 83.4%)\u001b[0m\n",
            "[2024-04-02 20:57:07] \u001b[32mTrain: [ 20/50] Step 180/520 Loss 2.296 Prec@(1,5) (54.2%, 83.4%)\u001b[0m\n",
            "[2024-04-02 20:57:07] \u001b[32mTrain: [ 20/50] Step 200/520 Loss 2.305 Prec@(1,5) (54.1%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:57:08] \u001b[32mTrain: [ 20/50] Step 220/520 Loss 2.310 Prec@(1,5) (54.1%, 83.1%)\u001b[0m\n",
            "[2024-04-02 20:57:08] \u001b[32mTrain: [ 20/50] Step 240/520 Loss 2.310 Prec@(1,5) (54.2%, 83.1%)\u001b[0m\n",
            "[2024-04-02 20:57:09] \u001b[32mTrain: [ 20/50] Step 260/520 Loss 2.304 Prec@(1,5) (54.3%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:57:09] \u001b[32mTrain: [ 20/50] Step 280/520 Loss 2.303 Prec@(1,5) (54.2%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:57:10] \u001b[32mTrain: [ 20/50] Step 300/520 Loss 2.306 Prec@(1,5) (54.2%, 83.1%)\u001b[0m\n",
            "[2024-04-02 20:57:10] \u001b[32mTrain: [ 20/50] Step 320/520 Loss 2.306 Prec@(1,5) (54.2%, 83.1%)\u001b[0m\n",
            "[2024-04-02 20:57:11] \u001b[32mTrain: [ 20/50] Step 340/520 Loss 2.308 Prec@(1,5) (54.2%, 83.1%)\u001b[0m\n",
            "[2024-04-02 20:57:11] \u001b[32mTrain: [ 20/50] Step 360/520 Loss 2.304 Prec@(1,5) (54.3%, 83.1%)\u001b[0m\n",
            "[2024-04-02 20:57:12] \u001b[32mTrain: [ 20/50] Step 380/520 Loss 2.303 Prec@(1,5) (54.3%, 83.1%)\u001b[0m\n",
            "[2024-04-02 20:57:12] \u001b[32mTrain: [ 20/50] Step 400/520 Loss 2.308 Prec@(1,5) (54.2%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:57:13] \u001b[32mTrain: [ 20/50] Step 420/520 Loss 2.315 Prec@(1,5) (54.0%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:57:13] \u001b[32mTrain: [ 20/50] Step 440/520 Loss 2.313 Prec@(1,5) (54.1%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:57:14] \u001b[32mTrain: [ 20/50] Step 460/520 Loss 2.316 Prec@(1,5) (54.0%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:57:14] \u001b[32mTrain: [ 20/50] Step 480/520 Loss 2.312 Prec@(1,5) (54.0%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:57:15] \u001b[32mTrain: [ 20/50] Step 500/520 Loss 2.313 Prec@(1,5) (54.0%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:57:15] \u001b[32mTrain: [ 20/50] Step 520/520 Loss 2.311 Prec@(1,5) (54.0%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:57:15] \u001b[32mTrain: [ 20/50] Final Prec@1 54.0140%\u001b[0m\n",
            "[2024-04-02 20:57:19] \u001b[32mValid: [ 20/50] Step 000/104 Loss 2.420 Prec@(1,5) (52.1%, 81.2%)\u001b[0m\n",
            "[2024-04-02 20:57:19] \u001b[32mValid: [ 20/50] Step 020/104 Loss 2.616 Prec@(1,5) (48.2%, 79.4%)\u001b[0m\n",
            "[2024-04-02 20:57:19] \u001b[32mValid: [ 20/50] Step 040/104 Loss 2.571 Prec@(1,5) (48.9%, 79.2%)\u001b[0m\n",
            "[2024-04-02 20:57:19] \u001b[32mValid: [ 20/50] Step 060/104 Loss 2.536 Prec@(1,5) (49.9%, 79.0%)\u001b[0m\n",
            "[2024-04-02 20:57:20] \u001b[32mValid: [ 20/50] Step 080/104 Loss 2.545 Prec@(1,5) (49.6%, 79.1%)\u001b[0m\n",
            "[2024-04-02 20:57:20] \u001b[32mValid: [ 20/50] Step 100/104 Loss 2.527 Prec@(1,5) (49.4%, 79.3%)\u001b[0m\n",
            "[2024-04-02 20:57:20] \u001b[32mValid: [ 20/50] Step 104/104 Loss 2.528 Prec@(1,5) (49.4%, 79.3%)\u001b[0m\n",
            "[2024-04-02 20:57:20] \u001b[32mValid: [ 20/50] Final Prec@1 49.3600%\u001b[0m\n",
            "[2024-04-02 20:57:20] \u001b[32mEpoch 20 LR 0.016363\u001b[0m\n",
            "[2024-04-02 20:57:25] \u001b[32mTrain: [ 21/50] Step 000/520 Loss 2.446 Prec@(1,5) (53.1%, 78.1%)\u001b[0m\n",
            "[2024-04-02 20:57:25] \u001b[32mTrain: [ 21/50] Step 020/520 Loss 2.311 Prec@(1,5) (54.8%, 83.0%)\u001b[0m\n",
            "[2024-04-02 20:57:26] \u001b[32mTrain: [ 21/50] Step 040/520 Loss 2.280 Prec@(1,5) (55.1%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:57:26] \u001b[32mTrain: [ 21/50] Step 060/520 Loss 2.257 Prec@(1,5) (55.7%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:57:27] \u001b[32mTrain: [ 21/50] Step 080/520 Loss 2.248 Prec@(1,5) (55.4%, 84.0%)\u001b[0m\n",
            "[2024-04-02 20:57:27] \u001b[32mTrain: [ 21/50] Step 100/520 Loss 2.245 Prec@(1,5) (55.3%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:57:27] \u001b[32mTrain: [ 21/50] Step 120/520 Loss 2.238 Prec@(1,5) (55.5%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:57:28] \u001b[32mTrain: [ 21/50] Step 140/520 Loss 2.237 Prec@(1,5) (55.6%, 84.0%)\u001b[0m\n",
            "[2024-04-02 20:57:28] \u001b[32mTrain: [ 21/50] Step 160/520 Loss 2.243 Prec@(1,5) (55.3%, 84.0%)\u001b[0m\n",
            "[2024-04-02 20:57:29] \u001b[32mTrain: [ 21/50] Step 180/520 Loss 2.246 Prec@(1,5) (55.3%, 84.0%)\u001b[0m\n",
            "[2024-04-02 20:57:29] \u001b[32mTrain: [ 21/50] Step 200/520 Loss 2.247 Prec@(1,5) (55.3%, 83.9%)\u001b[0m\n",
            "[2024-04-02 20:57:30] \u001b[32mTrain: [ 21/50] Step 220/520 Loss 2.247 Prec@(1,5) (55.4%, 84.0%)\u001b[0m\n",
            "[2024-04-02 20:57:30] \u001b[32mTrain: [ 21/50] Step 240/520 Loss 2.247 Prec@(1,5) (55.4%, 83.9%)\u001b[0m\n",
            "[2024-04-02 20:57:31] \u001b[32mTrain: [ 21/50] Step 260/520 Loss 2.257 Prec@(1,5) (55.1%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:57:31] \u001b[32mTrain: [ 21/50] Step 280/520 Loss 2.258 Prec@(1,5) (55.0%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:57:32] \u001b[32mTrain: [ 21/50] Step 300/520 Loss 2.259 Prec@(1,5) (55.0%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:57:32] \u001b[32mTrain: [ 21/50] Step 320/520 Loss 2.256 Prec@(1,5) (55.1%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:57:33] \u001b[32mTrain: [ 21/50] Step 340/520 Loss 2.259 Prec@(1,5) (54.9%, 83.7%)\u001b[0m\n",
            "[2024-04-02 20:57:33] \u001b[32mTrain: [ 21/50] Step 360/520 Loss 2.269 Prec@(1,5) (54.8%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:57:34] \u001b[32mTrain: [ 21/50] Step 380/520 Loss 2.270 Prec@(1,5) (54.8%, 83.5%)\u001b[0m\n",
            "[2024-04-02 20:57:34] \u001b[32mTrain: [ 21/50] Step 400/520 Loss 2.269 Prec@(1,5) (54.9%, 83.6%)\u001b[0m\n",
            "[2024-04-02 20:57:35] \u001b[32mTrain: [ 21/50] Step 420/520 Loss 2.269 Prec@(1,5) (55.0%, 83.5%)\u001b[0m\n",
            "[2024-04-02 20:57:35] \u001b[32mTrain: [ 21/50] Step 440/520 Loss 2.272 Prec@(1,5) (54.9%, 83.4%)\u001b[0m\n",
            "[2024-04-02 20:57:36] \u001b[32mTrain: [ 21/50] Step 460/520 Loss 2.277 Prec@(1,5) (54.9%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:57:36] \u001b[32mTrain: [ 21/50] Step 480/520 Loss 2.278 Prec@(1,5) (54.8%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:57:37] \u001b[32mTrain: [ 21/50] Step 500/520 Loss 2.279 Prec@(1,5) (54.8%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:57:37] \u001b[32mTrain: [ 21/50] Step 520/520 Loss 2.283 Prec@(1,5) (54.7%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:57:37] \u001b[32mTrain: [ 21/50] Final Prec@1 54.7260%\u001b[0m\n",
            "[2024-04-02 20:57:41] \u001b[32mValid: [ 21/50] Step 000/104 Loss 2.000 Prec@(1,5) (55.2%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:57:41] \u001b[32mValid: [ 21/50] Step 020/104 Loss 2.259 Prec@(1,5) (53.1%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:57:41] \u001b[32mValid: [ 21/50] Step 040/104 Loss 2.234 Prec@(1,5) (52.6%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:57:41] \u001b[32mValid: [ 21/50] Step 060/104 Loss 2.194 Prec@(1,5) (53.3%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:57:42] \u001b[32mValid: [ 21/50] Step 080/104 Loss 2.208 Prec@(1,5) (53.0%, 82.8%)\u001b[0m\n",
            "[2024-04-02 20:57:42] \u001b[32mValid: [ 21/50] Step 100/104 Loss 2.195 Prec@(1,5) (53.1%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:57:42] \u001b[32mValid: [ 21/50] Step 104/104 Loss 2.193 Prec@(1,5) (53.0%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:57:42] \u001b[32mValid: [ 21/50] Final Prec@1 52.9800%\u001b[0m\n",
            "[2024-04-02 20:57:42] \u001b[32mEpoch 21 LR 0.015609\u001b[0m\n",
            "[2024-04-02 20:57:47] \u001b[32mTrain: [ 22/50] Step 000/520 Loss 2.247 Prec@(1,5) (49.0%, 90.6%)\u001b[0m\n",
            "[2024-04-02 20:57:47] \u001b[32mTrain: [ 22/50] Step 020/520 Loss 2.195 Prec@(1,5) (56.4%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:57:48] \u001b[32mTrain: [ 22/50] Step 040/520 Loss 2.201 Prec@(1,5) (55.7%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:57:48] \u001b[32mTrain: [ 22/50] Step 060/520 Loss 2.196 Prec@(1,5) (56.6%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:57:49] \u001b[32mTrain: [ 22/50] Step 080/520 Loss 2.221 Prec@(1,5) (55.9%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:57:49] \u001b[32mTrain: [ 22/50] Step 100/520 Loss 2.216 Prec@(1,5) (55.8%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:57:50] \u001b[32mTrain: [ 22/50] Step 120/520 Loss 2.214 Prec@(1,5) (55.8%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:57:50] \u001b[32mTrain: [ 22/50] Step 140/520 Loss 2.207 Prec@(1,5) (56.0%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:57:51] \u001b[32mTrain: [ 22/50] Step 160/520 Loss 2.200 Prec@(1,5) (56.2%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:57:51] \u001b[32mTrain: [ 22/50] Step 180/520 Loss 2.199 Prec@(1,5) (56.3%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:57:52] \u001b[32mTrain: [ 22/50] Step 200/520 Loss 2.206 Prec@(1,5) (56.2%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:57:52] \u001b[32mTrain: [ 22/50] Step 220/520 Loss 2.205 Prec@(1,5) (56.2%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:57:53] \u001b[32mTrain: [ 22/50] Step 240/520 Loss 2.202 Prec@(1,5) (56.1%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:57:53] \u001b[32mTrain: [ 22/50] Step 260/520 Loss 2.205 Prec@(1,5) (56.1%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:57:54] \u001b[32mTrain: [ 22/50] Step 280/520 Loss 2.205 Prec@(1,5) (56.1%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:57:54] \u001b[32mTrain: [ 22/50] Step 300/520 Loss 2.212 Prec@(1,5) (55.9%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:57:55] \u001b[32mTrain: [ 22/50] Step 320/520 Loss 2.216 Prec@(1,5) (55.9%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:57:55] \u001b[32mTrain: [ 22/50] Step 340/520 Loss 2.220 Prec@(1,5) (55.8%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:57:56] \u001b[32mTrain: [ 22/50] Step 360/520 Loss 2.224 Prec@(1,5) (55.7%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:57:56] \u001b[32mTrain: [ 22/50] Step 380/520 Loss 2.227 Prec@(1,5) (55.7%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:57:57] \u001b[32mTrain: [ 22/50] Step 400/520 Loss 2.225 Prec@(1,5) (55.7%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:57:57] \u001b[32mTrain: [ 22/50] Step 420/520 Loss 2.224 Prec@(1,5) (55.7%, 84.3%)\u001b[0m\n",
            "[2024-04-02 20:57:58] \u001b[32mTrain: [ 22/50] Step 440/520 Loss 2.229 Prec@(1,5) (55.7%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:57:58] \u001b[32mTrain: [ 22/50] Step 460/520 Loss 2.230 Prec@(1,5) (55.6%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:57:59] \u001b[32mTrain: [ 22/50] Step 480/520 Loss 2.227 Prec@(1,5) (55.7%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:57:59] \u001b[32mTrain: [ 22/50] Step 500/520 Loss 2.231 Prec@(1,5) (55.7%, 84.2%)\u001b[0m\n",
            "[2024-04-02 20:58:00] \u001b[32mTrain: [ 22/50] Step 520/520 Loss 2.233 Prec@(1,5) (55.6%, 84.1%)\u001b[0m\n",
            "[2024-04-02 20:58:00] \u001b[32mTrain: [ 22/50] Final Prec@1 55.6360%\u001b[0m\n",
            "[2024-04-02 20:58:04] \u001b[32mValid: [ 22/50] Step 000/104 Loss 2.075 Prec@(1,5) (62.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:58:04] \u001b[32mValid: [ 22/50] Step 020/104 Loss 2.241 Prec@(1,5) (53.2%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:58:04] \u001b[32mValid: [ 22/50] Step 040/104 Loss 2.244 Prec@(1,5) (52.2%, 82.0%)\u001b[0m\n",
            "[2024-04-02 20:58:04] \u001b[32mValid: [ 22/50] Step 060/104 Loss 2.197 Prec@(1,5) (52.8%, 82.2%)\u001b[0m\n",
            "[2024-04-02 20:58:04] \u001b[32mValid: [ 22/50] Step 080/104 Loss 2.217 Prec@(1,5) (52.2%, 82.2%)\u001b[0m\n",
            "[2024-04-02 20:58:04] \u001b[32mValid: [ 22/50] Step 100/104 Loss 2.203 Prec@(1,5) (52.4%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:58:04] \u001b[32mValid: [ 22/50] Step 104/104 Loss 2.202 Prec@(1,5) (52.3%, 82.4%)\u001b[0m\n",
            "[2024-04-02 20:58:05] \u001b[32mValid: [ 22/50] Final Prec@1 52.3400%\u001b[0m\n",
            "[2024-04-02 20:58:05] \u001b[32mEpoch 22 LR 0.014843\u001b[0m\n",
            "[2024-04-02 20:58:09] \u001b[32mTrain: [ 23/50] Step 000/520 Loss 2.473 Prec@(1,5) (45.8%, 79.2%)\u001b[0m\n",
            "[2024-04-02 20:58:10] \u001b[32mTrain: [ 23/50] Step 020/520 Loss 2.173 Prec@(1,5) (55.5%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:58:10] \u001b[32mTrain: [ 23/50] Step 040/520 Loss 2.167 Prec@(1,5) (56.3%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:58:11] \u001b[32mTrain: [ 23/50] Step 060/520 Loss 2.179 Prec@(1,5) (56.6%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:58:11] \u001b[32mTrain: [ 23/50] Step 080/520 Loss 2.199 Prec@(1,5) (56.1%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:58:12] \u001b[32mTrain: [ 23/50] Step 100/520 Loss 2.202 Prec@(1,5) (56.1%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:58:12] \u001b[32mTrain: [ 23/50] Step 120/520 Loss 2.202 Prec@(1,5) (56.1%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:58:13] \u001b[32mTrain: [ 23/50] Step 140/520 Loss 2.200 Prec@(1,5) (56.1%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:58:13] \u001b[32mTrain: [ 23/50] Step 160/520 Loss 2.201 Prec@(1,5) (56.0%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:58:14] \u001b[32mTrain: [ 23/50] Step 180/520 Loss 2.196 Prec@(1,5) (56.2%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:58:14] \u001b[32mTrain: [ 23/50] Step 200/520 Loss 2.206 Prec@(1,5) (56.2%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:58:15] \u001b[32mTrain: [ 23/50] Step 220/520 Loss 2.206 Prec@(1,5) (56.2%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:58:15] \u001b[32mTrain: [ 23/50] Step 240/520 Loss 2.201 Prec@(1,5) (56.2%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:58:16] \u001b[32mTrain: [ 23/50] Step 260/520 Loss 2.205 Prec@(1,5) (56.1%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:58:16] \u001b[32mTrain: [ 23/50] Step 280/520 Loss 2.206 Prec@(1,5) (56.0%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:58:17] \u001b[32mTrain: [ 23/50] Step 300/520 Loss 2.202 Prec@(1,5) (56.2%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:58:17] \u001b[32mTrain: [ 23/50] Step 320/520 Loss 2.204 Prec@(1,5) (56.1%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:58:18] \u001b[32mTrain: [ 23/50] Step 340/520 Loss 2.201 Prec@(1,5) (56.1%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:58:18] \u001b[32mTrain: [ 23/50] Step 360/520 Loss 2.197 Prec@(1,5) (56.1%, 84.7%)\u001b[0m\n",
            "[2024-04-02 20:58:18] \u001b[32mTrain: [ 23/50] Step 380/520 Loss 2.200 Prec@(1,5) (56.0%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:58:19] \u001b[32mTrain: [ 23/50] Step 400/520 Loss 2.204 Prec@(1,5) (55.9%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:58:19] \u001b[32mTrain: [ 23/50] Step 420/520 Loss 2.205 Prec@(1,5) (55.9%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:58:20] \u001b[32mTrain: [ 23/50] Step 440/520 Loss 2.206 Prec@(1,5) (55.9%, 84.6%)\u001b[0m\n",
            "[2024-04-02 20:58:20] \u001b[32mTrain: [ 23/50] Step 460/520 Loss 2.208 Prec@(1,5) (55.9%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:58:21] \u001b[32mTrain: [ 23/50] Step 480/520 Loss 2.207 Prec@(1,5) (56.0%, 84.5%)\u001b[0m\n",
            "[2024-04-02 20:58:21] \u001b[32mTrain: [ 23/50] Step 500/520 Loss 2.205 Prec@(1,5) (56.0%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:58:22] \u001b[32mTrain: [ 23/50] Step 520/520 Loss 2.207 Prec@(1,5) (56.0%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:58:22] \u001b[32mTrain: [ 23/50] Final Prec@1 56.0180%\u001b[0m\n",
            "[2024-04-02 20:58:26] \u001b[32mValid: [ 23/50] Step 000/104 Loss 2.319 Prec@(1,5) (59.4%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:58:26] \u001b[32mValid: [ 23/50] Step 020/104 Loss 2.536 Prec@(1,5) (51.9%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:58:26] \u001b[32mValid: [ 23/50] Step 040/104 Loss 2.500 Prec@(1,5) (51.2%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:58:26] \u001b[32mValid: [ 23/50] Step 060/104 Loss 2.461 Prec@(1,5) (51.3%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:58:26] \u001b[32mValid: [ 23/50] Step 080/104 Loss 2.475 Prec@(1,5) (50.8%, 81.0%)\u001b[0m\n",
            "[2024-04-02 20:58:26] \u001b[32mValid: [ 23/50] Step 100/104 Loss 2.468 Prec@(1,5) (50.8%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:58:26] \u001b[32mValid: [ 23/50] Step 104/104 Loss 2.472 Prec@(1,5) (50.8%, 80.9%)\u001b[0m\n",
            "[2024-04-02 20:58:27] \u001b[32mValid: [ 23/50] Final Prec@1 50.7700%\u001b[0m\n",
            "[2024-04-02 20:58:27] \u001b[32mEpoch 23 LR 0.014067\u001b[0m\n",
            "[2024-04-02 20:58:31] \u001b[32mTrain: [ 24/50] Step 000/520 Loss 1.985 Prec@(1,5) (64.6%, 87.5%)\u001b[0m\n",
            "[2024-04-02 20:58:32] \u001b[32mTrain: [ 24/50] Step 020/520 Loss 2.155 Prec@(1,5) (56.4%, 85.9%)\u001b[0m\n",
            "[2024-04-02 20:58:32] \u001b[32mTrain: [ 24/50] Step 040/520 Loss 2.151 Prec@(1,5) (56.7%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:58:33] \u001b[32mTrain: [ 24/50] Step 060/520 Loss 2.168 Prec@(1,5) (56.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:58:33] \u001b[32mTrain: [ 24/50] Step 080/520 Loss 2.155 Prec@(1,5) (56.8%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:58:34] \u001b[32mTrain: [ 24/50] Step 100/520 Loss 2.157 Prec@(1,5) (56.7%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:58:34] \u001b[32mTrain: [ 24/50] Step 120/520 Loss 2.159 Prec@(1,5) (56.6%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:58:35] \u001b[32mTrain: [ 24/50] Step 140/520 Loss 2.160 Prec@(1,5) (56.7%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:58:35] \u001b[32mTrain: [ 24/50] Step 160/520 Loss 2.170 Prec@(1,5) (56.4%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:58:36] \u001b[32mTrain: [ 24/50] Step 180/520 Loss 2.172 Prec@(1,5) (56.5%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:58:36] \u001b[32mTrain: [ 24/50] Step 200/520 Loss 2.182 Prec@(1,5) (56.3%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:58:37] \u001b[32mTrain: [ 24/50] Step 220/520 Loss 2.186 Prec@(1,5) (56.3%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:58:37] \u001b[32mTrain: [ 24/50] Step 240/520 Loss 2.185 Prec@(1,5) (56.3%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:58:38] \u001b[32mTrain: [ 24/50] Step 260/520 Loss 2.187 Prec@(1,5) (56.2%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:58:38] \u001b[32mTrain: [ 24/50] Step 280/520 Loss 2.186 Prec@(1,5) (56.2%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:58:39] \u001b[32mTrain: [ 24/50] Step 300/520 Loss 2.186 Prec@(1,5) (56.2%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:58:39] \u001b[32mTrain: [ 24/50] Step 320/520 Loss 2.186 Prec@(1,5) (56.2%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:58:40] \u001b[32mTrain: [ 24/50] Step 340/520 Loss 2.185 Prec@(1,5) (56.3%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:58:40] \u001b[32mTrain: [ 24/50] Step 360/520 Loss 2.186 Prec@(1,5) (56.3%, 84.9%)\u001b[0m\n",
            "[2024-04-02 20:58:41] \u001b[32mTrain: [ 24/50] Step 380/520 Loss 2.187 Prec@(1,5) (56.3%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:58:41] \u001b[32mTrain: [ 24/50] Step 400/520 Loss 2.190 Prec@(1,5) (56.2%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:58:42] \u001b[32mTrain: [ 24/50] Step 420/520 Loss 2.188 Prec@(1,5) (56.2%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:58:42] \u001b[32mTrain: [ 24/50] Step 440/520 Loss 2.189 Prec@(1,5) (56.2%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:58:43] \u001b[32mTrain: [ 24/50] Step 460/520 Loss 2.188 Prec@(1,5) (56.2%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:58:43] \u001b[32mTrain: [ 24/50] Step 480/520 Loss 2.190 Prec@(1,5) (56.1%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:58:44] \u001b[32mTrain: [ 24/50] Step 500/520 Loss 2.190 Prec@(1,5) (56.1%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:58:44] \u001b[32mTrain: [ 24/50] Step 520/520 Loss 2.192 Prec@(1,5) (56.1%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:58:45] \u001b[32mTrain: [ 24/50] Final Prec@1 56.1100%\u001b[0m\n",
            "[2024-04-02 20:58:48] \u001b[32mValid: [ 24/50] Step 000/104 Loss 2.044 Prec@(1,5) (59.4%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:58:48] \u001b[32mValid: [ 24/50] Step 020/104 Loss 2.302 Prec@(1,5) (53.1%, 82.4%)\u001b[0m\n",
            "[2024-04-02 20:58:48] \u001b[32mValid: [ 24/50] Step 040/104 Loss 2.273 Prec@(1,5) (53.0%, 82.4%)\u001b[0m\n",
            "[2024-04-02 20:58:49] \u001b[32mValid: [ 24/50] Step 060/104 Loss 2.225 Prec@(1,5) (53.6%, 82.3%)\u001b[0m\n",
            "[2024-04-02 20:58:49] \u001b[32mValid: [ 24/50] Step 080/104 Loss 2.222 Prec@(1,5) (53.4%, 82.2%)\u001b[0m\n",
            "[2024-04-02 20:58:49] \u001b[32mValid: [ 24/50] Step 100/104 Loss 2.202 Prec@(1,5) (53.6%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:58:49] \u001b[32mValid: [ 24/50] Step 104/104 Loss 2.204 Prec@(1,5) (53.5%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:58:49] \u001b[32mValid: [ 24/50] Final Prec@1 53.4800%\u001b[0m\n",
            "[2024-04-02 20:58:49] \u001b[32mEpoch 24 LR 0.013285\u001b[0m\n",
            "[2024-04-02 20:58:54] \u001b[32mTrain: [ 25/50] Step 000/520 Loss 2.028 Prec@(1,5) (56.2%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:58:54] \u001b[32mTrain: [ 25/50] Step 020/520 Loss 2.178 Prec@(1,5) (56.8%, 84.8%)\u001b[0m\n",
            "[2024-04-02 20:58:55] \u001b[32mTrain: [ 25/50] Step 040/520 Loss 2.118 Prec@(1,5) (58.1%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:58:55] \u001b[32mTrain: [ 25/50] Step 060/520 Loss 2.097 Prec@(1,5) (58.1%, 86.0%)\u001b[0m\n",
            "[2024-04-02 20:58:56] \u001b[32mTrain: [ 25/50] Step 080/520 Loss 2.131 Prec@(1,5) (57.3%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:58:56] \u001b[32mTrain: [ 25/50] Step 100/520 Loss 2.121 Prec@(1,5) (57.4%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:58:57] \u001b[32mTrain: [ 25/50] Step 120/520 Loss 2.124 Prec@(1,5) (57.4%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:58:57] \u001b[32mTrain: [ 25/50] Step 140/520 Loss 2.119 Prec@(1,5) (57.5%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:58:58] \u001b[32mTrain: [ 25/50] Step 160/520 Loss 2.125 Prec@(1,5) (57.4%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:58:58] \u001b[32mTrain: [ 25/50] Step 180/520 Loss 2.125 Prec@(1,5) (57.4%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:58:59] \u001b[32mTrain: [ 25/50] Step 200/520 Loss 2.121 Prec@(1,5) (57.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:58:59] \u001b[32mTrain: [ 25/50] Step 220/520 Loss 2.120 Prec@(1,5) (57.6%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:59:00] \u001b[32mTrain: [ 25/50] Step 240/520 Loss 2.117 Prec@(1,5) (57.6%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:59:00] \u001b[32mTrain: [ 25/50] Step 260/520 Loss 2.121 Prec@(1,5) (57.5%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:59:01] \u001b[32mTrain: [ 25/50] Step 280/520 Loss 2.122 Prec@(1,5) (57.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:59:01] \u001b[32mTrain: [ 25/50] Step 300/520 Loss 2.122 Prec@(1,5) (57.4%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:59:02] \u001b[32mTrain: [ 25/50] Step 320/520 Loss 2.123 Prec@(1,5) (57.4%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:59:02] \u001b[32mTrain: [ 25/50] Step 340/520 Loss 2.126 Prec@(1,5) (57.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:59:03] \u001b[32mTrain: [ 25/50] Step 360/520 Loss 2.135 Prec@(1,5) (57.3%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:59:03] \u001b[32mTrain: [ 25/50] Step 380/520 Loss 2.137 Prec@(1,5) (57.3%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:59:04] \u001b[32mTrain: [ 25/50] Step 400/520 Loss 2.138 Prec@(1,5) (57.3%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:59:04] \u001b[32mTrain: [ 25/50] Step 420/520 Loss 2.138 Prec@(1,5) (57.3%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:59:05] \u001b[32mTrain: [ 25/50] Step 440/520 Loss 2.141 Prec@(1,5) (57.3%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:59:05] \u001b[32mTrain: [ 25/50] Step 460/520 Loss 2.143 Prec@(1,5) (57.3%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:59:06] \u001b[32mTrain: [ 25/50] Step 480/520 Loss 2.142 Prec@(1,5) (57.2%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:59:06] \u001b[32mTrain: [ 25/50] Step 500/520 Loss 2.140 Prec@(1,5) (57.3%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:59:07] \u001b[32mTrain: [ 25/50] Step 520/520 Loss 2.139 Prec@(1,5) (57.3%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:59:07] \u001b[32mTrain: [ 25/50] Final Prec@1 57.3340%\u001b[0m\n",
            "[2024-04-02 20:59:10] \u001b[32mValid: [ 25/50] Step 000/104 Loss 2.078 Prec@(1,5) (60.4%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:59:11] \u001b[32mValid: [ 25/50] Step 020/104 Loss 2.263 Prec@(1,5) (53.6%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:59:11] \u001b[32mValid: [ 25/50] Step 040/104 Loss 2.223 Prec@(1,5) (53.6%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:59:11] \u001b[32mValid: [ 25/50] Step 060/104 Loss 2.182 Prec@(1,5) (53.9%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:59:11] \u001b[32mValid: [ 25/50] Step 080/104 Loss 2.195 Prec@(1,5) (53.6%, 83.1%)\u001b[0m\n",
            "[2024-04-02 20:59:11] \u001b[32mValid: [ 25/50] Step 100/104 Loss 2.177 Prec@(1,5) (53.8%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:59:11] \u001b[32mValid: [ 25/50] Step 104/104 Loss 2.179 Prec@(1,5) (53.7%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:59:12] \u001b[32mValid: [ 25/50] Final Prec@1 53.7200%\u001b[0m\n",
            "[2024-04-02 20:59:12] \u001b[32mEpoch 25 LR 0.012500\u001b[0m\n",
            "[2024-04-02 20:59:16] \u001b[32mTrain: [ 26/50] Step 000/520 Loss 2.199 Prec@(1,5) (57.3%, 84.4%)\u001b[0m\n",
            "[2024-04-02 20:59:17] \u001b[32mTrain: [ 26/50] Step 020/520 Loss 2.089 Prec@(1,5) (56.9%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:59:17] \u001b[32mTrain: [ 26/50] Step 040/520 Loss 2.057 Prec@(1,5) (57.6%, 86.2%)\u001b[0m\n",
            "[2024-04-02 20:59:18] \u001b[32mTrain: [ 26/50] Step 060/520 Loss 2.103 Prec@(1,5) (57.6%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:59:18] \u001b[32mTrain: [ 26/50] Step 080/520 Loss 2.098 Prec@(1,5) (57.7%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:59:19] \u001b[32mTrain: [ 26/50] Step 100/520 Loss 2.104 Prec@(1,5) (57.6%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:59:19] \u001b[32mTrain: [ 26/50] Step 120/520 Loss 2.123 Prec@(1,5) (57.2%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:59:20] \u001b[32mTrain: [ 26/50] Step 140/520 Loss 2.116 Prec@(1,5) (57.4%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:59:20] \u001b[32mTrain: [ 26/50] Step 160/520 Loss 2.128 Prec@(1,5) (57.3%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:59:21] \u001b[32mTrain: [ 26/50] Step 180/520 Loss 2.132 Prec@(1,5) (57.2%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:59:21] \u001b[32mTrain: [ 26/50] Step 200/520 Loss 2.128 Prec@(1,5) (57.2%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:59:22] \u001b[32mTrain: [ 26/50] Step 220/520 Loss 2.136 Prec@(1,5) (57.0%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:59:22] \u001b[32mTrain: [ 26/50] Step 240/520 Loss 2.135 Prec@(1,5) (57.0%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:59:23] \u001b[32mTrain: [ 26/50] Step 260/520 Loss 2.144 Prec@(1,5) (56.8%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:59:23] \u001b[32mTrain: [ 26/50] Step 280/520 Loss 2.142 Prec@(1,5) (56.9%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:59:24] \u001b[32mTrain: [ 26/50] Step 300/520 Loss 2.148 Prec@(1,5) (56.7%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:59:24] \u001b[32mTrain: [ 26/50] Step 320/520 Loss 2.151 Prec@(1,5) (56.7%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:59:25] \u001b[32mTrain: [ 26/50] Step 340/520 Loss 2.147 Prec@(1,5) (56.8%, 85.0%)\u001b[0m\n",
            "[2024-04-02 20:59:25] \u001b[32mTrain: [ 26/50] Step 360/520 Loss 2.139 Prec@(1,5) (56.9%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:59:26] \u001b[32mTrain: [ 26/50] Step 380/520 Loss 2.136 Prec@(1,5) (56.9%, 85.1%)\u001b[0m\n",
            "[2024-04-02 20:59:26] \u001b[32mTrain: [ 26/50] Step 400/520 Loss 2.135 Prec@(1,5) (57.0%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:59:27] \u001b[32mTrain: [ 26/50] Step 420/520 Loss 2.134 Prec@(1,5) (57.1%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:59:27] \u001b[32mTrain: [ 26/50] Step 440/520 Loss 2.131 Prec@(1,5) (57.1%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:59:28] \u001b[32mTrain: [ 26/50] Step 460/520 Loss 2.133 Prec@(1,5) (57.2%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:59:28] \u001b[32mTrain: [ 26/50] Step 480/520 Loss 2.133 Prec@(1,5) (57.2%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:59:29] \u001b[32mTrain: [ 26/50] Step 500/520 Loss 2.131 Prec@(1,5) (57.2%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:59:29] \u001b[32mTrain: [ 26/50] Step 520/520 Loss 2.134 Prec@(1,5) (57.2%, 85.2%)\u001b[0m\n",
            "[2024-04-02 20:59:30] \u001b[32mTrain: [ 26/50] Final Prec@1 57.1560%\u001b[0m\n",
            "[2024-04-02 20:59:33] \u001b[32mValid: [ 26/50] Step 000/104 Loss 2.220 Prec@(1,5) (55.2%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:59:33] \u001b[32mValid: [ 26/50] Step 020/104 Loss 2.356 Prec@(1,5) (53.4%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:59:33] \u001b[32mValid: [ 26/50] Step 040/104 Loss 2.350 Prec@(1,5) (52.5%, 82.2%)\u001b[0m\n",
            "[2024-04-02 20:59:34] \u001b[32mValid: [ 26/50] Step 060/104 Loss 2.289 Prec@(1,5) (52.8%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:59:34] \u001b[32mValid: [ 26/50] Step 080/104 Loss 2.314 Prec@(1,5) (52.2%, 82.4%)\u001b[0m\n",
            "[2024-04-02 20:59:34] \u001b[32mValid: [ 26/50] Step 100/104 Loss 2.297 Prec@(1,5) (52.4%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:59:34] \u001b[32mValid: [ 26/50] Step 104/104 Loss 2.296 Prec@(1,5) (52.4%, 82.6%)\u001b[0m\n",
            "[2024-04-02 20:59:34] \u001b[32mValid: [ 26/50] Final Prec@1 52.3900%\u001b[0m\n",
            "[2024-04-02 20:59:34] \u001b[32mEpoch 26 LR 0.011716\u001b[0m\n",
            "[2024-04-02 20:59:39] \u001b[32mTrain: [ 27/50] Step 000/520 Loss 1.649 Prec@(1,5) (68.8%, 88.5%)\u001b[0m\n",
            "[2024-04-02 20:59:39] \u001b[32mTrain: [ 27/50] Step 020/520 Loss 2.056 Prec@(1,5) (59.2%, 86.3%)\u001b[0m\n",
            "[2024-04-02 20:59:40] \u001b[32mTrain: [ 27/50] Step 040/520 Loss 2.090 Prec@(1,5) (58.5%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:59:40] \u001b[32mTrain: [ 27/50] Step 060/520 Loss 2.078 Prec@(1,5) (58.7%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:59:41] \u001b[32mTrain: [ 27/50] Step 080/520 Loss 2.076 Prec@(1,5) (58.5%, 85.8%)\u001b[0m\n",
            "[2024-04-02 20:59:41] \u001b[32mTrain: [ 27/50] Step 100/520 Loss 2.087 Prec@(1,5) (58.3%, 85.7%)\u001b[0m\n",
            "[2024-04-02 20:59:42] \u001b[32mTrain: [ 27/50] Step 120/520 Loss 2.087 Prec@(1,5) (58.2%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:59:42] \u001b[32mTrain: [ 27/50] Step 140/520 Loss 2.101 Prec@(1,5) (58.0%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:59:43] \u001b[32mTrain: [ 27/50] Step 160/520 Loss 2.096 Prec@(1,5) (58.1%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:59:43] \u001b[32mTrain: [ 27/50] Step 180/520 Loss 2.102 Prec@(1,5) (58.0%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:59:44] \u001b[32mTrain: [ 27/50] Step 200/520 Loss 2.094 Prec@(1,5) (58.1%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:59:44] \u001b[32mTrain: [ 27/50] Step 220/520 Loss 2.088 Prec@(1,5) (58.2%, 85.6%)\u001b[0m\n",
            "[2024-04-02 20:59:45] \u001b[32mTrain: [ 27/50] Step 240/520 Loss 2.095 Prec@(1,5) (58.0%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:59:45] \u001b[32mTrain: [ 27/50] Step 260/520 Loss 2.095 Prec@(1,5) (57.9%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:59:46] \u001b[32mTrain: [ 27/50] Step 280/520 Loss 2.099 Prec@(1,5) (57.9%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:59:46] \u001b[32mTrain: [ 27/50] Step 300/520 Loss 2.101 Prec@(1,5) (57.8%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:59:47] \u001b[32mTrain: [ 27/50] Step 320/520 Loss 2.104 Prec@(1,5) (57.8%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:59:47] \u001b[32mTrain: [ 27/50] Step 340/520 Loss 2.103 Prec@(1,5) (57.8%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:59:48] \u001b[32mTrain: [ 27/50] Step 360/520 Loss 2.104 Prec@(1,5) (57.8%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:59:48] \u001b[32mTrain: [ 27/50] Step 380/520 Loss 2.101 Prec@(1,5) (57.9%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:59:49] \u001b[32mTrain: [ 27/50] Step 400/520 Loss 2.100 Prec@(1,5) (57.9%, 85.3%)\u001b[0m\n",
            "[2024-04-02 20:59:49] \u001b[32mTrain: [ 27/50] Step 420/520 Loss 2.100 Prec@(1,5) (57.8%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:59:50] \u001b[32mTrain: [ 27/50] Step 440/520 Loss 2.098 Prec@(1,5) (57.9%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:59:50] \u001b[32mTrain: [ 27/50] Step 460/520 Loss 2.100 Prec@(1,5) (57.8%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:59:51] \u001b[32mTrain: [ 27/50] Step 480/520 Loss 2.099 Prec@(1,5) (57.8%, 85.5%)\u001b[0m\n",
            "[2024-04-02 20:59:51] \u001b[32mTrain: [ 27/50] Step 500/520 Loss 2.102 Prec@(1,5) (57.7%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:59:52] \u001b[32mTrain: [ 27/50] Step 520/520 Loss 2.104 Prec@(1,5) (57.7%, 85.4%)\u001b[0m\n",
            "[2024-04-02 20:59:52] \u001b[32mTrain: [ 27/50] Final Prec@1 57.7160%\u001b[0m\n",
            "[2024-04-02 20:59:55] \u001b[32mValid: [ 27/50] Step 000/104 Loss 2.186 Prec@(1,5) (59.4%, 86.5%)\u001b[0m\n",
            "[2024-04-02 20:59:55] \u001b[32mValid: [ 27/50] Step 020/104 Loss 2.278 Prec@(1,5) (54.4%, 82.9%)\u001b[0m\n",
            "[2024-04-02 20:59:56] \u001b[32mValid: [ 27/50] Step 040/104 Loss 2.253 Prec@(1,5) (53.8%, 82.5%)\u001b[0m\n",
            "[2024-04-02 20:59:56] \u001b[32mValid: [ 27/50] Step 060/104 Loss 2.200 Prec@(1,5) (54.4%, 83.1%)\u001b[0m\n",
            "[2024-04-02 20:59:56] \u001b[32mValid: [ 27/50] Step 080/104 Loss 2.203 Prec@(1,5) (54.1%, 83.2%)\u001b[0m\n",
            "[2024-04-02 20:59:56] \u001b[32mValid: [ 27/50] Step 100/104 Loss 2.185 Prec@(1,5) (54.0%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:59:56] \u001b[32mValid: [ 27/50] Step 104/104 Loss 2.183 Prec@(1,5) (53.9%, 83.3%)\u001b[0m\n",
            "[2024-04-02 20:59:56] \u001b[32mValid: [ 27/50] Final Prec@1 53.9300%\u001b[0m\n",
            "[2024-04-02 20:59:56] \u001b[32mEpoch 27 LR 0.010934\u001b[0m\n",
            "[2024-04-02 21:00:01] \u001b[32mTrain: [ 28/50] Step 000/520 Loss 1.572 Prec@(1,5) (70.8%, 90.6%)\u001b[0m\n",
            "[2024-04-02 21:00:02] \u001b[32mTrain: [ 28/50] Step 020/520 Loss 2.131 Prec@(1,5) (57.7%, 86.1%)\u001b[0m\n",
            "[2024-04-02 21:00:02] \u001b[32mTrain: [ 28/50] Step 040/520 Loss 2.071 Prec@(1,5) (59.0%, 86.2%)\u001b[0m\n",
            "[2024-04-02 21:00:02] \u001b[32mTrain: [ 28/50] Step 060/520 Loss 2.043 Prec@(1,5) (59.8%, 86.3%)\u001b[0m\n",
            "[2024-04-02 21:00:03] \u001b[32mTrain: [ 28/50] Step 080/520 Loss 2.035 Prec@(1,5) (59.8%, 86.2%)\u001b[0m\n",
            "[2024-04-02 21:00:03] \u001b[32mTrain: [ 28/50] Step 100/520 Loss 2.049 Prec@(1,5) (59.4%, 86.0%)\u001b[0m\n",
            "[2024-04-02 21:00:04] \u001b[32mTrain: [ 28/50] Step 120/520 Loss 2.051 Prec@(1,5) (59.3%, 86.1%)\u001b[0m\n",
            "[2024-04-02 21:00:04] \u001b[32mTrain: [ 28/50] Step 140/520 Loss 2.063 Prec@(1,5) (58.9%, 86.1%)\u001b[0m\n",
            "[2024-04-02 21:00:05] \u001b[32mTrain: [ 28/50] Step 160/520 Loss 2.056 Prec@(1,5) (59.1%, 86.0%)\u001b[0m\n",
            "[2024-04-02 21:00:05] \u001b[32mTrain: [ 28/50] Step 180/520 Loss 2.061 Prec@(1,5) (58.9%, 86.0%)\u001b[0m\n",
            "[2024-04-02 21:00:06] \u001b[32mTrain: [ 28/50] Step 200/520 Loss 2.064 Prec@(1,5) (58.8%, 86.0%)\u001b[0m\n",
            "[2024-04-02 21:00:06] \u001b[32mTrain: [ 28/50] Step 220/520 Loss 2.068 Prec@(1,5) (58.6%, 86.0%)\u001b[0m\n",
            "[2024-04-02 21:00:07] \u001b[32mTrain: [ 28/50] Step 240/520 Loss 2.067 Prec@(1,5) (58.7%, 86.0%)\u001b[0m\n",
            "[2024-04-02 21:00:07] \u001b[32mTrain: [ 28/50] Step 260/520 Loss 2.067 Prec@(1,5) (58.8%, 85.9%)\u001b[0m\n",
            "[2024-04-02 21:00:08] \u001b[32mTrain: [ 28/50] Step 280/520 Loss 2.066 Prec@(1,5) (58.8%, 85.9%)\u001b[0m\n",
            "[2024-04-02 21:00:08] \u001b[32mTrain: [ 28/50] Step 300/520 Loss 2.067 Prec@(1,5) (58.8%, 85.9%)\u001b[0m\n",
            "[2024-04-02 21:00:09] \u001b[32mTrain: [ 28/50] Step 320/520 Loss 2.070 Prec@(1,5) (58.7%, 85.9%)\u001b[0m\n",
            "[2024-04-02 21:00:09] \u001b[32mTrain: [ 28/50] Step 340/520 Loss 2.069 Prec@(1,5) (58.7%, 85.9%)\u001b[0m\n",
            "[2024-04-02 21:00:10] \u001b[32mTrain: [ 28/50] Step 360/520 Loss 2.071 Prec@(1,5) (58.7%, 85.9%)\u001b[0m\n",
            "[2024-04-02 21:00:10] \u001b[32mTrain: [ 28/50] Step 380/520 Loss 2.070 Prec@(1,5) (58.8%, 85.9%)\u001b[0m\n",
            "[2024-04-02 21:00:11] \u001b[32mTrain: [ 28/50] Step 400/520 Loss 2.067 Prec@(1,5) (58.8%, 85.9%)\u001b[0m\n",
            "[2024-04-02 21:00:11] \u001b[32mTrain: [ 28/50] Step 420/520 Loss 2.069 Prec@(1,5) (58.8%, 85.9%)\u001b[0m\n",
            "[2024-04-02 21:00:12] \u001b[32mTrain: [ 28/50] Step 440/520 Loss 2.073 Prec@(1,5) (58.7%, 85.9%)\u001b[0m\n",
            "[2024-04-02 21:00:12] \u001b[32mTrain: [ 28/50] Step 460/520 Loss 2.073 Prec@(1,5) (58.7%, 85.9%)\u001b[0m\n",
            "[2024-04-02 21:00:13] \u001b[32mTrain: [ 28/50] Step 480/520 Loss 2.074 Prec@(1,5) (58.7%, 85.8%)\u001b[0m\n",
            "[2024-04-02 21:00:13] \u001b[32mTrain: [ 28/50] Step 500/520 Loss 2.075 Prec@(1,5) (58.6%, 85.8%)\u001b[0m\n",
            "[2024-04-02 21:00:14] \u001b[32mTrain: [ 28/50] Step 520/520 Loss 2.081 Prec@(1,5) (58.6%, 85.8%)\u001b[0m\n",
            "[2024-04-02 21:00:14] \u001b[32mTrain: [ 28/50] Final Prec@1 58.5660%\u001b[0m\n",
            "[2024-04-02 21:00:17] \u001b[32mValid: [ 28/50] Step 000/104 Loss 2.088 Prec@(1,5) (60.4%, 83.3%)\u001b[0m\n",
            "[2024-04-02 21:00:18] \u001b[32mValid: [ 28/50] Step 020/104 Loss 2.215 Prec@(1,5) (55.5%, 83.1%)\u001b[0m\n",
            "[2024-04-02 21:00:18] \u001b[32mValid: [ 28/50] Step 040/104 Loss 2.206 Prec@(1,5) (55.2%, 83.5%)\u001b[0m\n",
            "[2024-04-02 21:00:18] \u001b[32mValid: [ 28/50] Step 060/104 Loss 2.151 Prec@(1,5) (55.6%, 83.8%)\u001b[0m\n",
            "[2024-04-02 21:00:18] \u001b[32mValid: [ 28/50] Step 080/104 Loss 2.158 Prec@(1,5) (55.3%, 83.7%)\u001b[0m\n",
            "[2024-04-02 21:00:18] \u001b[32mValid: [ 28/50] Step 100/104 Loss 2.136 Prec@(1,5) (55.5%, 84.0%)\u001b[0m\n",
            "[2024-04-02 21:00:18] \u001b[32mValid: [ 28/50] Step 104/104 Loss 2.135 Prec@(1,5) (55.6%, 84.0%)\u001b[0m\n",
            "[2024-04-02 21:00:19] \u001b[32mValid: [ 28/50] Final Prec@1 55.5700%\u001b[0m\n",
            "[2024-04-02 21:00:19] \u001b[32mEpoch 28 LR 0.010158\u001b[0m\n",
            "[2024-04-02 21:00:23] \u001b[32mTrain: [ 29/50] Step 000/520 Loss 2.281 Prec@(1,5) (59.4%, 81.2%)\u001b[0m\n",
            "[2024-04-02 21:00:24] \u001b[32mTrain: [ 29/50] Step 020/520 Loss 2.052 Prec@(1,5) (58.3%, 86.1%)\u001b[0m\n",
            "[2024-04-02 21:00:24] \u001b[32mTrain: [ 29/50] Step 040/520 Loss 2.016 Prec@(1,5) (59.1%, 86.4%)\u001b[0m\n",
            "[2024-04-02 21:00:25] \u001b[32mTrain: [ 29/50] Step 060/520 Loss 2.021 Prec@(1,5) (58.8%, 86.3%)\u001b[0m\n",
            "[2024-04-02 21:00:25] \u001b[32mTrain: [ 29/50] Step 080/520 Loss 2.020 Prec@(1,5) (58.9%, 86.5%)\u001b[0m\n",
            "[2024-04-02 21:00:26] \u001b[32mTrain: [ 29/50] Step 100/520 Loss 2.024 Prec@(1,5) (59.0%, 86.4%)\u001b[0m\n",
            "[2024-04-02 21:00:26] \u001b[32mTrain: [ 29/50] Step 120/520 Loss 2.043 Prec@(1,5) (58.5%, 86.3%)\u001b[0m\n",
            "[2024-04-02 21:00:27] \u001b[32mTrain: [ 29/50] Step 140/520 Loss 2.048 Prec@(1,5) (58.7%, 86.1%)\u001b[0m\n",
            "[2024-04-02 21:00:27] \u001b[32mTrain: [ 29/50] Step 160/520 Loss 2.045 Prec@(1,5) (58.9%, 86.2%)\u001b[0m\n",
            "[2024-04-02 21:00:28] \u001b[32mTrain: [ 29/50] Step 180/520 Loss 2.040 Prec@(1,5) (58.8%, 86.3%)\u001b[0m\n",
            "[2024-04-02 21:00:28] \u001b[32mTrain: [ 29/50] Step 200/520 Loss 2.040 Prec@(1,5) (58.7%, 86.3%)\u001b[0m\n",
            "[2024-04-02 21:00:28] \u001b[32mTrain: [ 29/50] Step 220/520 Loss 2.041 Prec@(1,5) (58.8%, 86.2%)\u001b[0m\n",
            "[2024-04-02 21:00:29] \u001b[32mTrain: [ 29/50] Step 240/520 Loss 2.053 Prec@(1,5) (58.6%, 86.1%)\u001b[0m\n",
            "[2024-04-02 21:00:29] \u001b[32mTrain: [ 29/50] Step 260/520 Loss 2.052 Prec@(1,5) (58.5%, 86.2%)\u001b[0m\n",
            "[2024-04-02 21:00:30] \u001b[32mTrain: [ 29/50] Step 280/520 Loss 2.052 Prec@(1,5) (58.6%, 86.1%)\u001b[0m\n",
            "[2024-04-02 21:00:30] \u001b[32mTrain: [ 29/50] Step 300/520 Loss 2.050 Prec@(1,5) (58.7%, 86.1%)\u001b[0m\n",
            "[2024-04-02 21:00:31] \u001b[32mTrain: [ 29/50] Step 320/520 Loss 2.054 Prec@(1,5) (58.6%, 86.1%)\u001b[0m\n",
            "[2024-04-02 21:00:31] \u001b[32mTrain: [ 29/50] Step 340/520 Loss 2.051 Prec@(1,5) (58.7%, 86.1%)\u001b[0m\n",
            "[2024-04-02 21:00:32] \u001b[32mTrain: [ 29/50] Step 360/520 Loss 2.046 Prec@(1,5) (58.8%, 86.1%)\u001b[0m\n",
            "[2024-04-02 21:00:32] \u001b[32mTrain: [ 29/50] Step 380/520 Loss 2.049 Prec@(1,5) (58.8%, 86.0%)\u001b[0m\n",
            "[2024-04-02 21:00:33] \u001b[32mTrain: [ 29/50] Step 400/520 Loss 2.051 Prec@(1,5) (58.8%, 86.0%)\u001b[0m\n",
            "[2024-04-02 21:00:33] \u001b[32mTrain: [ 29/50] Step 420/520 Loss 2.052 Prec@(1,5) (58.7%, 86.0%)\u001b[0m\n",
            "[2024-04-02 21:00:34] \u001b[32mTrain: [ 29/50] Step 440/520 Loss 2.052 Prec@(1,5) (58.8%, 86.0%)\u001b[0m\n",
            "[2024-04-02 21:00:34] \u001b[32mTrain: [ 29/50] Step 460/520 Loss 2.053 Prec@(1,5) (58.7%, 86.0%)\u001b[0m\n",
            "[2024-04-02 21:00:35] \u001b[32mTrain: [ 29/50] Step 480/520 Loss 2.049 Prec@(1,5) (58.7%, 86.1%)\u001b[0m\n",
            "[2024-04-02 21:00:35] \u001b[32mTrain: [ 29/50] Step 500/520 Loss 2.049 Prec@(1,5) (58.7%, 86.1%)\u001b[0m\n",
            "[2024-04-02 21:00:36] \u001b[32mTrain: [ 29/50] Step 520/520 Loss 2.049 Prec@(1,5) (58.7%, 86.1%)\u001b[0m\n",
            "[2024-04-02 21:00:36] \u001b[32mTrain: [ 29/50] Final Prec@1 58.7100%\u001b[0m\n",
            "[2024-04-02 21:00:40] \u001b[32mValid: [ 29/50] Step 000/104 Loss 2.190 Prec@(1,5) (57.3%, 87.5%)\u001b[0m\n",
            "[2024-04-02 21:00:40] \u001b[32mValid: [ 29/50] Step 020/104 Loss 2.331 Prec@(1,5) (53.9%, 82.0%)\u001b[0m\n",
            "[2024-04-02 21:00:40] \u001b[32mValid: [ 29/50] Step 040/104 Loss 2.293 Prec@(1,5) (53.6%, 82.1%)\u001b[0m\n",
            "[2024-04-02 21:00:40] \u001b[32mValid: [ 29/50] Step 060/104 Loss 2.234 Prec@(1,5) (54.5%, 82.3%)\u001b[0m\n",
            "[2024-04-02 21:00:40] \u001b[32mValid: [ 29/50] Step 080/104 Loss 2.227 Prec@(1,5) (54.1%, 82.4%)\u001b[0m\n",
            "[2024-04-02 21:00:40] \u001b[32mValid: [ 29/50] Step 100/104 Loss 2.197 Prec@(1,5) (54.4%, 82.6%)\u001b[0m\n",
            "[2024-04-02 21:00:40] \u001b[32mValid: [ 29/50] Step 104/104 Loss 2.198 Prec@(1,5) (54.4%, 82.6%)\u001b[0m\n",
            "[2024-04-02 21:00:41] \u001b[32mValid: [ 29/50] Final Prec@1 54.3700%\u001b[0m\n",
            "[2024-04-02 21:00:41] \u001b[32mEpoch 29 LR 0.009392\u001b[0m\n",
            "[2024-04-02 21:00:45] \u001b[32mTrain: [ 30/50] Step 000/520 Loss 2.105 Prec@(1,5) (57.3%, 85.4%)\u001b[0m\n",
            "[2024-04-02 21:00:46] \u001b[32mTrain: [ 30/50] Step 020/520 Loss 1.983 Prec@(1,5) (60.4%, 87.5%)\u001b[0m\n",
            "[2024-04-02 21:00:46] \u001b[32mTrain: [ 30/50] Step 040/520 Loss 2.016 Prec@(1,5) (60.1%, 86.4%)\u001b[0m\n",
            "[2024-04-02 21:00:47] \u001b[32mTrain: [ 30/50] Step 060/520 Loss 2.009 Prec@(1,5) (60.0%, 86.6%)\u001b[0m\n",
            "[2024-04-02 21:00:47] \u001b[32mTrain: [ 30/50] Step 080/520 Loss 2.016 Prec@(1,5) (59.7%, 86.7%)\u001b[0m\n",
            "[2024-04-02 21:00:48] \u001b[32mTrain: [ 30/50] Step 100/520 Loss 2.011 Prec@(1,5) (59.8%, 86.7%)\u001b[0m\n",
            "[2024-04-02 21:00:48] \u001b[32mTrain: [ 30/50] Step 120/520 Loss 2.005 Prec@(1,5) (59.8%, 86.9%)\u001b[0m\n",
            "[2024-04-02 21:00:49] \u001b[32mTrain: [ 30/50] Step 140/520 Loss 2.008 Prec@(1,5) (59.8%, 86.8%)\u001b[0m\n",
            "[2024-04-02 21:00:49] \u001b[32mTrain: [ 30/50] Step 160/520 Loss 2.002 Prec@(1,5) (59.9%, 86.8%)\u001b[0m\n",
            "[2024-04-02 21:00:50] \u001b[32mTrain: [ 30/50] Step 180/520 Loss 2.012 Prec@(1,5) (59.8%, 86.7%)\u001b[0m\n",
            "[2024-04-02 21:00:50] \u001b[32mTrain: [ 30/50] Step 200/520 Loss 2.013 Prec@(1,5) (59.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 21:00:51] \u001b[32mTrain: [ 30/50] Step 220/520 Loss 2.010 Prec@(1,5) (59.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 21:00:51] \u001b[32mTrain: [ 30/50] Step 240/520 Loss 2.017 Prec@(1,5) (59.6%, 86.6%)\u001b[0m\n",
            "[2024-04-02 21:00:52] \u001b[32mTrain: [ 30/50] Step 260/520 Loss 2.016 Prec@(1,5) (59.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 21:00:52] \u001b[32mTrain: [ 30/50] Step 280/520 Loss 2.019 Prec@(1,5) (59.5%, 86.6%)\u001b[0m\n",
            "[2024-04-02 21:00:53] \u001b[32mTrain: [ 30/50] Step 300/520 Loss 2.021 Prec@(1,5) (59.5%, 86.6%)\u001b[0m\n",
            "[2024-04-02 21:00:53] \u001b[32mTrain: [ 30/50] Step 320/520 Loss 2.023 Prec@(1,5) (59.3%, 86.6%)\u001b[0m\n",
            "[2024-04-02 21:00:54] \u001b[32mTrain: [ 30/50] Step 340/520 Loss 2.029 Prec@(1,5) (59.2%, 86.4%)\u001b[0m\n",
            "[2024-04-02 21:00:54] \u001b[32mTrain: [ 30/50] Step 360/520 Loss 2.026 Prec@(1,5) (59.2%, 86.5%)\u001b[0m\n",
            "[2024-04-02 21:00:55] \u001b[32mTrain: [ 30/50] Step 380/520 Loss 2.024 Prec@(1,5) (59.3%, 86.5%)\u001b[0m\n",
            "[2024-04-02 21:00:55] \u001b[32mTrain: [ 30/50] Step 400/520 Loss 2.025 Prec@(1,5) (59.3%, 86.5%)\u001b[0m\n",
            "[2024-04-02 21:00:56] \u001b[32mTrain: [ 30/50] Step 420/520 Loss 2.026 Prec@(1,5) (59.3%, 86.4%)\u001b[0m\n",
            "[2024-04-02 21:00:56] \u001b[32mTrain: [ 30/50] Step 440/520 Loss 2.027 Prec@(1,5) (59.2%, 86.4%)\u001b[0m\n",
            "[2024-04-02 21:00:57] \u001b[32mTrain: [ 30/50] Step 460/520 Loss 2.029 Prec@(1,5) (59.2%, 86.4%)\u001b[0m\n",
            "[2024-04-02 21:00:57] \u001b[32mTrain: [ 30/50] Step 480/520 Loss 2.029 Prec@(1,5) (59.2%, 86.4%)\u001b[0m\n",
            "[2024-04-02 21:00:58] \u001b[32mTrain: [ 30/50] Step 500/520 Loss 2.025 Prec@(1,5) (59.3%, 86.4%)\u001b[0m\n",
            "[2024-04-02 21:00:58] \u001b[32mTrain: [ 30/50] Step 520/520 Loss 2.026 Prec@(1,5) (59.3%, 86.4%)\u001b[0m\n",
            "[2024-04-02 21:00:58] \u001b[32mTrain: [ 30/50] Final Prec@1 59.2560%\u001b[0m\n",
            "[2024-04-02 21:01:02] \u001b[32mValid: [ 30/50] Step 000/104 Loss 2.008 Prec@(1,5) (57.3%, 86.5%)\u001b[0m\n",
            "[2024-04-02 21:01:02] \u001b[32mValid: [ 30/50] Step 020/104 Loss 2.262 Prec@(1,5) (55.3%, 82.5%)\u001b[0m\n",
            "[2024-04-02 21:01:02] \u001b[32mValid: [ 30/50] Step 040/104 Loss 2.245 Prec@(1,5) (54.8%, 82.5%)\u001b[0m\n",
            "[2024-04-02 21:01:03] \u001b[32mValid: [ 30/50] Step 060/104 Loss 2.179 Prec@(1,5) (55.3%, 82.8%)\u001b[0m\n",
            "[2024-04-02 21:01:03] \u001b[32mValid: [ 30/50] Step 080/104 Loss 2.172 Prec@(1,5) (55.0%, 82.9%)\u001b[0m\n",
            "[2024-04-02 21:01:03] \u001b[32mValid: [ 30/50] Step 100/104 Loss 2.143 Prec@(1,5) (55.3%, 83.1%)\u001b[0m\n",
            "[2024-04-02 21:01:03] \u001b[32mValid: [ 30/50] Step 104/104 Loss 2.141 Prec@(1,5) (55.3%, 83.2%)\u001b[0m\n",
            "[2024-04-02 21:01:03] \u001b[32mValid: [ 30/50] Final Prec@1 55.2700%\u001b[0m\n",
            "[2024-04-02 21:01:03] \u001b[32mEpoch 30 LR 0.008638\u001b[0m\n",
            "[2024-04-02 21:01:08] \u001b[32mTrain: [ 31/50] Step 000/520 Loss 2.181 Prec@(1,5) (56.2%, 82.3%)\u001b[0m\n",
            "[2024-04-02 21:01:08] \u001b[32mTrain: [ 31/50] Step 020/520 Loss 2.000 Prec@(1,5) (59.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 21:01:09] \u001b[32mTrain: [ 31/50] Step 040/520 Loss 1.927 Prec@(1,5) (60.7%, 87.3%)\u001b[0m\n",
            "[2024-04-02 21:01:09] \u001b[32mTrain: [ 31/50] Step 060/520 Loss 1.938 Prec@(1,5) (60.4%, 87.1%)\u001b[0m\n",
            "[2024-04-02 21:01:10] \u001b[32mTrain: [ 31/50] Step 080/520 Loss 1.957 Prec@(1,5) (59.9%, 87.0%)\u001b[0m\n",
            "[2024-04-02 21:01:10] \u001b[32mTrain: [ 31/50] Step 100/520 Loss 1.972 Prec@(1,5) (59.8%, 86.8%)\u001b[0m\n",
            "[2024-04-02 21:01:11] \u001b[32mTrain: [ 31/50] Step 120/520 Loss 1.981 Prec@(1,5) (59.7%, 86.7%)\u001b[0m\n",
            "[2024-04-02 21:01:11] \u001b[32mTrain: [ 31/50] Step 140/520 Loss 1.984 Prec@(1,5) (59.7%, 86.8%)\u001b[0m\n",
            "[2024-04-02 21:01:12] \u001b[32mTrain: [ 31/50] Step 160/520 Loss 1.985 Prec@(1,5) (59.8%, 86.8%)\u001b[0m\n",
            "[2024-04-02 21:01:12] \u001b[32mTrain: [ 31/50] Step 180/520 Loss 1.986 Prec@(1,5) (59.7%, 86.7%)\u001b[0m\n",
            "[2024-04-02 21:01:13] \u001b[32mTrain: [ 31/50] Step 200/520 Loss 1.985 Prec@(1,5) (59.8%, 86.8%)\u001b[0m\n",
            "[2024-04-02 21:01:13] \u001b[32mTrain: [ 31/50] Step 220/520 Loss 1.991 Prec@(1,5) (59.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 21:01:14] \u001b[32mTrain: [ 31/50] Step 240/520 Loss 1.995 Prec@(1,5) (59.7%, 86.5%)\u001b[0m\n",
            "[2024-04-02 21:01:14] \u001b[32mTrain: [ 31/50] Step 260/520 Loss 1.994 Prec@(1,5) (59.7%, 86.6%)\u001b[0m\n",
            "[2024-04-02 21:01:15] \u001b[32mTrain: [ 31/50] Step 280/520 Loss 1.991 Prec@(1,5) (59.8%, 86.6%)\u001b[0m\n",
            "[2024-04-02 21:01:15] \u001b[32mTrain: [ 31/50] Step 300/520 Loss 1.990 Prec@(1,5) (59.8%, 86.7%)\u001b[0m\n",
            "[2024-04-02 21:01:16] \u001b[32mTrain: [ 31/50] Step 320/520 Loss 1.990 Prec@(1,5) (59.9%, 86.6%)\u001b[0m\n",
            "[2024-04-02 21:01:16] \u001b[32mTrain: [ 31/50] Step 340/520 Loss 1.986 Prec@(1,5) (59.9%, 86.6%)\u001b[0m\n",
            "[2024-04-02 21:01:17] \u001b[32mTrain: [ 31/50] Step 360/520 Loss 1.987 Prec@(1,5) (59.9%, 86.5%)\u001b[0m\n",
            "[2024-04-02 21:01:17] \u001b[32mTrain: [ 31/50] Step 380/520 Loss 1.987 Prec@(1,5) (60.0%, 86.6%)\u001b[0m\n",
            "[2024-04-02 21:01:18] \u001b[32mTrain: [ 31/50] Step 400/520 Loss 1.987 Prec@(1,5) (59.9%, 86.6%)\u001b[0m\n",
            "[2024-04-02 21:01:18] \u001b[32mTrain: [ 31/50] Step 420/520 Loss 1.986 Prec@(1,5) (59.9%, 86.6%)\u001b[0m\n",
            "[2024-04-02 21:01:19] \u001b[32mTrain: [ 31/50] Step 440/520 Loss 1.988 Prec@(1,5) (59.8%, 86.6%)\u001b[0m\n",
            "[2024-04-02 21:01:19] \u001b[32mTrain: [ 31/50] Step 460/520 Loss 1.988 Prec@(1,5) (59.8%, 86.6%)\u001b[0m\n",
            "[2024-04-02 21:01:20] \u001b[32mTrain: [ 31/50] Step 480/520 Loss 1.992 Prec@(1,5) (59.8%, 86.6%)\u001b[0m\n",
            "[2024-04-02 21:01:20] \u001b[32mTrain: [ 31/50] Step 500/520 Loss 1.991 Prec@(1,5) (59.8%, 86.6%)\u001b[0m\n",
            "[2024-04-02 21:01:21] \u001b[32mTrain: [ 31/50] Step 520/520 Loss 1.990 Prec@(1,5) (59.8%, 86.6%)\u001b[0m\n",
            "[2024-04-02 21:01:21] \u001b[32mTrain: [ 31/50] Final Prec@1 59.7860%\u001b[0m\n",
            "[2024-04-02 21:01:24] \u001b[32mValid: [ 31/50] Step 000/104 Loss 1.970 Prec@(1,5) (57.3%, 85.4%)\u001b[0m\n",
            "[2024-04-02 21:01:24] \u001b[32mValid: [ 31/50] Step 020/104 Loss 2.062 Prec@(1,5) (57.0%, 84.8%)\u001b[0m\n",
            "[2024-04-02 21:01:25] \u001b[32mValid: [ 31/50] Step 040/104 Loss 2.051 Prec@(1,5) (56.9%, 84.5%)\u001b[0m\n",
            "[2024-04-02 21:01:25] \u001b[32mValid: [ 31/50] Step 060/104 Loss 2.009 Prec@(1,5) (57.0%, 84.9%)\u001b[0m\n",
            "[2024-04-02 21:01:25] \u001b[32mValid: [ 31/50] Step 080/104 Loss 2.011 Prec@(1,5) (56.7%, 85.0%)\u001b[0m\n",
            "[2024-04-02 21:01:25] \u001b[32mValid: [ 31/50] Step 100/104 Loss 1.992 Prec@(1,5) (57.1%, 85.1%)\u001b[0m\n",
            "[2024-04-02 21:01:25] \u001b[32mValid: [ 31/50] Step 104/104 Loss 1.990 Prec@(1,5) (57.0%, 85.0%)\u001b[0m\n",
            "[2024-04-02 21:01:25] \u001b[32mValid: [ 31/50] Final Prec@1 57.0400%\u001b[0m\n",
            "[2024-04-02 21:01:25] \u001b[32mEpoch 31 LR 0.007899\u001b[0m\n",
            "[2024-04-02 21:01:30] \u001b[32mTrain: [ 32/50] Step 000/520 Loss 2.296 Prec@(1,5) (53.1%, 83.3%)\u001b[0m\n",
            "[2024-04-02 21:01:30] \u001b[32mTrain: [ 32/50] Step 020/520 Loss 1.968 Prec@(1,5) (60.9%, 86.9%)\u001b[0m\n",
            "[2024-04-02 21:01:31] \u001b[32mTrain: [ 32/50] Step 040/520 Loss 1.938 Prec@(1,5) (61.6%, 86.5%)\u001b[0m\n",
            "[2024-04-02 21:01:31] \u001b[32mTrain: [ 32/50] Step 060/520 Loss 1.944 Prec@(1,5) (60.9%, 86.9%)\u001b[0m\n",
            "[2024-04-02 21:01:32] \u001b[32mTrain: [ 32/50] Step 080/520 Loss 1.954 Prec@(1,5) (61.0%, 87.0%)\u001b[0m\n",
            "[2024-04-02 21:01:32] \u001b[32mTrain: [ 32/50] Step 100/520 Loss 1.970 Prec@(1,5) (60.8%, 86.8%)\u001b[0m\n",
            "[2024-04-02 21:01:33] \u001b[32mTrain: [ 32/50] Step 120/520 Loss 1.971 Prec@(1,5) (60.9%, 86.9%)\u001b[0m\n",
            "[2024-04-02 21:01:33] \u001b[32mTrain: [ 32/50] Step 140/520 Loss 1.976 Prec@(1,5) (60.8%, 86.8%)\u001b[0m\n",
            "[2024-04-02 21:01:34] \u001b[32mTrain: [ 32/50] Step 160/520 Loss 1.970 Prec@(1,5) (60.8%, 86.9%)\u001b[0m\n",
            "[2024-04-02 21:01:34] \u001b[32mTrain: [ 32/50] Step 180/520 Loss 1.973 Prec@(1,5) (60.7%, 86.9%)\u001b[0m\n",
            "[2024-04-02 21:01:35] \u001b[32mTrain: [ 32/50] Step 200/520 Loss 1.967 Prec@(1,5) (60.8%, 87.0%)\u001b[0m\n",
            "[2024-04-02 21:01:35] \u001b[32mTrain: [ 32/50] Step 220/520 Loss 1.964 Prec@(1,5) (60.6%, 87.1%)\u001b[0m\n",
            "[2024-04-02 21:01:36] \u001b[32mTrain: [ 32/50] Step 240/520 Loss 1.968 Prec@(1,5) (60.6%, 87.0%)\u001b[0m\n",
            "[2024-04-02 21:01:36] \u001b[32mTrain: [ 32/50] Step 260/520 Loss 1.965 Prec@(1,5) (60.6%, 87.0%)\u001b[0m\n",
            "[2024-04-02 21:01:37] \u001b[32mTrain: [ 32/50] Step 280/520 Loss 1.968 Prec@(1,5) (60.6%, 86.9%)\u001b[0m\n",
            "[2024-04-02 21:01:37] \u001b[32mTrain: [ 32/50] Step 300/520 Loss 1.970 Prec@(1,5) (60.4%, 86.9%)\u001b[0m\n",
            "[2024-04-02 21:01:38] \u001b[32mTrain: [ 32/50] Step 320/520 Loss 1.967 Prec@(1,5) (60.5%, 86.9%)\u001b[0m\n",
            "[2024-04-02 21:01:38] \u001b[32mTrain: [ 32/50] Step 340/520 Loss 1.968 Prec@(1,5) (60.5%, 86.9%)\u001b[0m\n",
            "[2024-04-02 21:01:39] \u001b[32mTrain: [ 32/50] Step 360/520 Loss 1.970 Prec@(1,5) (60.4%, 86.9%)\u001b[0m\n",
            "[2024-04-02 21:01:39] \u001b[32mTrain: [ 32/50] Step 380/520 Loss 1.972 Prec@(1,5) (60.4%, 86.9%)\u001b[0m\n",
            "[2024-04-02 21:01:40] \u001b[32mTrain: [ 32/50] Step 400/520 Loss 1.974 Prec@(1,5) (60.3%, 86.9%)\u001b[0m\n",
            "[2024-04-02 21:01:40] \u001b[32mTrain: [ 32/50] Step 420/520 Loss 1.978 Prec@(1,5) (60.2%, 86.8%)\u001b[0m\n",
            "[2024-04-02 21:01:41] \u001b[32mTrain: [ 32/50] Step 440/520 Loss 1.979 Prec@(1,5) (60.1%, 86.8%)\u001b[0m\n",
            "[2024-04-02 21:01:41] \u001b[32mTrain: [ 32/50] Step 460/520 Loss 1.977 Prec@(1,5) (60.2%, 86.8%)\u001b[0m\n",
            "[2024-04-02 21:01:42] \u001b[32mTrain: [ 32/50] Step 480/520 Loss 1.976 Prec@(1,5) (60.2%, 86.9%)\u001b[0m\n",
            "[2024-04-02 21:01:42] \u001b[32mTrain: [ 32/50] Step 500/520 Loss 1.973 Prec@(1,5) (60.2%, 86.9%)\u001b[0m\n",
            "[2024-04-02 21:01:43] \u001b[32mTrain: [ 32/50] Step 520/520 Loss 1.971 Prec@(1,5) (60.3%, 86.9%)\u001b[0m\n",
            "[2024-04-02 21:01:43] \u001b[32mTrain: [ 32/50] Final Prec@1 60.2820%\u001b[0m\n",
            "[2024-04-02 21:01:46] \u001b[32mValid: [ 32/50] Step 000/104 Loss 2.106 Prec@(1,5) (62.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 21:01:47] \u001b[32mValid: [ 32/50] Step 020/104 Loss 2.096 Prec@(1,5) (57.9%, 84.2%)\u001b[0m\n",
            "[2024-04-02 21:01:47] \u001b[32mValid: [ 32/50] Step 040/104 Loss 2.072 Prec@(1,5) (56.7%, 84.5%)\u001b[0m\n",
            "[2024-04-02 21:01:47] \u001b[32mValid: [ 32/50] Step 060/104 Loss 2.020 Prec@(1,5) (56.8%, 84.8%)\u001b[0m\n",
            "[2024-04-02 21:01:47] \u001b[32mValid: [ 32/50] Step 080/104 Loss 2.029 Prec@(1,5) (56.8%, 84.6%)\u001b[0m\n",
            "[2024-04-02 21:01:47] \u001b[32mValid: [ 32/50] Step 100/104 Loss 2.000 Prec@(1,5) (57.0%, 84.9%)\u001b[0m\n",
            "[2024-04-02 21:01:47] \u001b[32mValid: [ 32/50] Step 104/104 Loss 1.999 Prec@(1,5) (57.0%, 84.9%)\u001b[0m\n",
            "[2024-04-02 21:01:47] \u001b[32mValid: [ 32/50] Final Prec@1 57.0400%\u001b[0m\n",
            "[2024-04-02 21:01:47] \u001b[32mEpoch 32 LR 0.007178\u001b[0m\n",
            "[2024-04-02 21:01:52] \u001b[32mTrain: [ 33/50] Step 000/520 Loss 2.006 Prec@(1,5) (59.4%, 85.4%)\u001b[0m\n",
            "[2024-04-02 21:01:53] \u001b[32mTrain: [ 33/50] Step 020/520 Loss 1.888 Prec@(1,5) (62.1%, 87.4%)\u001b[0m\n",
            "[2024-04-02 21:01:53] \u001b[32mTrain: [ 33/50] Step 040/520 Loss 1.908 Prec@(1,5) (61.5%, 87.0%)\u001b[0m\n",
            "[2024-04-02 21:01:54] \u001b[32mTrain: [ 33/50] Step 060/520 Loss 1.935 Prec@(1,5) (61.0%, 87.0%)\u001b[0m\n",
            "[2024-04-02 21:01:54] \u001b[32mTrain: [ 33/50] Step 080/520 Loss 1.940 Prec@(1,5) (60.6%, 86.9%)\u001b[0m\n",
            "[2024-04-02 21:01:55] \u001b[32mTrain: [ 33/50] Step 100/520 Loss 1.923 Prec@(1,5) (60.7%, 87.3%)\u001b[0m\n",
            "[2024-04-02 21:01:55] \u001b[32mTrain: [ 33/50] Step 120/520 Loss 1.923 Prec@(1,5) (61.0%, 87.3%)\u001b[0m\n",
            "[2024-04-02 21:01:56] \u001b[32mTrain: [ 33/50] Step 140/520 Loss 1.924 Prec@(1,5) (60.9%, 87.3%)\u001b[0m\n",
            "[2024-04-02 21:01:56] \u001b[32mTrain: [ 33/50] Step 160/520 Loss 1.933 Prec@(1,5) (60.7%, 87.1%)\u001b[0m\n",
            "[2024-04-02 21:01:57] \u001b[32mTrain: [ 33/50] Step 180/520 Loss 1.933 Prec@(1,5) (60.9%, 87.1%)\u001b[0m\n",
            "[2024-04-02 21:01:57] \u001b[32mTrain: [ 33/50] Step 200/520 Loss 1.934 Prec@(1,5) (60.9%, 87.2%)\u001b[0m\n",
            "[2024-04-02 21:01:58] \u001b[32mTrain: [ 33/50] Step 220/520 Loss 1.935 Prec@(1,5) (60.9%, 87.2%)\u001b[0m\n",
            "[2024-04-02 21:01:58] \u001b[32mTrain: [ 33/50] Step 240/520 Loss 1.935 Prec@(1,5) (61.0%, 87.2%)\u001b[0m\n",
            "[2024-04-02 21:01:58] \u001b[32mTrain: [ 33/50] Step 260/520 Loss 1.935 Prec@(1,5) (60.9%, 87.3%)\u001b[0m\n",
            "[2024-04-02 21:01:59] \u001b[32mTrain: [ 33/50] Step 280/520 Loss 1.943 Prec@(1,5) (60.8%, 87.2%)\u001b[0m\n",
            "[2024-04-02 21:01:59] \u001b[32mTrain: [ 33/50] Step 300/520 Loss 1.941 Prec@(1,5) (60.9%, 87.3%)\u001b[0m\n",
            "[2024-04-02 21:02:00] \u001b[32mTrain: [ 33/50] Step 320/520 Loss 1.939 Prec@(1,5) (60.9%, 87.3%)\u001b[0m\n",
            "[2024-04-02 21:02:00] \u001b[32mTrain: [ 33/50] Step 340/520 Loss 1.943 Prec@(1,5) (60.8%, 87.2%)\u001b[0m\n",
            "[2024-04-02 21:02:01] \u001b[32mTrain: [ 33/50] Step 360/520 Loss 1.942 Prec@(1,5) (60.9%, 87.3%)\u001b[0m\n",
            "[2024-04-02 21:02:01] \u001b[32mTrain: [ 33/50] Step 380/520 Loss 1.943 Prec@(1,5) (60.8%, 87.2%)\u001b[0m\n",
            "[2024-04-02 21:02:02] \u001b[32mTrain: [ 33/50] Step 400/520 Loss 1.942 Prec@(1,5) (60.8%, 87.2%)\u001b[0m\n",
            "[2024-04-02 21:02:02] \u001b[32mTrain: [ 33/50] Step 420/520 Loss 1.944 Prec@(1,5) (60.8%, 87.2%)\u001b[0m\n",
            "[2024-04-02 21:02:03] \u001b[32mTrain: [ 33/50] Step 440/520 Loss 1.946 Prec@(1,5) (60.8%, 87.2%)\u001b[0m\n",
            "[2024-04-02 21:02:03] \u001b[32mTrain: [ 33/50] Step 460/520 Loss 1.948 Prec@(1,5) (60.8%, 87.1%)\u001b[0m\n",
            "[2024-04-02 21:02:04] \u001b[32mTrain: [ 33/50] Step 480/520 Loss 1.949 Prec@(1,5) (60.8%, 87.1%)\u001b[0m\n",
            "[2024-04-02 21:02:04] \u001b[32mTrain: [ 33/50] Step 500/520 Loss 1.950 Prec@(1,5) (60.8%, 87.1%)\u001b[0m\n",
            "[2024-04-02 21:02:05] \u001b[32mTrain: [ 33/50] Step 520/520 Loss 1.949 Prec@(1,5) (60.8%, 87.1%)\u001b[0m\n",
            "[2024-04-02 21:02:05] \u001b[32mTrain: [ 33/50] Final Prec@1 60.8060%\u001b[0m\n",
            "[2024-04-02 21:02:09] \u001b[32mValid: [ 33/50] Step 000/104 Loss 2.230 Prec@(1,5) (61.5%, 83.3%)\u001b[0m\n",
            "[2024-04-02 21:02:09] \u001b[32mValid: [ 33/50] Step 020/104 Loss 2.186 Prec@(1,5) (56.2%, 83.9%)\u001b[0m\n",
            "[2024-04-02 21:02:09] \u001b[32mValid: [ 33/50] Step 040/104 Loss 2.187 Prec@(1,5) (55.8%, 83.7%)\u001b[0m\n",
            "[2024-04-02 21:02:09] \u001b[32mValid: [ 33/50] Step 060/104 Loss 2.132 Prec@(1,5) (56.3%, 84.1%)\u001b[0m\n",
            "[2024-04-02 21:02:09] \u001b[32mValid: [ 33/50] Step 080/104 Loss 2.132 Prec@(1,5) (56.3%, 84.3%)\u001b[0m\n",
            "[2024-04-02 21:02:09] \u001b[32mValid: [ 33/50] Step 100/104 Loss 2.107 Prec@(1,5) (56.6%, 84.4%)\u001b[0m\n",
            "[2024-04-02 21:02:09] \u001b[32mValid: [ 33/50] Step 104/104 Loss 2.107 Prec@(1,5) (56.4%, 84.4%)\u001b[0m\n",
            "[2024-04-02 21:02:10] \u001b[32mValid: [ 33/50] Final Prec@1 56.4300%\u001b[0m\n",
            "[2024-04-02 21:02:10] \u001b[32mEpoch 33 LR 0.006479\u001b[0m\n",
            "[2024-04-02 21:02:14] \u001b[32mTrain: [ 34/50] Step 000/520 Loss 1.654 Prec@(1,5) (68.8%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:02:15] \u001b[32mTrain: [ 34/50] Step 020/520 Loss 1.880 Prec@(1,5) (61.1%, 87.5%)\u001b[0m\n",
            "[2024-04-02 21:02:15] \u001b[32mTrain: [ 34/50] Step 040/520 Loss 1.889 Prec@(1,5) (61.6%, 87.2%)\u001b[0m\n",
            "[2024-04-02 21:02:16] \u001b[32mTrain: [ 34/50] Step 060/520 Loss 1.888 Prec@(1,5) (61.5%, 87.2%)\u001b[0m\n",
            "[2024-04-02 21:02:16] \u001b[32mTrain: [ 34/50] Step 080/520 Loss 1.894 Prec@(1,5) (62.0%, 87.2%)\u001b[0m\n",
            "[2024-04-02 21:02:17] \u001b[32mTrain: [ 34/50] Step 100/520 Loss 1.899 Prec@(1,5) (62.0%, 87.3%)\u001b[0m\n",
            "[2024-04-02 21:02:17] \u001b[32mTrain: [ 34/50] Step 120/520 Loss 1.902 Prec@(1,5) (61.8%, 87.3%)\u001b[0m\n",
            "[2024-04-02 21:02:18] \u001b[32mTrain: [ 34/50] Step 140/520 Loss 1.902 Prec@(1,5) (61.7%, 87.4%)\u001b[0m\n",
            "[2024-04-02 21:02:18] \u001b[32mTrain: [ 34/50] Step 160/520 Loss 1.908 Prec@(1,5) (61.6%, 87.4%)\u001b[0m\n",
            "[2024-04-02 21:02:19] \u001b[32mTrain: [ 34/50] Step 180/520 Loss 1.910 Prec@(1,5) (61.5%, 87.4%)\u001b[0m\n",
            "[2024-04-02 21:02:19] \u001b[32mTrain: [ 34/50] Step 200/520 Loss 1.915 Prec@(1,5) (61.4%, 87.3%)\u001b[0m\n",
            "[2024-04-02 21:02:20] \u001b[32mTrain: [ 34/50] Step 220/520 Loss 1.917 Prec@(1,5) (61.4%, 87.2%)\u001b[0m\n",
            "[2024-04-02 21:02:20] \u001b[32mTrain: [ 34/50] Step 240/520 Loss 1.922 Prec@(1,5) (61.4%, 87.2%)\u001b[0m\n",
            "[2024-04-02 21:02:21] \u001b[32mTrain: [ 34/50] Step 260/520 Loss 1.924 Prec@(1,5) (61.3%, 87.2%)\u001b[0m\n",
            "[2024-04-02 21:02:21] \u001b[32mTrain: [ 34/50] Step 280/520 Loss 1.921 Prec@(1,5) (61.3%, 87.2%)\u001b[0m\n",
            "[2024-04-02 21:02:22] \u001b[32mTrain: [ 34/50] Step 300/520 Loss 1.921 Prec@(1,5) (61.3%, 87.3%)\u001b[0m\n",
            "[2024-04-02 21:02:22] \u001b[32mTrain: [ 34/50] Step 320/520 Loss 1.919 Prec@(1,5) (61.3%, 87.3%)\u001b[0m\n",
            "[2024-04-02 21:02:23] \u001b[32mTrain: [ 34/50] Step 340/520 Loss 1.922 Prec@(1,5) (61.3%, 87.3%)\u001b[0m\n",
            "[2024-04-02 21:02:23] \u001b[32mTrain: [ 34/50] Step 360/520 Loss 1.923 Prec@(1,5) (61.2%, 87.3%)\u001b[0m\n",
            "[2024-04-02 21:02:24] \u001b[32mTrain: [ 34/50] Step 380/520 Loss 1.924 Prec@(1,5) (61.3%, 87.2%)\u001b[0m\n",
            "[2024-04-02 21:02:24] \u001b[32mTrain: [ 34/50] Step 400/520 Loss 1.920 Prec@(1,5) (61.4%, 87.3%)\u001b[0m\n",
            "[2024-04-02 21:02:25] \u001b[32mTrain: [ 34/50] Step 420/520 Loss 1.919 Prec@(1,5) (61.4%, 87.4%)\u001b[0m\n",
            "[2024-04-02 21:02:25] \u001b[32mTrain: [ 34/50] Step 440/520 Loss 1.925 Prec@(1,5) (61.3%, 87.3%)\u001b[0m\n",
            "[2024-04-02 21:02:25] \u001b[32mTrain: [ 34/50] Step 460/520 Loss 1.924 Prec@(1,5) (61.2%, 87.4%)\u001b[0m\n",
            "[2024-04-02 21:02:26] \u001b[32mTrain: [ 34/50] Step 480/520 Loss 1.922 Prec@(1,5) (61.2%, 87.3%)\u001b[0m\n",
            "[2024-04-02 21:02:26] \u001b[32mTrain: [ 34/50] Step 500/520 Loss 1.921 Prec@(1,5) (61.2%, 87.3%)\u001b[0m\n",
            "[2024-04-02 21:02:27] \u001b[32mTrain: [ 34/50] Step 520/520 Loss 1.920 Prec@(1,5) (61.2%, 87.4%)\u001b[0m\n",
            "[2024-04-02 21:02:27] \u001b[32mTrain: [ 34/50] Final Prec@1 61.2040%\u001b[0m\n",
            "[2024-04-02 21:02:31] \u001b[32mValid: [ 34/50] Step 000/104 Loss 2.098 Prec@(1,5) (64.6%, 82.3%)\u001b[0m\n",
            "[2024-04-02 21:02:31] \u001b[32mValid: [ 34/50] Step 020/104 Loss 2.072 Prec@(1,5) (58.4%, 85.0%)\u001b[0m\n",
            "[2024-04-02 21:02:31] \u001b[32mValid: [ 34/50] Step 040/104 Loss 2.050 Prec@(1,5) (57.6%, 84.8%)\u001b[0m\n",
            "[2024-04-02 21:02:31] \u001b[32mValid: [ 34/50] Step 060/104 Loss 1.995 Prec@(1,5) (57.9%, 85.1%)\u001b[0m\n",
            "[2024-04-02 21:02:31] \u001b[32mValid: [ 34/50] Step 080/104 Loss 2.006 Prec@(1,5) (57.6%, 85.0%)\u001b[0m\n",
            "[2024-04-02 21:02:31] \u001b[32mValid: [ 34/50] Step 100/104 Loss 1.986 Prec@(1,5) (57.8%, 85.1%)\u001b[0m\n",
            "[2024-04-02 21:02:32] \u001b[32mValid: [ 34/50] Step 104/104 Loss 1.987 Prec@(1,5) (57.7%, 85.0%)\u001b[0m\n",
            "[2024-04-02 21:02:32] \u001b[32mValid: [ 34/50] Final Prec@1 57.7200%\u001b[0m\n",
            "[2024-04-02 21:02:32] \u001b[32mEpoch 34 LR 0.005803\u001b[0m\n",
            "[2024-04-02 21:02:36] \u001b[32mTrain: [ 35/50] Step 000/520 Loss 1.935 Prec@(1,5) (61.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 21:02:37] \u001b[32mTrain: [ 35/50] Step 020/520 Loss 1.859 Prec@(1,5) (62.6%, 88.0%)\u001b[0m\n",
            "[2024-04-02 21:02:37] \u001b[32mTrain: [ 35/50] Step 040/520 Loss 1.843 Prec@(1,5) (63.3%, 88.3%)\u001b[0m\n",
            "[2024-04-02 21:02:38] \u001b[32mTrain: [ 35/50] Step 060/520 Loss 1.848 Prec@(1,5) (63.1%, 87.9%)\u001b[0m\n",
            "[2024-04-02 21:02:38] \u001b[32mTrain: [ 35/50] Step 080/520 Loss 1.827 Prec@(1,5) (63.4%, 88.3%)\u001b[0m\n",
            "[2024-04-02 21:02:39] \u001b[32mTrain: [ 35/50] Step 100/520 Loss 1.839 Prec@(1,5) (63.3%, 88.1%)\u001b[0m\n",
            "[2024-04-02 21:02:39] \u001b[32mTrain: [ 35/50] Step 120/520 Loss 1.848 Prec@(1,5) (63.0%, 88.0%)\u001b[0m\n",
            "[2024-04-02 21:02:40] \u001b[32mTrain: [ 35/50] Step 140/520 Loss 1.861 Prec@(1,5) (62.9%, 87.7%)\u001b[0m\n",
            "[2024-04-02 21:02:41] \u001b[32mTrain: [ 35/50] Step 160/520 Loss 1.864 Prec@(1,5) (62.8%, 87.7%)\u001b[0m\n",
            "[2024-04-02 21:02:41] \u001b[32mTrain: [ 35/50] Step 180/520 Loss 1.867 Prec@(1,5) (62.8%, 87.7%)\u001b[0m\n",
            "[2024-04-02 21:02:42] \u001b[32mTrain: [ 35/50] Step 200/520 Loss 1.871 Prec@(1,5) (62.8%, 87.7%)\u001b[0m\n",
            "[2024-04-02 21:02:42] \u001b[32mTrain: [ 35/50] Step 220/520 Loss 1.874 Prec@(1,5) (62.5%, 87.7%)\u001b[0m\n",
            "[2024-04-02 21:02:43] \u001b[32mTrain: [ 35/50] Step 240/520 Loss 1.884 Prec@(1,5) (62.3%, 87.7%)\u001b[0m\n",
            "[2024-04-02 21:02:43] \u001b[32mTrain: [ 35/50] Step 260/520 Loss 1.885 Prec@(1,5) (62.3%, 87.6%)\u001b[0m\n",
            "[2024-04-02 21:02:44] \u001b[32mTrain: [ 35/50] Step 280/520 Loss 1.890 Prec@(1,5) (62.1%, 87.6%)\u001b[0m\n",
            "[2024-04-02 21:02:44] \u001b[32mTrain: [ 35/50] Step 300/520 Loss 1.894 Prec@(1,5) (62.1%, 87.6%)\u001b[0m\n",
            "[2024-04-02 21:02:45] \u001b[32mTrain: [ 35/50] Step 320/520 Loss 1.895 Prec@(1,5) (62.0%, 87.6%)\u001b[0m\n",
            "[2024-04-02 21:02:45] \u001b[32mTrain: [ 35/50] Step 340/520 Loss 1.898 Prec@(1,5) (62.1%, 87.6%)\u001b[0m\n",
            "[2024-04-02 21:02:46] \u001b[32mTrain: [ 35/50] Step 360/520 Loss 1.899 Prec@(1,5) (62.0%, 87.6%)\u001b[0m\n",
            "[2024-04-02 21:02:46] \u001b[32mTrain: [ 35/50] Step 380/520 Loss 1.899 Prec@(1,5) (62.0%, 87.5%)\u001b[0m\n",
            "[2024-04-02 21:02:47] \u001b[32mTrain: [ 35/50] Step 400/520 Loss 1.896 Prec@(1,5) (62.0%, 87.6%)\u001b[0m\n",
            "[2024-04-02 21:02:47] \u001b[32mTrain: [ 35/50] Step 420/520 Loss 1.899 Prec@(1,5) (61.9%, 87.6%)\u001b[0m\n",
            "[2024-04-02 21:02:48] \u001b[32mTrain: [ 35/50] Step 440/520 Loss 1.898 Prec@(1,5) (62.0%, 87.6%)\u001b[0m\n",
            "[2024-04-02 21:02:48] \u001b[32mTrain: [ 35/50] Step 460/520 Loss 1.898 Prec@(1,5) (61.9%, 87.6%)\u001b[0m\n",
            "[2024-04-02 21:02:49] \u001b[32mTrain: [ 35/50] Step 480/520 Loss 1.895 Prec@(1,5) (62.0%, 87.6%)\u001b[0m\n",
            "[2024-04-02 21:02:49] \u001b[32mTrain: [ 35/50] Step 500/520 Loss 1.897 Prec@(1,5) (61.9%, 87.6%)\u001b[0m\n",
            "[2024-04-02 21:02:50] \u001b[32mTrain: [ 35/50] Step 520/520 Loss 1.898 Prec@(1,5) (61.8%, 87.6%)\u001b[0m\n",
            "[2024-04-02 21:02:50] \u001b[32mTrain: [ 35/50] Final Prec@1 61.8320%\u001b[0m\n",
            "[2024-04-02 21:02:53] \u001b[32mValid: [ 35/50] Step 000/104 Loss 1.943 Prec@(1,5) (61.5%, 85.4%)\u001b[0m\n",
            "[2024-04-02 21:02:54] \u001b[32mValid: [ 35/50] Step 020/104 Loss 2.032 Prec@(1,5) (58.4%, 84.8%)\u001b[0m\n",
            "[2024-04-02 21:02:54] \u001b[32mValid: [ 35/50] Step 040/104 Loss 1.996 Prec@(1,5) (57.9%, 84.9%)\u001b[0m\n",
            "[2024-04-02 21:02:54] \u001b[32mValid: [ 35/50] Step 060/104 Loss 1.940 Prec@(1,5) (58.4%, 85.4%)\u001b[0m\n",
            "[2024-04-02 21:02:54] \u001b[32mValid: [ 35/50] Step 080/104 Loss 1.945 Prec@(1,5) (58.0%, 85.4%)\u001b[0m\n",
            "[2024-04-02 21:02:54] \u001b[32mValid: [ 35/50] Step 100/104 Loss 1.924 Prec@(1,5) (58.3%, 85.6%)\u001b[0m\n",
            "[2024-04-02 21:02:54] \u001b[32mValid: [ 35/50] Step 104/104 Loss 1.924 Prec@(1,5) (58.3%, 85.5%)\u001b[0m\n",
            "[2024-04-02 21:02:54] \u001b[32mValid: [ 35/50] Final Prec@1 58.3300%\u001b[0m\n",
            "[2024-04-02 21:02:54] \u001b[32mEpoch 35 LR 0.005153\u001b[0m\n",
            "[2024-04-02 21:02:59] \u001b[32mTrain: [ 36/50] Step 000/520 Loss 1.656 Prec@(1,5) (67.7%, 92.7%)\u001b[0m\n",
            "[2024-04-02 21:03:00] \u001b[32mTrain: [ 36/50] Step 020/520 Loss 1.840 Prec@(1,5) (62.1%, 88.1%)\u001b[0m\n",
            "[2024-04-02 21:03:00] \u001b[32mTrain: [ 36/50] Step 040/520 Loss 1.832 Prec@(1,5) (62.2%, 87.9%)\u001b[0m\n",
            "[2024-04-02 21:03:01] \u001b[32mTrain: [ 36/50] Step 060/520 Loss 1.817 Prec@(1,5) (62.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 21:03:01] \u001b[32mTrain: [ 36/50] Step 080/520 Loss 1.825 Prec@(1,5) (62.2%, 88.5%)\u001b[0m\n",
            "[2024-04-02 21:03:02] \u001b[32mTrain: [ 36/50] Step 100/520 Loss 1.826 Prec@(1,5) (62.2%, 88.5%)\u001b[0m\n",
            "[2024-04-02 21:03:02] \u001b[32mTrain: [ 36/50] Step 120/520 Loss 1.829 Prec@(1,5) (62.4%, 88.5%)\u001b[0m\n",
            "[2024-04-02 21:03:03] \u001b[32mTrain: [ 36/50] Step 140/520 Loss 1.840 Prec@(1,5) (62.3%, 88.3%)\u001b[0m\n",
            "[2024-04-02 21:03:03] \u001b[32mTrain: [ 36/50] Step 160/520 Loss 1.846 Prec@(1,5) (62.3%, 88.3%)\u001b[0m\n",
            "[2024-04-02 21:03:04] \u001b[32mTrain: [ 36/50] Step 180/520 Loss 1.845 Prec@(1,5) (62.5%, 88.3%)\u001b[0m\n",
            "[2024-04-02 21:03:04] \u001b[32mTrain: [ 36/50] Step 200/520 Loss 1.848 Prec@(1,5) (62.4%, 88.2%)\u001b[0m\n",
            "[2024-04-02 21:03:05] \u001b[32mTrain: [ 36/50] Step 220/520 Loss 1.849 Prec@(1,5) (62.3%, 88.2%)\u001b[0m\n",
            "[2024-04-02 21:03:05] \u001b[32mTrain: [ 36/50] Step 240/520 Loss 1.848 Prec@(1,5) (62.4%, 88.2%)\u001b[0m\n",
            "[2024-04-02 21:03:06] \u001b[32mTrain: [ 36/50] Step 260/520 Loss 1.847 Prec@(1,5) (62.5%, 88.2%)\u001b[0m\n",
            "[2024-04-02 21:03:06] \u001b[32mTrain: [ 36/50] Step 280/520 Loss 1.843 Prec@(1,5) (62.5%, 88.2%)\u001b[0m\n",
            "[2024-04-02 21:03:07] \u001b[32mTrain: [ 36/50] Step 300/520 Loss 1.848 Prec@(1,5) (62.5%, 88.2%)\u001b[0m\n",
            "[2024-04-02 21:03:07] \u001b[32mTrain: [ 36/50] Step 320/520 Loss 1.852 Prec@(1,5) (62.4%, 88.2%)\u001b[0m\n",
            "[2024-04-02 21:03:08] \u001b[32mTrain: [ 36/50] Step 340/520 Loss 1.854 Prec@(1,5) (62.3%, 88.2%)\u001b[0m\n",
            "[2024-04-02 21:03:08] \u001b[32mTrain: [ 36/50] Step 360/520 Loss 1.858 Prec@(1,5) (62.3%, 88.1%)\u001b[0m\n",
            "[2024-04-02 21:03:09] \u001b[32mTrain: [ 36/50] Step 380/520 Loss 1.857 Prec@(1,5) (62.2%, 88.1%)\u001b[0m\n",
            "[2024-04-02 21:03:09] \u001b[32mTrain: [ 36/50] Step 400/520 Loss 1.861 Prec@(1,5) (62.2%, 88.0%)\u001b[0m\n",
            "[2024-04-02 21:03:10] \u001b[32mTrain: [ 36/50] Step 420/520 Loss 1.859 Prec@(1,5) (62.2%, 88.0%)\u001b[0m\n",
            "[2024-04-02 21:03:10] \u001b[32mTrain: [ 36/50] Step 440/520 Loss 1.860 Prec@(1,5) (62.2%, 88.0%)\u001b[0m\n",
            "[2024-04-02 21:03:11] \u001b[32mTrain: [ 36/50] Step 460/520 Loss 1.860 Prec@(1,5) (62.1%, 88.1%)\u001b[0m\n",
            "[2024-04-02 21:03:11] \u001b[32mTrain: [ 36/50] Step 480/520 Loss 1.863 Prec@(1,5) (62.1%, 88.0%)\u001b[0m\n",
            "[2024-04-02 21:03:12] \u001b[32mTrain: [ 36/50] Step 500/520 Loss 1.865 Prec@(1,5) (62.0%, 88.0%)\u001b[0m\n",
            "[2024-04-02 21:03:12] \u001b[32mTrain: [ 36/50] Step 520/520 Loss 1.866 Prec@(1,5) (62.0%, 88.0%)\u001b[0m\n",
            "[2024-04-02 21:03:12] \u001b[32mTrain: [ 36/50] Final Prec@1 61.9880%\u001b[0m\n",
            "[2024-04-02 21:03:16] \u001b[32mValid: [ 36/50] Step 000/104 Loss 1.980 Prec@(1,5) (62.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 21:03:16] \u001b[32mValid: [ 36/50] Step 020/104 Loss 2.064 Prec@(1,5) (58.3%, 85.7%)\u001b[0m\n",
            "[2024-04-02 21:03:16] \u001b[32mValid: [ 36/50] Step 040/104 Loss 2.050 Prec@(1,5) (57.5%, 85.5%)\u001b[0m\n",
            "[2024-04-02 21:03:16] \u001b[32mValid: [ 36/50] Step 060/104 Loss 2.003 Prec@(1,5) (57.7%, 85.8%)\u001b[0m\n",
            "[2024-04-02 21:03:16] \u001b[32mValid: [ 36/50] Step 080/104 Loss 2.003 Prec@(1,5) (57.6%, 85.6%)\u001b[0m\n",
            "[2024-04-02 21:03:17] \u001b[32mValid: [ 36/50] Step 100/104 Loss 1.981 Prec@(1,5) (58.0%, 85.9%)\u001b[0m\n",
            "[2024-04-02 21:03:17] \u001b[32mValid: [ 36/50] Step 104/104 Loss 1.981 Prec@(1,5) (58.0%, 85.9%)\u001b[0m\n",
            "[2024-04-02 21:03:17] \u001b[32mValid: [ 36/50] Final Prec@1 57.9900%\u001b[0m\n",
            "[2024-04-02 21:03:17] \u001b[32mEpoch 36 LR 0.004533\u001b[0m\n",
            "[2024-04-02 21:03:21] \u001b[32mTrain: [ 37/50] Step 000/520 Loss 1.893 Prec@(1,5) (60.4%, 87.5%)\u001b[0m\n",
            "[2024-04-02 21:03:22] \u001b[32mTrain: [ 37/50] Step 020/520 Loss 1.831 Prec@(1,5) (62.9%, 88.9%)\u001b[0m\n",
            "[2024-04-02 21:03:22] \u001b[32mTrain: [ 37/50] Step 040/520 Loss 1.849 Prec@(1,5) (61.6%, 88.7%)\u001b[0m\n",
            "[2024-04-02 21:03:23] \u001b[32mTrain: [ 37/50] Step 060/520 Loss 1.849 Prec@(1,5) (62.1%, 88.6%)\u001b[0m\n",
            "[2024-04-02 21:03:23] \u001b[32mTrain: [ 37/50] Step 080/520 Loss 1.837 Prec@(1,5) (62.6%, 88.7%)\u001b[0m\n",
            "[2024-04-02 21:03:24] \u001b[32mTrain: [ 37/50] Step 100/520 Loss 1.828 Prec@(1,5) (62.9%, 88.8%)\u001b[0m\n",
            "[2024-04-02 21:03:24] \u001b[32mTrain: [ 37/50] Step 120/520 Loss 1.816 Prec@(1,5) (63.2%, 88.8%)\u001b[0m\n",
            "[2024-04-02 21:03:25] \u001b[32mTrain: [ 37/50] Step 140/520 Loss 1.815 Prec@(1,5) (63.3%, 88.8%)\u001b[0m\n",
            "[2024-04-02 21:03:25] \u001b[32mTrain: [ 37/50] Step 160/520 Loss 1.819 Prec@(1,5) (63.2%, 88.8%)\u001b[0m\n",
            "[2024-04-02 21:03:26] \u001b[32mTrain: [ 37/50] Step 180/520 Loss 1.826 Prec@(1,5) (63.1%, 88.7%)\u001b[0m\n",
            "[2024-04-02 21:03:26] \u001b[32mTrain: [ 37/50] Step 200/520 Loss 1.820 Prec@(1,5) (63.1%, 88.7%)\u001b[0m\n",
            "[2024-04-02 21:03:27] \u001b[32mTrain: [ 37/50] Step 220/520 Loss 1.830 Prec@(1,5) (62.9%, 88.6%)\u001b[0m\n",
            "[2024-04-02 21:03:27] \u001b[32mTrain: [ 37/50] Step 240/520 Loss 1.833 Prec@(1,5) (62.7%, 88.6%)\u001b[0m\n",
            "[2024-04-02 21:03:28] \u001b[32mTrain: [ 37/50] Step 260/520 Loss 1.837 Prec@(1,5) (62.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 21:03:28] \u001b[32mTrain: [ 37/50] Step 280/520 Loss 1.836 Prec@(1,5) (62.8%, 88.5%)\u001b[0m\n",
            "[2024-04-02 21:03:29] \u001b[32mTrain: [ 37/50] Step 300/520 Loss 1.838 Prec@(1,5) (62.7%, 88.4%)\u001b[0m\n",
            "[2024-04-02 21:03:29] \u001b[32mTrain: [ 37/50] Step 320/520 Loss 1.835 Prec@(1,5) (62.8%, 88.4%)\u001b[0m\n",
            "[2024-04-02 21:03:30] \u001b[32mTrain: [ 37/50] Step 340/520 Loss 1.834 Prec@(1,5) (62.8%, 88.5%)\u001b[0m\n",
            "[2024-04-02 21:03:30] \u001b[32mTrain: [ 37/50] Step 360/520 Loss 1.834 Prec@(1,5) (62.8%, 88.5%)\u001b[0m\n",
            "[2024-04-02 21:03:31] \u001b[32mTrain: [ 37/50] Step 380/520 Loss 1.834 Prec@(1,5) (62.9%, 88.5%)\u001b[0m\n",
            "[2024-04-02 21:03:31] \u001b[32mTrain: [ 37/50] Step 400/520 Loss 1.833 Prec@(1,5) (62.9%, 88.4%)\u001b[0m\n",
            "[2024-04-02 21:03:32] \u001b[32mTrain: [ 37/50] Step 420/520 Loss 1.832 Prec@(1,5) (62.9%, 88.4%)\u001b[0m\n",
            "[2024-04-02 21:03:32] \u001b[32mTrain: [ 37/50] Step 440/520 Loss 1.835 Prec@(1,5) (62.9%, 88.4%)\u001b[0m\n",
            "[2024-04-02 21:03:33] \u001b[32mTrain: [ 37/50] Step 460/520 Loss 1.836 Prec@(1,5) (62.9%, 88.4%)\u001b[0m\n",
            "[2024-04-02 21:03:33] \u001b[32mTrain: [ 37/50] Step 480/520 Loss 1.839 Prec@(1,5) (62.8%, 88.3%)\u001b[0m\n",
            "[2024-04-02 21:03:34] \u001b[32mTrain: [ 37/50] Step 500/520 Loss 1.840 Prec@(1,5) (62.8%, 88.3%)\u001b[0m\n",
            "[2024-04-02 21:03:34] \u001b[32mTrain: [ 37/50] Step 520/520 Loss 1.845 Prec@(1,5) (62.7%, 88.3%)\u001b[0m\n",
            "[2024-04-02 21:03:34] \u001b[32mTrain: [ 37/50] Final Prec@1 62.6840%\u001b[0m\n",
            "[2024-04-02 21:03:38] \u001b[32mValid: [ 37/50] Step 000/104 Loss 1.934 Prec@(1,5) (63.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 21:03:38] \u001b[32mValid: [ 37/50] Step 020/104 Loss 1.960 Prec@(1,5) (59.8%, 86.3%)\u001b[0m\n",
            "[2024-04-02 21:03:38] \u001b[32mValid: [ 37/50] Step 040/104 Loss 1.932 Prec@(1,5) (59.2%, 86.3%)\u001b[0m\n",
            "[2024-04-02 21:03:38] \u001b[32mValid: [ 37/50] Step 060/104 Loss 1.899 Prec@(1,5) (59.2%, 86.4%)\u001b[0m\n",
            "[2024-04-02 21:03:38] \u001b[32mValid: [ 37/50] Step 080/104 Loss 1.897 Prec@(1,5) (59.1%, 86.4%)\u001b[0m\n",
            "[2024-04-02 21:03:39] \u001b[32mValid: [ 37/50] Step 100/104 Loss 1.874 Prec@(1,5) (59.5%, 86.7%)\u001b[0m\n",
            "[2024-04-02 21:03:39] \u001b[32mValid: [ 37/50] Step 104/104 Loss 1.877 Prec@(1,5) (59.5%, 86.7%)\u001b[0m\n",
            "[2024-04-02 21:03:39] \u001b[32mValid: [ 37/50] Final Prec@1 59.4600%\u001b[0m\n",
            "[2024-04-02 21:03:39] \u001b[32mEpoch 37 LR 0.003944\u001b[0m\n",
            "[2024-04-02 21:03:43] \u001b[32mTrain: [ 38/50] Step 000/520 Loss 2.032 Prec@(1,5) (57.3%, 80.2%)\u001b[0m\n",
            "[2024-04-02 21:03:44] \u001b[32mTrain: [ 38/50] Step 020/520 Loss 1.761 Prec@(1,5) (64.5%, 88.8%)\u001b[0m\n",
            "[2024-04-02 21:03:44] \u001b[32mTrain: [ 38/50] Step 040/520 Loss 1.808 Prec@(1,5) (63.5%, 88.5%)\u001b[0m\n",
            "[2024-04-02 21:03:45] \u001b[32mTrain: [ 38/50] Step 060/520 Loss 1.815 Prec@(1,5) (63.4%, 88.5%)\u001b[0m\n",
            "[2024-04-02 21:03:45] \u001b[32mTrain: [ 38/50] Step 080/520 Loss 1.828 Prec@(1,5) (63.2%, 88.6%)\u001b[0m\n",
            "[2024-04-02 21:03:46] \u001b[32mTrain: [ 38/50] Step 100/520 Loss 1.828 Prec@(1,5) (63.2%, 88.5%)\u001b[0m\n",
            "[2024-04-02 21:03:46] \u001b[32mTrain: [ 38/50] Step 120/520 Loss 1.826 Prec@(1,5) (63.1%, 88.6%)\u001b[0m\n",
            "[2024-04-02 21:03:47] \u001b[32mTrain: [ 38/50] Step 140/520 Loss 1.839 Prec@(1,5) (62.9%, 88.4%)\u001b[0m\n",
            "[2024-04-02 21:03:47] \u001b[32mTrain: [ 38/50] Step 160/520 Loss 1.830 Prec@(1,5) (63.0%, 88.4%)\u001b[0m\n",
            "[2024-04-02 21:03:48] \u001b[32mTrain: [ 38/50] Step 180/520 Loss 1.816 Prec@(1,5) (63.2%, 88.4%)\u001b[0m\n",
            "[2024-04-02 21:03:48] \u001b[32mTrain: [ 38/50] Step 200/520 Loss 1.816 Prec@(1,5) (63.2%, 88.4%)\u001b[0m\n",
            "[2024-04-02 21:03:49] \u001b[32mTrain: [ 38/50] Step 220/520 Loss 1.819 Prec@(1,5) (63.1%, 88.4%)\u001b[0m\n",
            "[2024-04-02 21:03:49] \u001b[32mTrain: [ 38/50] Step 240/520 Loss 1.817 Prec@(1,5) (63.1%, 88.5%)\u001b[0m\n",
            "[2024-04-02 21:03:50] \u001b[32mTrain: [ 38/50] Step 260/520 Loss 1.814 Prec@(1,5) (63.2%, 88.5%)\u001b[0m\n",
            "[2024-04-02 21:03:50] \u001b[32mTrain: [ 38/50] Step 280/520 Loss 1.814 Prec@(1,5) (63.2%, 88.5%)\u001b[0m\n",
            "[2024-04-02 21:03:51] \u001b[32mTrain: [ 38/50] Step 300/520 Loss 1.816 Prec@(1,5) (63.2%, 88.4%)\u001b[0m\n",
            "[2024-04-02 21:03:51] \u001b[32mTrain: [ 38/50] Step 320/520 Loss 1.813 Prec@(1,5) (63.3%, 88.5%)\u001b[0m\n",
            "[2024-04-02 21:03:52] \u001b[32mTrain: [ 38/50] Step 340/520 Loss 1.819 Prec@(1,5) (63.2%, 88.4%)\u001b[0m\n",
            "[2024-04-02 21:03:53] \u001b[32mTrain: [ 38/50] Step 360/520 Loss 1.819 Prec@(1,5) (63.1%, 88.4%)\u001b[0m\n",
            "[2024-04-02 21:03:53] \u001b[32mTrain: [ 38/50] Step 380/520 Loss 1.821 Prec@(1,5) (63.0%, 88.4%)\u001b[0m\n",
            "[2024-04-02 21:03:54] \u001b[32mTrain: [ 38/50] Step 400/520 Loss 1.820 Prec@(1,5) (63.1%, 88.4%)\u001b[0m\n",
            "[2024-04-02 21:03:54] \u001b[32mTrain: [ 38/50] Step 420/520 Loss 1.824 Prec@(1,5) (63.0%, 88.4%)\u001b[0m\n",
            "[2024-04-02 21:03:55] \u001b[32mTrain: [ 38/50] Step 440/520 Loss 1.822 Prec@(1,5) (63.0%, 88.4%)\u001b[0m\n",
            "[2024-04-02 21:03:55] \u001b[32mTrain: [ 38/50] Step 460/520 Loss 1.823 Prec@(1,5) (63.0%, 88.4%)\u001b[0m\n",
            "[2024-04-02 21:03:56] \u001b[32mTrain: [ 38/50] Step 480/520 Loss 1.822 Prec@(1,5) (63.0%, 88.4%)\u001b[0m\n",
            "[2024-04-02 21:03:56] \u001b[32mTrain: [ 38/50] Step 500/520 Loss 1.824 Prec@(1,5) (63.0%, 88.4%)\u001b[0m\n",
            "[2024-04-02 21:03:57] \u001b[32mTrain: [ 38/50] Step 520/520 Loss 1.826 Prec@(1,5) (62.9%, 88.4%)\u001b[0m\n",
            "[2024-04-02 21:03:57] \u001b[32mTrain: [ 38/50] Final Prec@1 62.9400%\u001b[0m\n",
            "[2024-04-02 21:04:00] \u001b[32mValid: [ 38/50] Step 000/104 Loss 1.815 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:04:00] \u001b[32mValid: [ 38/50] Step 020/104 Loss 2.016 Prec@(1,5) (58.7%, 85.3%)\u001b[0m\n",
            "[2024-04-02 21:04:01] \u001b[32mValid: [ 38/50] Step 040/104 Loss 1.997 Prec@(1,5) (58.6%, 85.5%)\u001b[0m\n",
            "[2024-04-02 21:04:01] \u001b[32mValid: [ 38/50] Step 060/104 Loss 1.936 Prec@(1,5) (58.7%, 85.9%)\u001b[0m\n",
            "[2024-04-02 21:04:01] \u001b[32mValid: [ 38/50] Step 080/104 Loss 1.938 Prec@(1,5) (58.5%, 85.7%)\u001b[0m\n",
            "[2024-04-02 21:04:01] \u001b[32mValid: [ 38/50] Step 100/104 Loss 1.924 Prec@(1,5) (58.7%, 85.9%)\u001b[0m\n",
            "[2024-04-02 21:04:01] \u001b[32mValid: [ 38/50] Step 104/104 Loss 1.924 Prec@(1,5) (58.7%, 85.9%)\u001b[0m\n",
            "[2024-04-02 21:04:01] \u001b[32mValid: [ 38/50] Final Prec@1 58.6600%\u001b[0m\n",
            "[2024-04-02 21:04:01] \u001b[32mEpoch 38 LR 0.003389\u001b[0m\n",
            "[2024-04-02 21:04:06] \u001b[32mTrain: [ 39/50] Step 000/520 Loss 1.994 Prec@(1,5) (68.8%, 87.5%)\u001b[0m\n",
            "[2024-04-02 21:04:06] \u001b[32mTrain: [ 39/50] Step 020/520 Loss 1.774 Prec@(1,5) (65.8%, 88.5%)\u001b[0m\n",
            "[2024-04-02 21:04:07] \u001b[32mTrain: [ 39/50] Step 040/520 Loss 1.781 Prec@(1,5) (65.1%, 89.1%)\u001b[0m\n",
            "[2024-04-02 21:04:07] \u001b[32mTrain: [ 39/50] Step 060/520 Loss 1.781 Prec@(1,5) (64.8%, 88.9%)\u001b[0m\n",
            "[2024-04-02 21:04:08] \u001b[32mTrain: [ 39/50] Step 080/520 Loss 1.754 Prec@(1,5) (65.2%, 89.3%)\u001b[0m\n",
            "[2024-04-02 21:04:08] \u001b[32mTrain: [ 39/50] Step 100/520 Loss 1.760 Prec@(1,5) (65.0%, 89.2%)\u001b[0m\n",
            "[2024-04-02 21:04:09] \u001b[32mTrain: [ 39/50] Step 120/520 Loss 1.772 Prec@(1,5) (64.5%, 89.1%)\u001b[0m\n",
            "[2024-04-02 21:04:09] \u001b[32mTrain: [ 39/50] Step 140/520 Loss 1.781 Prec@(1,5) (64.3%, 89.0%)\u001b[0m\n",
            "[2024-04-02 21:04:10] \u001b[32mTrain: [ 39/50] Step 160/520 Loss 1.783 Prec@(1,5) (64.2%, 88.8%)\u001b[0m\n",
            "[2024-04-02 21:04:10] \u001b[32mTrain: [ 39/50] Step 180/520 Loss 1.783 Prec@(1,5) (64.1%, 88.9%)\u001b[0m\n",
            "[2024-04-02 21:04:11] \u001b[32mTrain: [ 39/50] Step 200/520 Loss 1.794 Prec@(1,5) (63.8%, 88.8%)\u001b[0m\n",
            "[2024-04-02 21:04:11] \u001b[32mTrain: [ 39/50] Step 220/520 Loss 1.798 Prec@(1,5) (63.8%, 88.7%)\u001b[0m\n",
            "[2024-04-02 21:04:12] \u001b[32mTrain: [ 39/50] Step 240/520 Loss 1.794 Prec@(1,5) (63.9%, 88.7%)\u001b[0m\n",
            "[2024-04-02 21:04:12] \u001b[32mTrain: [ 39/50] Step 260/520 Loss 1.796 Prec@(1,5) (63.9%, 88.7%)\u001b[0m\n",
            "[2024-04-02 21:04:13] \u001b[32mTrain: [ 39/50] Step 280/520 Loss 1.793 Prec@(1,5) (63.9%, 88.7%)\u001b[0m\n",
            "[2024-04-02 21:04:13] \u001b[32mTrain: [ 39/50] Step 300/520 Loss 1.794 Prec@(1,5) (63.9%, 88.7%)\u001b[0m\n",
            "[2024-04-02 21:04:14] \u001b[32mTrain: [ 39/50] Step 320/520 Loss 1.791 Prec@(1,5) (64.0%, 88.7%)\u001b[0m\n",
            "[2024-04-02 21:04:14] \u001b[32mTrain: [ 39/50] Step 340/520 Loss 1.793 Prec@(1,5) (63.9%, 88.7%)\u001b[0m\n",
            "[2024-04-02 21:04:15] \u001b[32mTrain: [ 39/50] Step 360/520 Loss 1.791 Prec@(1,5) (63.9%, 88.7%)\u001b[0m\n",
            "[2024-04-02 21:04:15] \u001b[32mTrain: [ 39/50] Step 380/520 Loss 1.788 Prec@(1,5) (64.0%, 88.8%)\u001b[0m\n",
            "[2024-04-02 21:04:16] \u001b[32mTrain: [ 39/50] Step 400/520 Loss 1.788 Prec@(1,5) (63.9%, 88.8%)\u001b[0m\n",
            "[2024-04-02 21:04:16] \u001b[32mTrain: [ 39/50] Step 420/520 Loss 1.787 Prec@(1,5) (63.9%, 88.8%)\u001b[0m\n",
            "[2024-04-02 21:04:17] \u001b[32mTrain: [ 39/50] Step 440/520 Loss 1.787 Prec@(1,5) (63.9%, 88.8%)\u001b[0m\n",
            "[2024-04-02 21:04:17] \u001b[32mTrain: [ 39/50] Step 460/520 Loss 1.789 Prec@(1,5) (63.8%, 88.8%)\u001b[0m\n",
            "[2024-04-02 21:04:18] \u001b[32mTrain: [ 39/50] Step 480/520 Loss 1.792 Prec@(1,5) (63.8%, 88.8%)\u001b[0m\n",
            "[2024-04-02 21:04:18] \u001b[32mTrain: [ 39/50] Step 500/520 Loss 1.796 Prec@(1,5) (63.7%, 88.8%)\u001b[0m\n",
            "[2024-04-02 21:04:19] \u001b[32mTrain: [ 39/50] Step 520/520 Loss 1.795 Prec@(1,5) (63.7%, 88.8%)\u001b[0m\n",
            "[2024-04-02 21:04:19] \u001b[32mTrain: [ 39/50] Final Prec@1 63.7080%\u001b[0m\n",
            "[2024-04-02 21:04:22] \u001b[32mValid: [ 39/50] Step 000/104 Loss 1.851 Prec@(1,5) (63.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 21:04:22] \u001b[32mValid: [ 39/50] Step 020/104 Loss 1.963 Prec@(1,5) (60.1%, 86.4%)\u001b[0m\n",
            "[2024-04-02 21:04:23] \u001b[32mValid: [ 39/50] Step 040/104 Loss 1.939 Prec@(1,5) (59.5%, 86.3%)\u001b[0m\n",
            "[2024-04-02 21:04:23] \u001b[32mValid: [ 39/50] Step 060/104 Loss 1.887 Prec@(1,5) (59.9%, 86.5%)\u001b[0m\n",
            "[2024-04-02 21:04:23] \u001b[32mValid: [ 39/50] Step 080/104 Loss 1.886 Prec@(1,5) (59.6%, 86.4%)\u001b[0m\n",
            "[2024-04-02 21:04:23] \u001b[32mValid: [ 39/50] Step 100/104 Loss 1.866 Prec@(1,5) (59.8%, 86.6%)\u001b[0m\n",
            "[2024-04-02 21:04:23] \u001b[32mValid: [ 39/50] Step 104/104 Loss 1.868 Prec@(1,5) (59.8%, 86.6%)\u001b[0m\n",
            "[2024-04-02 21:04:23] \u001b[32mValid: [ 39/50] Final Prec@1 59.8400%\u001b[0m\n",
            "[2024-04-02 21:04:23] \u001b[32mEpoch 39 LR 0.002869\u001b[0m\n",
            "[2024-04-02 21:04:28] \u001b[32mTrain: [ 40/50] Step 000/520 Loss 1.612 Prec@(1,5) (70.8%, 92.7%)\u001b[0m\n",
            "[2024-04-02 21:04:29] \u001b[32mTrain: [ 40/50] Step 020/520 Loss 1.766 Prec@(1,5) (65.5%, 88.9%)\u001b[0m\n",
            "[2024-04-02 21:04:29] \u001b[32mTrain: [ 40/50] Step 040/520 Loss 1.784 Prec@(1,5) (65.0%, 88.3%)\u001b[0m\n",
            "[2024-04-02 21:04:30] \u001b[32mTrain: [ 40/50] Step 060/520 Loss 1.780 Prec@(1,5) (64.2%, 88.7%)\u001b[0m\n",
            "[2024-04-02 21:04:30] \u001b[32mTrain: [ 40/50] Step 080/520 Loss 1.770 Prec@(1,5) (64.3%, 88.9%)\u001b[0m\n",
            "[2024-04-02 21:04:30] \u001b[32mTrain: [ 40/50] Step 100/520 Loss 1.769 Prec@(1,5) (64.1%, 89.0%)\u001b[0m\n",
            "[2024-04-02 21:04:31] \u001b[32mTrain: [ 40/50] Step 120/520 Loss 1.771 Prec@(1,5) (63.9%, 88.9%)\u001b[0m\n",
            "[2024-04-02 21:04:31] \u001b[32mTrain: [ 40/50] Step 140/520 Loss 1.773 Prec@(1,5) (63.9%, 88.9%)\u001b[0m\n",
            "[2024-04-02 21:04:32] \u001b[32mTrain: [ 40/50] Step 160/520 Loss 1.773 Prec@(1,5) (63.9%, 88.9%)\u001b[0m\n",
            "[2024-04-02 21:04:32] \u001b[32mTrain: [ 40/50] Step 180/520 Loss 1.778 Prec@(1,5) (63.7%, 88.9%)\u001b[0m\n",
            "[2024-04-02 21:04:33] \u001b[32mTrain: [ 40/50] Step 200/520 Loss 1.779 Prec@(1,5) (63.6%, 89.0%)\u001b[0m\n",
            "[2024-04-02 21:04:33] \u001b[32mTrain: [ 40/50] Step 220/520 Loss 1.785 Prec@(1,5) (63.6%, 88.9%)\u001b[0m\n",
            "[2024-04-02 21:04:34] \u001b[32mTrain: [ 40/50] Step 240/520 Loss 1.781 Prec@(1,5) (63.6%, 88.9%)\u001b[0m\n",
            "[2024-04-02 21:04:34] \u001b[32mTrain: [ 40/50] Step 260/520 Loss 1.785 Prec@(1,5) (63.6%, 88.9%)\u001b[0m\n",
            "[2024-04-02 21:04:35] \u001b[32mTrain: [ 40/50] Step 280/520 Loss 1.787 Prec@(1,5) (63.5%, 88.8%)\u001b[0m\n",
            "[2024-04-02 21:04:35] \u001b[32mTrain: [ 40/50] Step 300/520 Loss 1.789 Prec@(1,5) (63.5%, 88.7%)\u001b[0m\n",
            "[2024-04-02 21:04:36] \u001b[32mTrain: [ 40/50] Step 320/520 Loss 1.791 Prec@(1,5) (63.5%, 88.7%)\u001b[0m\n",
            "[2024-04-02 21:04:36] \u001b[32mTrain: [ 40/50] Step 340/520 Loss 1.792 Prec@(1,5) (63.5%, 88.7%)\u001b[0m\n",
            "[2024-04-02 21:04:37] \u001b[32mTrain: [ 40/50] Step 360/520 Loss 1.790 Prec@(1,5) (63.5%, 88.8%)\u001b[0m\n",
            "[2024-04-02 21:04:37] \u001b[32mTrain: [ 40/50] Step 380/520 Loss 1.789 Prec@(1,5) (63.5%, 88.8%)\u001b[0m\n",
            "[2024-04-02 21:04:38] \u001b[32mTrain: [ 40/50] Step 400/520 Loss 1.790 Prec@(1,5) (63.5%, 88.7%)\u001b[0m\n",
            "[2024-04-02 21:04:38] \u001b[32mTrain: [ 40/50] Step 420/520 Loss 1.793 Prec@(1,5) (63.5%, 88.7%)\u001b[0m\n",
            "[2024-04-02 21:04:39] \u001b[32mTrain: [ 40/50] Step 440/520 Loss 1.792 Prec@(1,5) (63.6%, 88.7%)\u001b[0m\n",
            "[2024-04-02 21:04:39] \u001b[32mTrain: [ 40/50] Step 460/520 Loss 1.790 Prec@(1,5) (63.5%, 88.8%)\u001b[0m\n",
            "[2024-04-02 21:04:40] \u001b[32mTrain: [ 40/50] Step 480/520 Loss 1.790 Prec@(1,5) (63.5%, 88.8%)\u001b[0m\n",
            "[2024-04-02 21:04:40] \u001b[32mTrain: [ 40/50] Step 500/520 Loss 1.793 Prec@(1,5) (63.5%, 88.8%)\u001b[0m\n",
            "[2024-04-02 21:04:41] \u001b[32mTrain: [ 40/50] Step 520/520 Loss 1.790 Prec@(1,5) (63.5%, 88.8%)\u001b[0m\n",
            "[2024-04-02 21:04:41] \u001b[32mTrain: [ 40/50] Final Prec@1 63.5480%\u001b[0m\n",
            "[2024-04-02 21:04:45] \u001b[32mValid: [ 40/50] Step 000/104 Loss 1.827 Prec@(1,5) (65.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 21:04:45] \u001b[32mValid: [ 40/50] Step 020/104 Loss 1.982 Prec@(1,5) (59.0%, 86.1%)\u001b[0m\n",
            "[2024-04-02 21:04:45] \u001b[32mValid: [ 40/50] Step 040/104 Loss 1.964 Prec@(1,5) (58.8%, 86.0%)\u001b[0m\n",
            "[2024-04-02 21:04:45] \u001b[32mValid: [ 40/50] Step 060/104 Loss 1.906 Prec@(1,5) (59.2%, 86.3%)\u001b[0m\n",
            "[2024-04-02 21:04:45] \u001b[32mValid: [ 40/50] Step 080/104 Loss 1.901 Prec@(1,5) (59.2%, 86.2%)\u001b[0m\n",
            "[2024-04-02 21:04:46] \u001b[32mValid: [ 40/50] Step 100/104 Loss 1.874 Prec@(1,5) (59.6%, 86.4%)\u001b[0m\n",
            "[2024-04-02 21:04:46] \u001b[32mValid: [ 40/50] Step 104/104 Loss 1.875 Prec@(1,5) (59.7%, 86.3%)\u001b[0m\n",
            "[2024-04-02 21:04:46] \u001b[32mValid: [ 40/50] Final Prec@1 59.6500%\u001b[0m\n",
            "[2024-04-02 21:04:46] \u001b[32mEpoch 40 LR 0.002388\u001b[0m\n",
            "[2024-04-02 21:04:50] \u001b[32mTrain: [ 41/50] Step 000/520 Loss 1.601 Prec@(1,5) (66.7%, 91.7%)\u001b[0m\n",
            "[2024-04-02 21:04:51] \u001b[32mTrain: [ 41/50] Step 020/520 Loss 1.678 Prec@(1,5) (66.0%, 90.0%)\u001b[0m\n",
            "[2024-04-02 21:04:51] \u001b[32mTrain: [ 41/50] Step 040/520 Loss 1.724 Prec@(1,5) (64.8%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:04:52] \u001b[32mTrain: [ 41/50] Step 060/520 Loss 1.763 Prec@(1,5) (64.5%, 89.1%)\u001b[0m\n",
            "[2024-04-02 21:04:52] \u001b[32mTrain: [ 41/50] Step 080/520 Loss 1.757 Prec@(1,5) (64.4%, 89.1%)\u001b[0m\n",
            "[2024-04-02 21:04:53] \u001b[32mTrain: [ 41/50] Step 100/520 Loss 1.757 Prec@(1,5) (64.5%, 89.1%)\u001b[0m\n",
            "[2024-04-02 21:04:53] \u001b[32mTrain: [ 41/50] Step 120/520 Loss 1.754 Prec@(1,5) (64.4%, 89.2%)\u001b[0m\n",
            "[2024-04-02 21:04:54] \u001b[32mTrain: [ 41/50] Step 140/520 Loss 1.748 Prec@(1,5) (64.6%, 89.3%)\u001b[0m\n",
            "[2024-04-02 21:04:55] \u001b[32mTrain: [ 41/50] Step 160/520 Loss 1.740 Prec@(1,5) (64.7%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:04:55] \u001b[32mTrain: [ 41/50] Step 180/520 Loss 1.738 Prec@(1,5) (64.7%, 89.3%)\u001b[0m\n",
            "[2024-04-02 21:04:56] \u001b[32mTrain: [ 41/50] Step 200/520 Loss 1.747 Prec@(1,5) (64.5%, 89.3%)\u001b[0m\n",
            "[2024-04-02 21:04:56] \u001b[32mTrain: [ 41/50] Step 220/520 Loss 1.748 Prec@(1,5) (64.5%, 89.2%)\u001b[0m\n",
            "[2024-04-02 21:04:57] \u001b[32mTrain: [ 41/50] Step 240/520 Loss 1.753 Prec@(1,5) (64.4%, 89.1%)\u001b[0m\n",
            "[2024-04-02 21:04:57] \u001b[32mTrain: [ 41/50] Step 260/520 Loss 1.757 Prec@(1,5) (64.4%, 89.1%)\u001b[0m\n",
            "[2024-04-02 21:04:58] \u001b[32mTrain: [ 41/50] Step 280/520 Loss 1.754 Prec@(1,5) (64.5%, 89.1%)\u001b[0m\n",
            "[2024-04-02 21:04:58] \u001b[32mTrain: [ 41/50] Step 300/520 Loss 1.753 Prec@(1,5) (64.5%, 89.1%)\u001b[0m\n",
            "[2024-04-02 21:04:59] \u001b[32mTrain: [ 41/50] Step 320/520 Loss 1.760 Prec@(1,5) (64.4%, 89.1%)\u001b[0m\n",
            "[2024-04-02 21:04:59] \u001b[32mTrain: [ 41/50] Step 340/520 Loss 1.760 Prec@(1,5) (64.5%, 89.1%)\u001b[0m\n",
            "[2024-04-02 21:05:00] \u001b[32mTrain: [ 41/50] Step 360/520 Loss 1.762 Prec@(1,5) (64.4%, 89.0%)\u001b[0m\n",
            "[2024-04-02 21:05:00] \u001b[32mTrain: [ 41/50] Step 380/520 Loss 1.764 Prec@(1,5) (64.4%, 89.0%)\u001b[0m\n",
            "[2024-04-02 21:05:01] \u001b[32mTrain: [ 41/50] Step 400/520 Loss 1.764 Prec@(1,5) (64.4%, 89.0%)\u001b[0m\n",
            "[2024-04-02 21:05:01] \u001b[32mTrain: [ 41/50] Step 420/520 Loss 1.764 Prec@(1,5) (64.4%, 89.1%)\u001b[0m\n",
            "[2024-04-02 21:05:02] \u001b[32mTrain: [ 41/50] Step 440/520 Loss 1.765 Prec@(1,5) (64.4%, 89.1%)\u001b[0m\n",
            "[2024-04-02 21:05:02] \u001b[32mTrain: [ 41/50] Step 460/520 Loss 1.766 Prec@(1,5) (64.3%, 89.1%)\u001b[0m\n",
            "[2024-04-02 21:05:03] \u001b[32mTrain: [ 41/50] Step 480/520 Loss 1.768 Prec@(1,5) (64.3%, 89.0%)\u001b[0m\n",
            "[2024-04-02 21:05:03] \u001b[32mTrain: [ 41/50] Step 500/520 Loss 1.768 Prec@(1,5) (64.3%, 89.0%)\u001b[0m\n",
            "[2024-04-02 21:05:04] \u001b[32mTrain: [ 41/50] Step 520/520 Loss 1.767 Prec@(1,5) (64.3%, 89.0%)\u001b[0m\n",
            "[2024-04-02 21:05:04] \u001b[32mTrain: [ 41/50] Final Prec@1 64.3380%\u001b[0m\n",
            "[2024-04-02 21:05:07] \u001b[32mValid: [ 41/50] Step 000/104 Loss 1.822 Prec@(1,5) (63.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 21:05:07] \u001b[32mValid: [ 41/50] Step 020/104 Loss 1.916 Prec@(1,5) (59.5%, 86.6%)\u001b[0m\n",
            "[2024-04-02 21:05:08] \u001b[32mValid: [ 41/50] Step 040/104 Loss 1.894 Prec@(1,5) (59.5%, 86.8%)\u001b[0m\n",
            "[2024-04-02 21:05:08] \u001b[32mValid: [ 41/50] Step 060/104 Loss 1.847 Prec@(1,5) (60.0%, 87.0%)\u001b[0m\n",
            "[2024-04-02 21:05:08] \u001b[32mValid: [ 41/50] Step 080/104 Loss 1.843 Prec@(1,5) (59.9%, 86.9%)\u001b[0m\n",
            "[2024-04-02 21:05:08] \u001b[32mValid: [ 41/50] Step 100/104 Loss 1.819 Prec@(1,5) (60.2%, 87.3%)\u001b[0m\n",
            "[2024-04-02 21:05:08] \u001b[32mValid: [ 41/50] Step 104/104 Loss 1.821 Prec@(1,5) (60.2%, 87.2%)\u001b[0m\n",
            "[2024-04-02 21:05:08] \u001b[32mValid: [ 41/50] Final Prec@1 60.1700%\u001b[0m\n",
            "[2024-04-02 21:05:08] \u001b[32mEpoch 41 LR 0.001947\u001b[0m\n",
            "[2024-04-02 21:05:13] \u001b[32mTrain: [ 42/50] Step 000/520 Loss 1.754 Prec@(1,5) (65.6%, 88.5%)\u001b[0m\n",
            "[2024-04-02 21:05:14] \u001b[32mTrain: [ 42/50] Step 020/520 Loss 1.716 Prec@(1,5) (65.6%, 89.0%)\u001b[0m\n",
            "[2024-04-02 21:05:14] \u001b[32mTrain: [ 42/50] Step 040/520 Loss 1.753 Prec@(1,5) (65.5%, 88.6%)\u001b[0m\n",
            "[2024-04-02 21:05:15] \u001b[32mTrain: [ 42/50] Step 060/520 Loss 1.745 Prec@(1,5) (65.3%, 89.2%)\u001b[0m\n",
            "[2024-04-02 21:05:15] \u001b[32mTrain: [ 42/50] Step 080/520 Loss 1.751 Prec@(1,5) (65.0%, 89.0%)\u001b[0m\n",
            "[2024-04-02 21:05:16] \u001b[32mTrain: [ 42/50] Step 100/520 Loss 1.743 Prec@(1,5) (64.9%, 89.1%)\u001b[0m\n",
            "[2024-04-02 21:05:16] \u001b[32mTrain: [ 42/50] Step 120/520 Loss 1.746 Prec@(1,5) (64.7%, 89.2%)\u001b[0m\n",
            "[2024-04-02 21:05:17] \u001b[32mTrain: [ 42/50] Step 140/520 Loss 1.739 Prec@(1,5) (64.9%, 89.2%)\u001b[0m\n",
            "[2024-04-02 21:05:17] \u001b[32mTrain: [ 42/50] Step 160/520 Loss 1.738 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:05:18] \u001b[32mTrain: [ 42/50] Step 180/520 Loss 1.736 Prec@(1,5) (65.0%, 89.3%)\u001b[0m\n",
            "[2024-04-02 21:05:18] \u001b[32mTrain: [ 42/50] Step 200/520 Loss 1.735 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:05:19] \u001b[32mTrain: [ 42/50] Step 220/520 Loss 1.734 Prec@(1,5) (64.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:05:19] \u001b[32mTrain: [ 42/50] Step 240/520 Loss 1.733 Prec@(1,5) (64.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:05:20] \u001b[32mTrain: [ 42/50] Step 260/520 Loss 1.739 Prec@(1,5) (64.8%, 89.3%)\u001b[0m\n",
            "[2024-04-02 21:05:20] \u001b[32mTrain: [ 42/50] Step 280/520 Loss 1.738 Prec@(1,5) (64.8%, 89.3%)\u001b[0m\n",
            "[2024-04-02 21:05:21] \u001b[32mTrain: [ 42/50] Step 300/520 Loss 1.741 Prec@(1,5) (64.7%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:05:21] \u001b[32mTrain: [ 42/50] Step 320/520 Loss 1.742 Prec@(1,5) (64.7%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:05:22] \u001b[32mTrain: [ 42/50] Step 340/520 Loss 1.746 Prec@(1,5) (64.6%, 89.3%)\u001b[0m\n",
            "[2024-04-02 21:05:22] \u001b[32mTrain: [ 42/50] Step 360/520 Loss 1.750 Prec@(1,5) (64.6%, 89.3%)\u001b[0m\n",
            "[2024-04-02 21:05:23] \u001b[32mTrain: [ 42/50] Step 380/520 Loss 1.748 Prec@(1,5) (64.6%, 89.3%)\u001b[0m\n",
            "[2024-04-02 21:05:23] \u001b[32mTrain: [ 42/50] Step 400/520 Loss 1.749 Prec@(1,5) (64.5%, 89.3%)\u001b[0m\n",
            "[2024-04-02 21:05:24] \u001b[32mTrain: [ 42/50] Step 420/520 Loss 1.751 Prec@(1,5) (64.5%, 89.3%)\u001b[0m\n",
            "[2024-04-02 21:05:24] \u001b[32mTrain: [ 42/50] Step 440/520 Loss 1.750 Prec@(1,5) (64.5%, 89.3%)\u001b[0m\n",
            "[2024-04-02 21:05:25] \u001b[32mTrain: [ 42/50] Step 460/520 Loss 1.750 Prec@(1,5) (64.5%, 89.3%)\u001b[0m\n",
            "[2024-04-02 21:05:25] \u001b[32mTrain: [ 42/50] Step 480/520 Loss 1.754 Prec@(1,5) (64.4%, 89.2%)\u001b[0m\n",
            "[2024-04-02 21:05:26] \u001b[32mTrain: [ 42/50] Step 500/520 Loss 1.757 Prec@(1,5) (64.3%, 89.2%)\u001b[0m\n",
            "[2024-04-02 21:05:26] \u001b[32mTrain: [ 42/50] Step 520/520 Loss 1.759 Prec@(1,5) (64.3%, 89.2%)\u001b[0m\n",
            "[2024-04-02 21:05:26] \u001b[32mTrain: [ 42/50] Final Prec@1 64.2740%\u001b[0m\n",
            "[2024-04-02 21:05:30] \u001b[32mValid: [ 42/50] Step 000/104 Loss 1.846 Prec@(1,5) (67.7%, 86.5%)\u001b[0m\n",
            "[2024-04-02 21:05:30] \u001b[32mValid: [ 42/50] Step 020/104 Loss 1.933 Prec@(1,5) (61.2%, 86.9%)\u001b[0m\n",
            "[2024-04-02 21:05:30] \u001b[32mValid: [ 42/50] Step 040/104 Loss 1.913 Prec@(1,5) (60.4%, 86.5%)\u001b[0m\n",
            "[2024-04-02 21:05:30] \u001b[32mValid: [ 42/50] Step 060/104 Loss 1.864 Prec@(1,5) (60.6%, 86.8%)\u001b[0m\n",
            "[2024-04-02 21:05:31] \u001b[32mValid: [ 42/50] Step 080/104 Loss 1.862 Prec@(1,5) (60.5%, 86.9%)\u001b[0m\n",
            "[2024-04-02 21:05:31] \u001b[32mValid: [ 42/50] Step 100/104 Loss 1.842 Prec@(1,5) (60.7%, 87.1%)\u001b[0m\n",
            "[2024-04-02 21:05:31] \u001b[32mValid: [ 42/50] Step 104/104 Loss 1.844 Prec@(1,5) (60.7%, 87.0%)\u001b[0m\n",
            "[2024-04-02 21:05:31] \u001b[32mValid: [ 42/50] Final Prec@1 60.7000%\u001b[0m\n",
            "[2024-04-02 21:05:31] \u001b[32mEpoch 42 LR 0.001547\u001b[0m\n",
            "[2024-04-02 21:05:36] \u001b[32mTrain: [ 43/50] Step 000/520 Loss 1.401 Prec@(1,5) (71.9%, 90.6%)\u001b[0m\n",
            "[2024-04-02 21:05:36] \u001b[32mTrain: [ 43/50] Step 020/520 Loss 1.696 Prec@(1,5) (64.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:05:37] \u001b[32mTrain: [ 43/50] Step 040/520 Loss 1.708 Prec@(1,5) (65.2%, 89.1%)\u001b[0m\n",
            "[2024-04-02 21:05:37] \u001b[32mTrain: [ 43/50] Step 060/520 Loss 1.704 Prec@(1,5) (65.1%, 89.3%)\u001b[0m\n",
            "[2024-04-02 21:05:38] \u001b[32mTrain: [ 43/50] Step 080/520 Loss 1.728 Prec@(1,5) (64.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:05:38] \u001b[32mTrain: [ 43/50] Step 100/520 Loss 1.728 Prec@(1,5) (64.7%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:05:39] \u001b[32mTrain: [ 43/50] Step 120/520 Loss 1.733 Prec@(1,5) (64.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:05:39] \u001b[32mTrain: [ 43/50] Step 140/520 Loss 1.725 Prec@(1,5) (65.1%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:05:40] \u001b[32mTrain: [ 43/50] Step 160/520 Loss 1.726 Prec@(1,5) (65.0%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:05:40] \u001b[32mTrain: [ 43/50] Step 180/520 Loss 1.736 Prec@(1,5) (64.8%, 89.3%)\u001b[0m\n",
            "[2024-04-02 21:05:41] \u001b[32mTrain: [ 43/50] Step 200/520 Loss 1.727 Prec@(1,5) (64.9%, 89.3%)\u001b[0m\n",
            "[2024-04-02 21:05:41] \u001b[32mTrain: [ 43/50] Step 220/520 Loss 1.727 Prec@(1,5) (64.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:05:42] \u001b[32mTrain: [ 43/50] Step 240/520 Loss 1.721 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:05:42] \u001b[32mTrain: [ 43/50] Step 260/520 Loss 1.728 Prec@(1,5) (65.0%, 89.3%)\u001b[0m\n",
            "[2024-04-02 21:05:43] \u001b[32mTrain: [ 43/50] Step 280/520 Loss 1.725 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:05:43] \u001b[32mTrain: [ 43/50] Step 300/520 Loss 1.725 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:05:44] \u001b[32mTrain: [ 43/50] Step 320/520 Loss 1.726 Prec@(1,5) (64.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:05:44] \u001b[32mTrain: [ 43/50] Step 340/520 Loss 1.726 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:05:45] \u001b[32mTrain: [ 43/50] Step 360/520 Loss 1.727 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:05:45] \u001b[32mTrain: [ 43/50] Step 380/520 Loss 1.728 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:05:45] \u001b[32mTrain: [ 43/50] Step 400/520 Loss 1.729 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:05:46] \u001b[32mTrain: [ 43/50] Step 420/520 Loss 1.728 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:05:46] \u001b[32mTrain: [ 43/50] Step 440/520 Loss 1.732 Prec@(1,5) (64.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:05:47] \u001b[32mTrain: [ 43/50] Step 460/520 Loss 1.731 Prec@(1,5) (64.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:05:47] \u001b[32mTrain: [ 43/50] Step 480/520 Loss 1.730 Prec@(1,5) (64.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:05:48] \u001b[32mTrain: [ 43/50] Step 500/520 Loss 1.732 Prec@(1,5) (64.9%, 89.3%)\u001b[0m\n",
            "[2024-04-02 21:05:48] \u001b[32mTrain: [ 43/50] Step 520/520 Loss 1.735 Prec@(1,5) (64.9%, 89.3%)\u001b[0m\n",
            "[2024-04-02 21:05:49] \u001b[32mTrain: [ 43/50] Final Prec@1 64.8600%\u001b[0m\n",
            "[2024-04-02 21:05:52] \u001b[32mValid: [ 43/50] Step 000/104 Loss 1.785 Prec@(1,5) (66.7%, 86.5%)\u001b[0m\n",
            "[2024-04-02 21:05:52] \u001b[32mValid: [ 43/50] Step 020/104 Loss 1.933 Prec@(1,5) (60.6%, 86.0%)\u001b[0m\n",
            "[2024-04-02 21:05:52] \u001b[32mValid: [ 43/50] Step 040/104 Loss 1.911 Prec@(1,5) (60.3%, 86.2%)\u001b[0m\n",
            "[2024-04-02 21:05:53] \u001b[32mValid: [ 43/50] Step 060/104 Loss 1.861 Prec@(1,5) (60.6%, 86.7%)\u001b[0m\n",
            "[2024-04-02 21:05:53] \u001b[32mValid: [ 43/50] Step 080/104 Loss 1.850 Prec@(1,5) (60.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 21:05:53] \u001b[32mValid: [ 43/50] Step 100/104 Loss 1.825 Prec@(1,5) (60.7%, 86.9%)\u001b[0m\n",
            "[2024-04-02 21:05:53] \u001b[32mValid: [ 43/50] Step 104/104 Loss 1.827 Prec@(1,5) (60.6%, 86.8%)\u001b[0m\n",
            "[2024-04-02 21:05:53] \u001b[32mValid: [ 43/50] Final Prec@1 60.6300%\u001b[0m\n",
            "[2024-04-02 21:05:53] \u001b[32mEpoch 43 LR 0.001191\u001b[0m\n",
            "[2024-04-02 21:05:58] \u001b[32mTrain: [ 44/50] Step 000/520 Loss 1.960 Prec@(1,5) (57.3%, 88.5%)\u001b[0m\n",
            "[2024-04-02 21:05:58] \u001b[32mTrain: [ 44/50] Step 020/520 Loss 1.701 Prec@(1,5) (66.0%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:05:59] \u001b[32mTrain: [ 44/50] Step 040/520 Loss 1.715 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:05:59] \u001b[32mTrain: [ 44/50] Step 060/520 Loss 1.674 Prec@(1,5) (65.5%, 89.9%)\u001b[0m\n",
            "[2024-04-02 21:06:00] \u001b[32mTrain: [ 44/50] Step 080/520 Loss 1.693 Prec@(1,5) (65.2%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:06:00] \u001b[32mTrain: [ 44/50] Step 100/520 Loss 1.689 Prec@(1,5) (65.5%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:06:01] \u001b[32mTrain: [ 44/50] Step 120/520 Loss 1.690 Prec@(1,5) (65.5%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:06:01] \u001b[32mTrain: [ 44/50] Step 140/520 Loss 1.690 Prec@(1,5) (65.6%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:06:02] \u001b[32mTrain: [ 44/50] Step 160/520 Loss 1.690 Prec@(1,5) (65.5%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:06:02] \u001b[32mTrain: [ 44/50] Step 180/520 Loss 1.692 Prec@(1,5) (65.6%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:06:03] \u001b[32mTrain: [ 44/50] Step 200/520 Loss 1.692 Prec@(1,5) (65.6%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:06:03] \u001b[32mTrain: [ 44/50] Step 220/520 Loss 1.704 Prec@(1,5) (65.4%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:06:04] \u001b[32mTrain: [ 44/50] Step 240/520 Loss 1.703 Prec@(1,5) (65.4%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:06:04] \u001b[32mTrain: [ 44/50] Step 260/520 Loss 1.703 Prec@(1,5) (65.4%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:06:05] \u001b[32mTrain: [ 44/50] Step 280/520 Loss 1.712 Prec@(1,5) (65.2%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:06:05] \u001b[32mTrain: [ 44/50] Step 300/520 Loss 1.712 Prec@(1,5) (65.2%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:06:06] \u001b[32mTrain: [ 44/50] Step 320/520 Loss 1.714 Prec@(1,5) (65.2%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:06:06] \u001b[32mTrain: [ 44/50] Step 340/520 Loss 1.717 Prec@(1,5) (65.1%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:06:07] \u001b[32mTrain: [ 44/50] Step 360/520 Loss 1.718 Prec@(1,5) (65.1%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:06:07] \u001b[32mTrain: [ 44/50] Step 380/520 Loss 1.720 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:06:08] \u001b[32mTrain: [ 44/50] Step 400/520 Loss 1.718 Prec@(1,5) (65.1%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:06:08] \u001b[32mTrain: [ 44/50] Step 420/520 Loss 1.721 Prec@(1,5) (65.1%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:06:09] \u001b[32mTrain: [ 44/50] Step 440/520 Loss 1.722 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:06:09] \u001b[32mTrain: [ 44/50] Step 460/520 Loss 1.722 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:06:10] \u001b[32mTrain: [ 44/50] Step 480/520 Loss 1.723 Prec@(1,5) (65.0%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:06:10] \u001b[32mTrain: [ 44/50] Step 500/520 Loss 1.725 Prec@(1,5) (64.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:06:11] \u001b[32mTrain: [ 44/50] Step 520/520 Loss 1.725 Prec@(1,5) (64.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:06:11] \u001b[32mTrain: [ 44/50] Final Prec@1 64.9020%\u001b[0m\n",
            "[2024-04-02 21:06:14] \u001b[32mValid: [ 44/50] Step 000/104 Loss 1.850 Prec@(1,5) (65.6%, 86.5%)\u001b[0m\n",
            "[2024-04-02 21:06:14] \u001b[32mValid: [ 44/50] Step 020/104 Loss 1.908 Prec@(1,5) (60.7%, 87.4%)\u001b[0m\n",
            "[2024-04-02 21:06:15] \u001b[32mValid: [ 44/50] Step 040/104 Loss 1.886 Prec@(1,5) (60.4%, 87.1%)\u001b[0m\n",
            "[2024-04-02 21:06:15] \u001b[32mValid: [ 44/50] Step 060/104 Loss 1.832 Prec@(1,5) (60.7%, 87.3%)\u001b[0m\n",
            "[2024-04-02 21:06:15] \u001b[32mValid: [ 44/50] Step 080/104 Loss 1.829 Prec@(1,5) (60.7%, 87.2%)\u001b[0m\n",
            "[2024-04-02 21:06:15] \u001b[32mValid: [ 44/50] Step 100/104 Loss 1.802 Prec@(1,5) (61.0%, 87.5%)\u001b[0m\n",
            "[2024-04-02 21:06:15] \u001b[32mValid: [ 44/50] Step 104/104 Loss 1.804 Prec@(1,5) (61.0%, 87.4%)\u001b[0m\n",
            "[2024-04-02 21:06:15] \u001b[32mValid: [ 44/50] Final Prec@1 61.0300%\u001b[0m\n",
            "[2024-04-02 21:06:15] \u001b[32mEpoch 44 LR 0.000879\u001b[0m\n",
            "[2024-04-02 21:06:20] \u001b[32mTrain: [ 45/50] Step 000/520 Loss 1.671 Prec@(1,5) (65.6%, 91.7%)\u001b[0m\n",
            "[2024-04-02 21:06:20] \u001b[32mTrain: [ 45/50] Step 020/520 Loss 1.729 Prec@(1,5) (65.0%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:06:21] \u001b[32mTrain: [ 45/50] Step 040/520 Loss 1.731 Prec@(1,5) (65.3%, 89.8%)\u001b[0m\n",
            "[2024-04-02 21:06:21] \u001b[32mTrain: [ 45/50] Step 060/520 Loss 1.741 Prec@(1,5) (64.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:06:22] \u001b[32mTrain: [ 45/50] Step 080/520 Loss 1.743 Prec@(1,5) (64.5%, 89.3%)\u001b[0m\n",
            "[2024-04-02 21:06:22] \u001b[32mTrain: [ 45/50] Step 100/520 Loss 1.730 Prec@(1,5) (64.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:06:23] \u001b[32mTrain: [ 45/50] Step 120/520 Loss 1.727 Prec@(1,5) (64.9%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:06:23] \u001b[32mTrain: [ 45/50] Step 140/520 Loss 1.717 Prec@(1,5) (65.1%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:06:24] \u001b[32mTrain: [ 45/50] Step 160/520 Loss 1.713 Prec@(1,5) (65.1%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:06:24] \u001b[32mTrain: [ 45/50] Step 180/520 Loss 1.713 Prec@(1,5) (65.1%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:06:25] \u001b[32mTrain: [ 45/50] Step 200/520 Loss 1.715 Prec@(1,5) (65.2%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:06:25] \u001b[32mTrain: [ 45/50] Step 220/520 Loss 1.709 Prec@(1,5) (65.4%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:06:26] \u001b[32mTrain: [ 45/50] Step 240/520 Loss 1.712 Prec@(1,5) (65.3%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:06:26] \u001b[32mTrain: [ 45/50] Step 260/520 Loss 1.715 Prec@(1,5) (65.3%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:06:27] \u001b[32mTrain: [ 45/50] Step 280/520 Loss 1.719 Prec@(1,5) (65.2%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:06:27] \u001b[32mTrain: [ 45/50] Step 300/520 Loss 1.717 Prec@(1,5) (65.2%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:06:28] \u001b[32mTrain: [ 45/50] Step 320/520 Loss 1.723 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:06:28] \u001b[32mTrain: [ 45/50] Step 340/520 Loss 1.723 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:06:29] \u001b[32mTrain: [ 45/50] Step 360/520 Loss 1.722 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:06:29] \u001b[32mTrain: [ 45/50] Step 380/520 Loss 1.724 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:06:30] \u001b[32mTrain: [ 45/50] Step 400/520 Loss 1.723 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:06:30] \u001b[32mTrain: [ 45/50] Step 420/520 Loss 1.721 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:06:31] \u001b[32mTrain: [ 45/50] Step 440/520 Loss 1.722 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:06:31] \u001b[32mTrain: [ 45/50] Step 460/520 Loss 1.720 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:06:32] \u001b[32mTrain: [ 45/50] Step 480/520 Loss 1.719 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:06:32] \u001b[32mTrain: [ 45/50] Step 500/520 Loss 1.720 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:06:33] \u001b[32mTrain: [ 45/50] Step 520/520 Loss 1.721 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:06:33] \u001b[32mTrain: [ 45/50] Final Prec@1 65.2140%\u001b[0m\n",
            "[2024-04-02 21:06:36] \u001b[32mValid: [ 45/50] Step 000/104 Loss 1.792 Prec@(1,5) (65.6%, 86.5%)\u001b[0m\n",
            "[2024-04-02 21:06:37] \u001b[32mValid: [ 45/50] Step 020/104 Loss 1.882 Prec@(1,5) (60.5%, 87.2%)\u001b[0m\n",
            "[2024-04-02 21:06:37] \u001b[32mValid: [ 45/50] Step 040/104 Loss 1.859 Prec@(1,5) (60.3%, 87.1%)\u001b[0m\n",
            "[2024-04-02 21:06:37] \u001b[32mValid: [ 45/50] Step 060/104 Loss 1.807 Prec@(1,5) (60.7%, 87.4%)\u001b[0m\n",
            "[2024-04-02 21:06:37] \u001b[32mValid: [ 45/50] Step 080/104 Loss 1.802 Prec@(1,5) (60.7%, 87.4%)\u001b[0m\n",
            "[2024-04-02 21:06:37] \u001b[32mValid: [ 45/50] Step 100/104 Loss 1.774 Prec@(1,5) (61.1%, 87.7%)\u001b[0m\n",
            "[2024-04-02 21:06:37] \u001b[32mValid: [ 45/50] Step 104/104 Loss 1.776 Prec@(1,5) (61.0%, 87.7%)\u001b[0m\n",
            "[2024-04-02 21:06:37] \u001b[32mValid: [ 45/50] Final Prec@1 60.9900%\u001b[0m\n",
            "[2024-04-02 21:06:37] \u001b[32mEpoch 45 LR 0.000613\u001b[0m\n",
            "[2024-04-02 21:06:42] \u001b[32mTrain: [ 46/50] Step 000/520 Loss 1.736 Prec@(1,5) (56.2%, 91.7%)\u001b[0m\n",
            "[2024-04-02 21:06:43] \u001b[32mTrain: [ 46/50] Step 020/520 Loss 1.758 Prec@(1,5) (63.9%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:06:43] \u001b[32mTrain: [ 46/50] Step 040/520 Loss 1.748 Prec@(1,5) (64.7%, 89.2%)\u001b[0m\n",
            "[2024-04-02 21:06:44] \u001b[32mTrain: [ 46/50] Step 060/520 Loss 1.738 Prec@(1,5) (64.9%, 89.2%)\u001b[0m\n",
            "[2024-04-02 21:06:44] \u001b[32mTrain: [ 46/50] Step 080/520 Loss 1.733 Prec@(1,5) (65.2%, 89.0%)\u001b[0m\n",
            "[2024-04-02 21:06:45] \u001b[32mTrain: [ 46/50] Step 100/520 Loss 1.731 Prec@(1,5) (65.2%, 89.1%)\u001b[0m\n",
            "[2024-04-02 21:06:45] \u001b[32mTrain: [ 46/50] Step 120/520 Loss 1.719 Prec@(1,5) (65.3%, 89.2%)\u001b[0m\n",
            "[2024-04-02 21:06:46] \u001b[32mTrain: [ 46/50] Step 140/520 Loss 1.725 Prec@(1,5) (65.4%, 89.3%)\u001b[0m\n",
            "[2024-04-02 21:06:46] \u001b[32mTrain: [ 46/50] Step 160/520 Loss 1.719 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:06:47] \u001b[32mTrain: [ 46/50] Step 180/520 Loss 1.721 Prec@(1,5) (65.4%, 89.3%)\u001b[0m\n",
            "[2024-04-02 21:06:47] \u001b[32mTrain: [ 46/50] Step 200/520 Loss 1.715 Prec@(1,5) (65.6%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:06:48] \u001b[32mTrain: [ 46/50] Step 220/520 Loss 1.715 Prec@(1,5) (65.6%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:06:48] \u001b[32mTrain: [ 46/50] Step 240/520 Loss 1.709 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:06:49] \u001b[32mTrain: [ 46/50] Step 260/520 Loss 1.708 Prec@(1,5) (65.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:06:49] \u001b[32mTrain: [ 46/50] Step 280/520 Loss 1.709 Prec@(1,5) (65.4%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:06:50] \u001b[32mTrain: [ 46/50] Step 300/520 Loss 1.708 Prec@(1,5) (65.4%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:06:50] \u001b[32mTrain: [ 46/50] Step 320/520 Loss 1.711 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:06:51] \u001b[32mTrain: [ 46/50] Step 340/520 Loss 1.708 Prec@(1,5) (65.4%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:06:51] \u001b[32mTrain: [ 46/50] Step 360/520 Loss 1.710 Prec@(1,5) (65.3%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:06:52] \u001b[32mTrain: [ 46/50] Step 380/520 Loss 1.714 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:06:52] \u001b[32mTrain: [ 46/50] Step 400/520 Loss 1.718 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:06:53] \u001b[32mTrain: [ 46/50] Step 420/520 Loss 1.720 Prec@(1,5) (65.1%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:06:53] \u001b[32mTrain: [ 46/50] Step 440/520 Loss 1.723 Prec@(1,5) (65.1%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:06:54] \u001b[32mTrain: [ 46/50] Step 460/520 Loss 1.722 Prec@(1,5) (65.1%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:06:54] \u001b[32mTrain: [ 46/50] Step 480/520 Loss 1.721 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:06:55] \u001b[32mTrain: [ 46/50] Step 500/520 Loss 1.719 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:06:55] \u001b[32mTrain: [ 46/50] Step 520/520 Loss 1.718 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:06:55] \u001b[32mTrain: [ 46/50] Final Prec@1 65.2300%\u001b[0m\n",
            "[2024-04-02 21:06:59] \u001b[32mValid: [ 46/50] Step 000/104 Loss 1.824 Prec@(1,5) (63.5%, 86.5%)\u001b[0m\n",
            "[2024-04-02 21:06:59] \u001b[32mValid: [ 46/50] Step 020/104 Loss 1.904 Prec@(1,5) (60.6%, 87.1%)\u001b[0m\n",
            "[2024-04-02 21:06:59] \u001b[32mValid: [ 46/50] Step 040/104 Loss 1.879 Prec@(1,5) (60.7%, 87.1%)\u001b[0m\n",
            "[2024-04-02 21:06:59] \u001b[32mValid: [ 46/50] Step 060/104 Loss 1.827 Prec@(1,5) (60.9%, 87.3%)\u001b[0m\n",
            "[2024-04-02 21:06:59] \u001b[32mValid: [ 46/50] Step 080/104 Loss 1.823 Prec@(1,5) (60.7%, 87.3%)\u001b[0m\n",
            "[2024-04-02 21:07:00] \u001b[32mValid: [ 46/50] Step 100/104 Loss 1.799 Prec@(1,5) (61.0%, 87.6%)\u001b[0m\n",
            "[2024-04-02 21:07:00] \u001b[32mValid: [ 46/50] Step 104/104 Loss 1.801 Prec@(1,5) (60.9%, 87.5%)\u001b[0m\n",
            "[2024-04-02 21:07:00] \u001b[32mValid: [ 46/50] Final Prec@1 60.8800%\u001b[0m\n",
            "[2024-04-02 21:07:00] \u001b[32mEpoch 46 LR 0.000394\u001b[0m\n",
            "[2024-04-02 21:07:04] \u001b[32mTrain: [ 47/50] Step 000/520 Loss 1.537 Prec@(1,5) (69.8%, 88.5%)\u001b[0m\n",
            "[2024-04-02 21:07:05] \u001b[32mTrain: [ 47/50] Step 020/520 Loss 1.710 Prec@(1,5) (64.9%, 89.1%)\u001b[0m\n",
            "[2024-04-02 21:07:05] \u001b[32mTrain: [ 47/50] Step 040/520 Loss 1.688 Prec@(1,5) (65.3%, 90.1%)\u001b[0m\n",
            "[2024-04-02 21:07:06] \u001b[32mTrain: [ 47/50] Step 060/520 Loss 1.684 Prec@(1,5) (65.7%, 90.2%)\u001b[0m\n",
            "[2024-04-02 21:07:06] \u001b[32mTrain: [ 47/50] Step 080/520 Loss 1.685 Prec@(1,5) (65.7%, 90.0%)\u001b[0m\n",
            "[2024-04-02 21:07:07] \u001b[32mTrain: [ 47/50] Step 100/520 Loss 1.679 Prec@(1,5) (65.8%, 89.9%)\u001b[0m\n",
            "[2024-04-02 21:07:07] \u001b[32mTrain: [ 47/50] Step 120/520 Loss 1.700 Prec@(1,5) (65.6%, 89.8%)\u001b[0m\n",
            "[2024-04-02 21:07:08] \u001b[32mTrain: [ 47/50] Step 140/520 Loss 1.698 Prec@(1,5) (65.8%, 89.8%)\u001b[0m\n",
            "[2024-04-02 21:07:08] \u001b[32mTrain: [ 47/50] Step 160/520 Loss 1.698 Prec@(1,5) (65.9%, 90.0%)\u001b[0m\n",
            "[2024-04-02 21:07:09] \u001b[32mTrain: [ 47/50] Step 180/520 Loss 1.699 Prec@(1,5) (65.9%, 90.0%)\u001b[0m\n",
            "[2024-04-02 21:07:09] \u001b[32mTrain: [ 47/50] Step 200/520 Loss 1.702 Prec@(1,5) (65.8%, 89.9%)\u001b[0m\n",
            "[2024-04-02 21:07:10] \u001b[32mTrain: [ 47/50] Step 220/520 Loss 1.695 Prec@(1,5) (65.8%, 89.9%)\u001b[0m\n",
            "[2024-04-02 21:07:10] \u001b[32mTrain: [ 47/50] Step 240/520 Loss 1.695 Prec@(1,5) (65.8%, 89.9%)\u001b[0m\n",
            "[2024-04-02 21:07:11] \u001b[32mTrain: [ 47/50] Step 260/520 Loss 1.700 Prec@(1,5) (65.7%, 89.8%)\u001b[0m\n",
            "[2024-04-02 21:07:11] \u001b[32mTrain: [ 47/50] Step 280/520 Loss 1.698 Prec@(1,5) (65.7%, 89.9%)\u001b[0m\n",
            "[2024-04-02 21:07:12] \u001b[32mTrain: [ 47/50] Step 300/520 Loss 1.697 Prec@(1,5) (65.8%, 89.9%)\u001b[0m\n",
            "[2024-04-02 21:07:12] \u001b[32mTrain: [ 47/50] Step 320/520 Loss 1.701 Prec@(1,5) (65.7%, 89.9%)\u001b[0m\n",
            "[2024-04-02 21:07:13] \u001b[32mTrain: [ 47/50] Step 340/520 Loss 1.703 Prec@(1,5) (65.7%, 89.8%)\u001b[0m\n",
            "[2024-04-02 21:07:13] \u001b[32mTrain: [ 47/50] Step 360/520 Loss 1.704 Prec@(1,5) (65.6%, 89.8%)\u001b[0m\n",
            "[2024-04-02 21:07:14] \u001b[32mTrain: [ 47/50] Step 380/520 Loss 1.706 Prec@(1,5) (65.6%, 89.8%)\u001b[0m\n",
            "[2024-04-02 21:07:14] \u001b[32mTrain: [ 47/50] Step 400/520 Loss 1.706 Prec@(1,5) (65.6%, 89.8%)\u001b[0m\n",
            "[2024-04-02 21:07:15] \u001b[32mTrain: [ 47/50] Step 420/520 Loss 1.706 Prec@(1,5) (65.6%, 89.8%)\u001b[0m\n",
            "[2024-04-02 21:07:15] \u001b[32mTrain: [ 47/50] Step 440/520 Loss 1.703 Prec@(1,5) (65.7%, 89.8%)\u001b[0m\n",
            "[2024-04-02 21:07:16] \u001b[32mTrain: [ 47/50] Step 460/520 Loss 1.705 Prec@(1,5) (65.6%, 89.8%)\u001b[0m\n",
            "[2024-04-02 21:07:16] \u001b[32mTrain: [ 47/50] Step 480/520 Loss 1.706 Prec@(1,5) (65.6%, 89.8%)\u001b[0m\n",
            "[2024-04-02 21:07:17] \u001b[32mTrain: [ 47/50] Step 500/520 Loss 1.706 Prec@(1,5) (65.5%, 89.8%)\u001b[0m\n",
            "[2024-04-02 21:07:17] \u001b[32mTrain: [ 47/50] Step 520/520 Loss 1.706 Prec@(1,5) (65.5%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:07:17] \u001b[32mTrain: [ 47/50] Final Prec@1 65.5180%\u001b[0m\n",
            "[2024-04-02 21:07:21] \u001b[32mValid: [ 47/50] Step 000/104 Loss 1.791 Prec@(1,5) (66.7%, 86.5%)\u001b[0m\n",
            "[2024-04-02 21:07:21] \u001b[32mValid: [ 47/50] Step 020/104 Loss 1.874 Prec@(1,5) (61.5%, 87.3%)\u001b[0m\n",
            "[2024-04-02 21:07:21] \u001b[32mValid: [ 47/50] Step 040/104 Loss 1.848 Prec@(1,5) (61.0%, 87.3%)\u001b[0m\n",
            "[2024-04-02 21:07:21] \u001b[32mValid: [ 47/50] Step 060/104 Loss 1.792 Prec@(1,5) (61.3%, 87.6%)\u001b[0m\n",
            "[2024-04-02 21:07:21] \u001b[32mValid: [ 47/50] Step 080/104 Loss 1.787 Prec@(1,5) (61.2%, 87.5%)\u001b[0m\n",
            "[2024-04-02 21:07:22] \u001b[32mValid: [ 47/50] Step 100/104 Loss 1.761 Prec@(1,5) (61.6%, 87.8%)\u001b[0m\n",
            "[2024-04-02 21:07:22] \u001b[32mValid: [ 47/50] Step 104/104 Loss 1.762 Prec@(1,5) (61.5%, 87.7%)\u001b[0m\n",
            "[2024-04-02 21:07:22] \u001b[32mValid: [ 47/50] Final Prec@1 61.5400%\u001b[0m\n",
            "[2024-04-02 21:07:22] \u001b[32mEpoch 47 LR 0.000222\u001b[0m\n",
            "[2024-04-02 21:07:26] \u001b[32mTrain: [ 48/50] Step 000/520 Loss 1.556 Prec@(1,5) (67.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:07:27] \u001b[32mTrain: [ 48/50] Step 020/520 Loss 1.697 Prec@(1,5) (65.7%, 89.8%)\u001b[0m\n",
            "[2024-04-02 21:07:27] \u001b[32mTrain: [ 48/50] Step 040/520 Loss 1.696 Prec@(1,5) (65.1%, 89.8%)\u001b[0m\n",
            "[2024-04-02 21:07:28] \u001b[32mTrain: [ 48/50] Step 060/520 Loss 1.686 Prec@(1,5) (65.5%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:07:28] \u001b[32mTrain: [ 48/50] Step 080/520 Loss 1.703 Prec@(1,5) (65.3%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:07:29] \u001b[32mTrain: [ 48/50] Step 100/520 Loss 1.705 Prec@(1,5) (65.5%, 89.8%)\u001b[0m\n",
            "[2024-04-02 21:07:29] \u001b[32mTrain: [ 48/50] Step 120/520 Loss 1.696 Prec@(1,5) (65.5%, 89.8%)\u001b[0m\n",
            "[2024-04-02 21:07:30] \u001b[32mTrain: [ 48/50] Step 140/520 Loss 1.702 Prec@(1,5) (65.3%, 89.8%)\u001b[0m\n",
            "[2024-04-02 21:07:30] \u001b[32mTrain: [ 48/50] Step 160/520 Loss 1.710 Prec@(1,5) (65.1%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:07:31] \u001b[32mTrain: [ 48/50] Step 180/520 Loss 1.707 Prec@(1,5) (65.2%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:07:31] \u001b[32mTrain: [ 48/50] Step 200/520 Loss 1.709 Prec@(1,5) (65.2%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:07:32] \u001b[32mTrain: [ 48/50] Step 220/520 Loss 1.713 Prec@(1,5) (65.1%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:07:32] \u001b[32mTrain: [ 48/50] Step 240/520 Loss 1.712 Prec@(1,5) (65.1%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:07:33] \u001b[32mTrain: [ 48/50] Step 260/520 Loss 1.708 Prec@(1,5) (65.3%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:07:33] \u001b[32mTrain: [ 48/50] Step 280/520 Loss 1.710 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:07:34] \u001b[32mTrain: [ 48/50] Step 300/520 Loss 1.709 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:07:34] \u001b[32mTrain: [ 48/50] Step 320/520 Loss 1.710 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:07:35] \u001b[32mTrain: [ 48/50] Step 340/520 Loss 1.709 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:07:35] \u001b[32mTrain: [ 48/50] Step 360/520 Loss 1.708 Prec@(1,5) (65.2%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:07:36] \u001b[32mTrain: [ 48/50] Step 380/520 Loss 1.706 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:07:36] \u001b[32mTrain: [ 48/50] Step 400/520 Loss 1.705 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:07:37] \u001b[32mTrain: [ 48/50] Step 420/520 Loss 1.703 Prec@(1,5) (65.4%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:07:37] \u001b[32mTrain: [ 48/50] Step 440/520 Loss 1.705 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:07:38] \u001b[32mTrain: [ 48/50] Step 460/520 Loss 1.704 Prec@(1,5) (65.3%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:07:38] \u001b[32mTrain: [ 48/50] Step 480/520 Loss 1.706 Prec@(1,5) (65.3%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:07:39] \u001b[32mTrain: [ 48/50] Step 500/520 Loss 1.706 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:07:39] \u001b[32mTrain: [ 48/50] Step 520/520 Loss 1.707 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:07:39] \u001b[32mTrain: [ 48/50] Final Prec@1 65.2760%\u001b[0m\n",
            "[2024-04-02 21:07:43] \u001b[32mValid: [ 48/50] Step 000/104 Loss 1.791 Prec@(1,5) (64.6%, 87.5%)\u001b[0m\n",
            "[2024-04-02 21:07:43] \u001b[32mValid: [ 48/50] Step 020/104 Loss 1.882 Prec@(1,5) (61.3%, 87.1%)\u001b[0m\n",
            "[2024-04-02 21:07:43] \u001b[32mValid: [ 48/50] Step 040/104 Loss 1.862 Prec@(1,5) (60.9%, 87.2%)\u001b[0m\n",
            "[2024-04-02 21:07:43] \u001b[32mValid: [ 48/50] Step 060/104 Loss 1.807 Prec@(1,5) (61.2%, 87.5%)\u001b[0m\n",
            "[2024-04-02 21:07:44] \u001b[32mValid: [ 48/50] Step 080/104 Loss 1.804 Prec@(1,5) (61.1%, 87.4%)\u001b[0m\n",
            "[2024-04-02 21:07:44] \u001b[32mValid: [ 48/50] Step 100/104 Loss 1.778 Prec@(1,5) (61.4%, 87.8%)\u001b[0m\n",
            "[2024-04-02 21:07:44] \u001b[32mValid: [ 48/50] Step 104/104 Loss 1.780 Prec@(1,5) (61.4%, 87.8%)\u001b[0m\n",
            "[2024-04-02 21:07:44] \u001b[32mValid: [ 48/50] Final Prec@1 61.3500%\u001b[0m\n",
            "[2024-04-02 21:07:44] \u001b[32mEpoch 48 LR 0.000100\u001b[0m\n",
            "[2024-04-02 21:07:49] \u001b[32mTrain: [ 49/50] Step 000/520 Loss 1.650 Prec@(1,5) (64.6%, 91.7%)\u001b[0m\n",
            "[2024-04-02 21:07:49] \u001b[32mTrain: [ 49/50] Step 020/520 Loss 1.741 Prec@(1,5) (64.2%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:07:50] \u001b[32mTrain: [ 49/50] Step 040/520 Loss 1.752 Prec@(1,5) (64.3%, 89.0%)\u001b[0m\n",
            "[2024-04-02 21:07:50] \u001b[32mTrain: [ 49/50] Step 060/520 Loss 1.742 Prec@(1,5) (64.5%, 88.9%)\u001b[0m\n",
            "[2024-04-02 21:07:51] \u001b[32mTrain: [ 49/50] Step 080/520 Loss 1.728 Prec@(1,5) (65.3%, 88.9%)\u001b[0m\n",
            "[2024-04-02 21:07:51] \u001b[32mTrain: [ 49/50] Step 100/520 Loss 1.723 Prec@(1,5) (65.3%, 89.1%)\u001b[0m\n",
            "[2024-04-02 21:07:52] \u001b[32mTrain: [ 49/50] Step 120/520 Loss 1.712 Prec@(1,5) (65.4%, 89.3%)\u001b[0m\n",
            "[2024-04-02 21:07:52] \u001b[32mTrain: [ 49/50] Step 140/520 Loss 1.706 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:07:53] \u001b[32mTrain: [ 49/50] Step 160/520 Loss 1.698 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:07:53] \u001b[32mTrain: [ 49/50] Step 180/520 Loss 1.700 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:07:54] \u001b[32mTrain: [ 49/50] Step 200/520 Loss 1.703 Prec@(1,5) (65.5%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:07:54] \u001b[32mTrain: [ 49/50] Step 220/520 Loss 1.708 Prec@(1,5) (65.4%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:07:55] \u001b[32mTrain: [ 49/50] Step 240/520 Loss 1.708 Prec@(1,5) (65.4%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:07:55] \u001b[32mTrain: [ 49/50] Step 260/520 Loss 1.704 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:07:56] \u001b[32mTrain: [ 49/50] Step 280/520 Loss 1.702 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:07:56] \u001b[32mTrain: [ 49/50] Step 300/520 Loss 1.702 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:07:56] \u001b[32mTrain: [ 49/50] Step 320/520 Loss 1.702 Prec@(1,5) (65.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:07:57] \u001b[32mTrain: [ 49/50] Step 340/520 Loss 1.699 Prec@(1,5) (65.7%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:07:57] \u001b[32mTrain: [ 49/50] Step 360/520 Loss 1.700 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:07:58] \u001b[32mTrain: [ 49/50] Step 380/520 Loss 1.703 Prec@(1,5) (65.6%, 89.6%)\u001b[0m\n",
            "[2024-04-02 21:07:58] \u001b[32mTrain: [ 49/50] Step 400/520 Loss 1.707 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:07:59] \u001b[32mTrain: [ 49/50] Step 420/520 Loss 1.710 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:07:59] \u001b[32mTrain: [ 49/50] Step 440/520 Loss 1.710 Prec@(1,5) (65.5%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:08:00] \u001b[32mTrain: [ 49/50] Step 460/520 Loss 1.707 Prec@(1,5) (65.6%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:08:00] \u001b[32mTrain: [ 49/50] Step 480/520 Loss 1.709 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:08:01] \u001b[32mTrain: [ 49/50] Step 500/520 Loss 1.712 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:08:01] \u001b[32mTrain: [ 49/50] Step 520/520 Loss 1.711 Prec@(1,5) (65.5%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:08:02] \u001b[32mTrain: [ 49/50] Final Prec@1 65.4720%\u001b[0m\n",
            "[2024-04-02 21:08:05] \u001b[32mValid: [ 49/50] Step 000/104 Loss 1.795 Prec@(1,5) (66.7%, 87.5%)\u001b[0m\n",
            "[2024-04-02 21:08:05] \u001b[32mValid: [ 49/50] Step 020/104 Loss 1.880 Prec@(1,5) (60.8%, 87.6%)\u001b[0m\n",
            "[2024-04-02 21:08:05] \u001b[32mValid: [ 49/50] Step 040/104 Loss 1.854 Prec@(1,5) (60.7%, 87.4%)\u001b[0m\n",
            "[2024-04-02 21:08:06] \u001b[32mValid: [ 49/50] Step 060/104 Loss 1.800 Prec@(1,5) (61.1%, 87.7%)\u001b[0m\n",
            "[2024-04-02 21:08:06] \u001b[32mValid: [ 49/50] Step 080/104 Loss 1.794 Prec@(1,5) (61.0%, 87.6%)\u001b[0m\n",
            "[2024-04-02 21:08:06] \u001b[32mValid: [ 49/50] Step 100/104 Loss 1.769 Prec@(1,5) (61.3%, 87.9%)\u001b[0m\n",
            "[2024-04-02 21:08:06] \u001b[32mValid: [ 49/50] Step 104/104 Loss 1.771 Prec@(1,5) (61.3%, 87.9%)\u001b[0m\n",
            "[2024-04-02 21:08:06] \u001b[32mValid: [ 49/50] Final Prec@1 61.2800%\u001b[0m\n",
            "[2024-04-02 21:08:06] \u001b[32mEpoch 49 LR 0.000026\u001b[0m\n",
            "[2024-04-02 21:08:11] \u001b[32mTrain: [ 50/50] Step 000/520 Loss 1.766 Prec@(1,5) (64.6%, 90.6%)\u001b[0m\n",
            "[2024-04-02 21:08:11] \u001b[32mTrain: [ 50/50] Step 020/520 Loss 1.663 Prec@(1,5) (66.1%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:08:12] \u001b[32mTrain: [ 50/50] Step 040/520 Loss 1.665 Prec@(1,5) (66.7%, 89.9%)\u001b[0m\n",
            "[2024-04-02 21:08:12] \u001b[32mTrain: [ 50/50] Step 060/520 Loss 1.686 Prec@(1,5) (66.0%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:08:13] \u001b[32mTrain: [ 50/50] Step 080/520 Loss 1.706 Prec@(1,5) (65.8%, 89.3%)\u001b[0m\n",
            "[2024-04-02 21:08:13] \u001b[32mTrain: [ 50/50] Step 100/520 Loss 1.701 Prec@(1,5) (65.7%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:08:14] \u001b[32mTrain: [ 50/50] Step 120/520 Loss 1.715 Prec@(1,5) (65.5%, 89.3%)\u001b[0m\n",
            "[2024-04-02 21:08:14] \u001b[32mTrain: [ 50/50] Step 140/520 Loss 1.714 Prec@(1,5) (65.2%, 89.4%)\u001b[0m\n",
            "[2024-04-02 21:08:15] \u001b[32mTrain: [ 50/50] Step 160/520 Loss 1.711 Prec@(1,5) (65.3%, 89.5%)\u001b[0m\n",
            "[2024-04-02 21:08:15] \u001b[32mTrain: [ 50/50] Step 180/520 Loss 1.698 Prec@(1,5) (65.5%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:08:16] \u001b[32mTrain: [ 50/50] Step 200/520 Loss 1.692 Prec@(1,5) (65.6%, 89.8%)\u001b[0m\n",
            "[2024-04-02 21:08:16] \u001b[32mTrain: [ 50/50] Step 220/520 Loss 1.697 Prec@(1,5) (65.6%, 89.8%)\u001b[0m\n",
            "[2024-04-02 21:08:17] \u001b[32mTrain: [ 50/50] Step 240/520 Loss 1.703 Prec@(1,5) (65.5%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:08:17] \u001b[32mTrain: [ 50/50] Step 260/520 Loss 1.701 Prec@(1,5) (65.6%, 89.8%)\u001b[0m\n",
            "[2024-04-02 21:08:18] \u001b[32mTrain: [ 50/50] Step 280/520 Loss 1.708 Prec@(1,5) (65.4%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:08:18] \u001b[32mTrain: [ 50/50] Step 300/520 Loss 1.707 Prec@(1,5) (65.4%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:08:19] \u001b[32mTrain: [ 50/50] Step 320/520 Loss 1.708 Prec@(1,5) (65.4%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:08:19] \u001b[32mTrain: [ 50/50] Step 340/520 Loss 1.706 Prec@(1,5) (65.4%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:08:20] \u001b[32mTrain: [ 50/50] Step 360/520 Loss 1.705 Prec@(1,5) (65.4%, 89.8%)\u001b[0m\n",
            "[2024-04-02 21:08:20] \u001b[32mTrain: [ 50/50] Step 380/520 Loss 1.702 Prec@(1,5) (65.4%, 89.8%)\u001b[0m\n",
            "[2024-04-02 21:08:21] \u001b[32mTrain: [ 50/50] Step 400/520 Loss 1.706 Prec@(1,5) (65.3%, 89.8%)\u001b[0m\n",
            "[2024-04-02 21:08:21] \u001b[32mTrain: [ 50/50] Step 420/520 Loss 1.707 Prec@(1,5) (65.3%, 89.8%)\u001b[0m\n",
            "[2024-04-02 21:08:22] \u001b[32mTrain: [ 50/50] Step 440/520 Loss 1.708 Prec@(1,5) (65.3%, 89.8%)\u001b[0m\n",
            "[2024-04-02 21:08:22] \u001b[32mTrain: [ 50/50] Step 460/520 Loss 1.707 Prec@(1,5) (65.3%, 89.8%)\u001b[0m\n",
            "[2024-04-02 21:08:23] \u001b[32mTrain: [ 50/50] Step 480/520 Loss 1.708 Prec@(1,5) (65.3%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:08:23] \u001b[32mTrain: [ 50/50] Step 500/520 Loss 1.708 Prec@(1,5) (65.3%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:08:24] \u001b[32mTrain: [ 50/50] Step 520/520 Loss 1.707 Prec@(1,5) (65.2%, 89.7%)\u001b[0m\n",
            "[2024-04-02 21:08:24] \u001b[32mTrain: [ 50/50] Final Prec@1 65.2460%\u001b[0m\n",
            "[2024-04-02 21:08:27] \u001b[32mValid: [ 50/50] Step 000/104 Loss 1.821 Prec@(1,5) (66.7%, 88.5%)\u001b[0m\n",
            "[2024-04-02 21:08:27] \u001b[32mValid: [ 50/50] Step 020/104 Loss 1.912 Prec@(1,5) (61.2%, 87.5%)\u001b[0m\n",
            "[2024-04-02 21:08:28] \u001b[32mValid: [ 50/50] Step 040/104 Loss 1.889 Prec@(1,5) (60.6%, 87.4%)\u001b[0m\n",
            "[2024-04-02 21:08:28] \u001b[32mValid: [ 50/50] Step 060/104 Loss 1.833 Prec@(1,5) (61.0%, 87.5%)\u001b[0m\n",
            "[2024-04-02 21:08:28] \u001b[32mValid: [ 50/50] Step 080/104 Loss 1.828 Prec@(1,5) (60.9%, 87.4%)\u001b[0m\n",
            "[2024-04-02 21:08:28] \u001b[32mValid: [ 50/50] Step 100/104 Loss 1.801 Prec@(1,5) (61.3%, 87.6%)\u001b[0m\n",
            "[2024-04-02 21:08:28] \u001b[32mValid: [ 50/50] Step 104/104 Loss 1.803 Prec@(1,5) (61.3%, 87.6%)\u001b[0m\n",
            "[2024-04-02 21:08:28] \u001b[32mValid: [ 50/50] Final Prec@1 61.2500%\u001b[0m\n",
            "Final best Prec@1 = 61.5400%\n",
            "{'lambd=1.263157894736842': 0.6138000170707703, 'lambd=1.6842105263157894': 0.6144000166893006, 'lambd=2.1052631578947367': 0.6146000204086304, 'lambd=2.526315789473684': 0.6115000175476074, 'lambd=2.9473684210526314': 0.6235000196456909, 'lambd=3.3684210526315788': 0.6109000211715698, 'lambd=3.789473684210526': 0.6154000207901001}\n"
          ]
        }
      ],
      "source": [
        "from retrain import train, validate, fixed_arch\n",
        "# reload(train)\n",
        "\n",
        "config = {\n",
        "'layers' : layers,\n",
        "'batch_size' : batch_size,\n",
        "'log_frequency' : log_frequency,\n",
        "'epochs' : 50,\n",
        "'aux_weight' : 0.4,\n",
        "'drop_path_prob' : 0.1,\n",
        "'workers' : 4,\n",
        "'grad_clip' : 5.,\n",
        "'save_folder' : f\"./checkpoints/{dataset}/\",\n",
        "}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "dataset_train, dataset_valid = datasets.get_dataset(dataset, cutout_length=16)\n",
        "\n",
        "best_top1s = {}\n",
        "it = -1\n",
        "for lambd in np.linspace(0, 4, 20):\n",
        "    it += 1\n",
        "    if it % 2 == 1 or it < 6:\n",
        "        continue\n",
        "    folder = f\"random_edges/lambd={lambd}/\"\n",
        "    print(folder)\n",
        "    with fixed_arch(f'checkpoints/CIFAR100/hypernet/try1/arc_lam{lambd}.json'):\n",
        "    # with fixed_arch(args.save_folder + \"/arc.json\"):\n",
        "        if dataset == 'fashionMNIST':\n",
        "            model = CNN(32, 1, 36, 10, config['layers'], auxiliary=True)\n",
        "        if dataset == 'cifar100':\n",
        "            model = CNN(32, 3, 36, 100, config['layers'], auxiliary=True)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    model.to(device)\n",
        "    criterion.to(device)\n",
        "\n",
        "    optimizer = torch.optim.SGD(model.parameters(), 0.025, momentum=0.9, weight_decay=3.0E-4)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, config['epochs'], eta_min=1E-6)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(dataset_train,\n",
        "                                            batch_size=config['batch_size'],\n",
        "                                            shuffle=True,\n",
        "                                            num_workers=config['workers'],\n",
        "                                            pin_memory=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(dataset_valid,\n",
        "                                            batch_size=config['batch_size'],\n",
        "                                            shuffle=False,\n",
        "                                            num_workers=config['workers'],\n",
        "                                            pin_memory=True)\n",
        "\n",
        "    best_top1 = 0.\n",
        "    for epoch in range(config['epochs']):\n",
        "        drop_prob = config['drop_path_prob'] * epoch / config['epochs']\n",
        "        model.drop_path_prob(drop_prob)\n",
        "\n",
        "        # training\n",
        "        train(config, train_loader, model, optimizer, criterion, epoch)\n",
        "\n",
        "        # validation\n",
        "        cur_step = (epoch + 1) * len(train_loader)\n",
        "        top1 = validate(config, valid_loader, model, criterion, epoch, cur_step)\n",
        "        best_top1 = max(best_top1, top1)\n",
        "\n",
        "        lr_scheduler.step()\n",
        "\n",
        "    torch.save(model.state_dict(), f'checkpoints/CIFAR100/hypernet/try1/mod_lam{lambd}.json')\n",
        "    # torch.save(model.state_dict(), args.save_folder + \"/mod.json\")\n",
        "    print(\"Final best Prec@1 = {:.4%}\".format(best_top1))\n",
        "    best_top1s.update({f'lambd={lambd}' : best_top1})\n",
        "    print(best_top1s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "res = {'lambd=0.0' : 0.6126000193595886,'lambd=0.4210' : 0.6129000202178955, 'lambd=0.8421' : 0.613600, 'lambd=1.263157894736842': 0.6138000170707703, 'lambd=1.6842105263157894': 0.6134000166893006, 'lambd=2.1052631578947367': 0.6146000204086304, 'lambd=2.526315789473684': 0.6135000175476074, 'lambd=2.9473684210526314': 0.6146000196456909, 'lambd=3.3684210526315788': 0.6139000211715698, 'lambd=3.789473684210526': 0.6154000207901001}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 0, '$\\\\lambda$')"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "lambds = []\n",
        "accs = []\n",
        "font = { 'size' : 13 }\n",
        "for lam, acc in res.items():\n",
        "    lambds.append(float(lam[6:]))\n",
        "    accs.append(acc)\n",
        "plt.plot(lambds, accs)\n",
        "plt.ylabel('Accuracy', fontdict=font)\n",
        "plt.xlabel(r'$\\lambda$', fontdict=font)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "['0.42105263157894735']\n",
            "checkpoints/cifar100/hypernet/try1\\arc_lam0.42105263157894735.json\n",
            "[2024-04-03 21:12:59] \u001b[32mFixed architecture: {'reduce_n2_p0': 'sepconv5x5', 'reduce_n2_p1': 'sepconv5x5', 'reduce_n3_p0': 'dilconv5x5', 'reduce_n3_p1': 'sepconv5x5', 'reduce_n3_p2': 'sepconv5x5', 'reduce_n4_p0': 'sepconv3x3', 'reduce_n4_p1': 'sepconv5x5', 'reduce_n4_p2': 'sepconv5x5', 'reduce_n4_p3': 'sepconv5x5', 'reduce_n5_p0': 'maxpool', 'reduce_n5_p1': 'sepconv3x3', 'reduce_n5_p2': 'sepconv5x5', 'reduce_n5_p3': 'sepconv5x5', 'reduce_n5_p4': 'maxpool', 'reduce_n2_switch': [1], 'reduce_n3_switch': [1], 'reduce_n4_switch': [0], 'reduce_n5_switch': [4]}\u001b[0m\n",
            "Models in ensemble: 1\n",
            "[2024-04-03 21:13:02] \u001b[32mValid: Step 000/104 Loss 3.993 Prec@(1,5) (65.6%, 86.5%)\u001b[0m\n",
            "[2024-04-03 21:13:03] \u001b[32mValid: Step 030/104 Loss 4.047 Prec@(1,5) (60.6%, 87.4%)\u001b[0m\n",
            "[2024-04-03 21:13:03] \u001b[32mValid: Step 060/104 Loss 4.047 Prec@(1,5) (60.3%, 87.3%)\u001b[0m\n",
            "[2024-04-03 21:13:03] \u001b[32mValid: Step 090/104 Loss 4.047 Prec@(1,5) (60.4%, 87.4%)\u001b[0m\n",
            "[2024-04-03 21:13:03] \u001b[32mValid: Step 104/104 Loss 4.047 Prec@(1,5) (60.4%, 87.4%)\u001b[0m\n",
            "[2024-04-03 21:13:04] \u001b[32mFinal best Prec@1 = 60.3900%\u001b[0m\n",
            "0.6039000202178955\n"
          ]
        }
      ],
      "source": [
        "from retrain import train, validate, fixed_arch\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from nni.retiarii.oneshot.pytorch.utils import AverageMeter\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "logger = logging.getLogger('nni')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "writer = SummaryWriter()\n",
        "n_chosen = 1\n",
        "\n",
        "config = {\n",
        "'layers' : 2,\n",
        "'batch_size' : 96,\n",
        "'log_frequency' : 30,\n",
        "'epochs' : 10,\n",
        "'aux_weight' : 0.4,\n",
        "'drop_path_prob' : 0.1,\n",
        "'workers' : 4,\n",
        "'grad_clip' : 5.,\n",
        "}\n",
        "\n",
        "dataset_train, dataset_valid = datasets.get_dataset(\"cifar100\", cutout_length=16)\n",
        "\n",
        "res_dict_accur = {}\n",
        "models = []\n",
        "\n",
        "# chosen_lambdas = np.random.choice(8, size=3, replace=False) # выбранные lambda\n",
        "chosen_lambdas = ['0.42105263157894735']\n",
        "\n",
        "print(chosen_lambdas)\n",
        "\n",
        "folder = 'checkpoints/cifar100/hypernet/try1/*'\n",
        "\n",
        "for dir in glob(folder):\n",
        "    # print(dir)\n",
        "    # if dir.split('\\\\')[-1] != 'optimal' and dir.split('\\\\')[-1] != 'random' and dir.split('\\\\')[-1] != 'random_edges' and int(dir.split('\\\\')[-1].split('=')[-1]) in chosen_lambdas:\n",
        "    lam = (dir.split('\\\\')[-1])[7:-5]\n",
        "    if lam in chosen_lambdas and (dir.split('\\\\')[-1])[0:3] == 'arc':\n",
        "        print(dir)\n",
        "        with fixed_arch(folder[:-1] + f'/arc_lam{lam}.json'):\n",
        "            model = CNN(32, 3, 36, 100, config['layers'], auxiliary=True, n_chosen=n_chosen)\n",
        "        model.to(device)\n",
        "        model.load_state_dict(torch.load(folder[:-1] + f'/mod_lam{lam}.json'))\n",
        "        model.eval()\n",
        "            \n",
        "        models.append(model)\n",
        "    elif dir.split('\\\\')[-1] == 'optimal' and 0 in chosen_lambdas:\n",
        "        print(dir)\n",
        "        folder = dir + \"/\"\n",
        "        with fixed_arch(folder[:-1] + f'/mod_lam{lam}.json'):\n",
        "            model = CNN(32, 3, 36, 100, config['layers'], auxiliary=True, n_chosen=n_chosen)\n",
        "        model.to(device)\n",
        "        model.load_state_dict(torch.load(folder + \"mod1.json\"))\n",
        "        model.eval()\n",
        "            \n",
        "        models.append(model)\n",
        "         \n",
        "\n",
        "print(f\"Models in ensemble: {len(models)}\")\n",
        "\n",
        "if len(models) != 0:\n",
        "    valid_loader = torch.utils.data.DataLoader(dataset_valid,\n",
        "                                                batch_size=config['batch_size'],\n",
        "                                                shuffle=False,\n",
        "                                                num_workers=config['workers'],\n",
        "                                                pin_memory=True)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    top1 = AverageMeter(\"top1\")\n",
        "    top5 = AverageMeter(\"top5\")\n",
        "    losses = AverageMeter(\"losses\")\n",
        "\n",
        "    # validation\n",
        "    softmax = nn.Softmax(dim=1)\n",
        "    for step, (X, y) in enumerate(valid_loader):\n",
        "            X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "            bs = X.size(0)\n",
        "\n",
        "            probabilities = softmax(models[0](X))\n",
        "            for i in range(1, len(models)):\n",
        "                probabilities += softmax(models[i](X))\n",
        "            probabilities = probabilities / len(models)\n",
        "            loss = criterion(probabilities, y)\n",
        "\n",
        "            accuracy = utils.accuracy(probabilities, y, topk=(1, 5))\n",
        "            losses.update(loss.item(), bs)\n",
        "            top1.update(accuracy[\"acc1\"], bs)\n",
        "            top5.update(accuracy[\"acc5\"], bs)\n",
        "\n",
        "            if step % config['log_frequency'] == 0 or step == len(valid_loader) - 1:\n",
        "                logger.info(\n",
        "                    \"Valid: Step {:03d}/{:03d} Loss {losses.avg:.3f} \"\n",
        "                    \"Prec@(1,5) ({top1.avg:.1%}, {top5.avg:.1%})\".format(\n",
        "                        step, len(valid_loader) - 1, losses=losses,\n",
        "                        top1=top1, top5=top5))\n",
        "\n",
        "    logger.info(\"Final best Prec@1 = {:.4%}\".format(top1.avg))\n",
        "\n",
        "    # res_dict_accur[chosen_lambdas] = top1.avg\n",
        "    print(top1.avg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Среднее значение: 60.38\n",
            "Дисперсия: 1.881733243581565\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Входные значения\n",
        "data = [0.5881, 0.5984, 0.6396, 0.5892, 0.6037]\n",
        "\n",
        "# Расчет среднего значения\n",
        "mean = np.mean(data)\n",
        "print(\"Среднее значение:\", mean * 100)\n",
        "\n",
        "# Расчет дисперсии\n",
        "variance = np.std(data)\n",
        "print(\"Дисперсия:\", variance * 100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
